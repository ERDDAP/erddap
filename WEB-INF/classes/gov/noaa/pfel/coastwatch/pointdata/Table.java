/* 
 * Table Copyright 2005, NOAA.
 * See the LICENSE.txt file in this file's directory.
 */
package gov.noaa.pfel.coastwatch.pointdata;

import com.cohort.array.*;
import com.cohort.util.*;

import gov.noaa.pfel.coastwatch.griddata.DataHelper;
import gov.noaa.pfel.coastwatch.griddata.FileNameUtility;
import gov.noaa.pfel.coastwatch.griddata.Matlab;
import gov.noaa.pfel.coastwatch.griddata.NcHelper;
import gov.noaa.pfel.coastwatch.griddata.OpendapHelper;
import gov.noaa.pfel.coastwatch.util.DataStream;
import gov.noaa.pfel.coastwatch.util.HtmlWidgets;
import gov.noaa.pfel.coastwatch.util.RegexFilenameFilter;
import gov.noaa.pfel.coastwatch.util.SimpleXMLReader;
import gov.noaa.pfel.coastwatch.util.SSR;
import gov.noaa.pfel.coastwatch.util.Tally;

import java.io.BufferedInputStream;
import java.io.BufferedOutputStream;
import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.ByteArrayOutputStream;
import java.io.DataInputStream;
import java.io.DataOutputStream;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.InputStreamReader;
import java.io.InputStream;
import java.io.IOException;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import java.io.Reader;
import java.io.StringReader;
import java.io.StringWriter;
import java.io.Writer;
import java.math.BigInteger;
import java.net.URL;
import java.sql.BatchUpdateException;
import java.sql.Connection;
import java.sql.DatabaseMetaData;
import java.sql.Date;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.ResultSetMetaData;
import java.sql.Savepoint;
import java.sql.Statement;
import java.sql.Time;
import java.sql.Timestamp;
import java.sql.Types;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.BitSet;
import java.util.Calendar;
import java.util.Enumeration;
import java.util.Formatter;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.GregorianCalendar;
import java.util.Map;
import java.util.Set;
import java.util.TimeZone;
import java.util.Vector;
import java.util.regex.Pattern;
import java.util.regex.Matcher;
import javax.sound.sampled.AudioFileFormat;
import javax.sound.sampled.AudioFormat;
import javax.sound.sampled.AudioInputStream;
import javax.sound.sampled.AudioSystem;

import org.json.JSONArray;
import org.json.JSONObject;
import org.json.JSONTokener;

/*import javax.xml.xpath.XPath;   //requires java 1.5
import org.w3c.dom.Document;
import org.w3c.dom.Element;
import org.w3c.dom.NamedNodeMap;
import org.w3c.dom.Node;
import org.w3c.dom.NodeList;
*/
import org.xml.sax.XMLReader;
//import org.xml.sax.Attributes;
import org.xml.sax.InputSource;
import org.xml.sax.helpers.XMLReaderFactory;
//import org.xml.sax.helpers.DefaultHandler;

/**
 * Get netcdfAll-......jar from ftp://ftp.unidata.ucar.edu/pub
 * and copy it to [tomcat]/webapps/erddap/WEB-INF/lib renamed as netcdf-latest.jar.
 * Put it in the classpath for the compiler and for Java.
 */
import ucar.nc2.*;
import ucar.nc2.constants.FeatureType;
import ucar.nc2.dataset.NetcdfDataset;
import ucar.nc2.ft.FeatureDataset;
import ucar.nc2.ft.point.standard.PointDatasetStandardFactory;
//import ucar.nc2.dods.*;
import ucar.nc2.util.*;
import ucar.ma2.*;

/** The Java DAP classes.  */
import dods.dap.*;

/**
 * This class holds tabular data as 
 *   <ul>
 *   <li>globalAttributes (a list of (String)name=(PrimitiveArray)value)
 *   <li>columnAttributes - an ArrayList of Attributes, one for each column
 *      (each is a list of (String)name=(PrimitiveArray)value).
 *   <li>columnNames - a StringArray
 *   <li>the columns of data - an ArrayList of PrimitiveArray
 *   </ul>
 * This class is used by CWBrowser as a way to read tabular data from 
 * ASCII and .nc files and Opendap, store the data in a standard 
 * in-memory format, and write the data to several types of files 
 * (ASCII, MatLab, .nc, ...).
 * Since there is often a lot of data, these objects are usually short-lived.
 *
 * @author Bob Simons (bob.simons@noaa.gov) 2005-12-05
 */
public class Table  {

    public static interface Rounder{
        double round(Double value) throws Exception;
    }

    private static interface WithColumnNames{
        void apply(String[] columnNames) throws Exception;
    }

    /**
     * Set this to true (by calling verbose=true in your program, not by changing the code here)
     * if you want lots of diagnostic messages sent to String2.log.
     */
    public static boolean verbose = false;

    /**
     * Set this to true (by calling reallyVerbose=true in your program, 
     * not by changing the code here)
     * if you want lots of diagnostic messages sent to String2.log.
     */
    public static boolean reallyVerbose = false; 

    /**
     * Set this to true (by calling debugMode=true in your program, not by changing the code here)
     * if you want lots and lots of diagnostic messages sent to String2.log.
     */
    public static boolean debugMode = false;    

    /**
     * If true, readASCII allows data lines to have varying numbers of 
     * values and assumes that the missing values are from the end columns.
     */
    public boolean allowRaggedRightInReadASCII = false;

    /**
     * If true, readOpendap requestes compressed data. 
     * I think this should always be true.
     */
    public boolean opendapAcceptDeflate = true;

    /** Since users use these numbers (not names) from the command line,
     * the value for a given option shouldn't ever change.
     */
    public final static int READ_ASCII = 0, READ_FLAT_NC = 1, READ_OPENDAP_SEQUENCE = 2, READ_4D_NC = 3;

    //the values here won't change as new file types are supported
    public static final int SAVE_AS_TABBED_ASCII = 0;
    public static final int SAVE_AS_FLAT_NC = 1;
    public static final int SAVE_AS_4D_NC = 2;
    public static final int SAVE_AS_MATLAB = 3;
    //public static final int SAVE_AS_HDF = 4;
    public static final String SAVE_AS_EXTENSIONS[] = {
        ".asc", ".nc", ".nc", ".mat"};

    public static String BGCOLOR = "#ffffcc"; 

    //this will only change if changes are made that aren't backwards and forwards compatible
    public final static int ENHANCED_VERSION = 4; 

    //related to ERDDAP
    /** 
     * This is a list of all operator symbols 
     * (for my convenience in Table.parseDapQuery and EDDTable.parseUserDapQuery): 
     * 2 letter ops are first). 
     * Note that all variables (numeric or String)
     * can be constrained via a ERDDAP constraint using any of these
     * operators.
     * If the source can't support the operator (e.g., 
     *    no source supports numeric =~ testing,
     *    and no source supports string &lt; &lt;= &gt; &gt;= testing),
     * ERDDAP will just get all the relevant data and do the test itself. 
     */
    public final static String OPERATORS[] = 
        //EDDTableFromFiles.isOK relies on this order
        {"!=", PrimitiveArray.REGEX_OP, "<=", ">=",   
         "=", "<", ">"}; 
    public final static String SEQUENCE_NAME = "s"; 
    public static String QUERY_ERROR = "Query error: ";

    //EDStatic replaces this with queryErrorOrderByClosest from messages.xml 
    public static String ORDER_BY_CLOSEST_ERROR = 
        "For orderByClosest, you must specify a CSV list of 1 or more orderBy column names " +
        "(each of which must be in the list of results variables) plus the interval " +
        "for the last orderBy variable (e.g., \"stationID,time,10 minutes\").";

    //EDStatic replaces this with queryErrorOrderByLimit from messages.xml 
    public static String ORDER_BY_LIMIT_ERROR = 
        "For orderByLimit, you must specify a CSV list of 0 or more orderBy column names " +
        "(each of which must be in the list of results variables; " +
        "numeric columns may have columnName[/divisor[timeUnits][:offset]]) plus the " +
        "maximum number of rows for each group (e.g., \"stationID,time/1day,10\").";

    //EDStatic replaces this with queryErrorOrderByMean from messages.xml 
    public static String ORDER_BY_MEAN_ERROR = 
        "For orderByMean, you must specify a CSV list of orderBy column names " +
        "(each of which must be in the list of results variables; " +
        "numeric columns may have columnName[/divisor[timeUnits][:offset]]), " +
        "e.g., \"stationID,time/10minutes\".";

    public static String NOT_FOUND_EOF = " not found before end-of-file.";
    public static String ELAPSED_TIME = "elapsedTime"; 
    public static String WARNING_BAD_LINE_OF_DATA_IN = String2.WARNING + ": Bad line(s) of data in "; 

    /** 
     * Igor Text File File reference: in Bob's /programs/igor/ or 
     *   https://www.wavemetrics.net/doc/igorman/II-09%20Data%20Import%20Export.pdf
     * <br>Command reference: in Bob's /programs/igor/ or 
     *   https://www.wavemetrics.net/doc/igorman/V-01%20Reference.pdf
     */
    public final static String IgorCharset = String2.ISO_8859_1; //they are vague, but it is 1-byte, not UTF variant
    public final static String IgorNanString = "NaN"; //Igor Text File Format: use "NaN"
    public final static String IgorEndOfLine = "\r";  //Igor Text File Format: "a carriage return at the end of the line"
    //Igor Text File Format: "use the standard Igor date format (number of seconds since 1/1/1904)"
    public final static double IgorBaseSeconds = -2.0828448E9; 
    public final static double IgorFactorToGetSeconds = 1;    
    /**
     * Igor reserved names are selected names from "Built-In Operations by Category"
     * from https://www.wavemetrics.net/doc/igorman/IgorMan.pdf
     */
    public final static String[] IgorReservedNamesSA = { //sorted for simplicity (not required)
        "abs", "acos", "AddLitItem", "airyA", "airyAD", "airyB", "alog", 
        "AnnotationInfo", "AnnotationList", 
        "area", "asin", "Append", "areaXY", "atan", "AxisInfo", "AxisList",
        "BackgroundInfo", "Besseli", "Besselj", "Besselk", "Bessely", 
        "bessI", "bessJ", "bessK", "bessY", 
        "beta", "betai", "binomial", "BoundingBall", "break", "BrowseURL", 
        "cabs", "CaptureHistory", "catch", "cd", "ceil", "cequal", "Chart", "char2num", 
        "CheckBox", "CheckName", "CleanupName", 
        "cmplx", "cmpstr",
        "ColorScale", "Concatenate", "conj", "Constant", "continue", 
        "ContourInfo", "ContourZ", "ControlBar", 
        "ConvexHull", "Convolve", 
        "Correlate", "CountObjects", "cos", "cot", "coth", "cpowi", 
        "CreationDate", "Cross", "csc", "CsrInfo", 
        "CsrWave", "CsrWaveRef", "CTabList", "Cursor", "CurveFit", "CWT",
        "DataFolderDir", "DataFolderExists", "date", "date2secs", "date2Julian", 
        "DateTime", "dawson", "default", "DefaultFont", 
        "deltax", "DFREF", "Differentiate", "digamma", "dimDelta", "DimOffset", "DimSize", 
        "Dir", "Display", "Duplicate", "DWT",
        "e", "EdgeStats", "Edit", "ei", "End", "EndMacro", "enoise", "erf", "erfc", "erfcw", 
        "exists", "exp", "ExperimentModified", "expInt", "expnoise", "Extract",
        "factorial", "FakeData", "FastGaussTransform", "faverage", 
        "FFT", "FilterIIR", "FindLevel", "FindListItem", "FindValue", "FitFunc", "floor", 
        "FontList", "FStatus", "FTPDownload", "FTPUpload", "FUNCREF", "FuncRefInfo", 
        "Function", "FunctionInfo", "FunctionList", "FunctionPath", 
        "gamma", "gammaInc", "gammaln", "gammaNoise", "gammp", "gammq", 
        "Gauss", "Gauss2D", "gcd", "gnoise", "Graph", "GraphMarquee", "GraphStyle", 
        "GridStyle", "GuideInfo", 
        "Hanning", "Hash", "hcsr", "hermite", "hide", "HilbertTransform", "Histogram",         
        "i", "IFFT", "ilim", "imag", "ImageFilter", 
        "ImageHistogram", "ImageInfo", "ImageNameList", 
        "ImageRotate", "ImageSave", "ImageStats", 
        "ImageThreshold", "ImageTransform", "ImageWindow", 
        "IndexedDir", "IndexedFile", "IndexSort", "Inf", "InsertPoints", "Integrate", 
        "IntegrateID", "interp", "Interp2D", "Interp3D", "inverseErf", "inverseErfc",
        "ItemsInList", 
        "j", "jlim", "JulianToDate", 
        "Label", "laguerre", "Layout", "LayoutInfo", "Legend", "limit", "ListMatch", 
        "ln", "LoadData", "Loess", "log", "LowerStr",
        "Macro", "magsqr", "Make", "MakeIndex", "MatrixDet", "MatrixDot", "MatrixFilter", 
        "MatrixRank", "MatrixTrace", 
        "max", "mean", "Menu", "min", "mod", "modDate", "Modify", "ModuleName", 
        "norm", "note", "Note", "Notebook", "num2char", "num2str", "numpnts", "numtype", "NVAR",
        "Open", "OperationList", "Optimize", "Override", 
        "p", "p2rect", "PadString", "Panel", "ParamIsDefault", 
        "PathInfo", "PathList", "PCA", "pcsr", "Pi", "PICTList", "Picture", "PlaySound", 
        "pnt2x", "Point", "poly", "poly2D", "PolygonArea", "popup", 
        "Preferences", "Print", "Proc", "ProcGlobal", "ProcedureText", "Project", "Prompt", 
        "PulseStats", "pwd",
        "q", "qcsr", "Quit", 
        "r", "r2polar", "real", "Rect", "Redimension", "Remove", "Rename", "Resample", "return", 
        "Reverse", "RGBColor", "rightx", "root", "Rotate", "round", "rtGlobals", 
        "s", "Save", "SaveData", "ScreenResolution", "sec", "Secs2Date", "Secs2Time", 
        "SelectNumber", "SelectString", "SetAxis", 
        "SetBackground", "SetDimLabel", "SetDrawLayer", 
        "SetRandomSeed", "SetScale", "sign", "sin", "sinc", "sinh", 
        "Sleep", "Slow", "Smooth", "Sort", "SortList", 
        "SpecialDirPath", "SplitString", "sqrt", 
        "Stack", "startMSTimer", "Static", "stopMSTimer", "str2num",  
        "Strconstant", "String", "StringByKey", 
        "StringCRC", "StringFromList", "StringList", "StringMatch", 
        "strlen", "strsearch", "STRUCT", "Structure", "Submenu", "sum", "SVAR", 
        "t", "Table", "TableInfo", "TableStyle", "Tag", "TagVal", 
        "tan", "tanh", "TextBox", "TextFile", "ticks", 
        "Tile", "TileWindows", "time", "TraceInfo", "trunc", 
        "UniqueName", "Unwrap", "UpperStr", "URLDecode", "URLEncode", 
        "Variable", "VariableList", "Variance", "vcsr", "version", 
        "WAVE", "WaveCRC", "WaveDims", "WaveExists", "WaveMeanStdv", 
        "WaveMax", "WaveMin", "WaveName", 
        "WaveStats", "WaveTransform", "WaveType", "WaveUnits", 
        "WhichListItem", "Window", "WinName", "wnoise", 
        "x", "x2pnt", "xcsr", "y", "z", "zcsr"};
        
    public final static HashSet IgorReservedNames = new HashSet();
    static {
        for (String s : IgorReservedNamesSA)
            IgorReservedNames.add(String2.canonical(s));
    }

    /** A link to erddap2.css. 
     * HTML allows link or inline. XHTML only allows link (and no close link tag!). 
     * See
     * https://en.wikibooks.org/wiki/Cascading_Style_Sheets/Applying_CSS_to_HTML_and_XHTML
     */
    public static String ERD_TABLE_CSS =
        "<link href=\"https://coastwatch.pfeg.noaa.gov/erddap/images/erddap2.css\" rel=\"stylesheet\" type=\"text/css\">";

    //this is used to find out if all readNcCF code is tested: cc=code coverage
    //Bits are set to true when chunk of code is tested.
    public static BitSet ncCFcc = null;  //null=inactive, new BitSet() = active

    /** An arrayList to hold 0 or more PrimitiveArray's with data.  */
    private ArrayList<PrimitiveArray> columns = new ArrayList();  

    /** An arrayList to hold the column names. */
    private StringArray columnNames = new StringArray();


    /**
     * This holds the global attributes ((String)name = (PrimitiveArray)value).
     * Although a HashTable is more appropriate for name=value pairs,
     * this uses ArrayList to preserve the order of the attributes.
     * This may be null if not in use.
     */
    private Attributes globalAttributes = new Attributes();

    /**
     * This holds the column Attributes ((String)name = (PrimitiveArray)value)
     * in an arrayList.
     * Although a HashTable is more appropriate for name=value pairs,
     * this uses ArrayList to preserve the order of the attributes.
     * This may be null if not in use.
     */
    private ArrayList<Attributes> columnAttributes = new ArrayList();


    /** testDir is used for tests. */
    public static String testDir = 
        String2.getClassPath() + //with / separator and / at the end
        "gov/noaa/pfel/coastwatch/pointdata/";

    /** The one known valid url for readIobis. */
    public final static String IOBIS_URL = "http://www.iobis.org/OBISWEB/ObisControllerServlet"; 


    /**
     */
    public Table() {
    }

    /**
     * A constructor that uses tGlobalAttributes as the global attributes (directly, not a clone).
     */
    public Table(Attributes tGlobalAttributes) {
        globalAttributes = tGlobalAttributes;
    }

    /** 
     * Makes a table with the specified columnNames and dataTypes.
     *
     * @param dataType if dataType == null, the table will have all String columns
     *   Otherwise, it should be the same length as colName
     * @return a new table
     */
    public static Table makeEmptyTable(String colName[], String dataType[]) {
        Table table = new Table();
        int n = colName.length;
        for (int i = 0; i < n; i++) {
            table.addColumn(colName[i], 
                PrimitiveArray.factory(
                    PAType.fromCohortString(dataType == null? "String" : dataType[i]), 
                    8, false));
        }
        return table;
    }


    /**
     * This clears everything.
     */
    public void clear() {
        columns.clear();  
        columnNames.clear(); 

        globalAttributes.clear();
        columnAttributes.clear();
    }

    /** 
     * This reads and ignores lines until it finds a line that matches skipHeaderToRegex.
     *
     * @param skipHeaderToRegex the regex to be matched (or null or "" if nothing to be done)
     * @param sourceName for an error message. Usually the name of the file.
     * @param linesReader the bufferedReader that is the data source
     * @return the number of lines read (0 if skipHeaderToRegex is null).
     * @throws Exception if trouble
     */
    public static int skipHeaderToRegex(String skipHeaderToRegex, String sourceName, 
        BufferedReader linesReader) throws IOException {
        int linesRead = 0;
        if (skipHeaderToRegex != null && !skipHeaderToRegex.equals("")) {
            Pattern shtp = Pattern.compile(skipHeaderToRegex);
            while (true) {
                String s = linesReader.readLine(); //null if end. exception if trouble
                linesRead++;
                if (s == null)
                    throw new SimpleException(MustBe.THERE_IS_NO_DATA + 
                        " (skipHeaderToRegex=" + String2.toJson(skipHeaderToRegex) + 
                        " not found in " + 
                        (String2.isSomething(sourceName)? sourceName : "[unknown]") + 
                        ")");
                if (shtp.matcher(s).matches())
                    break;             
            }
        }
        return linesRead;
    }

    /**
     * This converts the specified column from epochSeconds doubles to ISO 8601 Strings.
     *
     * @param timeIndex
     */
    public void convertEpochSecondsColumnToIso8601(int timeIndex) {
        int tnRows = nRows();
        PrimitiveArray pa = getColumn(timeIndex);
        StringArray sa = new StringArray(tnRows, false);
        for (int row = 0; row < tnRows; row++) 
            sa.add(Calendar2.safeEpochSecondsToIsoStringTZ(pa.getDouble(row), ""));
        setColumn(timeIndex, sa);

        if (String2.isSomething(columnAttributes(timeIndex).getString("units"))) 
            columnAttributes(timeIndex).set("units", Calendar2.ISO8601TZ_FORMAT);
    }


    /**
     * This makes a deep clone of the current table (data and attributes).
     *
     * @param startRow
     * @param stride
     * @param endRow (inclusive)  e.g., nRows()-1 
     * @return a new Table.
     */
    public Table subset(int startRow, int stride, int endRow) {
        Table tTable = new Table();

        int n = columns.size();
        for (int i = 0; i < n; i++)
            tTable.columns.add(columns.get(i).subset(startRow, stride, endRow));

        tTable.columnNames = (StringArray)columnNames.clone();

        tTable.globalAttributes = (Attributes)globalAttributes.clone(); 

        for (int col = 0; col < columnAttributes.size(); col++) 
            tTable.columnAttributes.add((Attributes)columnAttributes.get(col).clone()); 

        return tTable;
    }

    /**
     * This makes a deep clone of the entire current table (data and attributes).
     *
     * @return a new Table.
     */
    public Object clone() {
        return subset(0, 1, nRows() - 1);
    }

    /**
     * This returns the current number of columns.
     *
     * @return the current number of columns
     */
    public int nColumns() {
        return columns.size();
    }

    /**
     * This returns the PrimitiveArray for a specific column.
     *
     * @param col (0..)
     * @return the corresponding PrimitiveArray
     * @throws Exception if col is invalid
     */
    public PrimitiveArray getColumn(int col) {
        if (col < 0 || col >= columns.size())
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.getColumn: col=" + col + " must be 0 ... " + (columns.size()-1) + "."); 
        return columns.get(col);
    }

    /**
     * This returns the PrimitiveArray for a specific column.
     *
     * @param columnName
     * @return the corresponding PrimitiveArray
     * @throws IllegalArgumentException if columnName is invalid
     */
    public PrimitiveArray getColumn(String columnName) {
        int col = findColumnNumber(columnName);
        if (col < 0)
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.getColumn: columnName=" + columnName + " not found."); 
        return columns.get(col);
    }

    /**
     * This sets the PrimitiveArray for a specific column.
     *
     * @param col (0.. size-1)
     * @param pa the corresponding PrimitiveArray
     * @throws Exception if col is invalid
     */
    public void setColumn(int col, PrimitiveArray pa) {
        if (col >= columns.size())
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.setColumn: col (" + col + ") is >= size (" + columns.size() + ")."); 
        if (pa == null)
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.setColumn(col=" + col + ", pa): pa is null."); 
        columns.set(col, pa);
    }

    /**
     * This returns the PrimitiveArrays for all of the columns.
     *
     * @return the PrimitiveArray[]
     * @throws Exception if col is invalid
     */
    public PrimitiveArray[] getColumns() {
        PrimitiveArray pa[] = new PrimitiveArray[columns.size()];
        for (int i = 0; i < columns.size(); i++)
            pa[i] = getColumn(i);
        return pa;
    }

    /**
     * This simplifies (changes the datatype to the simplest possible type)
     * a column.
     *
     * @param col the column to be simplified, 0...
     */
    public void simplify(int col) {
        columns.set(col, getColumn(col).simplify(getColumnName(col)));
    }

    /**
     * This simplifies (changes the datatype to the simplest possible type)
     * all columns.
     *
     */
    public void simplify() {
        int nColumns = columns.size();
        for (int col = 0; col < nColumns; col++) 
            simplify(col);
    }

    /**
     * This converts columns with _Unsigned=true attributes to be unsigned PA's (e.g., UByteArray).
     * In any case, the _Unsigned attribute is removed.
     */
    public void convertToUnsignedPAs() {
/* 2020-07-22 This is no longer needed because NcHelper calls attributes.convertSomeSignedToUnsigned() and removes _Unsigned att.

        String attsToCheck[] = {"_FillValue", "missing_value", "actual_range", "data_min", "data_max"};
        int nColumns = columns.size();
        for (int col = 0; col < nColumns; col++) {
            Attributes atts = columnAttributes(col);
            String unsigned = atts.getString("_Unsigned");
            atts.remove("_Unsigned");
            if ("true".equals(unsigned)) {
                PrimitiveArray pa = getColumn(col);
                PAType paType = pa.elementType();
                if (paType == PAType.BYTE ||
                    paType == PAType.SHORT ||
                    paType == PAType.INT ||
                    paType == PAType.LONG) {
                    setColumn(col, pa.makeUnsignedPA());
                    for (int i = 0; i < attsToCheck.length; i++) {
                        PrimitiveArray tAtt = atts.get(attsToCheck[i]);
                        if (tAtt != null && tAtt.elementType() == paType)
                            atts.set(attsToCheck[i], tAtt.makeUnsignedPA());
                    }
                }
            }
        }
*/
    }

    /**
     * This converts columns with unsigned PA's (e.g. UByteArray) to have _Unsigned=true attribute and signed PA's
     * (e.g., for right before storing in nc file).
     */
/*    public void convertToSignedPAs() {
        String attsToCheck[] = {"_FillValue", "missing_value", "actual_range", "data_min", "data_max"};
        int nColumns = columns.size();
        for (int col = 0; col < nColumns; col++) {
            PrimitiveArray pa = getColumn(col);
            if (pa.isUnsigned()) {
                PAType paType = pa.elementType();
                if (paType == PAType.UBYTE ||
                    paType == PAType.USHORT ||
                    paType == PAType.UINT ||
                    paType == PAType.ULONG) {
                    setColumn(col, pa.makeSignedPA());
                    Attributes atts = columnAttributes(col);
                    atts.set("_Unsigned", true);
                    for (int i = 0; i < attsToCheck.length; i++) {
                        PrimitiveArray tAtt = atts.get(attsToCheck[i]);
                        if (tAtt != null && tAtt.elementType() == paType)
                            atts.set(attsToCheck[i], tAtt.makeSignedPA());
                    }
                }
            }
        }
    }
*/

    /**
     * This runs StringArray.convertIsSomething2 (change all e.g., "N/A" to "") 
     * on the specified column, if it is a StringArray column.
     *
     */
    public int convertIsSomething2(int col) {
        PrimitiveArray pa = getColumn(col);
        if (pa.elementType() == PAType.STRING)
            return ((StringArray)pa).convertIsSomething2();
        return 0;
    }

    /**
     * This runs StringArray.convertIsSomething2 (change all e.g., "N/A" to "") 
     * on all StringArray columns.
     *
     */
    public void convertIsSomething2() {
        int nColumns = columns.size();
        for (int col = 0; col < nColumns; col++) 
            convertIsSomething2(col);
    }

    /**
     * This copies the values from one row to another already extant row 
     * (without affecting any other rows).
     *
     * @param from the 'from' row
     * @param to the 'to' row
     */
    public void copyRow(int from, int to) {
        PrimitiveArray.copyRow(columns, from, to);
    }

    /** 
     * This writes a row to a DataOutputStream.
     * @param row
     * @param dos
     */
    public void writeRowToDOS(int row, DataOutputStream dos) throws Exception {
        int nColumns = columns.size();
        for (int col = 0; col < nColumns; col++) 
            columns.get(col).writeDos(dos, row);
    }

    /** 
     * This reads/appends a row from a DataInputStream.
     * @param dis
     */
    public void readRowFromDIS(DataInputStream dis) throws Exception {
        int nColumns = columns.size();
        for (int col = 0; col < nColumns; col++) 
            columns.get(col).readDis(dis, 1); //read 1 value
    }

    /**
     * This returns an estimate of the number of bytes per row
     * (assuming 20 per String column, which is probably low).
     */
    public int estimatedBytesPerRow() {
        int sum = 0;
        for (int col = 0; col < columnAttributes.size(); col++) 
            sum += getColumn(col).elementSize();
        return sum;
    }


    /**
     * This inserts a column in the table.
     *
     * @param position  0..
     * @param name the name for the column
     *    If name is null, the name will be "Column<#>" (0..)
     * @param pa the data for the column.
     *    The data is not copied. 
     *    This primitiveArray will continue to be used to store the data. 
     *    This doesn't ensure that it has the correct size().
     * @param attributes the attributes (used directly, not a copy) for the column. 
     * @return the column's number
     */
    public int addColumn(int position, String name, PrimitiveArray pa, Attributes attributes) {
        if (pa == null)
            throw new SimpleException(String2.ERROR + " in Table.addColumn: pa is null.");
        if (attributes == null)
            throw new SimpleException(String2.ERROR + " in Table.addColumn: attributes is null.");
        int size = columns.size();
        if (position > size) 
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.addColumn: position (" + position + 
                ") is beyond size (" + size  + ").");
        if (name == null) 
            name = "Column" + position;
        columnNames.atInsert(position, name);
        columns.add(position, pa);
        columnAttributes.add(position, attributes);
        return columns.size() - 1;
    }

    /**
     * This inserts a column in the table.
     * The column's will initially have 0 attributes.
     *
     * @param position  0..
     * @param name the name for the column
     *    If name is null, the name will be "Column<#>" (0..)
     * @param pa the data for the column.
     *    The data is not copied. This primitiveArray will continue to be 
     *    used to store the data.
     * @return the column's number
     */
    public int addColumn(int position, String name, PrimitiveArray pa) {
        return addColumn(position, name, pa, new Attributes());
    }

    /**
     * This adds a column to the table and the end.
     * The column's will initially have 0 attributes.
     *
     * @param name the name for the column
     *    If name is null, the name will be "Column<#>" (0..)
     * @param pa the data for the column.
     *    The data is not copied. This primitiveArray will continue to be 
     *    used to store the data.
     * @return the column's number
     */
    public int addColumn(String name, PrimitiveArray pa) {
        return addColumn(columnNames.size(), name, pa);
    }

    /**
     * This removes a column (and any associated columnName and attributes).
     *
     * @param col (0..)
     * @throws Exception if col is invalid
     */
    public void removeColumn(int col) {
        columnNames.remove(col);
        columns.remove(col);
        columnAttributes.remove(col);
    }

    /**
     * This removes a column (and any associated columnName and attributes).
     *
     * @param columnName
     * @throws IllegalArgumentException if columnName is invalid
     */
    public void removeColumn(String columnName) {
        int col = findColumnNumber(columnName);
        if (col < 0)
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.removeColumn: columnName=" + columnName + " not found."); 
        removeColumn(col);
    }



    /**
     * This removes a range of columns (and any associated columnName and attributes).
     *
     * @param from (0..)
     * @param to   exclusive (0..)
     * @throws Exception if col is invalid
     */
    public void removeColumns(int from, int to) {
        for (int col = to - 1; col >= from; col--)
            removeColumn(col);
    }

    /**
     * This removes all columns.
     *
     */
    public void removeAllColumns() {
        removeColumns(0, nColumns());
    }

    /**
     * This moves a column.
     *
     * @param from
     * @param to
     * @throws Exception if 'from' or 'to' is not valid.
     */
    public void moveColumn(int from, int to) {
        if (from == to)
            return;
        addColumn(to, getColumnName(from), getColumn(from), columnAttributes(from));

        //the 'from' column may now be in a different position
        if (from > to) 
            from++;
        removeColumn(from);
    }

    /** 
     * This moves the columns into the desired order.
     * If a column in desiredOrder isn't in the table, it is ignored.
     * If a column in the table isn't in desiredOrder, it will be pushed to the right.
     * 
     * @param desiredOrder a list of column names
     * @param discardOthers if true, columns not in desiredOrder list will be removed
     * @return the number of desiredOrder columns that were found
     */
    public int reorderColumns(StringArray desiredOrder, boolean discardOthers) {
        int nFound = 0;
        int doSize = desiredOrder.size();
        for (int i = 0; i < desiredOrder.size(); i++) {
            int from = findColumnNumber(desiredOrder.get(i));
            if (from >= 0) 
                moveColumn(from, nFound++);
        }
        if (discardOthers && nFound < nColumns())
            removeColumns(nFound, nColumns());
        return nFound;
    }

    /**
     * This returns the columnName for a specific column.
     *
     * @param col (0..)
     * @return the corresponding column name (or "Column#<col>", where col is 0..).
     * @throws Exception if col not valid.
     */
    public String getColumnName(int col) {
        if (col < 0 || col >= nColumns())
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.getColumnName: nColumns=" + nColumns() + ". There is no col #" + col + ".");
        return columnNames.get(col);
    }

    /**
     * This returns a String[] with all of the column names.
     *
     * @return a String[] with all of the column names.
     */
    public String[] getColumnNames() {
        return columnNames.toArray();
    }

    /**
     * This returns the number of the column named columnName.
     *
     * @param columnName
     * @return the corresponding column number (or -1 if not found).
     */
    public int findColumnNumber(String columnName) {
        return columnNames.indexOf(columnName, 0);
    }

    /**
     * This returns the number of the column named columnName (case-insensitive).
     *
     * @param columnName
     * @return the corresponding column number (or -1 if not found).
     */
    public int findColumnNumberIgnoreCase(String columnName) {
        return columnNames.indexOfIgnoreCase(columnName);
    }

    /**
     * This returns the number of the first column with the specified attName=attValue.
     *
     * @param attName  e.g., cf_role       (case sensitive)
     * @param attValue e.g., timeseries_id (case insensitive)
     * @return the corresponding column number (or -1 if not found).
     */
    public int findColumnNumberWithAttributeValue(String attName, String attValue) {
        attValue = attValue.toLowerCase();
        int nCol = nColumns();
        for (int col = 0; col < nCol; col++) {
            if (attValue.equalsIgnoreCase(columnAttributes(col).getString(attName)))
                return col;
        }
        return -1;
    }

    /**
     * This returns the column named columnName.
     *
     * @param columnName
     * @return the corresponding column
     * @throws IllegalArgumentException if not found
     */
    public PrimitiveArray findColumn(String columnName) {
        int col = findColumnNumber(columnName);
        if (col < 0) 
            throw new IllegalArgumentException(String2.ERROR + " in Table.findColumn: columnName=" + 
                columnName + " not found.");
        return getColumn(col);
    }

    /**
     * This sets the columnName for a specific column.
     *
     * @param col (0..)
     * @param newName the new name for the column
     * @throws Exception if columnNames is null, or col not valid.
     */
    public void setColumnName(int col, String newName) {
        if (col < 0 || col >= nColumns())
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.setColumnName: col " + col + " is invalid.");
        columnNames.set(col, newName);
    }

    /**
     * This returns the columnName for a specific column
     * with internal spaces replaced with '_'s.
     *
     * @param col (0..)
     * @return the corresponding column name (or "Column_" + col, 
     *   or "" if col is invalid)
     */
    public String getColumnNameWithoutSpaces(int col) {
        return String2.replaceAll(getColumnName(col), " ", "_");
    }

    /**
     * Test of speed and memory efficiency of ucar.ma package.
     *
     */
    /*public static void testMA() {
        String2.log("testMA");
        Math2.incgc(200); //in a test
        Math2.incgc(200); //in a test
        int n = 10000000;
        int j;
        double d;

        //test ArrayInt.D1
        long oMemory = Math2.getUsingMemory();
        ArrayInt.D1 arrayInt = new ArrayInt.D1(n, false); //isUnsigned
        String2.log("ArrayInt.D1 bytes/int  = " + ((Math2.getUsingMemory() - oMemory) / (double)n));
        long time = System.currentTimeMillis();
        Index1D index = new Index1D(new int[]{n});
        for (int i = 0; i < n; i++)
            d = arrayInt.getDouble(index.set(i));
        String2.log("ArrayInt.D1 read time=" + (System.currentTimeMillis() - time) + "ms"); //157

        //test int[]
        oMemory = Math2.getUsingMemory();
        int iar[] = new int[n];
        String2.log("int[] bytes/int  = " + ((Math2.getUsingMemory() - oMemory) / (double)n));
        time = System.currentTimeMillis();
        for (int i = 0; i < n; i++)
            d = iar[i];
        String2.log("int[] read time=" + (System.currentTimeMillis() - time) + "ms"); //32

        //test int[] as object
        Object o = iar;
        time = System.currentTimeMillis();
        for (int i = 0; i < n; i++) 
            d = getDouble(o, i);
        String2.log("(int[])o read time=" + (System.currentTimeMillis() - time) + "ms"); //172

        //test Integer[]
        oMemory = Math2.getUsingMemory();
        Number nar[] = new Integer[n];
        String2.log("Integer[] bytes/int  = " + ((Math2.getUsingMemory() - oMemory) / (double)n));
        time = System.currentTimeMillis();
        for (int i = 0; i < n; i++)
            nar[i] = new Integer(i);
        String2.log("Integer[] create time=" + (System.currentTimeMillis() - time) + "ms"); //2271!
        time = System.currentTimeMillis();
        for (int i = 0; i < n; i++)
            d = nar[i].doubleValue();
        String2.log("Integer[] read time=" + (System.currentTimeMillis() - time) + "ms"); //110

        Math2.sleep(30000);

    } */

    /**
     * This returns the current number of rows.
     *
     * @return the current number of rows
     */
    public int nRows() {
        if (nColumns() == 0)
            return 0;
        return getColumn(0).size();
    }

    /**
     * This inserts a blank row.
     *
     * @param index 0..size
     * @throws Exception if trouble
     */
    public void insertBlankRow(int index) throws Exception {
        if (index < 0 || index > nRows())
            throw new Exception("index=" + index + " must be between 0 and " + nRows() + ".");
        int nCols = nColumns();
        for (int col = 0; col < nCols; col++) 
            columns.get(col).atInsertString(index, "");
    }

    /**
     * Moves rows 'first' through 'last' (inclusive)
     *   to 'destination', shifting intermediate values to fill the gap.
     *
     * @param first  the first to be move
     * @param last  (exclusive)
     * @param destination the destination, can't be in the range 'first+1..last-1'.
     */
    public void moveRows(int first, int last, int destination) {
        int nCols = nColumns();
        for (int col = 0; col < nCols; col++) 
            columns.get(col).move(first, last, destination);
    }

    /**
     * This removes 1 row.
     *
     * @param row 0 ... size-1. 
     * @throws Exception if trouble
     */
    public void removeRow(int row) {
        removeRows(row, row + 1);
    }

    /**
     * This removes a range of rows.
     * This does the best it can to not throw an exception 
     * (e.g., to help clean up a damaged table with columns with different numbers
     * of rows).
     *
     * @param from the first element to be removed, 0 ... size
     * @param to one after the last element to be removed, from ... size
     *    (or use Integer.MAX_VALUE to remove to the end).
     * @throws Exception if trouble
     */
    public void removeRows(int from, int to) {
        int nCols = nColumns();
        for (int col = 0; col < nCols; col++) {
            PrimitiveArray pa = columns.get(col);
            int nRows = pa.size();
            if (from < nRows)
                pa.removeRange(from, Math.min(nRows, to));
        }
    }

    /**
     * This removes all rows of data, but leaves the columns intact.
     *
     */
    public void removeAllRows() {
        int nCols = nColumns();
        for (int col = 0; col < nCols; col++) 
            columns.get(col).clear();
    }

    /**
     * This finds all rows of data that have data (not all 
     * ("missing_value", "_FillValue", or the PrimitiveArray's native MV).
     *
     * <p>CF 1.6 Discrete Sampling Geometry and Incomplete Multidimensional Arrays:
     * the spec doesn't say which attribute is to be used: missing_value or _FillValue.
     * It just says "missing value" (in the generic sense) repeatedly.           
     *
     * @return a BitSet with bit=true for each row that has data (not all missing-values).
     */
    public BitSet rowsWithData() {
        int tnRows = nRows();
        int tnCols = nColumns();
        BitSet keep = new BitSet(tnRows);  //all false
        int keepN = 0;
        for (int col = 0; col < tnCols; col++) {  
            //this is very similar to lastRowWithData
            PrimitiveArray pa = columns.get(col);
            PAType paType = pa.elementType();
            Attributes atts = columnAttributes(col); 
            if (paType == PAType.STRING) {
                String mv = atts.getString("missing_value"); //may be null
                String fv = atts.getString("_FillValue"); 
                if (mv == null) mv = "";
                if (fv == null) fv = "";
                for (int row = keep.nextClearBit(0); row < tnRows; row = keep.nextClearBit(row+1)) {
                    String t = pa.getString(row);
                    if (t != null && t.length() > 0 && !mv.equals(t) && !fv.equals(t)) {
                        keepN++;
                        keep.set(row);
                    }
                }
            } else if (paType == PAType.DOUBLE) {
                double mv = atts.getDouble("missing_value"); //may be NaN
                double fv = atts.getDouble("_FillValue"); 
                for (int row = keep.nextClearBit(0); row < tnRows; row = keep.nextClearBit(row+1)) {
                    double t = pa.getDouble(row);
                    if (Double.isFinite(t) &&            //think carefully
                        !Math2.almostEqual(9, t, mv) && //if mv=NaN, !M.ae will be true
                        !Math2.almostEqual(9, t, fv)) {
                        keepN++;
                        keep.set(row);
                    }
                }
            } else if (paType == PAType.FLOAT) {
                float mv = atts.getFloat("missing_value"); //may be NaN
                float fv = atts.getFloat("_FillValue"); 
                for (int row = keep.nextClearBit(0); row < tnRows; row = keep.nextClearBit(row+1)) {
                    float t = pa.getFloat(row);
                    if (Double.isFinite(t) &&            //think carefully
                        !Math2.almostEqual(5, t, mv) && //if mv=NaN, !M.ae will be true
                        !Math2.almostEqual(5, t, fv)) {
                        keepN++;
                        keep.set(row);
                    }
                }
            } else if (paType == PAType.ULONG) {
                BigInteger mv = atts.getULong("missing_value"); //may be null
                BigInteger fv = atts.getULong("_FillValue"); 
                for (int row = keep.nextClearBit(0); row < tnRows; row = keep.nextClearBit(row+1)) {
                    BigInteger t = pa.getULong(row);
                    if (t == null || t.equals(mv) || t.equals(fv)) { 
                    } else {
                        keepN++;
                        keep.set(row);
                    }
                }
            } else {
                long mv = atts.getLong("missing_value"); //may be Long.MAX_VALUE
                long fv = atts.getLong("_FillValue"); 
                for (int row = keep.nextClearBit(0); row < tnRows; row = keep.nextClearBit(row+1)) {
                    float t = pa.getLong(row);
                    if (t < Long.MAX_VALUE && t != mv && t != fv) { //trouble: for LongArray, this assumes maxIsMV
                        keepN++;
                        keep.set(row);
                    }
                }
            }
            //if (debugMode)
            //    String2.log("  rowsWithData after col#" + col + " keepN=" + keepN);
            if (keepN == tnRows)
                return keep;
        }
        return keep;
    } 

    /**
     * This removes all rows of data that have just missing_values
     * ("missing_value", "_FillValue", or the PrimitiveArray's native MV).
     *
     * <p>CF 1.6 Discrete Sampling Geometry and Incomplete Multidimensional Arrays:
     * the spec doesn't say which attribute is to be used: missing_value or _FillValue.
     * It just says "missing value" (in the generic sense) repeatedly.           
     *
     * @return the number of rows remaining
     */
    public int removeRowsWithoutData() {
        justKeep(rowsWithData());
        return nRows();
    }

    /**
     * This finds the last row with data in some column 
     * (not missing_value or _FillValue or the PrimitiveArray's native MV).
     *
     * <p>CF 1.6 Discrete Sampling Geometry and Incomplete Multidimensional Arrays:
     * the spec doesn't say which attribute is to be used: missing_value or _FillValue.
     * It just says "missing value" (in the generic sense) repeatedly.           
     *
     * @return the last row with data (perhaps -1)
     */
    public int lastRowWithData() {
        int tnRows = nRows();
        int tnCols = nColumns();
        int lastRowWithData = -1;
        for (int col = 0; col < tnCols; col++) {  
            //this is very similar to rowsWithData
            PrimitiveArray pa = columns.get(col);
            PAType paType = pa.elementType();
            Attributes atts = columnAttributes(col); 
            if (paType == PAType.STRING) {
                String mv = atts.getString("missing_value"); //may be null
                String fv = atts.getString("_FillValue"); 
                if (mv == null) mv = "";
                if (fv == null) fv = "";
                for (int row = tnRows - 1; row > lastRowWithData; row--) {
                    String t = pa.getString(row);
                    if (t != null && t.length() > 0 && !mv.equals(t) && !fv.equals(t)) {
                        lastRowWithData = row;
                        break;
                    }
                }
            } else if (paType == PAType.DOUBLE) {
                double mv = atts.getDouble("missing_value"); //may be NaN
                double fv = atts.getDouble("_FillValue"); 
                for (int row = tnRows - 1; row > lastRowWithData; row--) {
                    double t = pa.getDouble(row);
                    if (Double.isFinite(t) &&            //think carefully
                        !Math2.almostEqual(9, t, mv) && //if mv=NaN, !M.ae will be true
                        !Math2.almostEqual(9, t, fv)) {
                        lastRowWithData = row;
                        break;
                    }
                }
            } else if (paType == PAType.FLOAT) {
                float mv = atts.getFloat("missing_value"); //may be NaN
                float fv = atts.getFloat("_FillValue"); 
                for (int row = tnRows - 1; row > lastRowWithData; row--) {
                    float t = pa.getFloat(row);
                    if (Float.isFinite(t) &&            //think carefully
                        !Math2.almostEqual(5, t, mv) && //if mv=NaN, !M.ae will be true
                        !Math2.almostEqual(5, t, fv)) {
                        lastRowWithData = row;
                        break;
                    }
                }
            } else if (paType == PAType.ULONG) {
                BigInteger mv = atts.getULong("missing_value"); //may be null
                BigInteger fv = atts.getULong("_FillValue"); 
                boolean paMaxIsMV = pa.getMaxIsMV();
                for (int row = tnRows - 1; row > lastRowWithData; row--) {
                    BigInteger t = pa.getULong(row);
                    if (t == null || t.equals(mv) || t.equals(fv)) {
                    } else {
                        lastRowWithData = row;
                        break;
                    }
                }
            } else {
                long mv = atts.getLong("missing_value"); //may be Long.MAX_VALUE
                long fv = atts.getLong("_FillValue"); 
                for (int row = tnRows - 1; row > lastRowWithData; row--) {
                    long t = pa.getLong(row);
                    if (t != Long.MAX_VALUE && t != mv && t != fv) { //trouble: for LongArray, this works as if maxIsMV=true
                        lastRowWithData = row;
                        break;
                    }
                }
            }
            //if (debugMode)
            //    String2.log("  lastRowWithData=" + lastRowWithData + " after col#" + col);
            if (lastRowWithData == tnRows - 1)
                return lastRowWithData;
        }
        return lastRowWithData;
    }

    /**
     * This removes all rows of data at the end of the table that have just 
     * missing_value or _FillValue or the PrimitiveArray's native MV.
     *
     * <p>CF 1.6 Discrete Sampling Geometry and Incomplete Multidimensional Arrays:
     * the spec doesn't say which attribute is to be used: missing_value or _FillValue.
     *
     * @return the number of rows remaining
     */
    public int removeRowsAtEndWithoutData() {
        int nRemain = lastRowWithData() + 1;
        removeRows(nRemain, nRows());
        return nRemain;
    }

    /**
     * This returns the value of one datum as a String.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @return the value of one datum as a String.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public String getStringData(int col, int row) {
        return getColumn(col).getString(row);
    }

    /**
     * This returns the value of one datum as a PAOne.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @return the value of one datum as a PAOne.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public PAOne getPAOneData(int col, int row) {
        return getColumn(col).getPAOne(row);
    }

    /**
     * This returns the value of one datum as a float.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @return the value of one datum as a float.
     * @throws Exception if trouble (e.g., row or col out of range)
     *   Strings return the parsed value of the string 
     *    (Double.NaN if not a number).
     */
    public float getFloatData(int col, int row) {
        return getColumn(col).getFloat(row);
    }

    /**
     * This returns the value of one datum as a double.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @return the value of one datum as a double.
     * @throws Exception if trouble (e.g., row or col out of range)
     *   Strings return the parsed value of the string 
     *    (Double.NaN if not a number).
     */
    public double getDoubleData(int col, int row) {
        return getColumn(col).getDouble(row);
    }

    /**
     * This returns the value of one datum as a double.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @return the value of one datum as a nice double 
     *    (rounded to 7 significant digits, so not bruised).
     * @throws Exception if trouble (e.g., row or col out of range)
     *   Strings return the parsed value of the string 
     *    (Double.NaN if not a number).
     */
    public double getNiceDoubleData(int col, int row) {
        return getColumn(col).getNiceDouble(row);
    }

    /**
     * This returns the value of one datum as a long.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @return the value of one datum as a long.
     * @throws Exception if trouble (e.g., row or col out of range)
     *   Strings return the parsed value of the string 
     *    (Long.MAX_VALUE if not a number).
     */
    public long getLongData(int col, int row) {
        return getColumn(col).getLong(row);
    }

    /**
     * This returns the value of one datum as an int.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @return the value of one datum as an int.
     * @throws Exception if trouble (e.g., row or col out of range)
     *   Strings return the parsed value of the string 
     *    (Integer.MAX_VALUE if not a number).
     */
    public int getIntData(int col, int row) {
        return getColumn(col).getInt(row);
    }

    /**
     * This sets the value of one datum as a String.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @param s the value of one datum as a String.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public void setStringData(int col, int row, String s) {
        getColumn(col).setString(row, s);
    }

    /**
     * This sets the value of one datum as a float.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @param d the value of one datum as a float.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public void setFloatData(int col, int row, float d) {
        getColumn(col).setFloat(row, d);
    }

    /**
     * This sets the value of one datum as a double.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @param d the value of one datum as a double.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public void setDoubleData(int col, int row, double d) {
        getColumn(col).setDouble(row, d);
    }

    /**
     * This sets the value of one datum as an int.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param row the row number (0 ... nRows-1 )
     * @param i the value of one datum as an int.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public void setIntData(int col, int row, int i) {
        getColumn(col).setInt(row, i);
    }

    /**
     * This add the value of one datum as a String to one of the columns,
     * thereby increasing the number of rows in that column.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param s the value of one datum as a String.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public void addStringData(int col, String s) {
        getColumn(col).addString(s);
    }

    /**
     * This add the value of one datum as a float to one of the columns,
     * thereby increasing the number of rows in that column.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param d the value of one datum as a float.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public void addFloatData(int col, float d) {
        getColumn(col).addFloat(d);
    }

    /**
     * This add the value of one datum as a double to one of the columns,
     * thereby increasing the number of rows in that column.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param d the value of one datum as a double.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public void addDoubleData(int col, double d) {
        getColumn(col).addDouble(d);
    }

    /**
     * This add the value of one datum as an int to one of the columns,
     * thereby increasing the number of rows in that column.
     *
     * @param col the column number (0 ... nColumns-1 )
     * @param d the value of one datum as an int.
     * @throws Exception if trouble (e.g., row or col out of range)
     */
    public void addIntData(int col, int d) {
        getColumn(col).addInt(d);
    }

    /** This tests that the value in a column is as expected.
     * @throws Exception if trouble
     */
    public void test1(String columnName, int row, String expected) {
        String observed = findColumn(columnName).getString(row);
        //ensureEqual deals with nulls
        Test.ensureEqual(observed, expected, "colName=" + columnName + " row=" + row);
    }

    /** This tests that the value in a column is as expected.
     * @throws Exception if trouble
     */
    public void test1(String columnName, int row, int expected) {
        int observed = findColumn(columnName).getInt(row);
        if (observed != expected)
            throw new RuntimeException("colName=" + columnName + " row=" + row);
    }

    /** This tests that the value in a column is as expected.
     * @throws Exception if trouble
     */
    public void test1(String columnName, int row, float expected) {
        float observed = findColumn(columnName).getFloat(row);
        //ensureEqual does fuzzy test
        Test.ensureEqual(observed, expected, "colName=" + columnName + " row=" + row);
    }

    /** This tests that the value in a column is as expected.
     * @throws Exception if trouble
     */
    public void test1(String columnName, int row, double expected) {
        double observed = findColumn(columnName).getDouble(row);
        //ensureEqual does fuzzy test
        Test.ensureEqual(observed, expected, "colName=" + columnName + " row=" + row);
    }

    /** This tests that the value in a column is as expected.
     * The table's column should have epoch seconds values.
     * 
     * @param expected value formatted with 
     *     Calendar2.safeEpochSecondsToIsoStringTZ(seconds, "")
     * @throws Exception if trouble
     */
    public void test1Time(String columnName, int row, String expected) {
        double seconds = findColumn(columnName).getDouble(row);
        String observed = Calendar2.safeEpochSecondsToIsoStringTZ(seconds, "");
        if (!observed.equals(expected))
            throw new RuntimeException("colName=" + columnName + " row=" + row);
    }


    /** This checks that the value in a column is as expected and prints PASS/FAIL and the test. */
    public String check1(String columnName, int row, String expected) {
        String observed = findColumn(columnName).getString(row);
        //Test.equal deals with nulls
        return (Test.equal(observed, expected)? "PASS" : "FAIL") +
            ": col=" + String2.left(columnName, 15) + 
             " row=" + String2.left("" + row, 2) + 
            " observed=" + observed + " expected=" + expected;
    }

    /** This checks that the value in a column is as expected and prints PASS/FAIL and the test. */
    public String check1(String columnName, int row, int expected) {
        int observed = findColumn(columnName).getInt(row);
        return (Test.equal(observed, expected)? "PASS" : "FAIL") +
            ": col=" + String2.left(columnName, 15) + 
             " row=" + String2.left("" + row, 2) + 
            " observed=" + observed + " expected=" + expected;
    }

    /** This checks that the value in a column is as expected and prints PASS/FAIL and the test. */
    public String check1(String columnName, int row, float expected) {
        float observed = findColumn(columnName).getFloat(row);
        return (Test.equal(observed, expected)? "PASS" : "FAIL") +
            ": col=" + String2.left(columnName, 15) + 
             " row=" + String2.left("" + row, 2) + 
            " observed=" + observed + " expected=" + expected;
    }

    /** This checks that the value in a column is as expected and prints PASS/FAIL and the test. */
    public String check1(String columnName, int row, double expected) {
        double observed = findColumn(columnName).getDouble(row);
        return (Test.equal(observed, expected)? "PASS" : "FAIL") +
            ": col=" + String2.left(columnName, 15) + 
             " row=" + String2.left("" + row, 2) + 
            " observed=" + observed + " expected=" + expected;
    }

    /** This checks that the value in a column is as expected and prints PASS/FAIL and the test. 
     * The table's column should have epoch seconds values.
     * 
     * @param expected value formatted with 
     *     Calendar2.safeEpochSecondsToIsoStringTZ(seconds, "")
     */
    public String check1Time(String columnName, int row, String expected) {
        double seconds = findColumn(columnName).getDouble(row);
        String observed = Calendar2.safeEpochSecondsToIsoStringTZ(seconds, "");
        return (Test.equal(observed, expected)? "PASS" : "FAIL") +
            ": col=" + String2.left(columnName, 15) + 
             " row=" + String2.left("" + row, 2) + 
            " observed=" + observed + " expected=" + expected;
    }

    /**
     * This prints a header in a format that pretty closely mimics the C version of ncdump
     * (starting with the "{") and acts as if the file will be stored as an .nc file.
     *
     * @param dimensionName the name for the rows (e.g., "time", "row", "station", "observation")
     * @return a string representation of this grid
     */
    public String getNCHeader(String dimensionName) {
        //dimensions
        StringBuilder sb = new StringBuilder(
            //this pretty closely mimics the C version of ncdump 
            //(number formats are a little different)
            //and acts as if the file will be stored as an .nc file
            "{\n" +
            "dimensions:\n" +
                "\t" + dimensionName + " = " + nRows() + " ;\n");
        int nColumns = nColumns();
        for (int col = 0; col < nColumns; col++) {
            PrimitiveArray pa = columns.get(col);
            if (pa instanceof StringArray) {
                StringArray sa = (StringArray)pa;
                //String2.log(">>getNcHeader sa=" + sa.toNccsvAttString());
                sb.append("\t" + getColumnName(col) + NcHelper.StringLengthSuffix + 
                    " = " + sa.maxStringLength() + " ;\n");
            }
        }

        //variables
        sb.append("variables:\n");
        for (int col = 0; col < nColumns; col++) {
            PrimitiveArray pa = columns.get(col);
            String columnName = getColumnName(col);
            if (pa instanceof StringArray) {
                StringArray sa = (StringArray)pa;
                sb.append("\tchar " + columnName + "(" + dimensionName + ", " +
                    columnName + NcHelper.StringLengthSuffix + ") ;\n");
            } else {
                sb.append("\t" + pa.elementTypeString() + 
                    " " + columnName + "(" + dimensionName + ") ;\n");
            }
            sb.append(columnAttributes(col).toNcString("\t\t" + columnName + ":", " ;"));
            }
        sb.append("\n// global attributes:\n");
        sb.append(globalAttributes.toNcString("\t\t:", " ;"));
        sb.append("}\n");

        return sb.toString();
    }

    /**
     * This prints the metadata and the data to a CSV table.
     * This shows row numbers.
     */
    public String toString() {
        return toString(Integer.MAX_VALUE);
    }


    /**
     * This returns a string CSV representation of this data.
     *
     * @param showFirstNRows  use Integer.MAX_VALUE for all rows.
     * @return a string representation of this point data
     */
    public String toString(int showFirstNRows) {
        ensureValid(); //throws Exception if not
        return getNCHeader("row") + dataToString(showFirstNRows);
    }

    /**
     * This is convenience for dataToString(Integer.MAX_VALUE).
     * 
     */
    public String dataToString() {
        return dataToString(Integer.MAX_VALUE);
    }

    /**
     * This is convenience for dataToString(int showFirstNRows, showRowNumber=true).
     * This shows row numbers.
     * 
     * @param showFirstNRows  use Integer.MAX_VALUE for all rows.
     *  If not all rows are shown, this adds a "..." line to the output.
     */
    public String dataToString(int showFirstNRows) {
        return dataToString(0, showFirstNRows);
    }

    /**
     * This prints a range of rows to a CSV table.
     * 
     * @param start the first row to be included
     * @param stop one past the last row to be included.
     *  If not all rows are shown, this adds a "..." line to the output.
     */
    public String dataToString(int start, int stop) {
        ensureValid();
        start = Math.max(start, 0);
        stop = Math.min(stop, nRows());
        StringBuilder sb = new StringBuilder();
        int nCols = nColumns();
        sb.append(getColumnNamesCSVString() + "\n");
        for (int row = start; row < stop; row++) {
            for (int col = 0; col < nCols; col++) {
                sb.append(columns.get(col).getNccsvDataString(row));
                if (col == nCols - 1)
                    sb.append('\n');
                else 
                    sb.append(",");
            }
        }
        if (stop < nRows())
            sb.append("...\n");
        return sb.toString();
    }

    /**
     * This returns a Comma Separated Value (CSV) string with the names of the columns.
     *
     * @return a csv string with the column names.
     */
    public String getColumnNamesCSVString() {
        return columnNames.toCSVString();
    }

    /**
     * This returns a Comma Space Separated Value (CSSV) string with the names of the columns.
     *
     * @return a csv string with the column names.
     */
    public String getColumnNamesCSSVString() {
        return columnNames.toString();
    }

    /**
     * This returns the Attributes with the global attributes.
     * 
     * @return the Attributes with global attributes.
     */
    public Attributes globalAttributes() {
        return globalAttributes;
    }

    /**
     * This gets the Attributes for a given column.
     * Use this with care; this is the actual data structure, not a clone.
     * 
     * @param column
     * @return the ArrayList with the attributes for the column
     */
    public Attributes columnAttributes(int column) {
        return columnAttributes.get(column);
    }

    /**
     * This gets the Attributes for a given column.
     * Use this with care; this is the actual data structure, not a clone.
     * 
     * @param columnName
     * @return the ArrayList with the attributes for the column
     * @throws IllegalArgumentException if columnName not found
     */
    public Attributes columnAttributes(String columnName) {
        int col = findColumnNumber(columnName);
        if (col < 0)
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.getColumn: columnName=" + columnName + " not found."); 
        return columnAttributes(col);
    }

    /**
     * This adds the standard attributes, including calling setActualRangeAndBoundingBox
     * (which sets the coordinate variables' axis, long_name, standard_name, and units).
     * If a string parameter is null, nothing is done; the attribute is not set and not cleared.
     * If a string parameter is "", that attributes is cleared.
     *
     * <p>This does not call convertToFakeMissingValues(), nor should that
     * (generally speaking) be called before or after calling this.
     * This procedure expects NaN's as the missing values.
     * convertToFakeMissingValues and convertToStandardMissingValues are called
     * internally by the saveAsXxx methods to temporarily switch to fakeMissingValue.
     *
     * <p>This does not set the data columns' attributes, notably:
     *   "long_name" (boldTitle?), "standard_name", "units" (UDUnits).
     *
     * <p>NOW OBSOLETE [This sets most of the metadata needed to comply with 
     * Unidata Observation Dataset Conventions 
     * (https://www.unidata.ucar.edu/software/netcdf-java/formats/UnidataObsConvention.html) [GONE!]
     * To fully comply, you may need to add the global attribute 
     * observationDimension (see saveAsFlatNc). ]   
     *
     * @param lonIndex identifies the longitude column (or -1 if none)
     * @param latIndex identifies the latitude column (or -1 if none)
     * @param depthIndex identifies the depth column (or -1 if none)
     * @param timeIndex identifies the time column (or -1 if none)
     * @param boldTitle  a descriptive title for this data
     * @param cdmDataType   "Grid", "Image", "Station", "Point", "Trajectory", or "Radial"
     * @param creatorEmail usually already set, e.g., DataHelper.CS_CREATOR_EMAIL, "erd.data@noaa.gov"
     * @param creatorName usually already set, e.g., DataHelper.CS_CREATOR_NAME, "NOAA CoastWatch, West Coast Node"
     * @param creatorUrl usually already set, e.g., DataHelper.CS_CREATOR_URL, "https://coastwatch.pfeg.noaa.gov"
     * @param project usually already set, e.g., DataHelper.CS_PROJECT
     * @param id a unique string identifying this table
     * @param keywordsVocabulary e.g., "GCMD Science Keywords"
     * @param keywords  e.g., a keyword string from 
     *    http://gcmd.gsfc.nasa.gov/Resources/valids/gcmd_parameters.html
     *    e.g., "Oceans > Ocean Temperature > Sea Surface Temperature"
     * @param references
     * @param summary a longer description of this data
     * @param courtesy   e.g., "Channel Islands National Park (David Kushner)"
     * @param timeLongName "Time" (the default if this is null), 
     *    or a better description of time, e.g., "Centered Time",
     *    "Centered Time of 1 Day Averages"
     */
    public void setAttributes(int lonIndex, int latIndex, int depthIndex, int timeIndex,
        String boldTitle, String cdmDataType, 
        String creatorEmail, String creatorName, String creatorUrl, String project,
        String id, String keywordsVocabulary,
        String keywords, String references, String summary, 
        String courtesy, String timeLongName) {

        String currentDateTimeZ = Calendar2.getCurrentISODateTimeStringZulu() + "Z";
        trySet(globalAttributes, "acknowledgement", "NOAA NESDIS COASTWATCH, NOAA SWFSC ERD");
        trySet(globalAttributes, "cdm_data_type", cdmDataType);
        trySet(globalAttributes, "contributor_name", courtesy);
        trySet(globalAttributes, "contributor_role", "Source of data."); 
        trySet(globalAttributes, "Conventions", "COARDS, CF-1.6, ACDD-1.3"); //unidata-related
        trySet(globalAttributes, "creator_email", creatorEmail);
        trySet(globalAttributes, "creator_name", creatorName);
        trySet(globalAttributes, "creator_url", creatorUrl);
        trySet(globalAttributes, "date_created", currentDateTimeZ);
        trySet(globalAttributes, "date_issued",  currentDateTimeZ);
        String oldHistory = globalAttributes.getString("history");
        if (oldHistory == null)
            oldHistory = courtesy;
        trySet(globalAttributes, "history", DataHelper.addBrowserToHistory(oldHistory));
        //String2.log("Table.setAttributes new history=" + globalAttributes.getString("history") +
        //    "\nstack=" + MustBe.stackTrace());
        trySet(globalAttributes, "id", id);
        trySet(globalAttributes, "institution", creatorName);
        if (keywords != null && keywords.length() > 0) {
            trySet(globalAttributes, "keywords_vocabulary", keywordsVocabulary);
            trySet(globalAttributes, "keywords", keywords);
        }
        trySet(globalAttributes, "license", "The data may be used and redistributed for free but is not intended for legal use, since it may contain inaccuracies. Neither the data Contributor, CoastWatch, NOAA, nor the United States Government, nor any of their employees or contractors, makes any warranty, express or implied, including warranties of merchantability and fitness for a particular purpose, or assumes any legal liability for the accuracy, completeness, or usefulness, of this information.");
        trySet(globalAttributes, "naming_authority", "gov.noaa.pfel.coastwatch");  //for generating id
        //trySet(globalAttributes, "processing_level", "3"); //appropriate for satellite data
        trySet(globalAttributes, "project", project);
        trySet(globalAttributes, "references", references);
        trySet(globalAttributes, "standard_name_vocabulary", FileNameUtility.getStandardNameVocabulary());
        trySet(globalAttributes, "summary", summary);
        trySet(globalAttributes, "title", boldTitle);  //Time series from ... ?

        //remove some commonly set, but no longer relevant, attributes
        globalAttributes.remove(CacheOpendapStation.OPENDAP_TIME_DIMENSION_SIZE);
        globalAttributes.remove("Unlimited_Dimension"); //e.g., MBARI has this

        //setActualRangeAndBoundingBox
        setActualRangeAndBoundingBox(lonIndex, latIndex, depthIndex, -1, timeIndex, timeLongName);

    }


    /**
     * This is called by setAttributes to calculate and 
     * set each column's "actual_range" attributes
     * and set the THREDDS ACDD-style
     * geospatial_lat_min and max, ... and time_coverage_start and end
     * global attributes, and the Google Earth-style 
     *   Southernmost_Northing, ... Easternmost_Easting.
     * This also sets column attributes for the lon, lat, depth, and time variables 
     * (if the index isn't -1).
     * <p>OBSOLETE [For Unidata Observation Dataset Conventions (e.g., _Coordinate), 
     * see https://www.unidata.ucar.edu/software/netcdf-java/formats/UnidataObsConvention.html .] [GONE!]
     *
     * @param lonIndex identifies the longitude column (or -1 if none)
     * @param latIndex identifies the latitude column (or -1 if none)
     * @param depthIndex identifies the depth column (or -1 if none)
     * @param altIndex identifies the altitude column (or -1 if none).
     *   There shouldn't be both a depth and an altitude column.
     * @param timeIndex identifies the time column (or -1 if none)
     * @param timeLongName "Time" (the default, if this is null), 
     *    or a better description of time, e.g., "Centered Time",
     *    "Centered Time of 1 Day Averages"
     */
    public void setActualRangeAndBoundingBox(
        int lonIndex, int latIndex, int depthIndex, int altIndex, int timeIndex, String timeLongName) {
        //set actual_range
        for (int col = 0; col < nColumns(); col++) {
            setActualRange(col);

            //set acdd-style and google-style bounding box
            PrimitiveArray range = columnAttributes(col).get("actual_range");
            if (col == lonIndex) {
                columnAttributes(col).set("_CoordinateAxisType", "Lon");  //unidata-related
                columnAttributes(col).set("axis",                "X");
                columnAttributes(col).set("long_name",           "Longitude");
                columnAttributes(col).set("standard_name",       "longitude");
                columnAttributes(col).set("units",               "degrees_east");

                globalAttributes.set("geospatial_lon_units", "degrees_east");
                if (range == null) {
                    globalAttributes.remove("geospatial_lon_min");
                    globalAttributes.remove("geospatial_lon_max");
                    globalAttributes.remove("Westernmost_Easting");
                    globalAttributes.remove("Easternmost_Easting");
                } else if (range instanceof FloatArray) {
                    globalAttributes.set("geospatial_lon_min",  range.getFloat(0));
                    globalAttributes.set("geospatial_lon_max",  range.getFloat(1));
                    globalAttributes.set("Westernmost_Easting", range.getFloat(0));
                    globalAttributes.set("Easternmost_Easting", range.getFloat(1));
                } else {
                    globalAttributes.set("geospatial_lon_min",  range.getDouble(0));
                    globalAttributes.set("geospatial_lon_max",  range.getDouble(1));
                    globalAttributes.set("Westernmost_Easting", range.getDouble(0));
                    globalAttributes.set("Easternmost_Easting", range.getDouble(1));
                }
            } else if (col == latIndex) {
                columnAttributes(col).set("_CoordinateAxisType", "Lat"); //unidata-related
                columnAttributes(col).set("axis",                "Y");
                columnAttributes(col).set("long_name",           "Latitude");
                columnAttributes(col).set("standard_name",       "latitude");
                columnAttributes(col).set("units",               "degrees_north");

                globalAttributes.set("geospatial_lat_units", "degrees_north");
                if (range == null) {
                    globalAttributes.remove("geospatial_lat_min");
                    globalAttributes.remove("geospatial_lat_max");
                    globalAttributes.remove("Southernmost_Northing");
                    globalAttributes.remove("Northernmost_Northing");
                } else if (range instanceof FloatArray) {
                    globalAttributes.set("geospatial_lat_min",    range.getFloat(0)); //unidata-related
                    globalAttributes.set("geospatial_lat_max",    range.getFloat(1));
                    globalAttributes.set("Southernmost_Northing", range.getFloat(0));
                    globalAttributes.set("Northernmost_Northing", range.getFloat(1));
                } else {
                    globalAttributes.set("geospatial_lat_min",    range.getDouble(0)); //unidata-related
                    globalAttributes.set("geospatial_lat_max",    range.getDouble(1));
                    globalAttributes.set("Southernmost_Northing", range.getDouble(0));
                    globalAttributes.set("Northernmost_Northing", range.getDouble(1));
                }
            } else if (col == depthIndex) {
                columnAttributes(col).set("_CoordinateAxisType", "Height");   //unidata
                columnAttributes(col).set("_CoordinateZisPositive", "down");  //unidata
                columnAttributes(col).set("axis",                "Z");
                columnAttributes(col).set("long_name",           "Depth");  //this is a commitment to Depth
                columnAttributes(col).set("positive",            "down");   //this is a commitment to Depth, //unidata-related
                columnAttributes(col).set("standard_name",       "depth");  //this is a commitment to Depth
                columnAttributes(col).set("units",               "m");  //CF standard names says canonical units are "m"

                if (range == null) {
                    globalAttributes.remove("geospatial_vertical_min"); //unidata-related
                    globalAttributes.remove("geospatial_vertical_max");
                } else if (range instanceof DoubleArray) {
                    globalAttributes.set("geospatial_vertical_min", range.getDouble(0));
                    globalAttributes.set("geospatial_vertical_max", range.getDouble(1));
                } else if (range instanceof FloatArray) {
                    globalAttributes.set("geospatial_vertical_min", range.getFloat(0));
                    globalAttributes.set("geospatial_vertical_max", range.getFloat(1));
                } else {
                    globalAttributes.set("geospatial_vertical_min", range.getInt(0));
                    globalAttributes.set("geospatial_vertical_max", range.getInt(1));
                }
                globalAttributes.set("geospatial_vertical_units", "m");
                globalAttributes.set("geospatial_vertical_positive", "down"); //this is a commitment to Depth
            } else if (col == altIndex) {
                columnAttributes(col).set("_CoordinateAxisType", "Height");   //unidata
                columnAttributes(col).set("_CoordinateZisPositive", "up");  //unidata
                columnAttributes(col).set("axis",                "Z");
                columnAttributes(col).set("long_name",           "Altitude");  //this is a commitment to Altitude
                columnAttributes(col).set("positive",            "up");        //this is a commitment to Altitude, //unidata-related
                columnAttributes(col).set("standard_name",       "altitude");  //this is a commitment to Altitude
                columnAttributes(col).set("units",               "m");  //CF standard names says canonical units are "m"

                if (range == null) {
                    globalAttributes.remove("geospatial_vertical_min"); //unidata-related
                    globalAttributes.remove("geospatial_vertical_max");
                } else if (range instanceof DoubleArray) {
                    globalAttributes.set("geospatial_vertical_min", range.getDouble(0));
                    globalAttributes.set("geospatial_vertical_max", range.getDouble(1));
                } else if (range instanceof FloatArray) {
                    globalAttributes.set("geospatial_vertical_min", range.getFloat(0));
                    globalAttributes.set("geospatial_vertical_max", range.getFloat(1));
                } else {
                    globalAttributes.set("geospatial_vertical_min", range.getInt(0));
                    globalAttributes.set("geospatial_vertical_max", range.getInt(1));
                }
                globalAttributes.set("geospatial_vertical_units", "m");
                globalAttributes.set("geospatial_vertical_positive", "up"); //this is a commitment to Altitude
            } else if (col == timeIndex) {
                columnAttributes(col).set("_CoordinateAxisType", "Time"); //unidata-related
                columnAttributes(col).set("axis",                "T");
                if (timeLongName == null || timeLongName.length() == 0)
                    timeLongName = "Time";
                columnAttributes(col).set("long_name",           timeLongName); 
                columnAttributes(col).set("standard_name",       "time");
                //LAS Intermediate files wants time_origin "01-Jan-1970 00:00:00" ;
                //https://ferret.pmel.noaa.gov/LASdoc/serve/cache/90.html
                columnAttributes(col).set("time_origin",         "01-JAN-1970 00:00:00");
                columnAttributes(col).set("units",               Calendar2.SECONDS_SINCE_1970);

                //this range is a little misleading for averaged data
                if (range == null) {
                    globalAttributes.remove("time_coverage_start");   //unidata-related
                    globalAttributes.remove("time_coverage_end");
                } else {
                    globalAttributes.set("time_coverage_start", 
                        Calendar2.epochSecondsToIsoStringTZ(range.getDouble(0)));
                    globalAttributes.set("time_coverage_end",   
                        Calendar2.epochSecondsToIsoStringTZ(range.getDouble(1)));
                }
                //this doesn't set tableGlobalAttributes.set("time_coverage_resolution", "P1H");
            } 
        }

    }

    /**
     * Call this to remove file-specific attributes 
     * (which are wrong if applied to an aggregated dataset):
     * each column's "actual_range" attributes and the THREDDS ACDD-style
     * geospatial_lat_min and max, ... and time_coverage_start and end
     * global attributes, and the Google Earth-style 
     *   Southernmost_Northing, ... Easternmost_Easting.
     * <p>OBSOLETE [For Unidata Observation Dataset Conventions (e.g., _Coordinate), 
     * see https://www.unidata.ucar.edu/software/netcdf-java/formats/UnidataObsConvention.html .] [GONE!]
     *
     */
    public void unsetActualRangeAndBoundingBox() {

        //remove acdd-style and google-style bounding box
        globalAttributes.remove("geospatial_lon_min");
        globalAttributes.remove("geospatial_lon_max");
        globalAttributes.remove("Westernmost_Easting");
        globalAttributes.remove("Easternmost_Easting");
        globalAttributes.remove("geospatial_lat_min");
        globalAttributes.remove("geospatial_lat_max");
        globalAttributes.remove("Southernmost_Northing");
        globalAttributes.remove("Northernmost_Northing");
        globalAttributes.remove("geospatial_vertical_min"); //unidata-related
        globalAttributes.remove("geospatial_vertical_max");
        globalAttributes.remove("time_coverage_start");   //unidata-related
        globalAttributes.remove("time_coverage_end");
     
        //remove actual_range
        for (int col = 0; col < nColumns(); col++) {
            Attributes atts = columnAttributes(col);
            atts.remove("actual_min");
            atts.remove("actual_max");
            atts.remove("actual_range");
            atts.remove("data_min");
            atts.remove("data_max");
        }

    }

    /**
     * This is called by setActualRangeAndBoundingBox to set (or revise) the actual_range metadata.
     * This works on the current (unpacked; not scaled) data. So call this when the
     * data is unpacked.
     * If the column is a String column, nothing will be done.
     *
     * @param column
     */
    public void setActualRange(int column) {
        PrimitiveArray pa = getColumn(column);
        if (pa instanceof StringArray) 
            return;
        double stats[] = pa.calculateStats();
        double min = stats[PrimitiveArray.STATS_MIN];
        double max = stats[PrimitiveArray.STATS_MAX];

        //if no data, don't specify range
        if (Double.isNaN(min)) {
            columnAttributes(column).remove("actual_range");
            return;
        }

        PrimitiveArray minMax = PrimitiveArray.factory(pa.elementType(), 2, false);
        minMax.addDouble(min);
        minMax.addDouble(max);
        columnAttributes(column).set("actual_range", minMax);
        return;
    }

    /**
     * If attValue is null, this does nothing.
     * If attValue is "", this removes the attribute (if present).'
     * Otherwise, this sets the attribute.
     */
    private void trySet(Attributes attributes, String attName, String attValue) {
        if (attValue == null)
            return;
        if (attValue.length() == 0)
            attributes.remove(attName);
        attributes.set(attName, attValue);
    }

    /** 
     * This tests if this object is valid (e.g., each column in 'data' has 
     * the same number of rows, and there are no duplicate column names).
     * This also checks the validity of globalAttribute or columnAttribute. (?)
     *
     * @throws a SimpleException if table not valid 
     */
    public void ensureValid() {

        //check that all columns have the same size
        int nRows = nRows();  //from column[0]
        int nColumns = nColumns();
        for (int col = 1; col < nColumns; col++)
            if (columns.get(col).size() != nRows)
                throw new SimpleException(
                    "Invalid Table: " +
                    "column[" + col + "=" + getColumnName(col) + "].size=" + columns.get(col).size() +
                    " != column[0=" + getColumnName(0) + "].size=" + nRows);

        ensureNoDuplicateColumnNames("");
    }

    /** 
     * This throws a SimpleException if there are duplicate column names.
     *
     * @param msg addition message, e.g., "AxisVariable source names: "
     * @throws a SimpleException if there are duplicate column names.
     */
    public void ensureNoDuplicateColumnNames(String msg) {    
        columnNames.ensureNoDuplicates("Invalid Table: " + msg + "Duplicate column names: ");
    }

    /** 
     * This makes the column names unique by adding _2, _3, ... as needed.
     *
     */
    public void makeColumnNamesUnique() {    
        columnNames.makeUnique();
    }


    /**
     * This adds missingValues (NaN) to columns as needed so all columns have the same number of rows.
     *
     */
    public void makeColumnsSameSize() {

        //columns may have different numbers of rows (some may not have had data)
        //find maxNRows
        int maxNRows = 0;
        int tNCol = nColumns();
        for (int col = 0; col < tNCol; col++) 
            maxNRows = Math.max(columns.get(col).size(), maxNRows);

        //ensure all columns have correct maxNRows 
        if (maxNRows > 0) {
            for (int col = 0; col < tNCol; col++) {
                PrimitiveArray pa = columns.get(col);
                pa.addNDoubles(maxNRows - pa.size(), Double.NaN);
            }
        }
    }

    /**
     * This replicates the last value as needed so all columns have the same number of rows.
     *
     */
    public void ensureColumnsAreSameSize_LastValue() {

        //columns may have different numbers of rows (some may not have had data)
        //find maxNRows
        int maxNRows = 0;
        int tNCol = nColumns();
        for (int col = 0; col < tNCol; col++) 
            maxNRows = Math.max(columns.get(col).size(), maxNRows);

        //ensure all columns have correct maxNRows 
        if (maxNRows > 0) {
            for (int col = 0; col < tNCol; col++) {
                PrimitiveArray pa = columns.get(col);
                String s = pa.size() == 0? "" : pa.getString(pa.size() - 1);
                pa.addNStrings(maxNRows - pa.size(), s);
            }
        }
    }

    /** 
     * This tests if o is a Table with the same data and columnNames as this table. 
     * (Currently) This doesn't test globalAttribute or columnAttribute.
     * This requires that the column types be identical.
     *
     * @param o (usually) a Table object
     * @return true if o is a Table object and has column types and data values 
     *   that equal this Table object.
     */
    public boolean equals(Object o) {
        return equals(o, true);
    }

    /** 
     * This tests if o is a Table with the same data and columnNames as this table. 
     * (Currently) This doesn't test globalAttribute or columnAttribute.
     *
     * @param o (usually) a Table object
     * @param ensureColumnTypesEqual
     * @return true if o is a Table object and has column types and data values 
     *   that equal this Table object.
     */
    public boolean equals(Object o, boolean ensureColumnTypesEqual) {

        String errorInMethod = String2.ERROR + " in Table.equals while testing ";
        try {

            Table table2 = (Table)o;
            ensureValid(); //throws Exception if not
            table2.ensureValid();

            int nRows = nRows();
            int nColumns = nColumns();
            Test.ensureEqual(nRows, table2.nRows(), 
                errorInMethod + "nRows");
            Test.ensureEqual(nColumns(), table2.nColumns(), 
                errorInMethod + "nColumns\nthis table: " + columnNames.toString() +
                  "\nother table: " + table2.columnNames.toString());

            for (int col = 0; col < nColumns; col++) {
                Test.ensureEqual(getColumnName(col), table2.getColumnName(col),
                    errorInMethod + "column=" + col + " names.");
                PrimitiveArray array1 = columns.get(col);
                PrimitiveArray array2 = table2.getColumn(col);
                if (ensureColumnTypesEqual) 
                    Test.ensureEqual(array1.elementTypeString(), array2.elementTypeString(),
                        errorInMethod + "column=" + col + " types.");
                boolean a1String = array1 instanceof StringArray;
                boolean a2String = array2 instanceof StringArray;
                for (int row = 0; row < nRows; row++) {
                    String s1 = array1.getString(row);
                    String s2 = array2.getString(row);
                    if (!s1.equals(s2)) {
                        //deal with NaN in long column not simplified to LongArray
                        //  so left as NaN in String column
                        //or char array missing value ?
                        if (a1String && ("NaN".equals(s1)))
                            s1 = "";
                        if (a2String && ("NaN".equals(s2)))
                            s2 = "";
                        if (!s1.equals(s2))
                            Test.ensureEqual(s1, s2,
                                errorInMethod + 
                                    "data(col=" + col + " (" + array1.elementTypeString() + 
                                    " vs. " + array2.elementTypeString() + "), row=" + row + ").");
                    }
                }
            }

            return true;
        } catch (Exception e) {
            String2.log(MustBe.throwableToString(e));
            return false;
        }
    }

    /** This makes a table with 2 String columns with the keys (sorted) and values
     * from the map.
     *
     * @param map  if it needs to be thread-safe, use ConcurrentHashMap
     * @param keysName
     * @param valuesName
     */
    public void readMap(Map map, String keysName, String valuesName) {
        //create the empty table
        clear();
        StringArray keys = new StringArray();
        StringArray values = new StringArray();
        addColumn(keysName, keys);
        addColumn(valuesName, values);

        //get the keys and values
        Set entrySet = map.entrySet();
        Iterator it = entrySet.iterator();
        while (it.hasNext()) {
            Map.Entry me = (Map.Entry)it.next();
            keys.add(me.getKey().toString());
            values.add(me.getValue().toString());
        }
        leftToRightSort(1);
    }

    /**
     * This reads data from an ASCII file.
     * <br>The lineSeparator can be \n, \r\n, or \r.
     * <br>See readASCII(lines, nHeaderLines) for other details.
     * <br>This does simplify the columns.
     *
     * @param fullFileName
     * @param charset  e.g., ISO-8859-1 (used if charset is null or "") or UTF-8.
     * @param columnNamesLine (0.., or -1 if no names)
     * @param dataStartLine (0..)
     * @param testColumns the names of the columns to be tested (null = no tests).
     *   All of the test columns must use the same, one, dimension that the
     *   loadColumns use.
     *   Ideally, the first tests will greatly restrict the range of valid rows.
     * @param testMin the minimum allowed value for each testColumn (null = no tests)
     * @param testMax the maximum allowed value for each testColumn (null = no tests)
     * @param loadColumns the names of the columns to be loaded
     *     (perhaps in different order than in the file).
     *     If loadColumns is null, this will read all of the data columns.
     * @param simplify
     * @throws Exception if trouble
     */
    public void readASCII(String fullFileName, String charset, 
        String skipHeaderToRegex, String skipLinesRegex,
        int columnNamesLine, int dataStartLine, String tColSeparator,
        String testColumns[], double testMin[], double testMax[], 
        String loadColumns[], boolean simplify) throws Exception {

        readASCII(fullFileName, 
            File2.getDecompressedBufferedFileReader(fullFileName, charset), 
            skipHeaderToRegex, skipLinesRegex, columnNamesLine, dataStartLine, tColSeparator,
            testColumns, testMin, testMax, loadColumns, simplify); 
    }
 

    /** Another variant. 
     * This uses simplify=true.
     * 
     * @throws Exception if trouble
     */
    public void readASCII(String fullFileName, int columnNamesLine, int dataStartLine) 
        throws Exception {

        readASCII(fullFileName, String2.ISO_8859_1,
            "", "", columnNamesLine, dataStartLine,
            null, null, null, null, null, true);
    }


    /** Another variant. 
     * This uses columnNamesLine=0, dataStartLine=1, simplify=true.
     * 
     * @throws Exception if trouble
     */
    public void readASCII(String fullFileName) throws Exception {

        readASCII(fullFileName, String2.ISO_8859_1,
            "", "", 0, 1, null, null, null, null, null, true);
    }

    /**
     * This reads data from an array of tab, comma, or space-separated ASCII Strings.
     * <ul>
     * <li> If no exception is thrown, the file was successfully read.
     * <li> The item separator in the file can be tab, comma, or 1 or more spaces.
     * <li> Missing values for tab- and comma-separated files can be "" or "." or "NaN".
     * <li> Missing values for space-separated files can be "." or "NaN".
     * <li> Normally, all data rows must have the same number of data items, or the row is skipped. 
     *    However, you can set the instance's allowRaggedRightInReadASCII to true
     *    to allow missing values at the end of a row.
     * </ul>
     *
     * @param fileName for diagnostic messages only
     * @param linesReader the array of ASCII strings with the info from the file.
     *    This will always close the reader.
     * @param columnNamesLine (0.., or -1 if no names).
     *    If there are no columnNames, names in the form "Column#<col>" 
     *    (where col is 0 .. nColumns) will be created.
     * @param dataStartLine (0..)  Usually 1 or 2.
     * @param tColSeparator the character that separates the columns. 
     *   Use "" or null to have this method guess. Otherwise,
     *   the first character of this string will be used.
     * @param testColumns the names of the columns to be tested (null = no tests).
     *   All of the test columns must use the same, one, dimension that the
     *   loadColumns use.
     *   The tests are done as if the testColumns were doubles.
     *   Ideally, the first tests will greatly restrict the range of valid rows.
     * @param testMin the minimum allowed value for each testColumn (null = no tests)
     * @param testMax the maximum allowed value for each testColumn (null = no tests)
     * @param loadColumns the names of the columns to be loaded 
     *     (perhaps in different order than in the file).
     *     If null, this will read all variables.
     * @param simplify 
     *    The data is initially read as Strings. 
     *    If this is set to 'true', the columns are simplified to their simplest type
     *      (e.g., to doubles, ... or bytes) so they store the data compactly.
     *       Date strings are left as strings. 
     *    If this is set to 'false', the columns are left as strings.
     * @throws Exception if trouble  
     *    (e.g., a specified testColumn or loadColumn not found)
     */
    public void readASCII(String fileName, BufferedReader linesReader,
        String skipHeaderToRegex, String skipLinesRegex,
        int columnNamesLine, int dataStartLine, String tColSeparator,
        String testColumns[], double testMin[], double testMax[], 
        String loadColumns[], boolean simplify) throws Exception {

        try { 

        //clear everything
        clear();

        //validate parameters
        //if (reallyVerbose) String2.log("Table.readASCII " + fileName); 
        long time = System.currentTimeMillis();
        String errorInMethod = String2.ERROR + " in Table.readASCII(" + fileName + "):\n";
        if (testColumns == null)
            testColumns = new String[0];
        else {
            Test.ensureEqual(testColumns.length, testMin.length, 
                errorInMethod + "testColumns.length != testMin.length.");
            Test.ensureEqual(testColumns.length, testMax.length, 
                errorInMethod + "testColumns.length != testMax.length.");
            Test.ensureTrue(columnNamesLine < dataStartLine, 
                errorInMethod + "columnNamesLine=" + columnNamesLine + 
                " must be less than dataStartLine=" + dataStartLine + ".");
            Test.ensureTrue(dataStartLine >= 0, 
                errorInMethod + "dataStartLine=" + dataStartLine + " must be >=0.");
        }
        Pattern skipLinesPattern = skipLinesRegex != null && !skipLinesRegex.equals("")?
             Pattern.compile(skipLinesRegex) : null;

        //skipHeaderToRegex
        int row = skipHeaderToRegex(skipHeaderToRegex, fileName, linesReader); //the number of rows read (1..)

        //try to read up to 3rd row of data (ignoring skipLines)
        //this method caches initial lines read to enable re-reading some lines near the start
        ArrayList<String> linesCache = new ArrayList();
        int nonSkipLines = 0;
        while (true) {
            String s = linesReader.readLine(); //null if end. exception if trouble
            if (s == null)
                break;
            linesCache.add(s);
            if (skipLinesPattern == null || skipLinesPattern.matcher(s).matches())
                nonSkipLines++;
            if (nonSkipLines == dataStartLine + 2) //both 0-based
                break;
        }
        int linesCacheSize = linesCache.size();

        //determine column separator
        //look for separator that appears the most and on in 3 test lines
//FUTURE also look for separator that appears the same number of times on the 3 test lines.
        String oneLine;
        char colSeparator = ',';
        if (tColSeparator == null || tColSeparator.length() == 0) {
            int nTab   = 1;
            int nComma = 1;
            int nSemi  = 1;
            int nSpace = 1;
            int tRow = 0;
            for (int cacheRow = 0; cacheRow < linesCacheSize; cacheRow++) {
                oneLine = linesCache.get(cacheRow);
                if (skipLinesPattern != null && skipLinesPattern.matcher(oneLine).matches())
                    continue;
                if (tRow++ < dataStartLine) //both are 0..
                    continue;
                nTab   *= String2.countAll(oneLine, "\t"); //* (not +) puts emphasis on every line having several of the separator
                nComma *= String2.countAll(oneLine, ",");
                nSemi  *= String2.countAll(oneLine, ";");
                nSpace *= String2.countAll(oneLine, " ");  //lines with lots of text can fool this
            }
            colSeparator = 
                nTab   >= 1 && nTab   >= Math.max(nComma, nSemi)? '\t':
                nComma >= 1 && nComma >= Math.max(nTab,   nSemi)? ',' :
                nSemi  >= 1?                                      ';' : 
                nSpace >= 1?                                      ' ' : 
                    '\u0000'; //only one datum per line; colSeparator irrelevant        
            if (debugMode) String2.log(">> separator=#" + (int)colSeparator + " nTab=" + nTab + 
                " nComma=" + nComma + " nSemi=" + nSemi + " nSpace=" + nSpace);
        } else {
            colSeparator = tColSeparator.charAt(0);
        }

        //read the file's column names
        StringArray fileColumnNames = new StringArray();
        int expectedNItems = -1;
        int nextLinesCache = 0;
        int logicalLine = -1; //0-based line as if skipHeader and skipLines were removed
        if (columnNamesLine >= 0) {
            while (true) {
                oneLine = linesCache.get(nextLinesCache++);
                row++;
                if (skipLinesPattern != null && skipLinesPattern.matcher(oneLine).matches())
                    continue;
                if (++logicalLine == columnNamesLine) //both are 0-based
                    break;
            }

            oneLine = oneLine.trim();
            //break the line into items
            String items[];
            if (colSeparator == '\u0000')
                items = new String[]{oneLine.trim()};
            else if (colSeparator == ' ')
                items = oneLine.split(" +"); //regex for one or more spaces
            else if (colSeparator == ',')
                items = StringArray.arrayFromCSV(oneLine);  //does handle "'d phrases
            else items = String2.split(oneLine, colSeparator);
            //store the fileColumnNames
            expectedNItems = items.length;
            for (int col = 0; col < expectedNItems; col++) {
                fileColumnNames.add(items[col]);
            }
            //if (reallyVerbose) String2.log("fileColumnNames=" + fileColumnNames);
        }

        //get the data
        int testColumnNumbers[] = null;
        int loadColumnNumbers[] = null;
        StringArray loadColumnSA[] = null;
        boolean missingItemNoted = false;
        StringBuilder warnings = new StringBuilder();
        while (true) {
            oneLine = null;
            if (nextLinesCache < linesCacheSize) {
                oneLine = linesCache.get(nextLinesCache);
                linesCache.set(nextLinesCache, null);
                nextLinesCache++;
            } else {
                oneLine = linesReader.readLine();
                if (oneLine == null)
                    break;  //end of linesReader content
            }
            //actual row number
            row++;
            //then check skipLines
            if (skipLinesPattern != null && skipLinesPattern.matcher(oneLine).matches())
                continue;
            //then check dataStartLine
            if (++logicalLine < dataStartLine)
                continue;
              
            //if (debugMode && row % 1000000 == 0) {
            //    Math2.gcAndWait(); 
            //    String2.log(Math2.memoryString() + "\n" + String2.canonicalStatistics());
            //}

            String items[];
            try {
                //break the lines into items
                if (colSeparator == ',')
                    items = StringArray.arrayFromCSV(oneLine);  //does handle "'d phrases
                else if (colSeparator == ' ')
                    items = StringArray.wordsAndQuotedPhrases(oneLine).toArray();
                else if (colSeparator == '\u0000')
                    items = new String[]{oneLine.trim()};
                else items = String2.split(oneLine, colSeparator);
                //if (debugMode && logicalLine-dataStartLine<5) String2.log(">> row=" + row + " nItems=" + items.length + "\nitems=" + String2.toCSSVString(items));
            } catch (Exception e) {
                warnings.append(String2.WARNING + ": line #" + row + ": " + e.getMessage() + "\n");
                continue;
            }

            //one time things 
            if (logicalLine == dataStartLine) {
                if (expectedNItems < 0)
                    expectedNItems = items.length;

                //make column names (if not done already) 
                for (int col = fileColumnNames.size(); col < items.length; col++) 
                    fileColumnNames.add("Column#" + col);

                //identify the testColumnNumbers
                testColumnNumbers = new int[testColumns.length];
                for (int col = 0; col < testColumns.length; col++) {
                    int po = fileColumnNames.indexOf(testColumns[col], 0);
                    if (po < 0)
                       throw new IllegalArgumentException(errorInMethod + 
                           "testColumn '" + testColumns[col] + "' not found.");
                    testColumnNumbers[col] = po;
                }

                //loadColumnNumbers[sourceColumn#] -> outputColumn# 
                //  (-1 if a var not in this file)
                if (loadColumns == null) {
                    //load all
                    loadColumnNumbers = new int[fileColumnNames.size()];
                    loadColumnSA = new StringArray[fileColumnNames.size()];
                    for (int col = 0; col < fileColumnNames.size(); col++) {
                        loadColumnNumbers[col] = col;
                        loadColumnSA[col] = new StringArray(); 
                        addColumn(fileColumnNames.get(col), loadColumnSA[col]);                         
                    }
                } else {
                    loadColumnNumbers = new int[loadColumns.length];
                    loadColumnSA = new StringArray[loadColumns.length];
                    for (int col = 0; col < loadColumns.length; col++) {
                        loadColumnNumbers[col] = fileColumnNames.indexOf(loadColumns[col], 0);
                        loadColumnSA[col] = new StringArray(); 
                        addColumn(loadColumns[col], loadColumnSA[col]); 
                    }
                }
                //if (reallyVerbose) String2.log("loadColumnNumbers=" + String2.toCSSVString(loadColumnNumbers));
            }

            //ensure nItems is correct
            int nItems = items.length;
            if (nItems == 0)
                continue; //silent error
            if (nItems > expectedNItems ||
                (nItems < expectedNItems && !allowRaggedRightInReadASCII)) { // if allow..., it is noted below once
                warnings.append(String2.WARNING + ": skipping line #" + row + 
                    ": unexpected number of items (observed=" + nItems + 
                       ", expected=" + expectedNItems + "). [a]\n");
                continue;
            }

            //do the tests
            boolean ok = true;
            for (int test = 0; test < testColumnNumbers.length; test++) {
                int which = testColumnNumbers[test];
                if (which < 0 || which >= nItems)  //value treated as NaN. NaN will fail any test.
                    continue;
                double d = String2.parseDouble(items[which]);
                if (d >= testMin[test] && d <= testMax[test]) { //NaN will fail this test
                    continue;
                } else {ok = false; 
                    if (debugMode) String2.log(">> skipping row=" + row + 
                        " because it failed test #" + test);
                    break; 
                }
            }
            if (!ok) 
                continue;

            //store the data items
            for (int col = 0; col < loadColumnNumbers.length; col++) {
                int itemNumber = loadColumnNumbers[col];
                if (itemNumber < 0) {
                    //request col is not in the file
                    loadColumnSA[col].add(""); 
                } else if (itemNumber < nItems) {
                    loadColumnSA[col].add(String2.fromNccsvString(items[itemNumber]));
                } else if (allowRaggedRightInReadASCII) {  
                    //it is a bad idea to allow this (who knows which value is missing?), 
                    //but some buoy files clearly lack the last value,
                    //see NdbcMeteorologicalStation.java
                    if (!missingItemNoted) {
                        warnings.append("NOTE: skipping line #" + row + 
                            " (and others?): unexpected number of items (observed=" + nItems + 
                           ", expected=" + expectedNItems + ") starting on this line. [allowRaggedRightInReadASCII=true]\n");
                        missingItemNoted = true;
                    }
                    loadColumnSA[col].add(""); //missing value
                } //else incorrect nItems added to warnings above
            }
        }
        //if (debugMode) String2.log(">> partial table:\n" + dataToString(4));

        if (warnings.length() > 0) 
            String2.log(WARNING_BAD_LINE_OF_DATA_IN + "readASCII(" + fileName + "):\n" +
                warnings.toString());

        //no data?
        if (loadColumnNumbers == null)
            throw new SimpleException(MustBe.THERE_IS_NO_DATA + " (loadColumns not found)");

        //simplify the columns
        if (simplify) 
            simplify();

        //if (debugMode) String2.log(">> partial table2:\n" + dataToString(4));
        if (reallyVerbose) String2.log("  Table.readASCII " + fileName + 
            " finished. nCols=" + nColumns() + " nRows=" + nRows() + 
            " TIME=" + (System.currentTimeMillis() - time) + "ms");

        //ensure the linesReader is closed
        } finally {
            try {linesReader.close();} catch (Exception e2) {}
        }
    }

    /** 
     * Test readASCII with csv file.
     *
     * @throws Exception if trouble
     */
    public static void testReadAsciiCsvFile() throws Exception {
        
        String2.log("\nTable.testReadAsciiCsvASCIIFile");
        String results, expected;
        StringArray sa = new StringArray();
        String fileName = String2.unitTestDataDir + "csvAscii.txt";
        String skipHeaderToRegex = "\\*\\*\\* END OF HEADER.*";
        String skipLinesRegex = "#.*";

        Table table;

//    public void readASCII(String fullFileName, int columnNamesLine, int dataStartLine,
//        String testColumns[], double testMin[], double testMax[], 
//        String loadColumns[], boolean simplify) throws Exception {
            
        //read as Strings 
        table = new Table();
        table.allowRaggedRightInReadASCII = true;
        table.readASCII(fileName, String2.ISO_8859_1, 
            skipHeaderToRegex, skipLinesRegex,
            0, 1, "", null, null, null, null, false);
        results = table.dataToString();
        expected = 
"aString,aChar,aBoolean,aByte,aShort,anInt,aLong,aFloat,aDouble\n" +
"\" b,d \",Ab,t,24,24000,24000000,240000000000,2.4,2.412345678987654\n" +
"needs,1comma:,,,,,,,\n" +
"fg,F,true,11,12001,1200000,12000000000,1.21,1e200\n" +
"h,H,1,12,12002,120000,1200000000,1.22,2e200\n" +
"i,I,TRUE,13,12003,12000,120000000,1.23,3e200\n" +
"j,J,f,14,12004,1200,12000000,1.24,4e200\n" +
"k,K,false,15,12005,120,1200000,1.25,5e200\n" +
"\"BAD LINE: UNCLOSED QUOTE,K,false,15,12005,120,1200000,1.25,   5.5e200\",,,,,,,,\n" +
"l,L,0,16,12006,12,120000,1.26,6e200\n" +
"m,M,FALSE,17,12007,121,12000,1.27,7e200\n" +
"n,N,8,18,12008,122,1200,1.28,8e200\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //test types
        sa.clear();
        for (int col = 0; col < table.nColumns(); col++) 
            sa.add(table.getColumn(col).elementTypeString());
        results = sa.toString();
        expected = "String, String, String, String, String, String, String, String, String";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test simplify
        table = new Table();
        table.allowRaggedRightInReadASCII = false;
        table.readASCII(fileName, String2.ISO_8859_1,
            skipHeaderToRegex, skipLinesRegex,
            0, 1, "", null, null, null, null, true);
        results = table.dataToString();
        expected =   //bad lines are removed 
"aString,aChar,aBoolean,aByte,aShort,anInt,aLong,aFloat,aDouble\n" +
"\" b,d \",Ab,t,24,24000,24000000,240000000000,2.4,2.412345678987654\n" +
"fg,F,true,11,12001,1200000,12000000000,1.21,1.0E200\n" +
"h,H,1,12,12002,120000,1200000000,1.22,2.0E200\n" +
"i,I,TRUE,13,12003,12000,120000000,1.23,3.0E200\n" +
"j,J,f,14,12004,1200,12000000,1.24,4.0E200\n" +
"k,K,false,15,12005,120,1200000,1.25,5.0E200\n" +
"l,L,0,16,12006,12,120000,1.26,6.0E200\n" +
"m,M,FALSE,17,12007,121,12000,1.27,7.0E200\n" +
"n,N,8,18,12008,122,1200,1.28,8.0E200\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //test types
        sa.clear();
        for (int col = 0; col < table.nColumns(); col++) 
            sa.add(table.getColumn(col).elementTypeString());
        results = sa.toString();
        expected = "String, String, String, byte, short, int, long, float, double";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read subset 
        table = new Table();
        table.allowRaggedRightInReadASCII = false;
        table.readASCII(fileName, String2.ISO_8859_1,
            skipHeaderToRegex, skipLinesRegex,
            0, 1, "", 
            new String[]{"aByte"}, new double[]{14}, new double[]{16}, 
            new String[]{"aDouble","aString","aByte"}, true);  //load cols
        results = table.dataToString();
        expected =  //bad lines are removed 
"aDouble,aString,aByte\n" +
"4.0E200,j,14\n" +
"5.0E200,k,15\n" +
"6.0E200,l,16\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
    }

    /** 
     * Test readASCII with ssv file.
     *
     * @throws Exception if trouble
     */
    public static void testReadAsciiSsvFile() throws Exception {
        
        String2.log("\nTable.testReadAsciiSsvASCIIFile");
        String results, expected;
        StringArray sa = new StringArray();
        String fileName = String2.unitTestDataDir + "ssvAscii.txt";
        Table table;

//    public void readASCII(String fullFileName, int columnNamesLine, int dataStartLine,
//        String testColumns[], double testMin[], double testMax[], 
//        String loadColumns[], boolean simplify) throws Exception {
            
        //read as Strings 
        table = new Table();
        table.allowRaggedRightInReadASCII = true;
        table.readASCII(fileName, String2.ISO_8859_1,
            "", "", 0, 1, "", null, null, null, null, false);
        results = table.dataToString();
        expected = 
"aString,aChar,aBoolean,aByte,aShort,anInt,aLong,aFloat,aDouble\n" +
"\" b d \",Ab,t,24,24000,24000000,240000000000,2.4,2.412345678987654\n" +
"needs1space,E,,,,,,,\n" +
"fg,F,true,11,12001,1200000,12000000000,1.21,1e200\n" +
"h,H,1,12,12002,120000,1200000000,1.22,2e200\n" +
"i,I,TRUE,13,12003,12000,120000000,1.23,3e200\n" +
"j,J,f,14,12004,1200,12000000,1.24,4e200\n" +
"k,K,false,15,12005,120,1200000,1.25,5e200\n" +
"l,L,0,16,12006,12,120000,1.26,6e200\n" +
"m,M,FALSE,17,12007,121,12000,1.27,7e200\n" +
"n,N,8,18,12008,122,1200,1.28,8e200\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //test types
        sa.clear();
        for (int col = 0; col < table.nColumns(); col++) 
            sa.add(table.getColumn(col).elementTypeString());
        results = sa.toString();
        expected = "String, String, String, String, String, String, String, String, String";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test simplify
        table = new Table();
        table.allowRaggedRightInReadASCII = true;
        table.readASCII(fileName, String2.ISO_8859_1,
            "", "", 0, 1, "", null, null, null, null, true);
        results = table.dataToString();
        expected = 
"aString,aChar,aBoolean,aByte,aShort,anInt,aLong,aFloat,aDouble\n" +
"\" b d \",Ab,t,24,24000,24000000,240000000000,2.4,2.412345678987654\n" +
"needs1space,E,,,,,,,\n" +
"fg,F,true,11,12001,1200000,12000000000,1.21,1.0E200\n" +
"h,H,1,12,12002,120000,1200000000,1.22,2.0E200\n" +
"i,I,TRUE,13,12003,12000,120000000,1.23,3.0E200\n" +
"j,J,f,14,12004,1200,12000000,1.24,4.0E200\n" +
"k,K,false,15,12005,120,1200000,1.25,5.0E200\n" +
"l,L,0,16,12006,12,120000,1.26,6.0E200\n" +
"m,M,FALSE,17,12007,121,12000,1.27,7.0E200\n" +
"n,N,8,18,12008,122,1200,1.28,8.0E200\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //test types
        sa.clear();
        for (int col = 0; col < table.nColumns(); col++) 
            sa.add(table.getColumn(col).elementTypeString());
        results = sa.toString();
        expected = "String, String, String, byte, short, int, long, float, double";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read subset 
        table = new Table();
        table.allowRaggedRightInReadASCII = true;
        table.readASCII(fileName, String2.ISO_8859_1,
            "", "", 0, 1, "", 
            new String[]{"aByte"}, new double[]{14}, new double[]{16}, 
            new String[]{"aDouble","aString","aByte"}, true);  //load cols
        results = table.dataToString();
        expected = 
"aDouble,aString,aByte\n" +
",needs1space,\n" +
"4.0E200,j,14\n" +
"5.0E200,k,15\n" +
"6.0E200,l,16\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
    }


    /**
     * This is like the other readStandardTabbedASCII, but this one actually reads the 
     * data from the file.
     *
     * @throws Exception if trouble
     */
    public void readStandardTabbedASCII(String fullFileName, String loadColumns[], 
        boolean simplify) throws Exception {

        readStandardTabbedASCII(fullFileName, 
            File2.getDecompressedBufferedFileReader(fullFileName, null), 
            loadColumns, simplify); 
    }

    /**
     * This reads data from an array of tab-separated ASCII Strings.
     * This differs from readASCII in that a given field (but not the last field)
     * can have internal newlines and thus span multiple lines in the file.
     * Also, column names *must* all be on the first line and
     *  data *must* start on the second line. (There is no units line.)
     * <ul>
     * <li> If no exception is thrown, the file was successfully read.
     * <li> Missing values can be "" or "." or "NaN".
     * <li> All data rows must have the same number of data items. 
     * </ul>
     *
     * @param fileName for diagnostic messages only
     * @param linesReader to get the info from the data file.
     * @param loadColumns the names of the columns to be loaded 
     *     (perhaps in different order than in the file).
     *     If null, this will read all variables.
     * @param simplify 
     *    The data is initially read as Strings. 
     *    If this is set to 'true', the columns are simplified to their simplest type
     *      (e.g., to doubles, ... or bytes) so they store the data compactly.
     *       Date strings are left as strings. 
     *    If this is set to 'false', the columns are left as strings.
     * @throws Exception if trouble  (e.g., a specified loadColumn wasn't found,
     *    or unexpected number of items on a row)
     */
    public void readStandardTabbedASCII(String fileName, BufferedReader linesReader,
        String loadColumns[], boolean simplify) throws Exception {
        try {
        if (reallyVerbose) String2.log("Table.readStandardTabbedASCII " + fileName); 
        long time = System.currentTimeMillis();
        String errorInMethod = String2.ERROR + " in Table.readStandardTabbedASCII(" + fileName + "):\n";

        char colSeparator = '\t';
        int columnNamesLine = 0;  //must be >=0 or code needs to be changed
        int dataStartLine = 1;

        //clear the table
        clear();

        //read the file's column names (must be on one line)
        StringArray fileColumnNames = new StringArray();
        int linei = 0; //line# of next line to be read
        String oneLine = null;
        while (linei <= columnNamesLine) {
            oneLine = linesReader.readLine();
            linei++;
            if (oneLine == null)
                throw new SimpleException(errorInMethod + 
                    "unexpected end-of-file on line#" + (linei - 1)+ 
                    ", before columnNamesLine=" + columnNamesLine + ".");
        }
        oneLine = oneLine.trim();
        //break the lines into items
        String items[] = String2.split(oneLine, colSeparator);
        int nItems = items.length;
        int expectedNItems = nItems;
        for (int col = 0; col < nItems; col++) 
            fileColumnNames.add(items[col]);
        //if (reallyVerbose) String2.log("fileColumnNames=" + fileColumnNames);

        //identify the loadColumnNumbers
        int loadColumnNumbers[];
        if (loadColumns == null) {
            //load all
            loadColumnNumbers = new int[fileColumnNames.size()];
            for (int col = 0; col < fileColumnNames.size(); col++)
                loadColumnNumbers[col] = col;
        } else {
            loadColumnNumbers = new int[loadColumns.length];
            for (int col = 0; col < loadColumns.length; col++) {
                int po = fileColumnNames.indexOf(loadColumns[col], 0);
                if (po < 0)
                    throw new IllegalArgumentException(errorInMethod + 
                       "loadColumn '" + loadColumns[col] + "' not found.");
                loadColumnNumbers[col] = po;
            }
            //if (reallyVerbose) String2.log("loadColumnNumbers=" + String2.toCSSVString(loadColumnNumbers));
        }

        //generate the Table's columns which will be loaded
        //and create the primitiveArrays for loaded data
        StringArray loadColumnSA[] = new StringArray[loadColumnNumbers.length];
        for (int col = 0; col < loadColumnNumbers.length; col++) {
            loadColumnSA[col] = new StringArray(); 
            addColumn(fileColumnNames.get(loadColumnNumbers[col]), loadColumnSA[col]); 
        }

        //jump to dataStartLine  
        while (linei < dataStartLine) {
            oneLine = linesReader.readLine();
            linei++;
            if (oneLine == null)
                throw new SimpleException(errorInMethod + 
                    "unexpected end-of-file on line#" + (linei - 1)+ 
                    ", before dataStartLine=" + dataStartLine + ".");
        }

        //get the data
        int row = 0;
        if (debugMode) String2.log("expectedNItems=" + expectedNItems);
        if (debugMode) String2.log("row=" + row);
        READ_ROWS:
        while (true) { //read rows of data
            items = null;
            nItems = 0;
            while (nItems < expectedNItems) {
                oneLine = linesReader.readLine();
                linei++; row++;
                if (oneLine == null) { //end-of-file
                    if (nItems == 0)
                        break READ_ROWS; 
                    else throw new SimpleException(errorInMethod + 
                        "unexpected end-of-file on line#" + (linei - 1)+ 
                      ". Perhaps last row (and others?) had incorrect number of items.");
                }

                //break the lines into items
                String tItems[] = String2.split(oneLine, colSeparator);
                int ntItems = tItems.length;
                if (debugMode) String2.log("row=" + (row-1) + " ntItems=" + ntItems + " tItems=" + String2.toCSSVString(tItems));
                
                if (items == null) {
                    items = tItems; 
                } else {
                    //append next line 
                    String ttItems[] = new String[nItems + ntItems - 1];
                    System.arraycopy(items, 0, ttItems, 0, nItems);
                    //combine last field old line + newline + first field new line
                    ttItems[nItems - 1] += "\n" + tItems[0]; 
                    if (ntItems > 1) 
                        System.arraycopy(tItems, 1, ttItems, nItems, ntItems - 1);
                    items = ttItems;
                }
                nItems = items.length;
            }

            //too many items?
            if (nItems > expectedNItems)
                throw new RuntimeException(errorInMethod + 
                    "unexpected number of items ending on line #" + 
                       (dataStartLine + row + 1) + " (observed=" + nItems + 
                    ", expected=" + expectedNItems + "). [c]");            
          
            //store the data items
            for (int col = 0; col < loadColumnNumbers.length; col++) 
                loadColumnSA[col].add(
                    loadColumnNumbers[col] < 0? "" : 
                      items[loadColumnNumbers[col]]);
        }

        //simplify the columns
        if (simplify) 
            simplify();

        if (reallyVerbose) String2.log("  Table.readStandardTabbedASCII done. fileName=" + fileName + 
            " nColumns=" + nColumns() + " nRows=" + nRows() + 
            " TIME=" + (System.currentTimeMillis() - time) + "ms");
        } finally {
            linesReader.close();
        }
    }

    /**
     * This is like readColumnarASCII, but this one actually reads the 
     * data from the file.
     *
     * @param charset ISO-8859-1 (used if charset is null or "") or UTF-8
     * @throws Exception if trouble
     */
    public void readColumnarASCIIFile(String fullFileName, String charset, 
        String skipHeaderToRegex, String skipLinesRegex, int dataStartLine,
        String loadColumns[], int startPo[], int endPo[], PAType columnPAType[]) 
        throws Exception {

        BufferedReader br = File2.getDecompressedBufferedFileReader(fullFileName, charset);
        readColumnarASCII(fullFileName, br, skipHeaderToRegex, skipLinesRegex, dataStartLine,
            loadColumns, startPo, endPo, columnPAType);
    }

    /**
     * This reads data from fixed length ASCII Strings.
     * I.e., each data variable is stored in a specific, fixed substring of each row.
     * On a given line, if a variable's startPo is greater or equal to a line's length, 
     *    that variable is set to NaN or "". 
     * So blank lines and ragged right lines are acceptable.
     * Lines at the end of the file with length=0 are ignored (e.g., a trailing line).
     * If no exception is thrown, the file was successfully read.
     * Any previous columns/conent in the table is thrown away.
     *
     * @param fileName for diagnostic messages only
     * @param reader 
     * @param dataStartLine (0..)
     * @param loadColumns the names of the columns to be loaded 
     *     (perhaps in different order than in the file).
     *     The values won't be changed.
     * @param startPo the substring startPo for each loadColumn (0..)
     *     The values won't be changed.
     * @param endPo the substring endPo (exclusive) for each loadColumn (0..)
     *     The values won't be changed.
     * @param columnPAType the class (e.g., PAType.DOUBLE, PAType.STRING)
     *   for each column (or null to have ERDDAP auto simplify the columns).
     *   String values are trim'd.
     *   PAType.BOOLEAN is a special case: the string data will be parsed via 
     *      String2.parseBoolean()? 1 : 0.
     *   If already specified, the values won't be changed.
     * @throws Exception if trouble  
     */
    public void readColumnarASCII(String fileName, BufferedReader reader, 
        String skipHeaderToRegex, String skipLinesRegex, int dataStartLine,
        String loadColumns[], int startPo[], int endPo[], PAType columnPAType[]) 
        throws Exception {

        String msg = "  Table.readColumnarASCII " + fileName; 
        long time = System.currentTimeMillis();
        String errorInMethod = String2.ERROR + " in" + msg + ":\n";

        //clear everything
        clear();

        try {
            //validate parameters
            dataStartLine = Math.max(0, dataStartLine);
            int nCols = loadColumns.length;
            Test.ensureEqual(loadColumns.length, startPo.length, 
                errorInMethod + "loadColumns.length != startPo.length.");
            Test.ensureEqual(loadColumns.length, endPo.length, 
                errorInMethod + "loadColumns.length != endPo.length.");
            boolean simplify = columnPAType == null;
            if (simplify) {
                columnPAType = new PAType[nCols];
                Arrays.fill(columnPAType, PAType.STRING);
            }
            Test.ensureEqual(loadColumns.length, columnPAType.length, 
                errorInMethod + "loadColumns.length != columnPAType.length.");
            for (int col = 0; col < nCols; col++) {
                if (startPo[col] < 0)
                    throw new RuntimeException(errorInMethod + 
                        "For sourceName=" + loadColumns[col] +
                        ", startPo[" + col + "]=" + startPo[col] + ". It must be >=0.");
                if (startPo[col] >= endPo[col])
                    throw new RuntimeException(errorInMethod + 
                        "For sourceName=" + loadColumns[col] +
                        ", startPo[" + col + "]=" + startPo[col] + " >= " + 
                          "endPo[" + col + "]=" +   endPo[col] + ". startPo must be less than endPo.");
            }
            Pattern skipLinesPattern = skipLinesRegex != null && !skipLinesRegex.equals("")?
                 Pattern.compile(skipLinesRegex) : null;

            //create the columns
            PrimitiveArray pa[] = new PrimitiveArray[nCols];
            ByteArray arBool[] = new ByteArray[nCols]; //ByteArray (from boolean) if boolean, else null
            for (int col = 0; col < nCols; col++) {
                pa[col] = PrimitiveArray.factory(
                    columnPAType[col] == PAType.BOOLEAN? PAType.BYTE : columnPAType[col], 
                    128, false);
                addColumn(loadColumns[col], pa[col]);
                arBool[col] = columnPAType[col] == PAType.BOOLEAN? (ByteArray)(pa[col]) : null;
            }

            //skipHeaderToRegex
            int row = skipHeaderToRegex(skipHeaderToRegex, fileName, reader); //the number of rows read (1..)

            //get the data
            int logicalLine = -1; //0-based line as if skipHeader and skipLines were removed
            boolean firstErrorLogged = false;
            while (true) {
                String tLine = reader.readLine();
                row++;
                if (tLine == null) //end of file
                    break;
                if (skipLinesPattern != null && skipLinesPattern.matcher(tLine).matches())
                    continue;
                logicalLine++;
                if (logicalLine < dataStartLine)
                    continue;

                int tLength = tLine.length();
                if (tLength > 0) {
                    for (int col = 0; col < nCols; col++) {
                        String s = tLength > startPo[col]? 
                            tLine.substring(startPo[col], Math.min(tLength, endPo[col])).trim() : "";
                        if (columnPAType[col] == PAType.BOOLEAN)                     
                            arBool[col].addInt(String2.parseBooleanToInt(s));
                        else pa[col].addString(s);
                        //if (row < dataStartLine + 3) String2.log(">> row=" + row + " col=" + col + " s=" + s);
                    }
                } else if (!firstErrorLogged) {
                    String2.log("  WARNING: row #" + row + " had no data. (There may be other such rows.)");
                    firstErrorLogged = true;                        
                }
            }

            //simplify
            if (simplify)
                simplify();

            if (reallyVerbose) String2.log( 
                msg + " finished. nColumns=" + nColumns() + " nRows=" + row + 
                " TIME=" + (System.currentTimeMillis() - time) + "ms");
            

        } catch (Exception e) {
            if (!reallyVerbose) String2.log(msg + " failed.");
            throw e;

        } finally {
            try {reader.close();} catch (Exception e2) {}
        }
    }

    /** 
     * Test readColumnarASCII.
     *
     * @throws Exception if trouble
     */
    public static void testReadColumnarASCIIFile() throws Exception {
        
        String2.log("\nTable.testReadColumnarASCIIFile");
        String results, expected;
        StringArray sa = new StringArray();
        String fullFileName = String2.unitTestDataDir + "columnarAsciiWithComments.txt";
        String skipHeaderToRegex = "END OF HEADER.*";
        String skipLinesRegex = "%.*";
        String colNames[] = {
            "aDouble", "aString","aChar","aBoolean","aByte","aShort", "anInt","aLong","aFloat"};
        int start[] = {       
            66,         0,        9,      15,        24,     30,       37,     45,     57};
        int end[]   = {
            86,         9,        15,     24,        30,     37,       45,     57,     66};        
            
//012345678911234567892123456789312345678941234567895123456789612345678971234567898123456
//aString  aChar aBoolean aByte aShort anInt   aLong       aFloat   aDouble
//abc      a     true     24    24000  240000002400000000002.4      2.412345678987654   

        //read as Strings 
        PAType colPAType[] = new PAType[9];
        Arrays.fill(colPAType, PAType.STRING);
        Table table = new Table();
        table.readColumnarASCIIFile(fullFileName, "", 
            skipHeaderToRegex, skipLinesRegex, 3, colNames, start, end, colPAType);
        results = table.dataToString();
        expected = 
"aDouble,aString,aChar,aBoolean,aByte,aShort,anInt,aLong,aFloat\n" +
"2.412345678987654,abcdef,Ab,t,24,24000,24000000,240000000000,2.4\n" +
",short:,,,,,,,\n" +
"1e200,fg,F,true,11,12001,1200000,12000000000,1.21\n" +
"2e200,h,H,1,12,12002,120000,1200000000,1.22\n" +
"3e200,i,I,TRUE,13,12003,12000,120000000,1.23\n" +
"4e200,j,J,f,14,12004,1200,12000000,1.24\n" +
"5e200,k,K,false,15,12005,120,1200000,1.25\n" +
"6e200,l,L,0,16,12006,12,120000,1.26\n" +
"7e200,m,M,FALSE,17,12007,121,12000,1.27\n" +
"8e200,n,N,8,18,12008,122,1200,1.28\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //test types
        sa.clear();
        for (int col = 0; col < table.nColumns(); col++) 
            sa.add(table.getColumn(col).elementTypeString());
        results = sa.toString();
        expected = "String, String, String, String, String, String, String, String, String";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //simplify
        table.readColumnarASCIIFile(fullFileName, "", 
            skipHeaderToRegex, skipLinesRegex, 3, colNames, start, end, null);
        results = table.dataToString();
        expected = 
"aDouble,aString,aChar,aBoolean,aByte,aShort,anInt,aLong,aFloat\n" +
"2.412345678987654,abcdef,Ab,t,24,24000,24000000,240000000000,2.4\n" +
",short:,,,,,,,\n" +
"1.0E200,fg,F,true,11,12001,1200000,12000000000,1.21\n" +
"2.0E200,h,H,1,12,12002,120000,1200000000,1.22\n" +
"3.0E200,i,I,TRUE,13,12003,12000,120000000,1.23\n" +
"4.0E200,j,J,f,14,12004,1200,12000000,1.24\n" +
"5.0E200,k,K,false,15,12005,120,1200000,1.25\n" +
"6.0E200,l,L,0,16,12006,12,120000,1.26\n" +
"7.0E200,m,M,FALSE,17,12007,121,12000,1.27\n" +
"8.0E200,n,N,8,18,12008,122,1200,1.28\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //test types
        sa.clear();
        for (int col = 0; col < table.nColumns(); col++) 
            sa.add(table.getColumn(col).elementTypeString());
        results = sa.toString();
        expected = "double, String, String, String, byte, short, int, long, float";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read as types 
        colPAType = new PAType[] {
            PAType.DOUBLE, PAType.STRING, PAType.CHAR, PAType.BOOLEAN, PAType.BYTE, 
            PAType.SHORT, PAType.INT, PAType.LONG, PAType.FLOAT};
        table.readColumnarASCIIFile(fullFileName, "", 
            skipHeaderToRegex, skipLinesRegex, 3, colNames, start, end, colPAType);
        results = table.dataToString();
        expected = 
"aDouble,aString,aChar,aBoolean,aByte,aShort,anInt,aLong,aFloat\n" +
"2.412345678987654,abcdef,A,1,24,24000,24000000,240000000000,2.4\n" +
",short:,,,,,,,\n" +
"1.0E200,fg,F,1,11,12001,1200000,12000000000,1.21\n" +
"2.0E200,h,H,1,12,12002,120000,1200000000,1.22\n" +
"3.0E200,i,I,1,13,12003,12000,120000000,1.23\n" +
"4.0E200,j,J,0,14,12004,1200,12000000,1.24\n" +
"5.0E200,k,K,0,15,12005,120,1200000,1.25\n" +
"6.0E200,l,L,0,16,12006,12,120000,1.26\n" +
"7.0E200,m,M,0,17,12007,121,12000,1.27\n" +
"8.0E200,n,N,1,18,12008,122,1200,1.28\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //test types
        sa.clear();
        for (int col = 0; col < table.nColumns(); col++) 
            sa.add(table.getColumn(col).elementTypeString());
        results = sa.toString();
        expected = 
            "double, String, char, byte, byte, short, int, long, float";
        Test.ensureEqual(results, expected, "results=\n" + results);
    }


    /**
     * This reads an NCCSV .csv file from a URL or a file.
     * See https://coastwatch.pfeg.noaa.gov/erddap/download/NCCSV.html .
     * *SCALAR* and dataType attributes are processed and removed.
     * This just calls readNccsv(fullName, true).
     * 
     * @param fullName a URL or the name of a file
     * @throws Exception if trouble
     */
    public void readNccsv(String fullName) throws Exception {
        readNccsv(fullName, true);
    }

    /**
     * This reads an NCCSV .csv file from a URL or a file.
     * *SCALAR* and dataType attributes are processed and removed.
     * 
     * @param fullName a URL or the name of a file
     * @param readData If false, the PA for *SCALAR* vars will have 1 value; 
     *   all others will have 0 values.
     * @throws Exception if trouble
     */
    public void readNccsv(String fullName, boolean readData) throws Exception {
        BufferedReader bufferedReader = String2.isRemote(fullName)?
            SSR.getBufferedUrlReader(fullName) :
            new BufferedReader(new FileReader(fullName));      
        try {
            lowReadNccsv(fullName, readData, bufferedReader);
        } finally {
            bufferedReader.close();
        }
    }

    /**
     * This reads an NCCSV .csv file.
     * See https://coastwatch.pfeg.noaa.gov/erddap/download/NCCSV.html .
     * *SCALAR* and *DATA_TYPE* attributes are processed and removed.
     * 
     * @param fullName for error messages only
     * @param reader from a file or URL
     * @throws SimpleException if trouble  (but doesn't close the reader)
     */
    public void lowReadNccsv(String fullName, boolean readData, BufferedReader reader) {
        long time = System.currentTimeMillis();
        long lineNumber = 0;
        clear();
        String conventionsNotFound = String2.NCCSV_GLOBAL + ",Conventions,\"..., NCCSV-...\" not found on line 1.";

        try {

            //read the header
            String s;
            HashMap<String,Attributes> varNameAtts = new HashMap();
            HashSet<String> expectedDCols = new HashSet();

            while ((s = reader.readLine()) != null) {
                lineNumber++;
                if (s.startsWith(String2.NCCSV_END_METADATA))  //extra commas are ignored
                    break;

                //split the csv line
                StringArray sa = StringArray.simpleFromNccsv(s);
                if (sa.size() < 3) {
                    if (lineNumber == 1)
                        throw new SimpleException(conventionsNotFound);
                    continue;  //e.g., blank line or ignore content
                }
                String varName = String2.fromNccsvString(sa.get(0));
                String attName = String2.fromNccsvString(sa.get(1));
                sa.removeRange(0, 2);
                if (lineNumber == 1) { 
                    //ensure first line is as expected
                    if (!varName.equals(String2.NCCSV_GLOBAL) ||
                        !attName.equals("Conventions") ||
                        sa.get(0).indexOf("NCCSV-") < 0)
                        throw new SimpleException(conventionsNotFound);
                    globalAttributes.add(attName, String2.fromNccsvString(sa.get(0)));                 
                    continue;
                }
                if (sa.removeEmptyAtEnd() == 0) //extra commas are ignored
                    continue;

                //save the attributes
                PrimitiveArray pa = PrimitiveArray.parseNccsvAttributes(sa);
                if (varName.equals(String2.NCCSV_GLOBAL)) {
                    globalAttributes.add(attName, pa);
                } else {
                    Attributes atts = varNameAtts.get(varName);
                    if (atts == null) {
                        //create a new column with StringArray capacity=0 
                        //as a marker for a dummyPA which needs to be set by
                        //*DATA_TYPE* or *SCALAR*
                        atts = new Attributes();
                        varNameAtts.put(varName, atts);
                        addColumn(nColumns(), varName, new StringArray(0, false), atts); 
                    }

                    if (String2.NCCSV_DATATYPE.equals(attName)) {
                        //if *SCALAR* and *DATA_TYPE* specified, ignore *DATA_TYPE* 
                        int col = findColumnNumber(varName); //it will exist
                        if (columns.get(col).capacity() == 0) //i.e., the dummy pa
                            //new PrimitiveArray with capacity=1024
                            setColumn(col, PrimitiveArray.factory(
                                PAType.fromCohortStringCaseInsensitive(sa.get(0)), 
                                1024, false)); //active?
                        //String2.log(">> " + getColumnName(col) + " " + getColumn(col).elementType());
                        expectedDCols.add(varName);
                    } else if (String2.NCCSV_SCALAR.equals(attName)) {
                        if (pa.size() != 1)
                            throw new SimpleException(
                                "There must be just 1 value for a *SCALAR*. varName=" + varName +
                                " has " + pa.size() + ".");
                        setColumn(findColumnNumber(varName), pa);
                    } else {
                        //most common case is very fast
                        atts.add(attName, pa);
                    }
                }       
            }
            if (s == null)
                throw new SimpleException(String2.NCCSV_END_METADATA + NOT_FOUND_EOF);

            //check that all *DATA_TYPE*s were set
            int nc = nColumns();
            for (int c = 0; c < nc; c++) {
                //if (getColumn(c) instanceof CharArray) String2.log(">> col=" + c + " is a CharArray");
                if (columns.get(c).capacity() == 0)
                    throw new SimpleException(
                        "Neither *SCALAR* nor *DATA_TYPE* were specified for column=" + getColumnName(c));
            }

            //don't readData?
            if (!readData)
                return;

            //read the column names in the data section
            s = reader.readLine();
            lineNumber++;
            if (s == null)
                throw new SimpleException("Column names" + NOT_FOUND_EOF);
            StringArray sa = StringArray.simpleFromNccsv(s);
            if (sa.removeEmptyAtEnd() == 0)
                throw new SimpleException(
                    "No column names found names at start of data section.");
            sa.fromNccsv(); //un enquote any quoted strings
            int nDataCol = sa.size();
            PrimitiveArray dpa[] = new PrimitiveArray[nDataCol]; //so fast below
            boolean dpaIsLongArray[]   = new boolean[nDataCol];
            boolean dpaIsULongArray[]  = new boolean[nDataCol];
            boolean dpaIsCharArray[]   = new boolean[nDataCol];
            boolean dpaIsStringArray[] = new boolean[nDataCol];
            for (int dcol = 0; dcol < nDataCol; dcol++) {
                String varName = sa.get(dcol);
                if (!String2.isVariableNameSafe(varName))
                    throw new SimpleException("varName=" + varName + 
                        " is not a valid variableName.");
                int col = findColumnNumber(varName);
                if (col < 0)
                    throw new SimpleException(
                        "No attributes were specified for varName=" + 
                        varName + ". *DATA_TYPE* must be specified.");
                dpa[dcol] = columns.get(col);
                //is this a scalar column?!
                if (dpa[dcol].size() == 1)
                    throw new SimpleException(
                        "*SCALAR* variable=" + varName +
                        " must not be in the data section.");
                //is this column name in csv section twice?
                if (!expectedDCols.remove(varName))
                    throw new SimpleException(
                        "varName=" + varName + " occurs twice in the data section.");
                dpaIsLongArray[  dcol] = dpa[dcol] instanceof LongArray;
                dpaIsULongArray[ dcol] = dpa[dcol] instanceof ULongArray;
                dpaIsCharArray[  dcol] = dpa[dcol] instanceof CharArray;
                //if (dpaIsCharArray[dcol]) String2.log(">> dcol=" + dcol + " is CharArray");
                dpaIsStringArray[dcol] = dpa[dcol] instanceof StringArray;
            }
            //all expectedDCols were found?
            if (expectedDCols.size() > 0)
                throw new SimpleException(
                    "Some variables are missing in the data section: " +
                    String2.toCSSVString(expectedDCols.toArray()));

            //read the data
            StringBuilder warnings = new StringBuilder();
            while ((s = reader.readLine()) != null) {
                lineNumber++;
                if (s.startsWith(String2.NCCSV_END_DATA))  //extra commas are ignored
                    break;     
                try {
                    sa = StringArray.simpleFromNccsv(s);  
                } catch (Exception e) {
                    warnings.append("  line #" + lineNumber + ": " + e.getMessage() + "\n");
                    continue;
                }
                if (sa.size() < nDataCol) {  //extra commas are ignored
                    warnings.append(String2.WARNING + ": skipping line #" + lineNumber + 
                        ": unexpected number of items (observed=" + sa.size() + 
                           ", expected=" + nDataCol + "). [d]\n");
                    continue;
                }
                for (int dcol = 0; dcol < nDataCol; dcol++) {
                    String ts = sa.get(dcol);
                    if (dpaIsStringArray[dcol]) {
                        dpa[dcol].addString(String2.fromNccsvString(ts));
                    } else if (dpaIsCharArray[dcol]) {
                        ((CharArray)dpa[dcol]).add(String2.fromNccsvChar(ts));
                    } else if (dpaIsLongArray[dcol]) {
                        if (ts.endsWith("L"))
                            ts = ts.substring(0, ts.length() - 1);
                        dpa[dcol].addString(ts);
                    } else if (dpaIsULongArray[dcol]) {
                        if (ts.endsWith("uL"))
                            ts = ts.substring(0, ts.length() - 2);
                        dpa[dcol].addString(ts);
                    } else {
                        dpa[dcol].addString(ts);
                    }
                    //String2.log(">> dcol=" + dcol + " " + dpa[dcol].elementType() + " ts=" + ts + " -> " + dpa[dcol].getString(dpa[dcol].size() - 1));
                }
            }
            //if (s == null)  //NCCSV_END_DATA now optional
            //    throw new SimpleException(String2.NCCSV_END_DATA + NOT_FOUND_EOF);

            if (warnings.length() > 0) 
                String2.log(WARNING_BAD_LINE_OF_DATA_IN + "readNccsv(" + fullName + "):\n" +
                    warnings.toString());

            //expand scalars
            ensureColumnsAreSameSize_LastValue();

            String2.log("readNccsv(" + fullName + ") finished successfully.  nColumns=" + nColumns() + 
                " nRows=" + nRows() + " time=" + (System.currentTimeMillis() - time) + "ms");

        } catch (Exception e) {
            String2.log(MustBe.throwableToString(e));
            throw new SimpleException(String2.ERROR + " on line #" + lineNumber + 
                " in readNccsv(" + fullName + "): " + e.getMessage());
        }
    }

    /** This is like saveAsNccsv(true, true, Integer.MAX_VALUE) */
    public String saveAsNccsv() throws Exception {
        return saveAsNccsv(true, true, 0, Integer.MAX_VALUE);
    }

    /**
     * This saves this table in an NCCSV .csv file.
     * See https://coastwatch.pfeg.noaa.gov/erddap/download/NCCSV.html .
     * This can be a metadata table -- where scalar vars have 1 value and others have 0 values.
     * This doesn't close the writer at the end.
     * 
     * @param firstDataRow 0..
     * @param lastDataRow exclusive (use Integer.MAX_VALUE for all rows).
     *    If first = last, *END_METADATA* is the last thing in the file.
     * @throws Exception if trouble. No_data is not an error.
     */
    public String saveAsNccsv(boolean catchScalars, boolean writeMetadata, 
        int firstDataRow, int lastDataRow) throws Exception {

        StringWriter sw = new StringWriter(1024 + nColumns() * nRows() * 10);
        saveAsNccsv(catchScalars, writeMetadata, firstDataRow, lastDataRow, sw);
        return sw.toString();
    }


    /**
     * This writes this table to an nccsv file.
     * This writes to a temp file, then renames it into place.
     */
    public void saveAsNccsvFile(boolean catchScalars, boolean writeMetadata, 
        int firstDataRow, int lastDataRow, String fullFileName) throws Exception {

        BufferedWriter bw = null;
        int randomInt = Math2.random(Integer.MAX_VALUE);
        String msg = "  Table.saveAsNccsvFile " + fullFileName;
        long time = System.currentTimeMillis();

        try {
            bw = String2.getBufferedOutputStreamWriter88591(
                 new FileOutputStream(fullFileName + randomInt));
            saveAsNccsv(catchScalars, writeMetadata, firstDataRow, lastDataRow, bw);
            bw.close(); 
            bw = null;
            File2.rename(fullFileName + randomInt, fullFileName); //throws Exception if trouble
            if (reallyVerbose) String2.log(msg + " finished. TIME=" +
                (System.currentTimeMillis() - time));

        } catch (Exception e) {
            if (bw != null) {
                try {bw.close();} catch (Throwable t2) {}
            }
            File2.delete(fullFileName + randomInt);
            File2.delete(fullFileName);
            String2.log(msg);
            throw e;
        }
    }




    /**
     * This saves this table as an NCCSV .csv file.
     * This can be a metadata table -- where scalar vars have 1 value and others have 0 values.
     * This doesn't change representation of time (e.g., as seconds or as String).
     * This doesn't close the writer at the end.
     * 
     * @param catchScalars If true, this looks at the data for scalars (just 1 value).
     * @param writeMetadata If true, this writes the metadata section.
     *    This adds a *DATA_TYPE* or *SCALAR* attribute to each column.
     * @param firstDataRow 0..
     * @param lastDataRow exclusive.  Use Integer.MAX_VALUE to write all.
     * @param writer   At the end it is flushed, not closed.
     * @throws Exception if trouble. No_data is not an error.
     */
    public void saveAsNccsv(boolean catchScalars, boolean writeMetadata, 
        int firstDataRow, int lastDataRow, Writer writer) throws Exception {

        //figure out what's what
        int nc = nColumns();
        int nr = Integer.MAX_VALUE;  //shortest non-scalar pa (may be scalars have 1, others 0 or many)
        boolean isLong[]   = new boolean[nc];
        boolean isULong[]  = new boolean[nc];
        boolean isScalar[] = new boolean[nc];
        boolean allScalar = true;
        int firstNonScalar = nc;
        for (int c = 0; c < nc; c++) {
            PrimitiveArray pa = columns.get(c);
            isLong[c]  = pa.elementType() == PAType.LONG;
            isULong[c] = pa.elementType() == PAType.ULONG;
            isScalar[c] = catchScalars && pa.size() > 0 && pa.allSame();
            if (!isScalar[c]) {
                nr = Math.min(nr, pa.size());
                allScalar = false;
                if (firstNonScalar == nc)
                    firstNonScalar = c;
            }
        }

        //write metadata       
        if (writeMetadata) {
            writer.write(globalAttributes.toNccsvString(String2.NCCSV_GLOBAL));

            for (int c = 0; c < nc; c++) {
                //scalar
                if (isScalar[c]) {
                    writer.write(
                        String2.toNccsvDataString(getColumnName(c))       + "," + 
                        String2.NCCSV_SCALAR                              + "," + 
                        columns.get(c).subset(0, 1, 0).toNccsvAttString() + "\n");
                } else {
                    writer.write(
                        String2.toNccsvDataString(getColumnName(c)) + 
                        "," + String2.NCCSV_DATATYPE + "," + 
                        columns.get(c).elementTypeString() + "\n");
                }
                writer.write(columnAttributes(c).toNccsvString(getColumnName(c)));
            }
            writer.write("\n" + String2.NCCSV_END_METADATA + "\n");
            writer.flush();  //important
        }

        if (firstDataRow >= lastDataRow)
            return;

        //write the non-scalar column data
        if (!allScalar) {
            //column names
            for (int c = firstNonScalar; c < nc; c++) {
                if (isScalar[c])
                    continue;
                if (c > firstNonScalar)
                    writer.write(',');
                writer.write(String2.toNccsvAttString(getColumnName(c)));
            }
            writer.write("\n");

            //csv data
            int tnr = Math.min(nr, lastDataRow);
            for (int r = firstDataRow; r < tnr; r++) {
                for (int c = firstNonScalar; c < nc; c++) {
                    if (isScalar[c])
                        continue;

                    if (c > firstNonScalar)
                        writer.write(',');
                    String ts = columns.get(c).getNccsvDataString(r);
                    writer.write(ts);
                    if (isLong[c] && ts.length() > 0)
                        writer.write('L'); //special case not handled by getNccsvDataString
                    else if (isULong[c] && ts.length() > 0)
                        writer.write("uL"); //special case not handled by getNccsvDataString
                }
                writer.write("\n");
            }
        }
        writer.write(String2.NCCSV_END_DATA + "\n");
        writer.flush();  //important
    }
        

    /**
     * This tests readNccsv(), readNccsvMetadata(), 
     */
    public static void testNccsv() throws Exception {
        String2.log("\n**** Table.testNccsv()\n");
        String dir = String2.unitTestDataDir + "nccsv/";

        //read/write scalar
        String fileName = dir + "testScalar.csv";
        Table table = new Table();
        table.readNccsv(fileName); 
        for (int c = 0; c < table.nColumns(); c++) {
            Test.ensureTrue(table.columnAttributes(c).get(String2.NCCSV_SCALAR)  ==null, "col=" + c);
            Test.ensureTrue(table.columnAttributes(c).get(String2.NCCSV_DATATYPE)==null, "col=" + c);
        }
        String results = table.saveAsNccsv(); 
        String expected = 
"*GLOBAL*,Conventions,\"COARDS, CF-1.6, ACDD-1.3, NCCSV-1.1\"\n" +
"*GLOBAL*,cdm_trajectory_variables,ship\n" +
"*GLOBAL*,creator_email,bob.simons@noaa.gov\n" +
"*GLOBAL*,creator_name,Bob Simons\n" +
"*GLOBAL*,creator_type,person\n" +
"*GLOBAL*,creator_url,https://www.pfeg.noaa.gov\n" +
"*GLOBAL*,featureType,trajectory\n" +
"*GLOBAL*,infoUrl,https://coastwatch.pfeg.noaa.gov/erddap/download/NCCSV.html\n" +
"*GLOBAL*,institution,\"NOAA NMFS SWFSC ERD, NOAA PMEL\"\n" +
"*GLOBAL*,keywords,\"NOAA, sea, ship, sst, surface, temperature, trajectory\"\n" +
"*GLOBAL*,license,\"\"\"NCCSV Demonstration\"\" by Bob Simons and Steve Hankin is licensed under CC BY 4.0, https://creativecommons.org/licenses/by/4.0/ .\"\n" +
"*GLOBAL*,standard_name_vocabulary,CF Standard Name Table v55\n" +
"*GLOBAL*,subsetVariables,ship\n" +
"*GLOBAL*,summary,This is a paragraph or two describing the dataset.\n" +
"*GLOBAL*,title,NCCSV Demonstration\n" +
"ship,*SCALAR*,\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\"\n" +
"ship,cf_role,trajectory_id\n" +
"time,*DATA_TYPE*,String\n" +
"time,standard_name,time\n" +
"time,units,yyyy-MM-dd'T'HH:mm:ssZ\n" +
"lat,*DATA_TYPE*,double\n" +
"lat,units,degrees_north\n" +
"lon,*DATA_TYPE*,double\n" +
"lon,units,degrees_east\n" +
"status,*DATA_TYPE*,char\n" +
"status,comment,\"From http://some.url.gov/someProjectDocument , Table C\"\n" +
"testByte,*DATA_TYPE*,byte\n" +
"testByte,units,\"1\"\n" +
"testUByte,*DATA_TYPE*,ubyte\n" +
"testUByte,units,\"1\"\n" +
"testLong,*DATA_TYPE*,long\n" +
"testLong,units,\"1\"\n" +
"testULong,*DATA_TYPE*,ulong\n" +
"testULong,units,\"1\"\n" +
"sst,*DATA_TYPE*,float\n" +
"sst,actual_range,0.17f,23.58f\n" +
"sst,missing_value,99.0f\n" +
"sst,standard_name,sea_surface_temperature\n" +
"sst,testBytes,-128b,0b,127b\n" +
"sst,testChars,\"','\",\"'\"\"'\",\"'\\u20ac'\"\n" +
"sst,testDoubles,-1.7976931348623157E308d,0.0d,1.7976931348623157E308d\n" +
"sst,testFloats,-3.4028235E38f,0.0f,3.4028235E38f\n" +
"sst,testInts,-2147483648i,0i,2147483647i\n" +
"sst,testLongs,-9223372036854775808L,-9007199254740992L,9007199254740992L,9223372036854775806L,9223372036854775807L\n" +
"sst,testShorts,-32768s,0s,32767s\n" +
"sst,testStrings,\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\"\n" +
"sst,testUBytes,0ub,127ub,255ub\n" +
"sst,testUInts,0ui,2147483647ui,4294967295ui\n" +
"sst,testULongs,0uL,9223372036854775807uL,18446744073709551615uL\n" +
"sst,testUShorts,0us,32767us,65535us\n" +
"sst,units,degree_C\n" +
"\n" +
"*END_METADATA*\n" +
"time,lat,lon,status,testByte,testUByte,testLong,testULong,sst\n" +
"2017-03-23T00:45:00Z,28.0002,-130.2576,A,-128,0,-9223372036854775808L,0uL,10.9\n" +
"2017-03-23T01:45:00Z,28.0003,-130.3472,\\u20ac,0,127,-9007199254740992L,9223372036854775807uL,10.0\n" +
"2017-03-23T02:45:00Z,28.0001,-130.4305,\\t,126,254,9223372036854775806L,18446744073709551614uL,99.0\n" +
"2017-03-23T12:45:00Z,27.9998,-131.5578,\"\"\"\",,,,,\n" +
"2017-03-23T21:45:00Z,28.0003,-132.0014,\\u00fc,,,,,\n" +
"2017-03-23T23:45:00Z,28.0002,-132.1591,?,,,,,\n" +
"*END_DATA*\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        results = table.saveAsNccsv(false, true, 0, Integer.MAX_VALUE); //don't catch scalar
        expected = 
"*GLOBAL*,Conventions,\"COARDS, CF-1.6, ACDD-1.3, NCCSV-1.1\"\n" +
"*GLOBAL*,cdm_trajectory_variables,ship\n" +
"*GLOBAL*,creator_email,bob.simons@noaa.gov\n" +
"*GLOBAL*,creator_name,Bob Simons\n" +
"*GLOBAL*,creator_type,person\n" +
"*GLOBAL*,creator_url,https://www.pfeg.noaa.gov\n" +
"*GLOBAL*,featureType,trajectory\n" +
"*GLOBAL*,infoUrl,https://coastwatch.pfeg.noaa.gov/erddap/download/NCCSV.html\n" +
"*GLOBAL*,institution,\"NOAA NMFS SWFSC ERD, NOAA PMEL\"\n" +
"*GLOBAL*,keywords,\"NOAA, sea, ship, sst, surface, temperature, trajectory\"\n" +
"*GLOBAL*,license,\"\"\"NCCSV Demonstration\"\" by Bob Simons and Steve Hankin is licensed under CC BY 4.0, https://creativecommons.org/licenses/by/4.0/ .\"\n" +
"*GLOBAL*,standard_name_vocabulary,CF Standard Name Table v55\n" +
"*GLOBAL*,subsetVariables,ship\n" +
"*GLOBAL*,summary,This is a paragraph or two describing the dataset.\n" +
"*GLOBAL*,title,NCCSV Demonstration\n" +
"ship,*DATA_TYPE*,String\n" +
"ship,cf_role,trajectory_id\n" +
"time,*DATA_TYPE*,String\n" +
"time,standard_name,time\n" +
"time,units,yyyy-MM-dd'T'HH:mm:ssZ\n" +
"lat,*DATA_TYPE*,double\n" +
"lat,units,degrees_north\n" +
"lon,*DATA_TYPE*,double\n" +
"lon,units,degrees_east\n" +
"status,*DATA_TYPE*,char\n" +
"status,comment,\"From http://some.url.gov/someProjectDocument , Table C\"\n" +
"testByte,*DATA_TYPE*,byte\n" +
"testByte,units,\"1\"\n" +
"testUByte,*DATA_TYPE*,ubyte\n" +
"testUByte,units,\"1\"\n" +
"testLong,*DATA_TYPE*,long\n" +
"testLong,units,\"1\"\n" +
"testULong,*DATA_TYPE*,ulong\n" +
"testULong,units,\"1\"\n" +
"sst,*DATA_TYPE*,float\n" +
"sst,actual_range,0.17f,23.58f\n" +
"sst,missing_value,99.0f\n" +
"sst,standard_name,sea_surface_temperature\n" +
"sst,testBytes,-128b,0b,127b\n" +
"sst,testChars,\"','\",\"'\"\"'\",\"'\\u20ac'\"\n" +
"sst,testDoubles,-1.7976931348623157E308d,0.0d,1.7976931348623157E308d\n" +
"sst,testFloats,-3.4028235E38f,0.0f,3.4028235E38f\n" +
"sst,testInts,-2147483648i,0i,2147483647i\n" +
"sst,testLongs,-9223372036854775808L,-9007199254740992L,9007199254740992L,9223372036854775806L,9223372036854775807L\n" +
"sst,testShorts,-32768s,0s,32767s\n" +
"sst,testStrings,\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\"\n" +
"sst,testUBytes,0ub,127ub,255ub\n" +
"sst,testUInts,0ui,2147483647ui,4294967295ui\n" +
"sst,testULongs,0uL,9223372036854775807uL,18446744073709551615uL\n" +
"sst,testUShorts,0us,32767us,65535us\n" +
"sst,units,degree_C\n" +
"\n" +
"*END_METADATA*\n" +
"ship,time,lat,lon,status,testByte,testUByte,testLong,testULong,sst\n" +
"\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\",2017-03-23T00:45:00Z,28.0002,-130.2576,A,-128,0,-9223372036854775808L,0uL,10.9\n" +
"\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\",2017-03-23T01:45:00Z,28.0003,-130.3472,\\u20ac,0,127,-9007199254740992L,9223372036854775807uL,10.0\n" +
"\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\",2017-03-23T02:45:00Z,28.0001,-130.4305,\\t,126,254,9223372036854775806L,18446744073709551614uL,99.0\n" +
"\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\",2017-03-23T12:45:00Z,27.9998,-131.5578,\"\"\"\",,,,,\n" +
"\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\",2017-03-23T21:45:00Z,28.0003,-132.0014,\\u00fc,,,,,\n" +
"\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\",2017-03-23T23:45:00Z,28.0002,-132.1591,?,,,,,\n" +
"*END_DATA*\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //non scalar  
        fileName = dir + "sample.csv";
        table.readNccsv(fileName); 
        for (int c = 0; c < table.nColumns(); c++) {
            Test.ensureTrue(table.columnAttributes(c).get(String2.NCCSV_SCALAR)  ==null, "col=" + c);
            Test.ensureTrue(table.columnAttributes(c).get(String2.NCCSV_DATATYPE)==null, "col=" + c);
        }
        //String2.log(table.toString());

        results = table.saveAsNccsv(false, true, 0, Integer.MAX_VALUE); //don't catch scalars
        expected = 
"*GLOBAL*,Conventions,\"COARDS, CF-1.6, ACDD-1.3, NCCSV-1.1\"\n" +
"*GLOBAL*,cdm_trajectory_variables,ship\n" +
"*GLOBAL*,creator_email,bob.simons@noaa.gov\n" +
"*GLOBAL*,creator_name,Bob Simons\n" +
"*GLOBAL*,creator_type,person\n" +
"*GLOBAL*,creator_url,https://www.pfeg.noaa.gov\n" +
"*GLOBAL*,featureType,trajectory\n" +
"*GLOBAL*,infoUrl,https://coastwatch.pfeg.noaa.gov/erddap/download/NCCSV.html\n" +
"*GLOBAL*,institution,\"NOAA NMFS SWFSC ERD, NOAA PMEL\"\n" +
"*GLOBAL*,keywords,\"NOAA, sea, ship, sst, surface, temperature, trajectory\"\n" +
"*GLOBAL*,license,\"\"\"NCCSV Demonstration\"\" by Bob Simons and Steve Hankin is licensed under CC BY 4.0, https://creativecommons.org/licenses/by/4.0/ .\"\n" +
"*GLOBAL*,standard_name_vocabulary,CF Standard Name Table v55\n" +
"*GLOBAL*,subsetVariables,ship\n" +
"*GLOBAL*,summary,This is a paragraph or two describing the dataset.\n" +
"*GLOBAL*,title,NCCSV Demonstration\n" +
"ship,*DATA_TYPE*,String\n" +
"ship,cf_role,trajectory_id\n" +
"time,*DATA_TYPE*,String\n" +
"time,standard_name,time\n" +
"time,units,yyyy-MM-dd'T'HH:mm:ssZ\n" +
"lat,*DATA_TYPE*,double\n" +
"lat,units,degrees_north\n" +
"lon,*DATA_TYPE*,double\n" +
"lon,units,degrees_east\n" +
"status,*DATA_TYPE*,char\n" +
"status,comment,\"From http://some.url.gov/someProjectDocument , Table C\"\n" +
"testByte,*DATA_TYPE*,byte\n" +
"testByte,units,\"1\"\n" +
"testUByte,*DATA_TYPE*,ubyte\n" +
"testUByte,units,\"1\"\n" +
"testLong,*DATA_TYPE*,long\n" +
"testLong,units,\"1\"\n" +
"testULong,*DATA_TYPE*,ulong\n" +
"testULong,units,\"1\"\n" +
"sst,*DATA_TYPE*,float\n" +
"sst,actual_range,0.17f,23.58f\n" +
"sst,missing_value,99.0f\n" +
"sst,standard_name,sea_surface_temperature\n" +
"sst,testBytes,-128b,0b,127b\n" +
"sst,testChars,\"','\",\"'\"\"'\",\"'\\u20ac'\"\n" +
"sst,testDoubles,-1.7976931348623157E308d,0.0d,1.7976931348623157E308d\n" +
"sst,testFloats,-3.4028235E38f,0.0f,3.4028235E38f\n" +
"sst,testInts,-2147483648i,0i,2147483647i\n" +
"sst,testLongs,-9223372036854775808L,0L,9223372036854775807L\n" +
"sst,testShorts,-32768s,0s,32767s\n" +
"sst,testStrings,\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\"\n" +
"sst,testUBytes,0ub,127ub,255ub\n" +
"sst,testUInts,0ui,2147483647ui,4294967295ui\n" +
"sst,testULongs,0uL,9223372036854775807uL,18446744073709551615uL\n" +
"sst,testUShorts,0us,32767us,65535us\n" +
"sst,units,degree_C\n" +
"\n" +
"*END_METADATA*\n" +
"ship,time,lat,lon,status,testByte,testUByte,testLong,testULong,sst\n" +
"Bell M. Shimada,2017-03-23T00:45:00Z,28.0002,-130.2576,A,-128,0,-9223372036854775808L,0uL,10.9\n" +
"Bell M. Shimada,2017-03-23T01:45:00Z,28.0003,-130.3472,\\u20ac,0,127,-9007199254740992L,9223372036854775807uL,10.0\n" +
"Bell M. Shimada,2017-03-23T02:45:00Z,28.0001,-130.4305,\\t,126,254,9223372036854775806L,18446744073709551614uL,99.0\n" +
"Bell M. Shimada,2017-03-23T12:45:00Z,27.9998,-131.5578,\"\"\"\",,,,,\n" +
"Bell M. Shimada,2017-03-23T21:45:00Z,28.0003,-132.0014,\\u00fc,,,,,\n" +
"Bell M. Shimada,2017-03-23T23:45:00Z,28.0002,-132.1591,?,,,,,\n" +
"*END_DATA*\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        
        //just metadata
        fileName = dir + "sampleMetadata.csv";
        table = new Table();
        table.readNccsv(fileName, false); //readData?
        for (int c = 0; c < table.nColumns(); c++) {
            Test.ensureTrue(table.columnAttributes(c).get(String2.NCCSV_SCALAR)  ==null, "col=" + c);
            Test.ensureTrue(table.columnAttributes(c).get(String2.NCCSV_DATATYPE)==null, "col=" + c);
        }
        results = table.saveAsNccsv(true, true, 0, 0);  //catch scalar, writeMetadata, don't write data
        expected = 
"*GLOBAL*,Conventions,\"COARDS, CF-1.6, ACDD-1.3, NCCSV-1.1\"\n" +
"*GLOBAL*,cdm_trajectory_variables,ship\n" +
"*GLOBAL*,creator_email,bob.simons@noaa.gov\n" +
"*GLOBAL*,creator_name,Bob Simons\n" +
"*GLOBAL*,creator_type,person\n" +
"*GLOBAL*,creator_url,https://www.pfeg.noaa.gov\n" +
"*GLOBAL*,featureType,trajectory\n" +
"*GLOBAL*,infoUrl,https://coastwatch.pfeg.noaa.gov/erddap/download/NCCSV.html\n" +
"*GLOBAL*,institution,\"NOAA NMFS SWFSC ERD, NOAA PMEL\"\n" +
"*GLOBAL*,keywords,\"NOAA, sea, ship, sst, surface, temperature, trajectory\"\n" +
"*GLOBAL*,license,\"\"\"NCCSV Demonstration\"\" by Bob Simons and Steve Hankin is licensed under CC BY 4.0, https://creativecommons.org/licenses/by/4.0/ .\"\n" +
"*GLOBAL*,standard_name_vocabulary,CF Standard Name Table v55\n" +
"*GLOBAL*,subsetVariables,ship\n" +
"*GLOBAL*,summary,This is a paragraph or two describing the dataset.\n" +
"*GLOBAL*,title,NCCSV Demonstration\n" +
"ship,*SCALAR*,Bell M. Shimada\n" +
"ship,cf_role,trajectory_id\n" +
"time,*DATA_TYPE*,String\n" +
"time,standard_name,time\n" +
"time,units,yyyy-MM-dd'T'HH:mm:ssZ\n" +
"lat,*DATA_TYPE*,double\n" +
"lat,units,degrees_north\n" +
"lon,*DATA_TYPE*,double\n" +
"lon,units,degrees_east\n" +
"status,*DATA_TYPE*,char\n" +
"status,comment,\"From http://some.url.gov/someProjectDocument , Table C\"\n" +
"testLong,*DATA_TYPE*,long\n" +
"testLong,units,\"1\"\n" +
"sst,*DATA_TYPE*,float\n" +
"sst,actual_range,0.17f,23.58f\n" +
"sst,missing_value,99.0f\n" +
"sst,standard_name,sea_surface_temperature\n" +
"sst,testBytes,-128b,0b,127b\n" +
"sst,testChars,\"','\",\"'\"\"'\",\"'\\u20ac'\"\n" +
"sst,testDoubles,-1.7976931348623157E308d,0.0d,1.7976931348623157E308d\n" +
"sst,testFloats,-3.4028235E38f,0.0f,3.4028235E38f\n" +
"sst,testInts,-2147483648i,0i,2147483647i\n" +
"sst,testLongs,-9223372036854775808L,0L,9223372036854775807L\n" +
"sst,testShorts,-32768s,0s,32767s\n" +
"sst,testStrings,\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\"\n" +
"sst,testUBytes,0ub,127ub,255ub\n" +
"sst,testUInts,0ui,2147483647ui,4294967295ui\n" +
"sst,testULongs,0uL,9223372036854775807uL,18446744073709551615uL\n" +
"sst,testUShorts,0us,32767us,65535us\n" +
"sst,units,degree_C\n" +
"\n" +
"*END_METADATA*\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
    }

    public static void testNccsvInteractive() throws Exception {

        String dir = String2.unitTestDataDir + "nccsv/";

        //test round trip to spreadsheet and back
        //make a copy of sampleScalar
        String fileName = dir + "sampleExcel.csv";
        String2.writeToFile(fileName, 
            String2.directReadFrom88591File(dir + "testScalar.csv"));
        SSR.displayInBrowser("file://" + fileName);
        String2.pressEnterToContinue("\nIn Excel, use File : Save As : CSV : as sampleExcel.csv : yes : yes.");
        Table table = new Table();
        table.readNccsv(fileName); 
        for (int c = 0; c < table.nColumns(); c++) {
            Test.ensureTrue(table.columnAttributes(c).get(String2.NCCSV_SCALAR)  ==null, "col=" + c);
            Test.ensureTrue(table.columnAttributes(c).get(String2.NCCSV_DATATYPE)==null, "col=" + c);
        }
        String results = table.saveAsNccsv(); 
        String expected = 
"*GLOBAL*,Conventions,\"COARDS, CF-1.6, ACDD-1.3, NCCSV-1.1\"\n" +
"*GLOBAL*,cdm_trajectory_variables,ship\n" +
"*GLOBAL*,creator_email,bob.simons@noaa.gov\n" +
"*GLOBAL*,creator_name,Bob Simons\n" +
"*GLOBAL*,creator_type,person\n" +
"*GLOBAL*,creator_url,https://www.pfeg.noaa.gov\n" +
"*GLOBAL*,featureType,trajectory\n" +
"*GLOBAL*,infoUrl,https://coastwatch.pfeg.noaa.gov/erddap/download/NCCSV.html\n" +
"*GLOBAL*,institution,\"NOAA NMFS SWFSC ERD, NOAA PMEL\"\n" +
"*GLOBAL*,keywords,\"NOAA, sea, ship, sst, surface, temperature, trajectory\"\n" +
"*GLOBAL*,license,\"\"\"NCCSV Demonstration\"\" by Bob Simons and Steve Hankin is licensed under CC BY 4.0, https://creativecommons.org/licenses/by/4.0/ .\"\n" +
"*GLOBAL*,standard_name_vocabulary,CF Standard Name Table v55\n" +
"*GLOBAL*,subsetVariables,ship\n" +
"*GLOBAL*,summary,This is a paragraph or two describing the dataset.\n" +
"*GLOBAL*,title,NCCSV Demonstration\n" +
"ship,*SCALAR*,\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\"\n" +
"ship,cf_role,trajectory_id\n" +
"time,*DATA_TYPE*,String\n" +
"time,standard_name,time\n" +
"time,units,yyyy-MM-dd'T'HH:mm:ssZ\n" +
"lat,*DATA_TYPE*,double\n" +
"lat,units,degrees_north\n" +
"lon,*DATA_TYPE*,double\n" +
"lon,units,degrees_east\n" +
"status,*DATA_TYPE*,char\n" +
"status,comment,\"From http://some.url.gov/someProjectDocument , Table C\"\n" +
"testByte,*DATA_TYPE*,byte\n" +
"testByte,units,\"1\"\n" +
"testUByte,*DATA_TYPE*,ubyte\n" +
"testUByte,units,\"1\"\n" +
"testLong,*DATA_TYPE*,long\n" +
"testLong,units,\"1\"\n" +
"testULong,*DATA_TYPE*,ulong\n" +
"testULong,units,\"1\"\n" +
"sst,*DATA_TYPE*,float\n" +
"sst,actual_range,0.17f,23.58f\n" +
"sst,missing_value,99.0f\n" +
"sst,standard_name,sea_surface_temperature\n" +
"sst,testBytes,-128b,0b,127b\n" +
"sst,testChars,\"','\",\"'\"\"'\",\"'\\u20ac'\"\n" +
"sst,testDoubles,-1.7976931348623157E308d,0.0d,1.7976931348623157E308d\n" +
"sst,testFloats,-3.4028235E38f,0.0f,3.4028235E38f\n" +
"sst,testInts,-2147483648i,0i,2147483647i\n" +
"sst,testLongs,-9223372036854775808L,-9007199254740992L,9007199254740992L,9223372036854775806L,9223372036854775807L\n" +
"sst,testShorts,-32768s,0s,32767s\n" +
"sst,testStrings,\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\"\n" +
"sst,testUBytes,0ub,127ub,255ub\n" +
"sst,testUInts,0ui,2147483647ui,4294967295ui\n" +
"sst,testULongs,0uL,9223372036854775807uL,18446744073709551615uL\n" +
"sst,testUShorts,0us,32767us,65535us\n" +
"sst,units,degree_C\n" +
"\n" +
"*END_METADATA*\n" +
"time,lat,lon,status,testByte,testUByte,testLong,testULong,sst\n" +
"2017-03-23T00:45:00Z,28.0002,-130.2576,A,-128,0,-9223372036854775808L,0uL,10.9\n" +
"2017-03-23T01:45:00Z,28.0003,-130.3472,\\u20ac,0,127,-9007199254740992L,9223372036854775807uL,10.0\n" +
"2017-03-23T02:45:00Z,28.0001,-130.4305,\\t,126,254,9223372036854775806L,18446744073709551614uL,99.0\n" +
"2017-03-23T12:45:00Z,27.9998,-131.5578,\"\"\"\",,,,,\n" +
"BAD ROW: TOO FEW ITEMS,,,?,,\n" + //this disappears if I don't actually do Excel Save As
"2017-03-23T21:45:00Z,28.0003,-132.0014,\\u00fc,,,,,\n" +
"2017-03-23T23:45:00Z,28.0002,-132.1591,?,,,,,\n" +
"*END_DATA*\n";
        try {
            Test.ensureEqual(results, expected, "results=\n" + results);
        } catch (Exception e) {
            Test.knownProblem(
                "How to keep integer in string att as a string?!", 
                "If I don't actually do Excel 'Save As', the BAD ROW disappears.", e);
        }
    }

    /**
     * This saves this table as an NCCSV DataOutputStream.
     * This doesn't change representation of time (e.g., as seconds or as String).
     * This never calls dos.flush();
     * 
     * @param catchScalars If true, this looks at the data for scalars (just 1 value).
     * @param writeMetadata If true, this writes the metadata section.
     *    This adds a *DATA_TYPE* or *SCALAR* attribute to each column.
     * @param writeDataRows This is the maximum number of data rows to write.
     *   Use Integer.MAX_VALUE to write all.
     * @throws Exception if trouble. No_data is not an error.
     */
/* project not finished or tested
    public void writeNccsvDos(DataOutputStream dos, boolean catchScalars, 
        boolean writeMetadata, int writeDataRows) throws Exception {

        //figure out what's what
        int nc = nColumns();
        int nr = Integer.MAX_VALUE;  //shortest non-scalar pa (may be scalars have 1, others 0 or many)
        boolean isScalar[] = new boolean[nc];
        boolean allScalar = true;
        int firstNonScalar = nc;
        for (int c = 0; c < nc; c++) {
            PrimitiveArray pa = columns.get(c);
            isScalar[c] = catchScalars && pa.size() > 0 && pa.allSame();
            if (!isScalar[c]) {
                nr = Math.min(nr, pa.size());
                allScalar = false;
                if (firstNonScalar == nc)
                    firstNonScalar = c;
            }
        }

        //write metadata       
        if (writeMetadata) {
            globalAttributes.writeNccsvDos(dos, String2.NCCSV_GLOBAL);

            for (int c = 0; c < nc; c++) {
                //scalar
                if (isScalar[c]) {
                    String2.writeNccsvDos(dos, getColumnName(c));
                    String2.writeNccsvDos(dos, String2.NCCSV_SCALAR);
                    columns.get(c).subset(0, 1, 0).writeNccsvDos(dos);
                } else {
                    String2.writeNccsvDos(dos, getColumnName(c));
                    String2.writeNccsvDos(dos, String2.NCCSV_DATATYPE);
                    StringArray sa = new StringArray();
                    sa.add(columns.get(c).elementTypeString());
                    sa.writeNccsvDos(dos);
                }
                columnAttributes(c).writeNccsvDos(dos, getColumnName(c));
            }
            String2.writeNccsvDos(dos, String2.NCCSV_END_METADATA);
        }

        if (writeDataRows <= 0)
            return;

        //write the non-scalar column data
        if (!allScalar) {
            //column names
            for (int c = firstNonScalar; c < nc; c++) {
                if (isScalar[c])
                    continue;
                String2.writeNccsvDos(dos, getColumnName(c));
            }

            //csv data
            int tnr = Math.min(nr, writeDataRows);
            for (int r = 0; r < tnr; r++) {
                for (int c = firstNonScalar; c < nc; c++) {
                    if (isScalar[c])
                        continue;

                    columns.get(c).writeNccsvDos(dos, r);
                }
            }
        }
        //String2.writeNccsvDos(dos, String2.NCCSV_END_DATA);
    }
*/        


    /**
     * This gets data from the IOBIS website (http://www.iobis.org)
     * by mimicing the Advanced Search form 
     * (http://www.iobis.org/OBISWEB/ObisControllerServlet)
     * which has access to a cached version
     * of all the data from all of the obis data providers/resources.
     * So it lets you get results from all data providers/resources with one request.
     * This calls setObisAttributes().
     *
     * @param url I think the only valid url is IOBIS_URL.
     * @param genus  case sensitive, use null or "" for no preference 
     * @param species case sensitive, use null or "" for no preference
     * @param west the west boundary specified in degrees east, -180 to 180; use null or "" for no preference; 
     *     west must be &lt;= east.
     * @param east the east boundary specified in degrees east, -180 to 180; use null or "" for no preference; 
     * @param south the south boundary specified in degrees north; use null or "" for no preference; 
     *     south must be &lt;= north.
     * @param north the north boundary specified in degrees north; use null or "" for no preference;  
     * @param minDepth in meters; use null or "" for no preference; 
     *     positive equals down;
     *     minDepth must be &lt;= maxDepth.
     *     Depth has few values, so generally good not to specify minDepth or maxDepth.
     * @param maxDepth in meters; use null or "" for no preference; 
     * @param startDate an ISO date string (optional time, space or T connected), use null or "" for no preference; 
     *     startDate must be &lt;= endDate.
     *     The time part of the string is used.
     * @param endDate 
     * @param loadColumns which will follow LON,LAT,DEPTH,TIME,ID (which are always loaded) 
     *    (use null to load all).
     *    <br>DEPTH is from Minimumdepth
     *    <br>TIME is from Yearcollected|Monthcollected|Daycollected|Timeofday.
     *    <br>ID is Institutioncode:Collectioncode:Catalognumber.
     *    <br>The available column names are slightly different from obis schema 
     *    (and without namespace prefixes)!
     *   <p>The loadColumns storing data as Strings are:
     *   "Res_name", "Scientificname", "Institutioncode", 
     *   "Catalognumber", "Collectioncode", "Datelastmodified", 
     *   "Basisofrecord", "Genus", "Species", "Class", "Kingdom", "Ordername", "Phylum", 
     *   "Family", "Citation", "Source", "Scientificnameauthor", "Recordurl", 
     *   "Collector", "Locality", "Country", 
     *   "Fieldnumber", "Notes", 
     *   "Ocean", "Timezone", "State", 
     *   "County", "Collectornumber", 
     *   "Identifiedby", "Lifestage", "Depthrange", "Preparationtype", "Subspecies", 
     *   "Typestatus", "Sex", "Subgenus", 
     *   "Relatedcatalogitem", "Relationshiptype", 
     *   "Previouscatalognumber", "Samplesize".
     *
     *   <p>The loadColumns storing data as doubles are 
     *   "Latitude", "Longitude", "Minimumdepth", "Maximumdepth", "Slatitude",
     *   "Starttimecollected", "Endtimecollected", "Timeofday", "Slongitude", 
     *   "Coordinateprecision", "Seprecision",
     *   "Observedweight", "Elatitude", "Elongitude", "Temperature", 
     *   "Starttimeofday", "Endtimeofday".
     *
     *   <p>The loadColumns storing data as ints are
     *   "Yearcollected", "Monthcollected", "Daycollected", 
     *   "Startyearcollected", "Startmonthcollected", "Startdaycollected",
     *   "Julianday", "Startjulianday", 
     *   "Endyearcollected", "Endmonthcollected", "Enddaycollected",
     *   "Yearidentified", "Monthidentified", "Dayidentified",
     *   "Endjulianday", "Individualcount", "Observedindividualcount".
     * @throws Exception if trouble
     */
    public void readIobis(String url, String genus, String species, 
        String west, String east, String south, String north,
        String minDepth, String maxDepth,
        String startDate, String endDate, 
        String loadColumns[]) throws Exception {

        String errorInMethod = String2.ERROR + " in Table.readIobis: ";
        clear();
        if (genus     == null) genus = "";   
        if (species   == null) species = "";
        if (startDate == null) startDate = "";
        if (endDate   == null) endDate = "";
        if (minDepth  == null) minDepth = "";
        if (maxDepth  == null) maxDepth = "";
        if (south     == null) south = "";
        if (north     == null) north = "";
        if (west      == null) west = "";
        if (east      == null) east = "";
        //The website javascript tests that the constraints are supplied in pairs
        //(and NESW must be all or none).
        //I verified: if e.g., leave off north value, south is ignored.
        //So fill in missing values where needed.
        if (west.length() == 0) west = "-180";
        if (east.length() == 0) east = "180";
        if (south.length() == 0) south = "-90";
        if (north.length() == 0) north = "90";
        if (minDepth.length() >  0 && maxDepth.length() == 0) maxDepth = "10000";
        if (minDepth.length() == 0 && maxDepth.length() >  0) minDepth = "0";
        if (startDate.length() >  0 && endDate.length() == 0) endDate   = "2100-01-01";
        if (startDate.length() == 0 && endDate.length() >  0) startDate = "1500-01-01";
        //I HAVE NEVER GOTTEN STARTDATE ENDDATE REQUESTS TO WORK,
        //SO I DO THE TEST MANUALLY (BELOW) AFTER GETTING THE DATA.
        //convert iso date time format to their format e.g., 1983/12/31
        //if (startDate.length() > 10) startDate = startDate.substring(0, 10);
        //if (endDate.length()   > 10) endDate   = endDate.substring(0, 10);
        //startDate = String2.replaceAll(startDate, "-", "/"); 
        //endDate   = String2.replaceAll(endDate,   "-", "/");

        //submit the request
        String userQuery = //the part specified by the user
            "&genus="   + genus +   
            "&species=" + species +
            "&date1="   + "" + //startDate + 
            "&date2="   + "" + //endDate +       
            "&depth1="  + minDepth +     
            "&depth2="  + maxDepth +
            "&south="   + south + "&ss=N" +
            "&north="   + north + "&nn=N" + 
            "&west="    + west + "&ww=E" +   
            "&east="    + east + "&ee=E";  
        String glue = "?site=null&sbox=null&searchCategory=/AdvancedSearchServlet"; 
        if (reallyVerbose) String2.log("iobis url=" + url + glue + userQuery);
        String response = SSR.getUrlResponseStringUnchanged(url + glue + userQuery);
        //String2.log(response);

        //in the returned web page, search for .txt link, read into tTable
        int po2 = response.indexOf(".txt'); return false;\">.TXT</a>"); //changed just before 2007-09-10
        int po1 = po2 == -1? -1 : response.lastIndexOf("http://", po2);
        if (po1 < 0) {
            String2.log(errorInMethod + ".txt link not found in OBIS response; " +
                "probably because no data was found.\nresponse=" + response);
            return;
        }
        String url2 = response.substring(po1, po2 + 4);
        if (reallyVerbose) String2.log("url2=" + url2);

        //get the .txt file
        String dataLines = SSR.getUrlResponseStringUnchanged(url2);
        dataLines = String2.replaceAll(dataLines, '|', '\t');

        //read the data into a temporary table
        Table tTable = new Table();
        tTable.readASCII(url2, 
            new BufferedReader(new StringReader(dataLines)), 
            "", "", 0, 1, "", //skipHeaderToRegex, skipLinesRegex, columnNamesLine, dataStartLine, colSeparator
            null, null, null, //constraints
            null, false); //just load all the columns, and don't simplify
        dataLines = null;

        //immediatly remove 'index'
        if (tTable.getColumnName(0).equals("index"))
            tTable.removeColumn(0);

        //convert double columns to doubles, int columns to ints
        int nRows = tTable.nRows();
        int nCols = tTable.nColumns();
        //I wasn't super careful with assigning to Double or Int
        String doubleColumns[] = {"Latitude", "Longitude", "Minimumdepth", "Maximumdepth", "Slatitude",
            "Starttimecollected", "Endtimecollected", "Timeofday", "Slongitude", 
            "Coordinateprecision", "Seprecision",
            "Observedweight", "Elatitude", "Elongitude", "Temperature", 
            "Starttimeofday", "Endtimeofday"}; 
        String intColumns[] = {"Yearcollected", "Monthcollected", "Daycollected", 
            "Startyearcollected", "Startmonthcollected", "Startdaycollected",
            "Julianday", "Startjulianday", 
            "Endyearcollected", "Endmonthcollected", "Enddaycollected",
            "Yearidentified", "Monthidentified", "Dayidentified",
            "Endjulianday", "Individualcount", "Observedindividualcount"};
        for (int col = 0; col < nCols; col++) {
            String s = tTable.getColumnName(col);
            if (String2.indexOf(doubleColumns, s) >= 0)
                tTable.setColumn(col, new DoubleArray(tTable.getColumn(col)));
            if (String2.indexOf(intColumns, s) >= 0)
                tTable.setColumn(col, new IntArray(tTable.getColumn(col)));
        }

        //create and add x,y,z,t,id columns    (numeric cols forced to be doubles)
        addColumn(DataHelper.TABLE_VARIABLE_NAMES[0], new DoubleArray(tTable.findColumn("Longitude")));
        addColumn(DataHelper.TABLE_VARIABLE_NAMES[1], new DoubleArray(tTable.findColumn("Latitude")));
        addColumn(DataHelper.TABLE_VARIABLE_NAMES[2], new DoubleArray(tTable.findColumn("Minimumdepth")));
        DoubleArray tPA = new DoubleArray(nRows, false);
        addColumn(DataHelper.TABLE_VARIABLE_NAMES[3], tPA);
        StringArray idPA = new StringArray(nRows, false);
        addColumn(DataHelper.TABLE_VARIABLE_NAMES[4], idPA);
        PrimitiveArray yearPA      = tTable.findColumn("Yearcollected");
        PrimitiveArray monthPA     = tTable.findColumn("Monthcollected");
        PrimitiveArray dayPA       = tTable.findColumn("Daycollected");
        PrimitiveArray timeOfDayPA = tTable.findColumn("Timeofday");
//        PrimitiveArray timeZonePA = findColumn("Timezone"); //deal with ???
        //obis schema says to construct id as
        //"URN:catalog:[InstitutionCode]:[CollectionCode]:[CatalogNumber]"  but their example is more terse than values I see
        PrimitiveArray insPA       = tTable.findColumn("Institutioncode");
        PrimitiveArray colPA       = tTable.findColumn("Collectioncode");
        PrimitiveArray catPA       = tTable.findColumn("Catalognumber");
        for (int row = 0; row < nRows; row++) {
            //make the t value
            double seconds = Double.NaN;
            StringBuilder sb = new StringBuilder(yearPA.getString(row));
            if (sb.length() > 0) {
                String tMonth = monthPA.getString(row);
                if (tMonth.length() > 0) {
                    sb.append("-" + tMonth);  //month is 01 - 12 
                    String tDay = dayPA.getString(row);
                    if (tDay.length() > 0) {
                        sb.append("-" + tDay);
                    }
                }
                try { 
                    seconds = Calendar2.isoStringToEpochSeconds(sb.toString()); 
                    String tTime = timeOfDayPA.getString(row);  //decimal hours since midnight
                    int tSeconds = Math2.roundToInt(
                        String2.parseDouble(tTime) * Calendar2.SECONDS_PER_HOUR);
                    if (tSeconds < Integer.MAX_VALUE)
                        seconds += tSeconds;
                } catch (Exception e) {
                    if (verbose) String2.log("Table.readObis unable to parse date=" + sb);
                }
            }
            tPA.add(seconds);

            //make the id value
            idPA.add(insPA.getString(row) + ":" + colPA.getString(row) + ":" + catPA.getString(row));

        }

        //if loadColumns == null, make loadColumns with all the original column names ('index' already removed)
        if (loadColumns == null) 
            loadColumns = tTable.getColumnNames();   

        //add the loadColumns
        for (int col = 0; col < loadColumns.length; col++) 
            addColumn(loadColumns[col], tTable.findColumn(loadColumns[col]));

        //no more need for tTable
        tTable = null;

        //do startDate endDate test (if one is specified, both are)
        if (startDate.length() > 0) 
            subset(new int[]{3}, 
                new double[]{Calendar2.isoStringToEpochSeconds(startDate)}, 
                new double[]{Calendar2.isoStringToEpochSeconds(endDate)});

        //remove time=NaN rows? no, it gets rid of otherwise intesting data rows


        //setAttributes  (this sets the coordinate variables' axis, long_name, standard_name, and units)
//add column attributes from DigirDarwin.properties and DigirObis.properties?
        setObisAttributes(0,1,2,3, url, new String[]{"AdvancedQuery"}, userQuery);
   
    }

    /**
     * This sets obis attributes to this table.
     * Currently, this is more geared to the http://www.iobis.org/ portal
     * than it should be -- but I'm don't see how to generalize
     * for all possible DiGIR/Darwin/OBIS providers without a bigger
     * infrastructure for metadata info.
     * This correctly deals with attributes that have already been set.
     *
     * @param lonColumn or -1 if none
     * @param latColumn or -1 if none
     * @param depthColumn or -1 if none
     * @param timeColumn or -1 if none
     * @param url the url that was queried
     * @param resources the resources that were queried
     * @param querySummary a summary of the query
     */
    public void setObisAttributes(int lonColumn, int latColumn, int depthColumn,
        int timeColumn, String url, String resources[], String querySummary) {

        String courtesy = "OBIS, and the Darwin and OBIS Data Providers (" + 
            url + " : " + String2.toCSSVString(resources) + ")";
        String disCit = 
            "users acknowledge the OBIS disclaimer (http://www.iobis.org/data/policy/disclaimer/) " +
            "and agree to follow the OBIS citation policy (http://www.iobis.org/data/policy/citation/).";
        String agree = 
            //not appropriate if a non-iobis site is the source
            //but the intent and basic info is always appropriate
            "  By using data accessed from " + courtesy + ", " + disCit;
        setAttributes(lonColumn, latColumn, depthColumn, timeColumn,
            "Ocean Biogeographic Information System",  //boldTitle
            "Point", //cdmDataType 
            DataHelper.ERD_CREATOR_EMAIL, 
            DataHelper.ERD_CREATOR_NAME,
            DataHelper.ERD_CREATOR_URL,
            DataHelper.ERD_PROJECT,
            "OBIS_" + String2.md5Hex12(url + String2.toCSSVString(resources) + querySummary), 
            "GCMD Science Keywords",
            "Oceans > Marine Biology", //not correct if a darwin provider searched for non-oceanography data
            "http://www.iobis.org/ and " + url + " (" + String2.toCSSVString(resources) + ")", //references,   
            //summary  from http://www.iobis.org/about/     //not appropriate if non-obis
            "The Ocean Biogeographic Information System (OBIS) is the information " +
            "component of the Census of Marine Life (CoML), a growing network of " +
            "more than 1000 researchers in 73 nations engaged in a 10-year initiative " +
            "to assess and explain the diversity, distribution, and abundance of " +
            "life in the oceans - past, present, and future.  OBIS is a web-based " +
            "provider of global geo-referenced information on marine species. " +
            "We contain expert species level and habitat level databases and " +
            "provide a variety of spatial query tools for visualizing relationships " +
            "among species and their environment. OBIS strives to assess and " +
            "integrate biological, physical, and chemical oceanographic data from " +
            "multiple sources. Users of OBIS, including researchers, students, " +
            "and environmental managers, will gain a dynamic view of the " +
            "multi-dimensional oceanic world. You can explore this constantly " +
            "expanding and developing facility through the OBIS Portal (http://www.iobis.org/).", 

            courtesy, 
            null); //timeLongName

        //customize a little more
        globalAttributes.set("history", 
            DataHelper.addBrowserToHistory(
                Calendar2.getCurrentISODateStringZulu() + " " + 
                courtesy + " (" + querySummary + ")"));
      
        String license = globalAttributes.getString("license");
        if (license.indexOf(disCit) < 0)  //agree may change but disCit ending is constant
            globalAttributes.set("license", license + agree);
      
        String ack = globalAttributes.getString("acknowledgement");
        if (ack.indexOf(courtesy) < 0) 
            globalAttributes.set("acknowledgement", ack + ", " + courtesy);

        String lasConvention = "LAS Intermediate netCDF File";
        String con = globalAttributes.getString("Conventions");
        if (con.indexOf(lasConvention) < 0) 
            globalAttributes.set("Conventions", con + ", " + lasConvention);

    }
    


    /**
     * This tests readIObis.
     */
    public static void testIobis() throws Exception {
        verbose = true;
        reallyVerbose = true;
        String2.log("\n*** Table.testIobis");
        String testName = "c:/programs/digir/Macrocyctis.nc";
        Table table = new Table();
        if (true) {
            table.readIobis(IOBIS_URL, "Macrocystis", "", //String genus, String species, 
                "" , "", "53", "54", //String west, String east, String south, String north,
                "", "", //String minDepth, String maxDepth,
                "1970-01-01", "",//String iso startDate, String iso endDate, 
                new String[]{"Institutioncode", "Collectioncode", "Scientificname", "Temperature"}); //String loadColumns[])

//            table.saveAsFlatNc(testName, "row");
        } else {
            table.readFlatNc(testName, null, 1); //standardizeWhat
        }
        String2.log(table.toString());
        table.testObis5354Table();

    }

    /**
     * This tests that the values in this table are the expected results from 
     * the typical obis "Macrocystis", time 1970+, lat 53.. 54 request.
     */
    public void testObis5354Table() {
        String2.log("\n*** Table.testObis5354Table...");
        leftToRightSort(5);

        Test.ensureTrue(nRows() >= 30, "nRows=" + nRows());
        Test.ensureEqual(nColumns(), 9, "");
        if (String2.toCSSVString(getColumnNames()).equals(
            "LON, LAT, DEPTH, TIME, ID, " +
            "darwin:InstitutionCode, darwin:CollectionCode, " +
            "darwin:ScientificName, obis:Temperature")) {
        } else if (String2.toCSSVString(getColumnNames()).equals(
            "LON, LAT, DEPTH, TIME, ID, " +
            "Institutioncode, Collectioncode, " +
            "Scientificname, Temperature")) {
        } else throw new RuntimeException(
            "Unexpected col names: " + String2.toCSSVString(getColumnNames()));

        //!!!note that from GHMP request, rows of data are in pairs of almost duplicates
        //and CollectionCode includes 2 sources -- 1 I requested and another one (both served by GHMP?)
        //and Lat and Lon can be slightly different (e.g., row 60/61 lat)
        DoubleArray latCol = (DoubleArray)getColumn(1);
        double stats[] = latCol.calculateStats();
        Test.ensureTrue(stats[PrimitiveArray.STATS_MIN] >= 53, "min=" + stats[PrimitiveArray.STATS_MIN]);
        Test.ensureTrue(stats[PrimitiveArray.STATS_MAX] <= 54, "max=" + stats[PrimitiveArray.STATS_MAX]);
        Test.ensureEqual(stats[PrimitiveArray.STATS_N], nRows(), "");

        //test time > 0  (1970-01-01)
        DoubleArray timeCol = (DoubleArray)getColumn(3);
        stats = timeCol.calculateStats();
        Test.ensureTrue(stats[PrimitiveArray.STATS_MIN] >= 0, "min=" + stats[PrimitiveArray.STATS_MIN]);
        Test.ensureEqual(stats[PrimitiveArray.STATS_N], nRows(), "");

        DoubleArray lonCol = (DoubleArray)getColumn(0); //==0
        int row = lonCol.indexOf("-132.4223");  
        Test.ensureEqual(getDoubleData(0, row), -132.4223, "");
        Test.ensureEqual(getDoubleData(1, row), 53.292, "");
        Test.ensureEqual(getDoubleData(2, row), Double.NaN, "");
        Test.ensureEqual(getDoubleData(3, row), 347155200, "");
        Test.ensureEqual(getStringData(4, row), 
            "BIO:GHMP:10036-MACRINT", "");
        Test.ensureEqual(getStringData(5, row), "BIO", "");
        Test.ensureEqual(getStringData(6, row), "GHMP", "");
        Test.ensureEqual(getStringData(7, row), "Macrocystis integrifolia", "");
        Test.ensureEqual(getDoubleData(8, row), Double.NaN, "");
/* duplicates (described above) disappeared 2007-09-04
        row++;  
        Test.ensureEqual(getDoubleData(0, row), -132.4223, "");
        Test.ensureEqual(getDoubleData(1, row), 53.292, "");
        Test.ensureEqual(getDoubleData(2, row), Double.NaN, "");
        Test.ensureEqual(getDoubleData(3, row), 347155200, "");
        Test.ensureEqual(getStringData(4, row), 
            "Marine Fish Division, Fisheries and Oceans Canada:Gwaii Haanas Marine Algae:10036-MACRINT", "");
        Test.ensureEqual(getStringData(5, row), "Marine Fish Division, Fisheries and Oceans Canada", "");
        Test.ensureEqual(getStringData(6, row), "Gwaii Haanas Marine Algae", "");
        Test.ensureEqual(getStringData(7, row), "Macrocystis integrifolia", "");
        Test.ensureEqual(getDoubleData(8, row), Double.NaN, "");
*/
        row = lonCol.indexOf("-132.08171"); 
        Test.ensureEqual(getDoubleData(0, row), -132.08171, "");
        Test.ensureEqual(getDoubleData(1, row), 53.22519, "");
        Test.ensureEqual(getDoubleData(2, row), Double.NaN, "");
        Test.ensureEqual(getDoubleData(3, row), 63072000, "");
        Test.ensureEqual(getStringData(4, row), 
            "BIO:GHMP:198-MACRINT", "");
        Test.ensureEqual(getStringData(5, row), "BIO", "");
        Test.ensureEqual(getStringData(6, row), "GHMP", "");
        Test.ensureEqual(getStringData(7, row), "Macrocystis integrifolia", "");
        Test.ensureEqual(getDoubleData(8, row), Double.NaN, "");
/*
        row++; 
        Test.ensureEqual(getDoubleData(0, row), -132.08171, "");
        Test.ensureEqual(getDoubleData(1, row), 53.225193, "");
        Test.ensureEqual(getDoubleData(2, row), Double.NaN, "");
        Test.ensureEqual(getDoubleData(3, row), 63072000, "");
        Test.ensureEqual(getStringData(4, row), 
            "Marine Fish Division, Fisheries and Oceans Canada:Gwaii Haanas Marine Algae:198-MACRINT", "");
        Test.ensureEqual(getStringData(5, row), "Marine Fish Division, Fisheries and Oceans Canada", "");
        Test.ensureEqual(getStringData(6, row), "Gwaii Haanas Marine Algae", "");
        Test.ensureEqual(getStringData(7, row), "Macrocystis integrifolia", "");
        Test.ensureEqual(getDoubleData(8, row), Double.NaN, "");
*/

        String2.log("Table.testObis5354Table finished successfully.");
    }



    /**
     * This reads (and flattens) an xml document and populates this table.
     * See TableXmlHandler for details.
     *
     * @param xml the BufferedReader with access to the xml information
     * @param validate indicates if the XML parser should validate the xml
     *    against the .dtd specified by DOCTYPE in the file
     *    (see https://www.w3.org/TR/REC-xml#proc-types).
     *    true or false, the XMLReader always insists that the document be well formed.
     *    true or false, the XMLReader doesn't validate against a schema.
     *    The validate parameter will be ignored if the XMLReader doesn't support
     *    validation. (It is a good sign that, on Windows, the XMLReader that 
     *    comes with Java seems to support validation, or at least doesn't
     *    object to being told to validate the xml.)
     * @param rowElementXPath the element (XPath style) identifying a row, 
     *    e.g., /response/content/record.
     * @param rowElementAttributes are the attributes of the row element (e.g., "name")
     *    which will be noted and stored in columns of the table.
     *    May be null if none.
     *    (Other element's attributes are ignored.)
     *    E.g., <row name="Nate"> will cause a column called name to be
     *    created (with value "Nate" for this example row).
     * @param simplify 'true' simplifies the columns to their simplest type
     *    (without regard for what any schema says);
     *    'false' leaves the columns as StringArrays.
     * @throws Exception if trouble
     */
    public void readXml(Reader xml, boolean validate, String rowElementXPath, 
        String rowElementAttributes[], boolean simplify) throws Exception {

        //I had written an JDom + XPath version of readXml. It took 22 s! for a large file.
        //This SAX-based version takes 140 ms!
        //And this version requires a fraction of the memory
        //  (JDom version holds entire doc in place and with zillions of objects 
        //  pointing to parts).

        long time = System.currentTimeMillis();
        clear();  
        
        //get the XMLReader
        XMLReader xr = TableXmlHandler.getXmlReader(this, validate, rowElementXPath,
            rowElementAttributes);
        xr.parse(new InputSource(xml));

        //split gml:Point into gml:PointLat gml:pointLon
        //  <gml:Point>
        //    <gml:pos>38.796918000000062 -81.81363499999992</gml:pos>
        //  </gml:Point>
        //see https://en.wikipedia.org/wiki/Geography_Markup_Language#Coordinates
        int nr = nRows();
        String try1 = "/gml:Point/gml:pos";          //space separated
        String try2 = "/gml:Point/gml:coordinates";  //comma separated
        for (int col = nColumns() - 1; col >= 0; col--) {
            String colName = getColumnName(col);
            String match = colName.endsWith(try1)? try1 : 
                           colName.endsWith(try2)? try2 : null;
            if (match != null) {
                StringArray lat = (StringArray)getColumn(col);
                StringArray lon = new StringArray(nr, false);
                for (int row = 0; row < nr; row++) {
                    StringArray tsa = StringArray.wordsAndQuotedPhrases(lat.get(row));
                    lat.set(row, tsa.size() >= 1? tsa.get(0) : "");
                    lon.add(     tsa.size() >= 2? tsa.get(1) : "");
                }
                colName = colName.substring(0, colName.length() - (match.length() - 11)); //after 2nd / of match
                addColumn(col + 1, colName + "longitude", lon, new Attributes());
                setColumnName(col, colName + "latitude");
            }
        }           

        //simplify the columns
        if (simplify) 
            simplify();

        if (reallyVerbose) String2.log("  Table.readXml done. nColumns=" + nColumns() + 
            " nRows=" + nRows() + 
            " TIME=" + (System.currentTimeMillis() - time) + "ms");
    }

    /**
     * This tests readXml.
     */
    public static void testXml() throws Exception {
        String2.log("\n*** Table.testXml()");
        verbose = true;
        reallyVerbose = true;
        //TableXmlHandler.verbose = true;
        Table table = null;
        String xml, results, expected;

        //*** WFS
        table = new Table();
        BufferedReader reader = new BufferedReader(new FileReader(
            "c:/programs/mapserver/WVBoreholeResponse.xml"));
        try {
            table.readXml(reader, 
                false, //no validate since no .dtd
                "/wfs:FeatureCollection/wfs:member", //default tRowElementXPath,
                //was "/wfs:FeatureCollection/gml:featureMember",
                null, false);  //row attributes,  simplify
        } finally {
            reader.close();
        }
        results = table.dataToString(3);
        expected = 
"aasg:BoreholeTemperature/aasg:ObservationURI,aasg:BoreholeTemperature/aasg:WellName,aasg:BoreholeTemperature/aasg:APINo,aasg:BoreholeTemperature/aasg:HeaderURI,aasg:BoreholeTemperature/aasg:OtherName,aasg:BoreholeTemperature/aasg:Label,aasg:BoreholeTemperature/aasg:Operator,aasg:BoreholeTemperature/aasg:SpudDate,aasg:BoreholeTemperature/aasg:EndedDrillingDate,aasg:BoreholeTemperature/aasg:WellType,aasg:BoreholeTemperature/aasg:StatusDate,aasg:BoreholeTemperature/aasg:ReleaseDate,aasg:BoreholeTemperature/aasg:Field,aasg:BoreholeTemperature/aasg:County,aasg:BoreholeTemperature/aasg:State,aasg:BoreholeTemperature/aasg:UTM_E,aasg:BoreholeTemperature/aasg:UTM_N,aasg:BoreholeTemperature/aasg:LatDegree,aasg:BoreholeTemperature/aasg:LongDegree,aasg:BoreholeTemperature/aasg:SRS,aasg:BoreholeTemperature/aasg:LocationUncertaintyStatement,aasg:BoreholeTemperature/aasg:LocationUncertaintyRadius,aasg:BoreholeTemperature/aasg:DrillerTotalDepth,aasg:BoreholeTemperature/aasg:DepthReferencePoint,aasg:BoreholeTemperature/aasg:LengthUnits,aasg:BoreholeTemperature/aasg:WellBoreShape,aasg:BoreholeTemperature/aasg:TrueVerticalDepth,aasg:BoreholeTemperature/aasg:ElevationKB,aasg:BoreholeTemperature/aasg:ElevationDF,aasg:BoreholeTemperature/aasg:ElevationGL,aasg:BoreholeTemperature/aasg:FormationTD,aasg:BoreholeTemperature/aasg:BitDiameterTD,aasg:BoreholeTemperature/aasg:MaximumRecordedTemperature,aasg:BoreholeTemperature/aasg:MeasuredTemperature,aasg:BoreholeTemperature/aasg:CorrectedTemperature,aasg:BoreholeTemperature/aasg:TemperatureUnits,aasg:BoreholeTemperature/aasg:CirculationDuration,aasg:BoreholeTemperature/aasg:MeasurementProcedure,aasg:BoreholeTemperature/aasg:DepthOfMeasurement,aasg:BoreholeTemperature/aasg:MeasurementDateTime,aasg:BoreholeTemperature/aasg:MeasurementFormation,aasg:BoreholeTemperature/aasg:MeasurementSource,aasg:BoreholeTemperature/aasg:RelatedResource,aasg:BoreholeTemperature/aasg:CasingBottomDepthDriller,aasg:BoreholeTemperature/aasg:CasingTopDepth,aasg:BoreholeTemperature/aasg:CasingPipeDiameter,aasg:BoreholeTemperature/aasg:CasingWeight,aasg:BoreholeTemperature/aasg:CasingThickness,aasg:BoreholeTemperature/aasg:pH,aasg:BoreholeTemperature/aasg:InformationSource,aasg:BoreholeTemperature/aasg:Shape/gml:Point/latitude,aasg:BoreholeTemperature/aasg:Shape/gml:Point/longitude,aasg:BoreholeTemperature/aasg:LeaseName,aasg:BoreholeTemperature/aasg:LeaseOwner,aasg:BoreholeTemperature/aasg:LeaseNo,aasg:BoreholeTemperature/aasg:TimeSinceCirculation,aasg:BoreholeTemperature/aasg:Status,aasg:BoreholeTemperature/aasg:CommodityOfInterest,aasg:BoreholeTemperature/aasg:Function,aasg:BoreholeTemperature/aasg:Production,aasg:BoreholeTemperature/aasg:ProducingInterval,aasg:BoreholeTemperature/aasg:Notes\n" +
"http://resources.usgin.org/uri-gin/wvges/bhtemp/4705500185/,Dominion Appalachian Development Co.  Gilbert Bailey 1,4705500185,http://resources.usgin.org/uri-gin/wvges/well/api:4705500185/,Gilbert Bailey,4705500185,Dominion Appalachian Development Co.,1998-04-02T00:00:00,1998-04-13T00:00:00,Gas,1900-01-01T00:00:00,1900-01-01T00:00:00,Stovall Ridge,Mercer,West Virginia,0.0,0.0,37.4834349990001,-81.1519399999999,EPSG:4326,Location recorded as received from official permit application converted to NAD83 if required,0.0,4854,G.L.,ft,vertical,4854,0.0,0.0,2563,Up Devonian undiff:Berea to Lo Huron,0.0,0.0,87.8,0.0,F,0.0,Temperature log evaluated by WVGES staff for deepest stable log segment to extract data otherwise used given bottom hole temperature on log header if available,3550,1900-01-01T00:00:00,Big Lime,Well Temperature Log,TL | GR | DEN | NEL | IL | CAL | SL,0.0,0.0,0.0,0.0,0.0,0.0,West Virginia Geological and Economic Survey 2013,37.48343499900005,-81.15193999999991,,,,,,,,,,\n" +
"http://resources.usgin.org/uri-gin/wvges/bhtemp/4705500113/,\"Stonewall Gas Co., Inc.  State Conserv Comm 2\",4705500113,http://resources.usgin.org/uri-gin/wvges/well/api:4705500113/,Blue Jay Lumber Co,4705500113,\"Stonewall Gas Co., Inc.\",1991-09-20T00:00:00,1991-09-27T00:00:00,Gas,1900-01-01T00:00:00,1900-01-01T00:00:00,Rhodell,Mercer,West Virginia,0.0,0.0,37.530177999,-81.1708569999999,EPSG:4326,Location recorded as received from official permit application converted to NAD83 if required,0.0,4100,G.L.,ft,vertical,4100,0.0,0.0,2442,Price Fm & equivs,0.0,0.0,90,0.0,F,0.0,Temperature log evaluated by WVGES staff for deepest stable log segment to extract data otherwise used given bottom hole temperature on log header if available,3940,1900-01-01T00:00:00,,Well Temperature Log,TL | GR | DEN | NEL | IL | CAL | SL,0.0,0.0,0.0,0.0,0.0,0.0,West Virginia Geological and Economic Survey 2013,37.53017799900005,-81.1708569999999,,,,,,,,,,\n" +
"http://resources.usgin.org/uri-gin/wvges/bhtemp/4705500115/,\"Stonewall Gas Co., Inc.  State Conserv Comm 4\",4705500115,http://resources.usgin.org/uri-gin/wvges/well/api:4705500115/,Blue Jay Lumber Co 4,4705500115,\"Stonewall Gas Co., Inc.\",1992-12-01T00:00:00,1992-12-08T00:00:00,Gas,1900-01-01T00:00:00,1900-01-01T00:00:00,Rhodell,Mercer,West Virginia,0.0,0.0,37.533804999,-81.1585159999999,EPSG:4326,Location recorded as received from official permit application converted to NAD83 if required,0.0,4097,G.L.,ft,vertical,4097,0.0,0.0,2463,Price Fm & equivs,0.0,0.0,98,0.0,F,0.0,Temperature log evaluated by WVGES staff for deepest stable log segment to extract data otherwise used given bottom hole temperature on log header if available,3920,1900-01-01T00:00:00,,Well Temperature Log,TL | GR | DEN | NEL | IL | CAL | SL,0.0,0.0,0.0,0.0,0.0,0.0,West Virginia Geological and Economic Survey 2013,37.53380499900004,-81.15851599999991,,,,,,,,,,\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        
        //*** darwin core
//Lines are commented out to test some aspects of readXml.
xml = 
"<?xml version='1.0' encoding='utf-8' ?>\n" +
"<response\n" +
"  xmlns=\"http://digir.net/schema/protocol/2003/1.0\" \n" +
"  xmlns:xsd=\"https://www.w3.org/2001/XMLSchema\" \n" +
"  xmlns:xsi=\"https://www.w3.org/2001/XMLSchema-instance\" \n" +
"  xmlns:darwin=\"http://digir.net/schema/conceptual/darwin/2003/1.0\" \n" +
"  xmlns:obis=\"http://www.iobis.org/obis\" >\n" +
"<header>\n" +
"<version>$Revision: 1.12 $</version>\n" +
"</header>\n" + 
"<content><record>\n" +
//"<darwin:InstitutionCode>Marine Fish Division, Fisheries and Oceans Canada</darwin:InstitutionCode>\n" +
"<darwin:CollectionCode>Gwaii Haanas Marine Algae</darwin:CollectionCode>\n" +
"<darwin:CatalogNumber>100-MACRINT</darwin:CatalogNumber>\n" +
"<darwin:ScientificName>Macrocystis integrifolia</darwin:ScientificName>\n" +
"<darwin:ScientificName>sciName2</darwin:ScientificName>\n" +
"<darwin:Latitude>52.65172</darwin:Latitude>\n" +
"<darwin:Longitude>-131.66368</darwin:Longitude>\n" +
"<obis:Temperature xsi:nil='true'/>\n" +
"<parent>\n" +
"  <child1>child1data</child1>\n" +
"  <child2>child2data</child2>\n" +
"  <child2>child22data</child2>\n" +
"</parent>\n" +
"</record><record><darwin:InstitutionCode>BIO</darwin:InstitutionCode>\n" +
"<darwin:CollectionCode>GHMP</darwin:CollectionCode>\n" +
"<darwin:CatalogNumber>100-MACRINT</darwin:CatalogNumber>\n" +
"<darwin:ScientificName>Macrocystis integrifolia</darwin:ScientificName>\n" +
"<darwin:Latitude>52.65172</darwin:Latitude>\n" +
"<darwin:Longitude>-131.66368</darwin:Longitude>\n" +
"<obis:Temperature xsi:nil='true'/>\n" +
"</record><record>\n" +
//"<darwin:InstitutionCode>Marine Fish Division, Fisheries and Oceans Canada</darwin:InstitutionCode>\n" +
"<darwin:CollectionCode>Gwaii Haanas Marine Algae</darwin:CollectionCode>\n" +
"<darwin:CatalogNumber>10036-MACRINT</darwin:CatalogNumber>\n" +
"<darwin:ScientificName>Macrocystis integrifolia</darwin:ScientificName>\n" +
"<darwin:Latitude>53.292</darwin:Latitude>\n" +
"<darwin:Longitude>-132.4223</darwin:Longitude>\n" +
"<obis:Temperature xsi:nil='true'/>\n" +
"</record></content>\n" +
"<diagnostics>\n" +
"</diagnostics></response>\n";

//this doesn't test heirarchical elements
        table = new Table();
        reader = new BufferedReader(new StringReader(xml));
        try {
            table.readXml(reader, 
                false, //no validate since no .dtd
                "/response/content/record", null, true);
        } finally {
            reader.close();
        }
        table.ensureValid(); //throws Exception if not
        Test.ensureEqual(table.nRows(), 3, "");
        Test.ensureEqual(table.nColumns(), 10, "");
        Test.ensureEqual(table.getColumnName(0), "darwin:CollectionCode", "");
        Test.ensureEqual(table.getColumnName(1), "darwin:CatalogNumber", "");
        Test.ensureEqual(table.getColumnName(2), "darwin:ScientificName", "");
        Test.ensureEqual(table.getColumnName(3), "darwin:ScientificName2", "");
        Test.ensureEqual(table.getColumnName(4), "darwin:Latitude", "");
        Test.ensureEqual(table.getColumnName(5), "darwin:Longitude", "");
        //Test.ensureEqual(table.getColumnName(5), "obis:Temperature", ""); //no data, so no column
        Test.ensureEqual(table.getColumnName(6), "parent/child1", ""); 
        Test.ensureEqual(table.getColumnName(7), "parent/child2", ""); 
        Test.ensureEqual(table.getColumnName(8), "parent/child22", ""); 
        Test.ensureEqual(table.getColumnName(9), "darwin:InstitutionCode", "");
        Test.ensureEqual(table.getColumn(0).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(1).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(2).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(3).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(4).elementTypeString(), "float", "");
        Test.ensureEqual(table.getColumn(5).elementTypeString(), "double", "");
        Test.ensureEqual(table.getColumn(6).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(7).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(8).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(9).elementTypeString(), "String", "");
        Test.ensureEqual(table.getStringData(0, 2), "Gwaii Haanas Marine Algae", "");
        Test.ensureEqual(table.getStringData(1, 2), "10036-MACRINT", "");
        Test.ensureEqual(table.getStringData(2, 2), "Macrocystis integrifolia", "");
        Test.ensureEqual(table.getStringData(3, 0), "sciName2", "");
        Test.ensureEqual(table.getFloatData(4, 2), 53.292f, "");
        Test.ensureEqual(table.getFloatData(5, 2), -132.4223f, "");
        Test.ensureEqual(table.getStringData(6, 0), "child1data", "");
        Test.ensureEqual(table.getStringData(7, 0), "child2data", "");
        Test.ensureEqual(table.getStringData(8, 0), "child22data", "");
        Test.ensureEqual(table.getStringData(9, 0), "", "");
        Test.ensureEqual(table.getStringData(9, 1), "BIO", "");
        Test.ensureEqual(table.getStringData(9, 2), "", "");

//a subset of https://opendap.co-ops.nos.noaa.gov/stations/stationsXML.jsp
String stationsXml = 
"<?xml version=\"1.0\" encoding=\"ISO-8859-1\" ?>\n" +
"<stations xmlns=\"https://opendap.co-ops.nos.noaa.gov/stations/\" \n" +
"xmlns:xsi=\"https://www.w3.org/2001/XMLSchema-instance\" \n" +
"xsi:schemaLocation=\"https://opendap.co-ops.nos.noaa.gov/stations/   xml_schemas/stations.xsd\"> \n" +
"<station name=\"DART BUOY 46419\" ID=\"1600013\" >\n" +
"<metadata>\n" +
"<location>\n" +
"<lat> 48 28.7 N </lat>\n" +
"<long> 129 21.5 W </long>\n" +
"<state>   </state>\n" +
"</location>\n" +
"<date_established> 2003-01-01 </date_established>\n" +
"</metadata>\n" +
"</station>\n" +
"<station name=\"DART BUOY 46410\" ID=\"1600014\" >\n" +
"<metadata>\n" +
"<location>\n" +
"<lat> 57 29.9 N </lat>\n" +
"<long> 144 0.06 W </long>\n" +
"<state>   </state>\n" +
"</location>\n" +
"<date_established> 2001-01-01 </date_established>\n" +
"</metadata>\n" +
"</station>\n" +
"<station name=\"Magueyes Island\" ID=\"9759110\" >\n" +
"<metadata>\n" +
"<location>\n" +
"<lat> 17 58.3 N </lat>\n" +
"<long> 67 2.8 W </long>\n" +
"<state> PR </state>\n" +
"</location>\n" +
"<date_established> 1954-12-01 </date_established>\n" +
"</metadata>\n" +
"<parameter name=\"Water Level\" sensorID=\"A1\" DCP=\"1\" status=\"1\" />\n" +
"<parameter name=\"Winds\" sensorID=\"C1\" DCP=\"1\" status=\"1\" />\n" +
"<parameter name=\"Air Temp\" sensorID=\"D1\" DCP=\"1\" status=\"1\" />\n" +
"<parameter name=\"Water Temp\" sensorID=\"E1\" DCP=\"1\" status=\"1\" />\n" +
"<parameter name=\"Air Pressure\" sensorID=\"F1\" DCP=\"1\" status=\"1\" />\n" +
"</station>\n" +
"</stations>\n";
        table.clear();
        reader = new BufferedReader(new StringReader(stationsXml));
        try {
            table.readXml(reader, 
                false, //no validate since no .dtd
                "/stations/station", new String[]{"name", "ID"}, true);
        } finally {
            reader.close();
        }
        table.ensureValid(); //throws Exception if not
        String2.log(table.toString());
//    Row            name             ID metadata/locat metadata/locat metadata/date_ metadata/locat
//      0  DART BUOY 4641        1600013      48 28.7 N     129 21.5 W     2003-01-01
//      1  DART BUOY 4641        1600014      57 29.9 N     144 0.06 W     2001-01-01
//      2  Magueyes Islan        9759110      17 58.3 N       67 2.8 W     1954-12-01             PR
        Test.ensureEqual(table.nRows(), 3, "");
        Test.ensureEqual(table.nColumns(), 6, "");
        Test.ensureEqual(table.getColumnName(0), "name", "");
        Test.ensureEqual(table.getColumnName(1), "ID", "");
        Test.ensureEqual(table.getColumnName(2), "metadata/location/lat", "");
        Test.ensureEqual(table.getColumnName(3), "metadata/location/long", "");
        Test.ensureEqual(table.getColumnName(4), "metadata/date_established", "");
        Test.ensureEqual(table.getColumnName(5), "metadata/location/state", "");
        Test.ensureEqual(table.getColumn(0).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(1).elementTypeString(), "int", "");
        Test.ensureEqual(table.getColumn(2).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(3).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(4).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(5).elementTypeString(), "String", "");
        Test.ensureEqual(table.getStringData(0, 0), "DART BUOY 46419", "");
        Test.ensureEqual(table.getStringData(1, 0), "1600013", "");
        Test.ensureEqual(table.getStringData(2, 0), "48 28.7 N", "");
        Test.ensureEqual(table.getStringData(3, 0), "129 21.5 W", "");
        Test.ensureEqual(table.getStringData(4, 0), "2003-01-01", "");
        Test.ensureEqual(table.getStringData(5, 0), "", "");
        Test.ensureEqual(table.getStringData(0, 2), "Magueyes Island", "");
        Test.ensureEqual(table.getStringData(1, 2), "9759110", "");
        Test.ensureEqual(table.getStringData(2, 2), "17 58.3 N", "");
        Test.ensureEqual(table.getStringData(3, 2), "67 2.8 W", "");
        Test.ensureEqual(table.getStringData(4, 2), "1954-12-01", "");
        Test.ensureEqual(table.getStringData(5, 2), "PR", "");

        TableXmlHandler.verbose = false;

    }

    /**
     * This ensure the column exists and has the right name, then adds the value 
     * to the column, on currentRow.
     * If there are two or more tags for the same value, this won't throw an error and 
     * will keep the last value.
     *
     * @param colName   (e.g., aws:ob-date)
     * @param currentRow  0..
     * @param value
     * @param atts  If the column already exists, oldAtts.equals(atts) must be true
     *    or it throws a runtimeException.
     */
    private void addAwsColumnValue(String colName, int currentRow, 
        String value, Attributes atts) {

        if (colName.startsWith("aws:"))
            colName = colName.substring(4);
        int col = findColumnNumber(colName);
        PrimitiveArray pa = null;
        if (col < 0) {
            //add the column
            col = nColumns();
            pa = new StringArray();
            addColumn(col, colName, pa, atts);
        } else {
            pa = getColumn(col);
            //ensure atts are same as oldAtts
            Attributes oAtts = columnAttributes(col);
            String errorMsg = oAtts.testEquals(atts);
            if (errorMsg.length() > 0)
                throw new SimpleException("The attributes for column=" + colName + " aren't consistent:\n" +
                    errorMsg);
        }

        int panRows = pa.size();
        int nToAdd = currentRow - panRows + 1;
        if (nToAdd > 0)
            pa.addNStrings(nToAdd, "");
        pa.setString(currentRow, value);
    }

    /**
     * This reads all data from one Automatic Weather Station (AWS) file.
     * All columns will be String columns.
     * !!! Note, some units in the file have HTML character entities.  
     *   ERDDAP converts them to ASCII / UDUnits.
     *
     * @param fullFileName
     * @throws an exception if trouble (file not found, too much data, etc.).
     *  This won't throw an exception if no data.
     */
    public void readAwsXmlFile(String fullFileName) 
        throws Exception {

        long time = System.currentTimeMillis();
        clear(); // clear the table
        String msg = "  Table.readAwsXmlFile " + fullFileName;
        SimpleXMLReader xmlReader = new SimpleXMLReader(
            File2.getDecompressedBufferedInputStream(fullFileName), "aws:weather");
        try {
            GregorianCalendar gc = null;
            int currentRow = -1;
            Attributes atts = null;

            while (true) {
                xmlReader.nextTag();
                int nTags = xmlReader.stackSize();
                String tags = xmlReader.allTags();
                String content = xmlReader.content();

                if (tags.startsWith("<aws:weather><aws:ob>")) {
                    String endTags = tags.substring(21);

                    //  nTags == 2
                    if (nTags == 2) {
                        //This is the start of a new row of data.
                        currentRow++;
                        continue;
                    }

                    //  nTags == 3
                    if (nTags == 3) {
                        String tag2 = xmlReader.tag(2);
                        boolean isStartTag = !tag2.startsWith("/");

                        if (isStartTag) {
                            gc = null;
                            atts = xmlReader.attributes(); //must make a *new* Attributes object!

                            //attributes other than "units" become their own columns
                            //e.g., <aws:city-state zip="94123">  becomes city-state-zip
                            String[] attNames = xmlReader.attributeNames();                        
                            for (int ani = 0; ani < attNames.length; ani++) {
                                if (attNames[ani].equals("units")) {
                                    //fix common units problems in AWS xml files
                                    String tUnits = atts.getString("units");
                                    tUnits = String2.replaceAll(tUnits, "&deg;",  "degree_");
                                    //String2.pressEnterToContinue("tUnits=" + String2.annotatedString(tUnits));
                                    if (tUnits.indexOf('\u0094') >= 0) { //a Windows special "
                                        if (tag2.indexOf("pressure") >= 0) 
                                             tUnits = String2.replaceAll(tUnits, "\u0094", "inch_Hg");
                                        else tUnits = String2.replaceAll(tUnits, "\u0094", "inches");
                                    }
                                    if (tUnits.indexOf('"') >= 0) {
                                        if (tag2.indexOf("pressure") >= 0) 
                                             tUnits = String2.replaceAll(tUnits, "\"", "inch_Hg");
                                        else tUnits = String2.replaceAll(tUnits, "\"", "inches");
                                    }
                                    atts.set("units", tUnits);
                                    continue;
                                }
                                String s = atts.getString(attNames[ani]);
                                atts.remove(attNames[ani]);
                                if (attNames[ani].equals("xmlns:aws")) {
                                    //date start tags have this.  Just remove it.
                                } else {
                                    addAwsColumnValue(tag2 + "-" + attNames[ani], 
                                        currentRow, s, new Attributes());
                                }
                            }

                        } else { //is endTag
                            String value = xmlReader.content();
                            if (gc != null) {
                                value = "" + Calendar2.gcToEpochSeconds(gc);  
                                atts.add("units", "seconds since 1970-01-01T00:00:00Z");
                            }
                            addAwsColumnValue(tag2.substring(1), //remove leading /
                                currentRow, value, atts);
                        }
                        continue;
                    }

                    //  nTags == 4
                    if (nTags == 4) {
                        //dates 
                        //<aws:ob-date>
                        //  <aws:year number="2012" />
                        String tag3 = xmlReader.tag(3);
                        if (tag3.startsWith("/"))
                            continue;
                        if (tag3.equals("aws:year")) {
                            if (gc == null)
                                gc = Calendar2.newGCalendarZulu(0);
                            int ti = String2.parseInt(xmlReader.attributeValue("number"));
                            if (ti != Integer.MAX_VALUE)
                                gc.set(Calendar2.YEAR, ti);
                        } else if (tag3.equals("aws:month")) {
                            if (gc == null)
                                gc = Calendar2.newGCalendarZulu(0);
                            int ti = String2.parseInt(xmlReader.attributeValue("number"));
                            if (ti != Integer.MAX_VALUE)
                                gc.set(Calendar2.MONTH, ti - 1);  //0..
                        } else if (tag3.equals("aws:day")) {
                            if (gc == null)
                                gc = Calendar2.newGCalendarZulu(0);
                            int ti = String2.parseInt(xmlReader.attributeValue("number"));
                            if (ti != Integer.MAX_VALUE)
                                gc.set(Calendar2.DATE, ti); //of month
                        } else if (tag3.equals("aws:hour")) {
                            if (gc == null)
                                gc = Calendar2.newGCalendarZulu(0);
                            int ti = String2.parseInt(xmlReader.attributeValue("hour-24"));
                            if (ti != Integer.MAX_VALUE)
                                gc.set(Calendar2.HOUR, ti);
                        } else if (tag3.equals("aws:minute")) {
                            if (gc == null)
                                gc = Calendar2.newGCalendarZulu(0);
                            int ti = String2.parseInt(xmlReader.attributeValue("number"));
                            if (ti != Integer.MAX_VALUE)
                                gc.set(Calendar2.MINUTE, ti);
                        } else if (tag3.equals("aws:second")) {
                            if (gc == null)
                                gc = Calendar2.newGCalendarZulu(0);
                            int ti = String2.parseInt(xmlReader.attributeValue("number"));
                            if (ti != Integer.MAX_VALUE)
                                gc.set(Calendar2.SECOND, ti);
                        } else if (tag3.equals("aws:time-zone")) {
                            if (gc == null)
                                gc = Calendar2.newGCalendarZulu(0);
                            int ti = String2.parseInt(xmlReader.attributeValue("offset"));
                            if (ti != Integer.MAX_VALUE)
                                gc.add(Calendar2.HOUR, -ti);  
                        }
                        continue;
                    }


                } else if (nTags == 0 || tags.equals("</aws:weather>")) {
                    xmlReader.close();
                    xmlReader = null;
                    break;
                }
            }
            makeColumnsSameSize();
            if (reallyVerbose) 
                msg += " finished, nRows=" + nRows() +
                    " time=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            if (xmlReader != null)
                xmlReader.close();
            if (reallyVerbose) String2.log(msg);
        }
    }

    /** Test readAwsXmlFile.   Automatic Weather Station
     *
     * @throws Exception if trouble
     */
    public static void testReadAwsXmlFile() throws Exception {
        String2.log("\nTable.testReadAwsXmlFile");
        Table table = new Table();
        table.readAwsXmlFile(String2.unitTestDataDir + "aws/xml/SNFLS-2012-11-03T20_30_01Z.xml");
        String results = table.toString();
        String expected = 
"{\n" +
"dimensions:\n" +
"\trow = 1 ;\n" +
"\tob-date_strlen = 11 ;\n" +
"\tstation-id_strlen = 5 ;\n" +
"\tstation_strlen = 13 ;\n" +
"\tcity-state-zip_strlen = 5 ;\n" +
"\tcity-state_strlen = 17 ;\n" +
"\tsite-url_strlen = 0 ;\n" +
"\taux-temp_strlen = 2 ;\n" +
"\taux-temp-rate_strlen = 1 ;\n" +
"\tdew-point_strlen = 2 ;\n" +
"\televation_strlen = 1 ;\n" +
"\tfeels-like_strlen = 2 ;\n" +
"\tgust-time_strlen = 11 ;\n" +
"\tgust-direction_strlen = 1 ;\n" +
"\tgust-speed_strlen = 1 ;\n" +
"\thumidity_strlen = 2 ;\n" +
"\thumidity-high_strlen = 3 ;\n" +
"\thumidity-low_strlen = 2 ;\n" +
"\thumidity-rate_strlen = 2 ;\n" +
"\tindoor-temp_strlen = 2 ;\n" +
"\tindoor-temp-rate_strlen = 4 ;\n" +
"\tlight_strlen = 4 ;\n" +
"\tlight-rate_strlen = 4 ;\n" +
"\tmoon-phase-moon-phase-img_strlen = 12 ;\n" +
"\tmoon-phase_strlen = 2 ;\n" +
"\tpressure_strlen = 4 ;\n" +
"\tpressure-high_strlen = 5 ;\n" +
"\tpressure-low_strlen = 5 ;\n" +
"\tpressure-rate_strlen = 5 ;\n" +
"\train-month_strlen = 4 ;\n" +
"\train-rate_strlen = 1 ;\n" +
"\train-rate-max_strlen = 1 ;\n" +
"\train-today_strlen = 1 ;\n" +
"\train-year_strlen = 4 ;\n" +
"\ttemp_strlen = 4 ;\n" +
"\ttemp-high_strlen = 2 ;\n" +
"\ttemp-low_strlen = 2 ;\n" +
"\ttemp-rate_strlen = 3 ;\n" +
"\tsunrise_strlen = 13 ;\n" +
"\tsunset_strlen = 13 ;\n" +
"\twet-bulb_strlen = 6 ;\n" +
"\twind-speed_strlen = 1 ;\n" +
"\twind-speed-avg_strlen = 1 ;\n" +
"\twind-direction_strlen = 3 ;\n" +
"\twind-direction-avg_strlen = 1 ;\n" +
"variables:\n" +
"\tchar ob-date(row, ob-date_strlen) ;\n" +
"\t\tob-date:units = \"seconds since 1970-01-01T00:00:00Z\" ;\n" +
"\tchar station-id(row, station-id_strlen) ;\n" +
"\tchar station(row, station_strlen) ;\n" +
"\tchar city-state-zip(row, city-state-zip_strlen) ;\n" +
"\tchar city-state(row, city-state_strlen) ;\n" +
"\tchar site-url(row, site-url_strlen) ;\n" +
"\tchar aux-temp(row, aux-temp_strlen) ;\n" +
"\t\taux-temp:units = \"degree_F\" ;\n" +
"\tchar aux-temp-rate(row, aux-temp-rate_strlen) ;\n" +
"\t\taux-temp-rate:units = \"degree_F\" ;\n" +
"\tchar dew-point(row, dew-point_strlen) ;\n" +
"\t\tdew-point:units = \"degree_F\" ;\n" +
"\tchar elevation(row, elevation_strlen) ;\n" +
"\t\televation:units = \"ft\" ;\n" +
"\tchar feels-like(row, feels-like_strlen) ;\n" +
"\t\tfeels-like:units = \"degree_F\" ;\n" +
"\tchar gust-time(row, gust-time_strlen) ;\n" +
"\t\tgust-time:units = \"seconds since 1970-01-01T00:00:00Z\" ;\n" +
"\tchar gust-direction(row, gust-direction_strlen) ;\n" +
"\tchar gust-speed(row, gust-speed_strlen) ;\n" +
"\t\tgust-speed:units = \"mph\" ;\n" +
"\tchar humidity(row, humidity_strlen) ;\n" +
"\t\thumidity:units = \"%\" ;\n" +
"\tchar humidity-high(row, humidity-high_strlen) ;\n" +
"\t\thumidity-high:units = \"%\" ;\n" +
"\tchar humidity-low(row, humidity-low_strlen) ;\n" +
"\t\thumidity-low:units = \"%\" ;\n" +
"\tchar humidity-rate(row, humidity-rate_strlen) ;\n" +
"\tchar indoor-temp(row, indoor-temp_strlen) ;\n" +
"\t\tindoor-temp:units = \"degree_F\" ;\n" +
"\tchar indoor-temp-rate(row, indoor-temp-rate_strlen) ;\n" +
"\t\tindoor-temp-rate:units = \"degree_F\" ;\n" +
"\tchar light(row, light_strlen) ;\n" +
"\tchar light-rate(row, light-rate_strlen) ;\n" +
"\tchar moon-phase-moon-phase-img(row, moon-phase-moon-phase-img_strlen) ;\n" +
"\tchar moon-phase(row, moon-phase_strlen) ;\n" +
"\tchar pressure(row, pressure_strlen) ;\n" +
"\t\tpressure:units = \"inch_Hg\" ;\n" +
"\tchar pressure-high(row, pressure-high_strlen) ;\n" +
"\t\tpressure-high:units = \"inch_Hg\" ;\n" +
"\tchar pressure-low(row, pressure-low_strlen) ;\n" +
"\t\tpressure-low:units = \"inch_Hg\" ;\n" +
"\tchar pressure-rate(row, pressure-rate_strlen) ;\n" +
"\t\tpressure-rate:units = \"inch_Hg/h\" ;\n" +
"\tchar rain-month(row, rain-month_strlen) ;\n" +
"\t\train-month:units = \"inches\" ;\n" +
"\tchar rain-rate(row, rain-rate_strlen) ;\n" +
"\t\train-rate:units = \"inches/h\" ;\n" +
"\tchar rain-rate-max(row, rain-rate-max_strlen) ;\n" +
"\t\train-rate-max:units = \"inches/h\" ;\n" +
"\tchar rain-today(row, rain-today_strlen) ;\n" +
"\t\train-today:units = \"inches\" ;\n" +
"\tchar rain-year(row, rain-year_strlen) ;\n" +
"\t\train-year:units = \"inches\" ;\n" +
"\tchar temp(row, temp_strlen) ;\n" +
"\t\ttemp:units = \"degree_F\" ;\n" +
"\tchar temp-high(row, temp-high_strlen) ;\n" +
"\t\ttemp-high:units = \"degree_F\" ;\n" +
"\tchar temp-low(row, temp-low_strlen) ;\n" +
"\t\ttemp-low:units = \"degree_F\" ;\n" +
"\tchar temp-rate(row, temp-rate_strlen) ;\n" +
"\t\ttemp-rate:units = \"degree_F\" ;\n" +
"\tchar sunrise(row, sunrise_strlen) ;\n" +
"\t\tsunrise:units = \"seconds since 1970-01-01T00:00:00Z\" ;\n" +
"\tchar sunset(row, sunset_strlen) ;\n" +
"\t\tsunset:units = \"seconds since 1970-01-01T00:00:00Z\" ;\n" +
"\tchar wet-bulb(row, wet-bulb_strlen) ;\n" +
"\t\twet-bulb:units = \"degree_F\" ;\n" +
"\tchar wind-speed(row, wind-speed_strlen) ;\n" +
"\t\twind-speed:units = \"mph\" ;\n" +
"\tchar wind-speed-avg(row, wind-speed-avg_strlen) ;\n" +
"\t\twind-speed-avg:units = \"mph\" ;\n" +
"\tchar wind-direction(row, wind-direction_strlen) ;\n" +
"\tchar wind-direction-avg(row, wind-direction-avg_strlen) ;\n" +
"\n" +
"// global attributes:\n" +
"}\n" +
"ob-date,station-id,station,city-state-zip,city-state,site-url,aux-temp,aux-temp-rate,dew-point,elevation,feels-like,gust-time,gust-direction,gust-speed,humidity,humidity-high,humidity-low,humidity-rate,indoor-temp,indoor-temp-rate,light,light-rate,moon-phase-moon-phase-img,moon-phase,pressure,pressure-high,pressure-low,pressure-rate,rain-month,rain-rate,rain-rate-max,rain-today,rain-year,temp,temp-high,temp-low,temp-rate,sunrise,sunset,wet-bulb,wind-speed,wind-speed-avg,wind-direction,wind-direction-avg\n" +
"1.3519746E9,SNFLS,Exploratorium,94123,\"San Francisco, CA\",,32,0,54,0,67,1.3519746E9,E,8,63,100,63,-6,90,+4.6,67.9,-0.3,mphase16.gif,82,30.1,30.14,30.06,-0.01,0.21,0,0,0,1.76,66.9,67,52,3.8,1.351953497E9,1.351991286E9,59.162,0,2,ENE,E\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        Test.ensureEqual(Calendar2.epochSecondsToIsoStringTZ(1.3519746E9),   "2012-11-03T20:30:00Z", "");
        Test.ensureEqual(Calendar2.epochSecondsToIsoStringTZ(1.3519746E9),   "2012-11-03T20:30:00Z", "");
        Test.ensureEqual(Calendar2.epochSecondsToIsoStringTZ(1.351953497E9), "2012-11-03T14:38:17Z", "");
        Test.ensureEqual(Calendar2.epochSecondsToIsoStringTZ(1.351991286E9), "2012-11-04T01:08:06Z", "");
    }

    /**
     * This writes the table's data attributes (as if it were a DODS Sequence) 
     * to the outputStream as an DODS DAS (see www.opendap.org, DAP 2.0, 7.2.1).
     * Note that the table does needs columns (and their attributes),
     * but it doesn't need any rows of data.
     * See writeDAS.
     *
     * <p>CharArray columns appear as String columns in DAP.
     *
     * @param outputStream the outputStream to receive the results (will be encoded as ISO-8859-1).
     *    Afterwards, it is flushed, not closed.
     * @param sequenceName  e.g., "bottle_data_2002"
     * @throws Exception  if trouble. 
     */
    public void saveAsDAS(OutputStream outputStream, String sequenceName) throws Exception {

        if (reallyVerbose) String2.log("  Table.saveAsDAS"); 
        long time = System.currentTimeMillis();
        //DAP 2.0 section 3.2.3 says US-ASCII (7bit), so might as well go for compatible common 8bit
        Writer writer = String2.getBufferedOutputStreamWriter88591(outputStream); 
        writeDAS(writer, sequenceName, false);

        //diagnostic
        if (reallyVerbose)
            String2.log("  Table.saveAsDAS done. TIME=" + 
                (System.currentTimeMillis() - time) + "ms");
    }

    /**
     * This writes the table's data attributes (as if it were a DODS Sequence) 
     * to the outputStream as an DODS DAS (see www.opendap.org, DAP 2.0, 7.2.1).
     * Note that the table does needs columns (and their attributes),
     * but it doesn't need any rows of data.
     * E.g. from https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_bottle.das
<pre>
Attributes {
    bottle_data_2002 {
        date {
            String long_name "Date";
        }
        ship {
            String long_name "Ship";
        }
        day {
            String long_name "Day";
        }
        year {
            String long_name "Year";
        }
        lat {
            String long_name "Latitude";
        }
        lon {
            String long_name "Longitude";
        }
        chl_a_total {
            String long_name "Chlorophyll-a";
        }
    }
}
</pre> 
     *
     * <p>CharArray columns appear as String columns in DAP.
     *
     * @param writer the Writer to receive the results.
     *    Afterwards, it is flushed, not closed.
     * @param sequenceName  e.g., "bottle_data_2002"
     * @param encodeAsHtml if true, characters like &lt; are converted to their 
     *    character entities.
     * @throws Exception  if trouble. 
     */
    public void writeDAS(Writer writer, String sequenceName, boolean encodeAsHtml) throws Exception {

        writer.write("Attributes {" + OpendapHelper.EOL); //see EOL definition for comments
        writer.write(" " + XML.encodeAsHTML(sequenceName, encodeAsHtml) + " {" + OpendapHelper.EOL); //see EOL definition for comments
        for (int v = 0; v < nColumns(); v++) 
            OpendapHelper.writeToDAS(getColumnName(v), getColumn(v).elementType(),
                columnAttributes(v), writer, encodeAsHtml); 
        writer.write(" }" + OpendapHelper.EOL); //see EOL definition for comments 

        //how do global attributes fit into opendap view of attributes?
        OpendapHelper.writeToDAS(
            "NC_GLOBAL", //DAP 2.0 spec doesn't talk about global attributes, was "GLOBAL"; ncBrowse and netcdf-java treat NC_GLOBAL as special case
            PAType.DOUBLE, //isUnsigned doesn't apply to global atts. double won't trigger "_Unsigned"
            globalAttributes, writer, encodeAsHtml);
        writer.write("}" + OpendapHelper.EOL); //see EOL definition for comments 
        writer.flush(); //essential
    }


    /**
     * This writes the table's data structure (as if it were a DODS Sequence) 
     * to the outputStream as an DODS DDS (see www.opendap.org, DAP 2.0, 7.2.2).
     * Note that the table does needs columns (and their attributes),
     * but it doesn't need any rows of data.
     * E.g. from https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_bottle.dds
     <pre>
Dataset {
    Sequence {
        String date;
        String ship;
        Byte month;
        Byte day;
        Int16 year;
        Int16 time;
        Float64 lat;
        Float64 lon;
        Float64 chl_a_total;
    } bottle_data_2002;
} bottle_data_2002; </pre>
     * 
     * <p>CharArray columns appear as String columns in DAP.
     *
     * @param outputStream the outputStream to receive the results.
     *    Afterwards, it is flushed, not closed.
     * @param sequenceName  e.g., "bottle_data_2002"
     * @throws Exception  if trouble. 
     */
    public void saveAsDDS(OutputStream outputStream, String sequenceName) throws Exception {

        if (reallyVerbose) String2.log("  Table.saveAsDDS"); 
        long time = System.currentTimeMillis();
        //DAP 2.0 section 3.2.3 says US-ASCII (7bit), so might as well go for compatible common 8bit
        Writer writer = String2.getBufferedOutputStreamWriter88591(outputStream);  

        int nColumns = nColumns();
        writer.write("Dataset {" + OpendapHelper.EOL); //see EOL definition for comments
        writer.write("  Sequence {" + OpendapHelper.EOL); //see EOL definition for comments
        for (int v = 0; v < nColumns; v++) {
            PrimitiveArray pa = getColumn(v);
            writer.write("    " + OpendapHelper.getAtomicType(pa.elementType()) +
                " " + getColumnName(v) + ";" + OpendapHelper.EOL); //see EOL definition for comments
        }
        writer.write("  } " + sequenceName + ";" + OpendapHelper.EOL); //see EOL definition for comments 
        writer.write("} " + sequenceName + ";" + OpendapHelper.EOL); //see EOL definition for comments 
        writer.flush(); //essential

        if (reallyVerbose)
            String2.log("  Table.saveAsDDS done. TIME=" + 
                (System.currentTimeMillis() - time) + "ms");
    }


    /**
     * This writes the table's data structure (as if it were a DODS Sequence) 
     * to the outputStream as DODS ASCII data (which is not defined in DAP 2.0,
     * but which is very close to saveAsDODS below).
     * This mimics https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_bottle.asc?lon,ship,cast,t0,NO3&lon<-125.7
     * 
     * <p>This sends missing values as is.
     * This doesn't call convertToFakeMissingValues. Do it beforehand if you need to.
     * 
     * @param outputStream the outputStream to receive the results.
     *    Afterwards, it is flushed, not closed.
     * @param sequenceName  e.g., "erd_opendap_globec_bottle"
     * @throws Exception  if trouble. 
     */
    public void saveAsDodsAscii(OutputStream outputStream, String sequenceName) throws Exception {

        if (reallyVerbose) String2.log("  Table.saveAsDodsAscii"); 
        long time = System.currentTimeMillis();
        
        //write the dds    //DAP 2.0, 7.2.3
        saveAsDDS(outputStream, sequenceName);  

        //write the connector  
        Writer writer = String2.getBufferedOutputStreamWriter88591(outputStream); 
        writer.write("---------------------------------------------" + OpendapHelper.EOL); //see EOL definition for comments

        //write the column names
        int nColumns = nColumns();
        int nRows = nRows();
        boolean isCharOrString[] = new boolean[nColumns];
        for (int col = 0; col < nColumns; col++) {
            isCharOrString[col] = 
                getColumn(col).elementType() == PAType.CHAR ||
                getColumn(col).elementType() == PAType.STRING;
            writer.write(getColumnName(col) +
                (col == nColumns - 1? OpendapHelper.EOL : ", "));
        }

        //write the data  //DAP 2.0, 7.3.2.3
        //write elements of the sequence, in dds order
        for (int row = 0; row < nRows; row++) {
            for (int col = 0; col < nColumns; col++) {
                String s = getColumn(col).getString(row);
                if (isCharOrString[col]) 
                    //see DODS Appendix A, quoted-string. 
                    //It just talks about " to \", but Json format is implied and better
                    s = String2.toJson(s);
                writer.write(s + (col == nColumns - 1? OpendapHelper.EOL : ", "));
            }
        }

        writer.flush(); //essential

        if (reallyVerbose)
            String2.log("  Table.saveAsDodsAscii done. TIME=" + 
                (System.currentTimeMillis() - time) + "ms");
    }


    /**
     * This writes the table's data structure (as if it were a DODS Sequence) 
     * to the outputStream as an DODS DataDDS (see www.opendap.org, DAP 2.0, 7.2.3).
     *
     * <p>This sends missing values as is.
     * This doesn't call convertToFakeMissingValues. Do it beforehand if you need to.
     * 
     * @param outputStream the outputStream to receive the results.
     *    Afterwards, it is flushed, not closed.
     * @param sequenceName  e.g., "erd_opendap_globec_bottle"
     * @throws Exception  if trouble. 
     */
    public void saveAsDODS(OutputStream outputStream, String sequenceName) throws Exception {
        if (reallyVerbose) String2.log("  Table.saveAsDODS"); 
        long time = System.currentTimeMillis();

        //write the dds    //DAP 2.0, 7.2.3
        saveAsDDS(outputStream, sequenceName);  

        //write the connector  //DAP 2.0, 7.2.3
        //see EOL definition for comments
        outputStream.write((OpendapHelper.EOL + "Data:" + OpendapHelper.EOL).getBytes()); 

        //write the data  //DAP 2.0, 7.3.2.3
        //write elements of the sequence, in dds order
        int nColumns = nColumns();
        int nRows = nRows();
        DataOutputStream dos = new DataOutputStream(outputStream);
        for (int row = 0; row < nRows; row++) {
            dos.writeInt(0x5A << 24); //start of instance
            for (int col = 0; col < nColumns; col++) 
                getColumn(col).externalizeForDODS(dos, row);
        }
        dos.writeInt(0xA5 << 24); //end of sequence; so if nRows=0, this is all that is sent

        dos.flush(); //essential

        if (reallyVerbose)
            String2.log("  Table.saveAsDODS done. TIME=" + 
                (System.currentTimeMillis() - time) + "ms");
    }


    /**
     * This is like the other saveAsHtml, but saves to a UTF-8 file.
     *
     * @param fullFileName the complete file name (including directory and
     *    extension, usually ".htm" or ".html").
     */
    public void saveAsHtml(String fullFileName, 
        String preTableHtml, String postTableHtml, 
        String otherClasses, String bgColor, int border, boolean writeUnits, int timeColumn, 
        boolean needEncodingAsHtml, boolean allowWrap) throws Exception {

        if (reallyVerbose) String2.log("Table.saveAsHtml " + fullFileName); 
        long time = System.currentTimeMillis();

        //POLICY: because this procedure may be used in more than one thread,
        //do work on unique temp files names using randomInt, then rename to proper file name.
        //If procedure fails half way through, there won't be a half-finished file.
        int randomInt = Math2.random(Integer.MAX_VALUE);

        BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(
            fullFileName + randomInt));

        try {
            //saveAsHtml(outputStream, ...)
            saveAsHtml(bos, 
                File2.getNameNoExtension(fullFileName),
                preTableHtml, postTableHtml, 
                otherClasses, bgColor, border, writeUnits, timeColumn, 
                needEncodingAsHtml, allowWrap);
            bos.close();
            bos = null;

            //rename the file to the specified name, instantly replacing the original file
            File2.rename(fullFileName + randomInt, fullFileName); //throws Exception if trouble

        } catch (Exception e) {
            try {
                if (bos != null) bos.close();
            } catch (Exception e2) {
            }
            File2.delete(fullFileName + randomInt);
            File2.delete(fullFileName);
            throw e;
        }


        //diagnostic
        if (reallyVerbose)
            String2.log("Table.saveAsHtml done. fileName=" + fullFileName + 
            " TIME=" + (System.currentTimeMillis() - time) + "ms");

    }
    
    /**
     * Write this data as a table to an outputStream.
     * See saveAsHtmlTable (which this calls) for some of the details.
     * 
     * @param outputStream There is no need for it to be already buffered.
     *    Afterwards, it is flushed, not closed.
     * @param fileNameNoExt is the fileName without dir or extension (only used for the document title).
     * @param preTableHtml is html text to be inserted at the start of the 
     *   body of the document, before the table tag
     *   (or "" if none).
     * @param postTableHtml is html text to be inserted at the end of the 
     *   body of the document, after the table tag
     *   (or "" if none).
     * @param otherClasses a space separated list of other (HTML style) CSS classes (or null or "")
     * @param bgColor the backgroundColor, e.g., BGCOLOR, "#f1ecd8" or null (for none defined)
     * @param border the line width of the cell border lines (e.g., 0, 1, 2)
     * @param writeUnits if true, the table's second row will be units (from columnAttributes "units") 
     * @param timeColumn the column with epoch seconds which should be written
     *    as ISO formatted date times; if <0, this is ignored.
     * @param needEncodingAsHtml if true, the cell contents will be encodedAsHtml (i.e., they contain plain text);
     *    otherwise, they are written as is (i.e., they already contain html-encoded text).
     * @param allowWrap if true, data may be broken into different lines
     *    so the table is only as wide as the screen.
     * @throws Exception  if trouble. But if no data, it makes a simple html file.
     */
    public void saveAsHtml(OutputStream outputStream, String fileNameNoExt, 
        String preTableHtml, String postTableHtml, 
        String otherClasses, String bgColor, int border, boolean writeUnits, 
        int timeColumn, boolean needEncodingAsHtml, boolean allowWrap) throws Exception {

        if (reallyVerbose) String2.log("Table.saveAsHtml"); 
        long time = System.currentTimeMillis();

        //write the header
        BufferedWriter writer = String2.getBufferedOutputStreamWriterUtf8(outputStream);
        writer.write(
            "<!DOCTYPE HTML>\n" +
            "<html lang=\"en-US\">\n" +
            "<head>\n" +
            "  <title>" + fileNameNoExt + "</title>\n" +
            "  <meta charset=\"UTF-8\">\n" +
            "  " + ERD_TABLE_CSS + "\n" +
            "</head>\n" +
            "<body>\n");

        writer.write(preTableHtml);
        //write the actual table
        saveAsHtmlTable(writer, otherClasses, bgColor, border, writeUnits, timeColumn, 
            needEncodingAsHtml, allowWrap);

        //close the document
        writer.write(postTableHtml);
        writer.write(
            "</body>\n" +
            "</html>\n");

        writer.flush(); //essential

        //diagnostic
        if (reallyVerbose)
            String2.log("Table.saveAsHtml done. fileName=" + fileNameNoExt + 
                " TIME=" + (System.currentTimeMillis() - time) + "ms");

    }


    /**
     * Save this data as an html table (not a complete html document.
     * <br>This writes the lon values as they are currently in this table
     *    (e.g., +-180 or 0..360). 
     * <br>If no exception is thrown, the table was successfully written.
     * <br>Currently, all values are written as double.
     * <br>NaN's are written as "NaN".
     * <br>The table will be assigned class="erd".
     * <br>This is an HTML table, not quite a valid XHTML table.
     * 
     * @param writer usually already buffered
     * @param otherClasses a space separated list of other (HTML style) CSS classes (or null or "")
     * @param bgColor the backgroundColor, e.g., BGCOLOR, "#f1ecd8" or null (for none defined)
     * @param border the line width of the cell border lines (e.g., 0, 1, 2)
     * @param writeUnits if true, the table's second row will be units (from columnAttributes "units") 
     * @param timeColumn the column with epoch seconds which should be written
     *    as ISO formatted date times; if <0, this is ignored.
     * @param needEncodingAsHtml if true, the cell contents will be encodedAsHtml (i.e., they contain plain text);
     *    otherwise, they are written as is (i.e., they already contain html-encoded text).
     * @param allowWrap if true, data may be broken into different lines
     *    so the table is only as wide as the screen.
     * @throws Exception  if trouble. But if no data, it makes a simple html file.
     */
    public void saveAsHtmlTable(Writer writer, String otherClasses, String bgColor, int border, 
        boolean writeUnits, int timeColumn, boolean needEncodingAsHtml,
        boolean allowWrap) throws Exception {

        if (reallyVerbose) String2.log("  Table.saveAsHtmlTable"); 
        long time = System.currentTimeMillis();
        String s;

        //no data?
        if (nRows() == 0) {
            writer.write(MustBe.THERE_IS_NO_DATA + " (nRows = 0)");
        } else {
            //this assumes that the class options defined in ERD_TABLE_CSS are available. 
            writer.write(
                "<table class=\"erd" +  //has  empty-cells:show;
                (allowWrap? "" : " nowrap") +
                (otherClasses == null || otherClasses.length() == 0? "" : " " + otherClasses) + "\" " +
                (bgColor == null? "" : "style=\"background-color:" + bgColor + ";\" ") +
                ">\n");

            //write the column names   
            writer.write("<tr>\n");
            int nColumns = nColumns();
            String fileAccessBaseUrl[] = new String[nColumns];
            String fileAccessSuffix[]  = new String[nColumns];
            if (columnNames != null && columnNames.size() == nColumns) {
                boolean somethingWritten = false;
                for (int col = 0; col < nColumns; col++) {
                    s = getColumnName(col);
                    if (needEncodingAsHtml) 
                        s = XML.encodeAsHTML(s);

                    //ensure something written on each row (else row is very narrow)
                    if (somethingWritten) {
                    } else if (s.trim().length() > 0) {
                        somethingWritten = true;
                    } else if (col == nColumns - 1) {
                        s = "&nbsp;";
                    }

                    writer.write("<th>" + s + 
                        //"</th>" //HTML doesn't require it, so save bandwidth
                        "\n");

                    //gather fileAccess attributes 
                    Attributes catts = columnAttributes(col);
                    fileAccessBaseUrl[col] = catts.getString("fileAccessBaseUrl"); //null if none
                    fileAccessSuffix[ col] = catts.getString("fileAccessSuffix");  //null if none
                    if (!String2.isSomething(fileAccessBaseUrl[col]))
                        fileAccessBaseUrl[col] = "";
                    if (!String2.isSomething(fileAccessSuffix[col]))
                        fileAccessSuffix[col] = "";
                }
            }
            writer.write("</tr>\n");

            //write the units   
            if (writeUnits) {
                writer.write("<tr>\n");
                if (columnNames != null && columnNames.size() == nColumns) {
                    boolean somethingWritten = false;
                    for (int col = 0; col < nColumns; col++) {
                        String tUnits = columnAttributes(col).getString("units");
                        if (col == timeColumn)
                            tUnits = "UTC"; //no longer true: "seconds since 1970-01-01..."
                        if (tUnits == null)
                            tUnits = "";
                        if (needEncodingAsHtml) 
                            tUnits = XML.encodeAsHTML(tUnits);

                        //ensure something written on each row (else row is very narrow)
                        if (somethingWritten) {
                        } else if (tUnits.trim().length() > 0) {
                            somethingWritten = true;
                        } else if (col == nColumns - 1) {
                            tUnits = "&nbsp;";
                        }

                        writer.write("<th>" + tUnits + 
                            //"</th>" //HTML doesn't require it, so save bandwidth
                            "\n");
                    }
                }
                writer.write("</tr>\n");
            }

            //write the data
            int nRows = nRows();
            for (int row = 0; row < nRows; row++) {
                writer.write("<tr>\n"); 
                boolean somethingWritten = false;
                for (int col = 0; col < nColumns; col++) {
                    writer.write("<td>"); 
                    if (col == timeColumn) {
                        double d = getDoubleData(col, row);
                        s = Calendar2.safeEpochSecondsToIsoStringTZ(d, "");
                    } else {
                        s = getStringData(col, row);

                        if (fileAccessBaseUrl[col].length() > 0 ||
                            fileAccessSuffix[ col].length() > 0) {
                            //display as a link
                            String ts = needEncodingAsHtml? s : XML.decodeEntities(s); //now decoded
                            String url = XML.encodeAsHTMLAttribute(
                                fileAccessBaseUrl[col] + ts + fileAccessSuffix[col]);
                            s = "<a href=\"" + url + "\">" +
                                (needEncodingAsHtml? XML.encodeAsHTML(s) : s) + //just the fileName
                                "</a>";
                        } else if (needEncodingAsHtml && String2.isUrl(s)) {
                            s = "<a href=\"" + 
                                XML.encodeAsHTMLAttribute(s) + "\">" + 
                                XML.encodeAsHTML(s) + "</a>";
                        } else if (!needEncodingAsHtml && String2.isUrl(XML.decodeEntities(s))) {
                            s = XML.decodeEntities(s);
                            s = "<a href=\"" + 
                                XML.encodeAsHTMLAttribute(s) + "\">" + 
                                XML.encodeAsHTML(s) + "</a>";
                        } else if (String2.isEmailAddress(s)) {
                            //to improve security, convert "@" to " at "
                            s = needEncodingAsHtml? s : XML.decodeEntities(s); //now decoded
                            s = XML.encodeAsHTML(String2.replaceAll(s, "@", " at "));
                        } else if (needEncodingAsHtml) {
                            s = XML.encodeAsHTML(s);
                        }
                    }

                    //ensure something written on each row (else row is very narrow)
                    if (somethingWritten) {
                    } else if (s.trim().length() > 0) {
                        somethingWritten = true;
                    } else if (col == nColumns - 1) {
                        s = "&nbsp;";
                    }

                    writer.write(s);
                    writer.write(
                        //"</td>" + //HTML doesn't require it, so save bandwidth
                        "\n");
                }
                writer.write("</tr>\n");
            }

            //close the table
            writer.write(
                "</table>\n");
        }

        //diagnostic
        if (reallyVerbose)
            String2.log("    Table.saveAsHtmlTable done. TIME=" + 
                (System.currentTimeMillis() - time) + "ms");
    }

    /** This actually reads the file, then reads the HTML table in the file. */
    public void readHtml(String fullFileName, int skipNTables, 
        boolean secondRowHasUnits, boolean simplify) throws Exception {
        
        String sar[] = String2.readFromFile(fullFileName, String2.UTF_8, 2);
        Test.ensureEqual(sar[0].length(), 0, sar[0]); //check that there was no error
        //String2.log(String2.annotatedString(sar[1]));
        readHtml(fullFileName, sar[1], skipNTables, secondRowHasUnits, simplify); 
    }

    /**
     * This reads a standard HTML table of data from an HTML file.
     * <ul>
     * <li>Currently, this isn't very precise about HTML syntax.
     * <li>Currently, this doesn't deal with table-like tags in CDATA. They remain as is.
     * <li>And it doesn't deal with colspan or rowspan.
     * <li>Column Names are taken from first row.
     * <li>If secondRowHasUnits, data should start on 3rd row (else 2nd row).
     * <li>It is okay if a row has fewer columns or more columns than expected.
     *    If table.debugMode = true, a message will be logged about this.
     * <li>nRows=0 and nColumns=0 is not an error.
     * <li>XML.decodeEntities is applied to data in String columns,
     *   so there may be HTML tags if the data is HTML.
     *   Common entities (&amp;amp; &amp;lt; &amp;gt; &amp;quot;) are converted
     *   to the original characters.
     *   &amp;nbsp; is converted to a regular space.   
     * </ul>
     *
     * @param fullFileName just for diagnostics
     * @param html the html text
     * @param skipNTables the number of start &lt;table@gt; tags to be skipped.
     *    The tables may be separate or nested.
     * @param secondRowHasUnits  (ERDDAP tables do; others usually don't)
     * @param simplify if the columns should be simplified
     * @throws Exception
     */
    public void readHtml(String fullFileName, String html, int skipNTables, 
        boolean secondRowHasUnits, boolean simplify) 
        throws Exception {
        //This reads data from String, not BufferedReader.
        //But the nature of html means rows of data (and even individual items)
        //may span multiple rows of the file. 
        //So hard to handle via BufferedReader.

        if (reallyVerbose)
            String2.log("Table.readHtml " + fullFileName);
        long time = System.currentTimeMillis();
        String startError = "Error while reading HTML table from " + fullFileName + 
            "\nInvalid HTML: ";

        clear();

        //skipNTables
        int po = 0; //next po to look at
        for (int skip = 0; skip < skipNTables; skip++) {
            po = String2.indexOfIgnoreCase(html, "<table", po);
            if (po < 0) 
                throw new RuntimeException(startError + "unable to skip " + skipNTables + " <table>'s.");
            po += 6;
        }

        //find main table
        po = String2.indexOfIgnoreCase(html, "<table", po);
        if (po < 0) 
            throw new RuntimeException(startError + "missing main <table>.");
        po += 6;
        int endTable = String2.indexOfIgnoreCase(html, "</table", po);
        if (endTable < 0) 
            throw new RuntimeException(startError + "missing </table>.");

        //read a row
        int nRows = 0;
        int nCols = 0;
        while (po < endTable) {
            int potr = String2.indexOfIgnoreCase(html, "<tr", po);
            if (potr < 0 || potr > endTable) 
                break;
            //</tr> isn't required, so look for next <tr
            int endRow = String2.indexOfIgnoreCase(html, "<tr", potr + 3);
            if (endRow < 0)
                endRow = endTable;
            String row = html.substring(potr, endRow);            

            //process the row
            int poInRow = 2;
            int tCol = 0;
            while (true) {
                int poth = String2.indexOfIgnoreCase(row, "<th", poInRow);
                int potd = String2.indexOfIgnoreCase(row, "<td", poInRow);
                //ensure at least one was found
                if (poth < 0 && potd < 0) 
                    break;
                if (poth < 0) poth = row.length();
                if (potd < 0) potd = row.length();
                int gtPo = row.indexOf('>', Math.min(poth, potd) + 3);
                if (gtPo < 0) 
                    throw new RuntimeException(startError + "missing '>' after final " +
                        (poth < potd? "<th" : "<td") + 
                        " on table row#" + nRows + 
                        " on or before line #" + (1 + String2.countAll(html.substring(0, endRow), "\n")) + 
                        ".");
                //</th> and </td> aren't required, so look for next tag's <
                int endTagPo = row.indexOf('<', gtPo + 1);
                if (endTagPo < 0)
                    endTagPo = row.length();
                String datum = XML.decodeEntities(  
                    row.substring(gtPo + 1, endTagPo).trim());
                //String2.log(">> row=" + nRows + " col=" + tCol + " datum=" + String2.annotatedString(datum));
                if ("\u00a0".equals(datum))  //nbsp
                    datum = "";

                if (nRows == 0) {
                    //if first row, add a column
                    addColumn(datum, new StringArray());
                    nCols++;
                } else if (tCol < nCols) {
                    if (secondRowHasUnits && nRows == 1) {
                        //store the units
                        columnAttributes(tCol).add("units", datum);
                    } else {
                        //append the data
                        ((StringArray)getColumn(tCol)).add(datum);  
                    }
                } else {
                    //ignore this and subsequent columns on this row
                    if (debugMode) String2.log("!!!Extra columns were found on row=" + nRows);
                    break;
                }

                poInRow = endTagPo; //"endTag" might be next <th or <td
                tCol++;
            }

            //add blanks so all columns are same length
            if (tCol < nCols) {
                if (debugMode) String2.log("!!!Too few columns were found on row=" + nRows);
                makeColumnsSameSize();
            }
            nRows++;
            po = endRow;

        }

        //simplify the columns
        if (simplify) 
            simplify();

        //diagnostic
        if (reallyVerbose)
            String2.log("    Table.readHtml done. fileName=" + fullFileName + 
                " nRows=" + nRows + " nCols=" + nCols + " TIME=" + 
                (System.currentTimeMillis() - time) + "ms");
    }

    /**
     * This encodes the values of Attributes before saveAsEnhancedFlatNc.
     */
    void encodeEnhancedAttributes(Attributes atts) {
        String names[] = atts.getNames();
        int n = names.length;
        for (int i = 0; i < n; i++) {
            PrimitiveArray pa = atts.get(names[i]);
            if (pa instanceof CharArray) {
                atts.remove(names[i]);
                atts.set("_encodedCharArray_" + names[i], 
                    ShortArray.fromCharArrayBytes((CharArray)pa));

            } else if (pa instanceof UByteArray) {
                atts.remove(names[i]);
                atts.set("_encodedUByteArray_" + names[i], 
                    new ByteArray(((UByteArray)pa).toArray()));

            } else if (pa instanceof UShortArray) {
                atts.remove(names[i]);
                atts.set("_encodedUShortArray_" + names[i], 
                    new ShortArray(((UShortArray)pa).toArray()));

            } else if (pa instanceof UIntArray) {
                atts.remove(names[i]);
                atts.set("_encodedUIntArray_" + names[i], 
                    new IntArray(((UIntArray)pa).toArray()));

            } else if (pa instanceof LongArray) {
                atts.remove(names[i]);
                atts.set("_encodedLongArray_" + names[i], 
                    new StringArray(new String[]{pa.toString()}));

            } else if (pa instanceof ULongArray) {
                atts.remove(names[i]);
                atts.set("_encodedULongArray_" + names[i], 
                    new StringArray(new String[]{pa.toString()}));

            //Even nc3 saves attributes via utf-8
            //} else if (pa instanceof StringArray) {
            //    atts.remove(names[i]);
            //    atts.set("_encodedStringArray_" + names[i], 
            //        (new StringArray(pa)).toJson()); //change a copy of pa
            }
        }
    }

    /**
     * This decodes the values of an Attributes after readEnhancedFlatNc.
     */
    void decodeEnhancedAttributes(int sourceVersion, Attributes atts) {
        String names[] = atts.getNames();
        int n = names.length;
        for (int i = 0; i < n; i++) {
            if (names[i].startsWith("_encoded")) {
                PrimitiveArray pa = atts.get(names[i]);
                PAType paType = pa.elementType();
                if (paType == PAType.SHORT &&
                    names[i].startsWith("_encodedCharArray_")) {
                    atts.remove(names[i]);
                    atts.set(names[i].substring(18), 
                        CharArray.fromShortArrayBytes((ShortArray)pa));

                } else if (paType == PAType.BYTE &&
                    names[i].startsWith("_encodedUByteArray_")) {
                    atts.remove(names[i]);
                    atts.set(names[i].substring(19), 
                        new UByteArray(((ByteArray)pa).toArray()));

                } else if (paType == PAType.SHORT &&
                    names[i].startsWith("_encodedUShortArray_")) {
                    atts.remove(names[i]);
                    atts.set(names[i].substring(20), 
                        new UShortArray(((ShortArray)pa).toArray()));

                } else if (paType == PAType.INT &&
                    names[i].startsWith("_encodedUIntArray_")) {
                    atts.remove(names[i]);
                    atts.set(names[i].substring(18), 
                        new UIntArray(((IntArray)pa).toArray()));

                } else if (paType == PAType.STRING &&
                    names[i].startsWith("_encodedLongArray_")) {
                    atts.remove(names[i]);
                    atts.set(names[i].substring(18), 
                        PrimitiveArray.csvFactory(PAType.LONG, pa.getString(0)));

                } else if (paType == PAType.STRING &&
                    names[i].startsWith("_encodedULongArray_")) {
                    atts.remove(names[i]);
                    atts.set(names[i].substring(19), 
                        PrimitiveArray.csvFactory(PAType.ULONG, pa.getString(0)));

                //Even nc3 saves attributes via utf-8
                //} else if (paType == PAType.STRING &&
                //    names[i].startsWith("_encodedStringArray_")) {
                //    atts.remove(names[i]);
                //    atts.set(names[i].substring(20), 
                //        ((StringArray)pa).fromJson()); //actually a newline separated string
                }
            }
        }
    }

    /**
     * This writes this table as a Bob enhanced flatNc file 
     * (supports longs, 2-byte chars, and utf-8 strings, for data and attribute values).
     * The table is temporarily modified, but all changes are undone when this is finished.
     * 
     * @throws exception if trouble
     */
    public void saveAsEnhancedFlatNc(String fullName) throws Exception {

        //Important: make a new table and make changes to it (even if temporary).
        //  Some other thread may be using this table.

        //encode things
        Table newTable = new Table();
        newTable.globalAttributes().add(globalAttributes);
        newTable.globalAttributes().add("_enhanced_version_", ENHANCED_VERSION);
        encodeEnhancedAttributes(newTable.globalAttributes());

        int nCols = nColumns();
        int nRows = nRows();
        for (int col = 0; col < nCols; col++) {
            PrimitiveArray pa = getColumn(col);
            PAType paType = pa.elementType();
            Attributes atts = (Attributes)(columnAttributes(col).clone());
            newTable.addColumn(col, getColumnName(col), pa, atts);

            //for backwardcompatibility, always set it 
            if (pa.supportsMaxIsMV())
                atts.set("_MaxIsMV", "" + pa.getMaxIsMV());

            if        (paType == PAType.CHAR) {
                atts.set("_encoded_", "fromChar");
                newTable.setColumn(col, ShortArray.fromCharArrayBytes((CharArray)pa));               

            } else if (paType == PAType.LONG) {  //otherwise, stored as doubles (lossy)
                atts.set("_encoded_", "fromLong");
                newTable.setColumn(col, new StringArray(pa));                

            } else if (paType == PAType.ULONG) { //otherwise, stored as doubles (lossy)
                atts.set("_encoded_", "fromULong");
                newTable.setColumn(col, new StringArray(pa));                

            } else if (paType == PAType.STRING) {
                atts.set("_encoded_", String2.JSON); //not _Encoding because encodeEnhancedAtts will change it
                newTable.setColumn(col, (new StringArray(pa)).toJson()); //change a copy of pa
            }

            encodeEnhancedAttributes(atts);
        }

        //save newTable
        newTable.saveAsFlatNc(fullName, "row", false); //convertToStandardMissingValues
    }


    /**
     * This reads Bob's enhanced flatNc file (supports longs, 2-byte chars, 
     * and utf-8 strings for data and attribute values) 
     * into this table (replacing current contents).
     * 
     * @param loadColumns  a list of column names, or null for all
     * @return source enhancedVersion This is for informational purposes. 
     *   Normally, all the enhanced encoding/decoding is dealt with here.
     *   This returns
     *   <br>&lt; ENHANCED_VERSION (e.g., -1, i.e. out-of-date) 
     *     if error because not enhanced or not convertible to current standards.
     *   <br>ENHANCED_VERSION if all okay (including if from previous version that
     *     this was able to deal with).
     *   <br>&gt;ENHANCED_VERSION if trouble because it's from a future version
     *     (with implied significant changes that aren't caught here). 
     * @throws exception if trouble
     */
    public int readEnhancedFlatNc(String fullName, String loadColumns[]) throws Exception {

        lowReadFlatNc(fullName, loadColumns, 0, false, -1); //standardizeWhat=0. doAltStandardization=false (rare!)

        //String2.log(">>After lowReadFlatNc:\n" + toString());

        //check version #
        int sourceVersion = globalAttributes.getInt("_enhanced_version_");
        if (sourceVersion == Integer.MAX_VALUE) 
            sourceVersion = 0;
        if (sourceVersion < 3 || sourceVersion > ENHANCED_VERSION) //currently=4.  ver 3 is readable
            return sourceVersion;
        globalAttributes.remove("_enhanced_version_");

        //decode globalAtts
        decodeEnhancedAttributes(sourceVersion, globalAttributes);

        int nCols = nColumns();
        int nRows = nRows();
        for (int col = 0; col < nCols; col++) {
            PrimitiveArray pa = getColumn(col);
            Attributes atts = columnAttributes(col);
            decodeEnhancedAttributes(sourceVersion, atts);

            //maxIsMV
            PrimitiveArray tpa = atts.remove("_MaxIsMV");  
            if (pa.supportsMaxIsMV()) 
                pa.setMaxIsMV(tpa == null || tpa.size() == 0 ||  //for backwards compatibility
                    "true".equals(tpa.getString(0)));  // will be ignored if DoubleArray or FloatArray

            if (pa instanceof CharArray) {
                //trouble! significant info loss. There shouldn't be any CharArray 
                String2.log(String2.ERROR + ": Table.readEnhancedFlatNc(" + fullName + ") contained a CharArray variable.");
                return -1; //trouble
     
            } else if (sourceVersion == 3 && pa instanceof ShortArray &&
                "true".equals(atts.getString("_Unsigned"))) { //netcdf recommendation
                //convert sourceVersion=3 unsigned short to char
                atts.remove("_Unsigned");
                setColumn(col, CharArray.fromShortArrayBytes((ShortArray)pa));                

            } else if (sourceVersion >= 4 && pa instanceof ShortArray &&
                "fromChar".equals(atts.getString("_encoded_"))) {
                atts.remove("_encoded_");
                setColumn(col, CharArray.fromShortArrayBytes((ShortArray)pa));                

            } else if (pa instanceof StringArray) {
                String enc = atts.getString("_encoded_");
                atts.remove("_encoded_");
                if ("fromLong".equals(enc)) { 
                    //convert longs encoded as Strings back to longs
                    setColumn(col, new LongArray(pa));                
                } else if ("fromULong".equals(enc)) { 
                    //convert ulongs encoded as Strings back to ulongs
                    setColumn(col, new ULongArray(pa));                
                } else if (String2.JSON.equals(enc)) { 
                    //convert UTF-8 back to Java char-based strings
                    ((StringArray)pa).fromJson();                
                } else {
                    //unexpected encoding
                    String2.log(String2.ERROR + ": Table.readEnhancedFlatNc(" + fullName + 
                        ") contained an unexpected _encoded_ StringArray: " + enc);
                    return -1; //unexpected trouble
                }
            }
        }

        //then...
        convertToUnsignedPAs(); //which looks for attributes like _FillValue and adjusts them
        //convertToStandardMissingValues();

        return ENHANCED_VERSION; //successfully read (and perhaps converted to current version)
    }

    /**
     * This makes a tough test table.
     */
    public static Table makeToughTestTable() {

        Table table = new Table();

        Attributes gatts = table.globalAttributes();
        gatts.add("tests", "a\u00fcb\nc\td\u20acz");
        gatts.add("testc", '\u00fc');
        gatts.add("testub", UByteArray.fromCSV( "0, 255"));
        gatts.add("testus", UShortArray.fromCSV("0, 65535"));
        gatts.add("testui", UIntArray.fromCSV(  "0, 4294967295"));
        gatts.add("testl",  new LongArray(new long[]{Long.MIN_VALUE, Long.MAX_VALUE}));
        gatts.add("testul", ULongArray.fromCSV("0, 9223372036854775807, 18446744073709551615"));
        gatts.add("testi",  new IntArray(new int[]{Integer.MIN_VALUE, Integer.MAX_VALUE}));

        table.addColumn(0, "aString", 
            new StringArray(new String[]{"a\u00fcb\nc\td\u20ace", "ab", "", "cd", ""}),
            (new Attributes()).add("test", "a\u00fcb\nc\td\u20ace"));

        table.addColumn(1, "aChar", 
            new CharArray(new char[]{'\u00fc', (char)0, 'A', '\t', '\u20ac'}),
            (new Attributes()).add("test", '\u00fc'));

        table.addColumn(2, "aByte", //min,         med, fv, max-1,  max
            new ByteArray(new byte[]{Byte.MIN_VALUE, 0, 99, 126, Byte.MAX_VALUE}).setMaxIsMV(true),
            (new Attributes()).add("_FillValue", ByteArray.fromCSV("99"))
                              .add("test",       ByteArray.fromCSV("-128, 127")));
        table.addColumn(3, "aUByte", 
            new UByteArray(new short[]{0, 127, 99, 254, 255}).setMaxIsMV(true),
            (new Attributes()).add("_FillValue", UByteArray.fromCSV("99"))
                              .add("test",       UByteArray.fromCSV("0, 255")));
        table.addColumn(4, "aShort", 
            new ShortArray(new short[]{Short.MIN_VALUE, 0, 9999, 32766, Short.MAX_VALUE}).setMaxIsMV(true),
            (new Attributes()).add("_FillValue", ShortArray.fromCSV("9999"))
                              .add("test",       ShortArray.fromCSV("-32768, 32767")));
        table.addColumn(5, "aUShort", 
            UShortArray.fromCSV("0, 32767, 9999, 65534, 65535").setMaxIsMV(true),
            (new Attributes()).add("_FillValue", UShortArray.fromCSV("9999"))
                              .add("test",       UShortArray.fromCSV("0, 65535")));
        table.addColumn(6, "anInt", 
            new IntArray(new int[]{Integer.MIN_VALUE, 0, 999999999, Integer.MAX_VALUE-1, Integer.MAX_VALUE}).setMaxIsMV(true),
            (new Attributes()).add("_FillValue", IntArray.fromCSV("999999999"))
                              .add("test",       IntArray.fromCSV("-2147483648, 2147483647")));
        table.addColumn(7, "aUInt", 
            new UIntArray(new long[]{0, 7, Integer.MAX_VALUE, Math2.UINT_MAX_VALUE-1, Math2.UINT_MAX_VALUE}).setMaxIsMV(true),
            (new Attributes()).add("_FillValue", UIntArray.fromCSV("999999999"))
                              .add("test",       UIntArray.fromCSV("0, 4294967295")));
        table.addColumn(8, "aLong", 
            new LongArray(new long[]{Long.MIN_VALUE, 0, 8, Long.MAX_VALUE-1, Long.MAX_VALUE}).setMaxIsMV(true),
            (new Attributes()).add("_FillValue", LongArray.fromCSV("999999999999"))
                              .add("test",       LongArray.fromCSV("-9223372036854775808, 9223372036854775807")));
        table.addColumn(9, "aULong", 
            ULongArray.fromCSV("0,  1, 9223372036854775807, 18446744073709551614, 18446744073709551615").setMaxIsMV(true),
            (new Attributes()).add("_FillValue", ULongArray.fromCSV("999999999999"))
                              .add("test",       ULongArray.fromCSV("0, 18446744073709551615")));
        table.addColumn(10, "aFloat", 
            new FloatArray(new float[]{-Float.MAX_VALUE, 2.2f, Float.MIN_VALUE, Float.MAX_VALUE, Float.NaN}),
            (new Attributes()).add("_FillValue", 1e36f)
                              .add("test",       new FloatArray(new float[]{-Float.MAX_VALUE, Float.NaN})));
        table.addColumn(11, "aDouble", 
            new DoubleArray(new double[]{-Double.MAX_VALUE, 3.3, Double.MIN_VALUE, Double.MAX_VALUE, Double.NaN}),
            (new Attributes()).add("_FillValue", 1e300)
                              .add("test",       new DoubleArray(new double[]{-Double.MAX_VALUE, Double.NaN})));
        return table;

    }


    /**
     * This tests saveAsEnhancedFlatNcFile and readEnhancedFlatNcFile.
     */
    public static void testEnhancedFlatNcFile() throws Exception {

        String2.log("\n*** Table.testEnhancedFlatNcFile()");
        String results, expected;
        String fileName = File2.getSystemTempDirectory() + "enhancedFlatNcFile.nc";

        Table table = makeToughTestTable();
        expected = String2.annotatedString(table.toString());
        String2.log("expected=\n" + expected);

        table.saveAsEnhancedFlatNc(fileName);
        results = String2.annotatedString(table.toString());
        Test.ensureEqual(results, expected, "a"); //saveAsEnhancedFlatNc didn't change anything
        table.clear();

        table.readEnhancedFlatNc(fileName, null);
        table.globalAttributes().remove("id");
        results = String2.annotatedString(table.toString());
        expected = 
"{[10]\n" +
"dimensions:[10]\n" +
"[9]row = 5 ;[10]\n" +
"[9]aString_strlen = 9 ;[10]\n" +
"variables:[10]\n" +
"[9]char aString(row, aString_strlen) ;[10]\n" +
"[9][9]aString:test = \"a[252]b[10]\n" +
"c\\td[8364]e\" ;[10]\n" +
"[9]char aChar(row) ;[10]\n" +
"[9][9]aChar:test = \"[252]\" ;[10]\n" +
"[9]byte aByte(row) ;[10]\n" +
"[9][9]aByte:_FillValue = 99 ;[10]\n" +
"[9][9]aByte:test = -128, 127 ;[10]\n" +
"[9]ubyte aUByte(row) ;[10]\n" +
"[9][9]aUByte:_FillValue = 99 ;[10]\n" +
"[9][9]aUByte:test = 0, 255 ;[10]\n" +
"[9]short aShort(row) ;[10]\n" +
"[9][9]aShort:_FillValue = 9999 ;[10]\n" +
"[9][9]aShort:test = -32768, 32767 ;[10]\n" +
"[9]ushort aUShort(row) ;[10]\n" +
"[9][9]aUShort:_FillValue = 9999 ;[10]\n" +
"[9][9]aUShort:test = 0, 65535 ;[10]\n" +
"[9]int anInt(row) ;[10]\n" +
"[9][9]anInt:_FillValue = 999999999 ;[10]\n" +
"[9][9]anInt:test = -2147483648, 2147483647 ;[10]\n" +
"[9]uint aUInt(row) ;[10]\n" +
"[9][9]aUInt:_FillValue = 999999999 ;[10]\n" +
"[9][9]aUInt:test = 0, 4294967295 ;[10]\n" +
"[9]long aLong(row) ;[10]\n" +
"[9][9]aLong:_FillValue = 999999999999 ;[10]\n" +
"[9][9]aLong:test = -9223372036854775808, 9223372036854775807 ;[10]\n" +
"[9]ulong aULong(row) ;[10]\n" +
"[9][9]aULong:_FillValue = 999999999999 ;[10]\n" +
"[9][9]aULong:test = 0, 18446744073709551615 ;[10]\n" +
"[9]float aFloat(row) ;[10]\n" +
"[9][9]aFloat:_FillValue = 1.0E36f ;[10]\n" +
"[9][9]aFloat:test = -3.4028235E38f, NaNf ;[10]\n" +
"[9]double aDouble(row) ;[10]\n" +
"[9][9]aDouble:_FillValue = 1.0E300 ;[10]\n" +
"[9][9]aDouble:test = -1.7976931348623157E308, NaN ;[10]\n" +
"[10]\n" +
"// global attributes:[10]\n" +
"[9][9]:testc = \"[252]\" ;[10]\n" +
"[9][9]:testi = -2147483648, 2147483647 ;[10]\n" +
"[9][9]:testl = -9223372036854775808, 9223372036854775807 ;[10]\n" +
"[9][9]:tests = \"a[252]b[10]\n" +
"c\\td[8364]z\" ;[10]\n" +
"[9][9]:testub = 0, 255 ;[10]\n" +
"[9][9]:testui = 0, 4294967295 ;[10]\n" +
"[9][9]:testul = 0, 9223372036854775807, 18446744073709551615 ;[10]\n" +
"[9][9]:testus = 0, 65535 ;[10]\n" +
"}[10]\n" +
"aString,aChar,aByte,aUByte,aShort,aUShort,anInt,aUInt,aLong,aULong,aFloat,aDouble[10]\n" +
"a\\u00fcb\\nc\\td\\u20ace,\\u00fc,-128,0,-32768,0,-2147483648,0,-9223372036854775808,0,-3.4028235E38,-1.7976931348623157E308[10]\n" +
"ab,\\u0000,0,127,0,32767,0,7,0,1,2.2,3.3[10]\n" +
",A,99,99,9999,9999,999999999,2147483647,8,9223372036854775807,1.4E-45,4.9E-324[10]\n" +
"cd,\\t,126,254,32766,65534,2147483646,4294967294,9223372036854775806,18446744073709551614,3.4028235E38,1.7976931348623157E308[10]\n" +
",\\u20ac,,,,,,,,,,[10]\n" +
"[end]";
        Test.ensureEqual(results, expected, "b");
    }



    /**
     * This reads all rows of all of the specified columns in a flat .nc file
     * or an http:<ncFile> (several 1D variables (columns), all referencing the
     * same dimension).
     * This also reads global and variable attributes.
     *
     * <p>If the fullName is an http address, the name needs to start with "http:\\" 
     * (upper or lower case) and the server needs to support "byte ranges"
     * (see ucar.nc2.NetcdfFile documentation).
     * 
     * @param fullName This may be a local file name, an "http:" address of a
     *    .nc file, or an opendap url.
     * @param loadColumns if null, this searches for the (pseudo)structure variables
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat,
     *   or 0 to do nothing, or -1 to convertToStandardMissingValues (e.g., -999 to Int.MAX_VALUE)
     * @throws Exception if trouble
     */
    public void readFlatNc(String fullName, String loadColumns[], int standardizeWhat) throws Exception {
        lowReadFlatNc(fullName, loadColumns, standardizeWhat, true, -1);
    }

    /**
     * This is like readFlatNc, but just reads the first row of data and all the metadata
     * (useful to get the file info).
     *
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat
     */
    public void readFlatNcInfo(String fullName, String loadColumns[], int standardizeWhat) throws Exception {
        lowReadFlatNc(fullName, loadColumns, standardizeWhat, true, 0);
    }

    /**
     * The low level workhorse for readFlatNc and readFlatNcInfo.
     *
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat
     * @param doAltStandardization If true (normally) and if standardizeWhat == 0,
     *   converts fakeMissingValues (e.g., -999) to standard PrimitiveArray mv's (e.g., 32767).
     *   This always creates unsigned PAs when _Unsigned=true.
     * @param lastRow the last row to be read (inclusive).  
     *    If lastRow = -1, the entire var is read.
     */
    public void lowReadFlatNc(String fullName, String loadColumns[], int standardizeWhat, 
        boolean doAltStandardization, int lastRow) throws Exception {

        //get information
        String msg = "  Table.readFlatNc " + fullName; 
        long time = System.currentTimeMillis();
        NetcdfFile netcdfFile = NcHelper.openFile(fullName);
        Attributes gridMappingAtts = null;
        try {
            Variable loadVariables[] = NcHelper.findVariables(netcdfFile, loadColumns);

            //fill the table
            clear();
            appendNcRows(loadVariables, 0, lastRow);
            NcHelper.getGlobalAttributes(netcdfFile, globalAttributes());
            for (int col = 0; col < loadVariables.length; col++) {
                NcHelper.getVariableAttributes(loadVariables[col], columnAttributes(col));

                //does this var point to the pseudo-data var with CF grid_mapping (projection) information?
                if (gridMappingAtts == null) {
                    gridMappingAtts = NcHelper.getGridMappingAtts(netcdfFile, 
                        columnAttributes(col).getString("grid_mapping"));
                    if (gridMappingAtts != null)
                        globalAttributes.add(gridMappingAtts);
                }
            }

            //unpack 
            decodeCharsAndStrings();
            if (standardizeWhat > 0) {
                convertToUnsignedPAs();
                standardize(standardizeWhat);
            } else if (doAltStandardization) {
                convertToUnsignedPAs();
                convertToStandardMissingValues();
            }

            if (reallyVerbose) 
                msg += " finished. nColumns=" + nColumns() + " nRows=" + nRows() + 
                    " TIME=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            netcdfFile.close(); 
            if (reallyVerbose) String2.log(msg);
        }

    }

    /**
     * This makes a table global with global attributes and columns with attributes, but nRows=0.
     * 
     * @param fullName of the nc file
     * @param sourceColumnNames the list of columns to be loaded. Thus must be specified.
     *    If one isn't found, it's okay; the column will still be in the results, but with no metadata.
     * @param sourceDataTypes 
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat
     *   This always returns _Unsigned=true vars and related atts as unsigned vars and atts.
     */
    public void readNcMetadata(String fullName, String sourceColumnNames[], String sourceDataTypes[],
        int standardizeWhat) throws Exception {

        //get information
        String msg = "  Table.readNcMetadata " + fullName; 
        long time = System.currentTimeMillis();
        NetcdfFile netcdfFile = NcHelper.openFile(fullName);
        Attributes gridMappingAtts = null;
        try {
            //fill the table
            clear();
            NcHelper.getGlobalAttributes(netcdfFile, globalAttributes());
            for (int col = 0; col < sourceColumnNames.length; col++) {
                Attributes atts = new Attributes();
                addColumn(col, sourceColumnNames[col], 
                    PrimitiveArray.factory(PAType.fromCohortString(sourceDataTypes[col]), 0, false), 
                    atts);
                Variable var = netcdfFile.findVariable(sourceColumnNames[col]);
                if (var == null) {
                    if (verbose) String2.log(String2.WARNING + " in Table.readNcMetadata: variableName=" +
                        sourceColumnNames[col] + " not found in " + fullName);
                    continue;
                }

                NcHelper.getVariableAttributes(var, atts);

                //does this var point to the pseudo-data var with CF grid_mapping (projection) information?
                if (gridMappingAtts == null) {
                    gridMappingAtts = NcHelper.getGridMappingAtts(netcdfFile, 
                        atts.getString("grid_mapping"));
                    if (gridMappingAtts != null)
                        globalAttributes.add(gridMappingAtts);
                }
            }

            //unpack 
            decodeCharsAndStrings();
            if (standardizeWhat > 0) {
                convertToUnsignedPAs();
                standardize(standardizeWhat);
            }

            if (reallyVerbose) 
                msg += " finished. nColumns=" + nColumns() +  
                    " TIME=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            netcdfFile.close(); 
            if (reallyVerbose) String2.log(msg);
        }
    }


    /** 
     * This is commonly used by nc readers to decode any UTF-8 encoded
     * strings before returning the table.
     *
     * <p>There is similar code in GridDataAccessor and Table.decodeCharsAndStrings().
     */
    public void decodeCharsAndStrings() {
        int nc = nColumns();
        for (int col = 0; col < nc; col++) {
            PrimitiveArray pa = getColumn(col);
            Attributes atts = columnAttributes(col);
            String enc     = atts.getString(String2.ENCODING);
            atts.remove(String2.ENCODING);
// disabled until there is a standard
//            String charset = atts.getString(String2.CHARSET);
//            atts.remove(String2.CHARSET);

            //charset
//            if (String2.isSomething(charset)) {
//                //check that it is CharArray and 8859-1
//                if (pa.elementType() != PAType.CHAR)
//                    setColumn(col, new CharArray(pa));  //too bold?
//                if (!charset.toLowerCase().equals(String2.ISO_8859_1_LC))
//                    String2.log("col=" + getColumnName(col) + " has unexpected " +
//                        String2.CHARSET + "=" + charset);
//                continue;
//            }

            //encoding
            if (pa.elementType() != PAType.STRING ||
                !String2.isSomething(enc))
                continue;
            enc = enc.toLowerCase();

            //decode
            if (enc.toLowerCase().equals(String2.UTF_8_LC)) {
                //UTF-8
                //String2.log(">> before decode: " + pa);
                ((StringArray)pa).fromUTF8();
                //String2.log(">> after decode: " + pa);

            } else if (enc.toLowerCase().equals(String2.ISO_8859_1_LC)) {
                //unchanged ISO-8859-1 becomes the first page of unicode encoded strings

            } else {
                String2.log("col=" + getColumnName(col) + " has unexpected " +
                    String2.ENCODING + "=" + enc);
            }

            //currently, OTHER ENCODINGS ARE NOT HANDLED 
            //JUST LEAVE THE ATTRIBUTE AND VALUE
        }
    }

    /**
     * This reads the 1D variables from a .nc file *and* the scalar (0D) values 
     * (duplicated to have the same number of rows).
     *
     * <p>This always converts to standard missing values (MAX_INT, ..., NaN).
     *
     * @param fullName This may be a local file name, an "http:" address of a
     *    .nc file, or an opendap url.
     * @param loadColumns The 1D variables to be loaded. 
     *    If null, this searches for the (pseudo)structure variables.
     *    (The scalar variables are always loaded.)
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat,
     *   or 0 to do nothing, or -1 to convertToStandardMissingValues (e.g., -999 to Int.MAX_VALUE)
     * @param lastRow the last row to be read (inclusive).  
     *    If lastRow = -1, the entire var is read.
     * @throws Exception if trouble
     */
    public void readFlat0Nc(String fullName, String loadColumns[], int standardizeWhat, 
        int lastRow) throws Exception {

        //read the 1D variables
        long time = System.currentTimeMillis();
        lowReadFlatNc(fullName, loadColumns, standardizeWhat, true, lastRow); //doAltStandardization
        int tnRows = nRows();
        String msg = "  Table.readFlat0Nc " + fullName;

        //read the scalar variables
        NetcdfFile netcdfFile = NcHelper.openFile(fullName);
        //getGridMappingAtts() handled by lowReadFlatNc above
        int insertAt = 0;
        try {
            Group rootGroup = netcdfFile.getRootGroup();
            List rootGroupVariables = rootGroup.getVariables(); 
            int nv = rootGroupVariables.size();
            for (int v = 0; v < nv; v++) {
                Variable var = (Variable)rootGroupVariables.get(v);
                boolean isChar = var.getDataType() == DataType.CHAR;
                if (var.getRank() + (isChar? -1 : 0) == 0) {
                    PrimitiveArray pa = NcHelper.getPrimitiveArray(var);                    
                    //unpack is done at end of method
                    //nc allows strings to be 0-terminated or padded with spaces, so always trimEnd
                    if (pa instanceof StringArray) 
                        pa.setString(0, String2.trimEnd(pa.getString(0)));
                    if (tnRows > 1) {
                        if (pa instanceof StringArray) 
                             pa.addNStrings(tnRows-1, pa.getString(0));
                        else pa.addNDoubles(tnRows-1, pa.getDouble(0));
                    }

                    Attributes atts = new Attributes();
                    NcHelper.getVariableAttributes(var, atts);
                    addColumn(insertAt++, var.getShortName(), pa, atts);                    
                }
            }

            //unpack 
            decodeCharsAndStrings();
            if (standardizeWhat > 0) {
                convertToUnsignedPAs();
                standardize(standardizeWhat);
            } else if (standardizeWhat == 0) {
                //do nothing
            } else {
                convertToUnsignedPAs();
                convertToStandardMissingValues();
            }

            if (reallyVerbose) msg +=  
                " finished. nColumns=" + nColumns() + " nRows=" + nRows() + 
                " TIME=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            netcdfFile.close();
            if (reallyVerbose) String2.log(msg);
        }
    }
    
    /**
     * This reads all specified 4D numeric (or 5D char) variables into a flat table with
     * columns x,y,z,t (with type matching the type in the file) + loadColumns.
     * This works with true 4D numeric (or 5D char) variables (not just length=1 x,y,z axes).
     * It does not check for metadata standards compliance or ensure
     *    that axes correspond to lon, lat, depth, time.
     * This also reads global and variable attributes.
     *
     * <p>If the fullName is an http address, the name needs to start with "http:\\" 
     * (upper or lower case) and the server needs to support "byte ranges"
     * (see ucar.nc2.NetcdfFile documentation).
     * 
     * <p>This supports an optional stringVariable which is read
     * from the file as a 1D char array, but used to fill a String column.   
     * Dapper/DChart prefers this to a 4D array for the ID info.
     * 
     * @param fullName This may be a local file name, an "http:" address of a
     *    .nc file, or an opendap url.
     * @param loadColumns if null, this searches for a 4D numeric (or 5D char) variable
     *    and loads all variables using the same 4 axes.
     *    If no variables are found, the table will have 0 rows and columns.
     *    All dimension columns are automatically loaded.
     *    Dimension names in loadColumns are ignored (since they will be loaded automatically).
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat,
     *   or 0 to do nothing, or -1 to convertToStandardMissingValues (e.g., -999 to Int.MAX_VALUE)
     * @param stringVariableName the name of the stringVariable (or null if not used)
     * @param stringVariableColumn the columnNumber for the stringVariable (or -1 for the end)
     * @throws Exception if trouble
     */
    public void read4DNc(String fullName, String loadColumns[], int standardizeWhat, 
        String stringVariableName, int stringVariableColumn) throws Exception {

        long time = System.currentTimeMillis();
        String msg = "  Table.read4DNc " + fullName;
        String errorInMethod = String2.ERROR + " in" + msg;
        //get information
        NetcdfFile ncFile = NcHelper.openFile(fullName);
        Attributes gridMappingAtts = null;
        try {
            Variable loadVariables[] = NcHelper.find4DVariables(ncFile, loadColumns);

            //clear the table
            clear();

            //load the variables
            Dimension dimensions[] = new Dimension[4];  //all the 4D arrays are 0=t,1=z,2=y,3=x
            String dimensionNames[] = new String[4];
            Variable axisVariables[] = new Variable[4];
            PrimitiveArray axisPA[] = new PrimitiveArray[4];
            Attributes axisAtts[]   = new Attributes[4];
            int xLength, yLength, zLength, tLength;
            boolean needToSetUpAxes = true;
            for (int v = 0; v < loadVariables.length; v++) {
                Variable variable = loadVariables[v];
                if (variable.getRank() < 2)
                    continue;

                //if first variable, set up axis columns
                if (needToSetUpAxes) {
                    //get axes
                    needToSetUpAxes = false;
                    List dimList = variable.getDimensions();
                    if (variable.getDataType() != DataType.CHAR && dimList.size() != 4)
                        throw new SimpleException(errorInMethod + 
                            "nDimensions not 4 for numeric variable: " + variable.getName());

                    if (variable.getDataType() == DataType.CHAR && dimList.size() != 5)
                        throw new SimpleException(errorInMethod + 
                            "nDimensions not 5 for char variable: " + variable.getName());
                        
                    for (int i = 0; i < 4; i++) {
                        dimensions[i] = (Dimension)dimList.get(i);
                        dimensionNames[i] = dimensions[i].getName();
                        axisVariables[i] = ncFile.findVariable(dimensionNames[i]);
                        if (axisVariables[i] == null)
                            throw new SimpleException( 
                                errorInMethod + "dimension variable not found: " + dimensionNames[i]);
                        axisPA[i] = NcHelper.getPrimitiveArray(axisVariables[i]); 
                        //unpack is done at end of method
                        axisAtts[i] = new Attributes();
                        NcHelper.getVariableAttributes(axisVariables[i], axisAtts[i]);
                    }    

                    //make axes columns (x,y,z,t) to hold flattened axis values
                    xLength = axisPA[3].size();
                    yLength = axisPA[2].size();
                    zLength = axisPA[1].size();
                    tLength = axisPA[0].size();
                    int totalNValues = tLength * zLength * yLength * xLength;
                    PrimitiveArray xColumn = PrimitiveArray.factory(NcHelper.getElementPAType(axisVariables[3]), totalNValues, false);
                    PrimitiveArray yColumn = PrimitiveArray.factory(NcHelper.getElementPAType(axisVariables[2]), totalNValues, false);
                    PrimitiveArray zColumn = PrimitiveArray.factory(NcHelper.getElementPAType(axisVariables[1]), totalNValues, false);
                    PrimitiveArray tColumn = PrimitiveArray.factory(NcHelper.getElementPAType(axisVariables[0]), totalNValues, false);
                    addColumn(0, dimensionNames[3], xColumn, axisAtts[3]); 
                    addColumn(1, dimensionNames[2], yColumn, axisAtts[2]); 
                    addColumn(2, dimensionNames[1], zColumn, axisAtts[1]); 
                    addColumn(3, dimensionNames[0], tColumn, axisAtts[0]); 

                    //populate the columns
                    PrimitiveArray axisPA0 = axisPA[0];
                    PrimitiveArray axisPA1 = axisPA[1];
                    PrimitiveArray axisPA2 = axisPA[2];
                    PrimitiveArray axisPA3 = axisPA[3];
                    for (int t = 0; t < tLength; t++) {
                        for (int z = 0; z < zLength; z++) {
                            for (int y = 0; y < yLength; y++) {
                                for (int x = 0; x < xLength; x++) {
                                    xColumn.addFromPA(axisPA3, x);
                                    yColumn.addFromPA(axisPA2, y);
                                    zColumn.addFromPA(axisPA1, z);
                                    tColumn.addFromPA(axisPA0, t);                                  
                                }
                            }
                        }
                    }
                }

                //get data
                PrimitiveArray pa = PrimitiveArray.factory(NcHelper.getArray(variable.read())); 
                //unpack is done at end of method
                //String2.log("Table.read4DNc v=" + v + ": " + pa);

                //store data
                addColumn(variable.getName(), pa);
                NcHelper.getVariableAttributes(variable, columnAttributes(nColumns() - 1));

                //does this var point to the pseudo-data var with CF grid_mapping (projection) information?
                if (gridMappingAtts == null) 
                    gridMappingAtts = NcHelper.getGridMappingAtts(ncFile, 
                        columnAttributes(nColumns() - 1).getString("grid_mapping"));
            }

            //load the stringVariable
            if (stringVariableName != null) {
                Variable variable = ncFile.findVariable(stringVariableName);
                PrimitiveArray pa = PrimitiveArray.factory(NcHelper.getArray(variable.read())); 
                //unpack is done at end of method
                if (debugMode) String2.log("  stringVariableName values=" + pa);
                Attributes atts = new Attributes();
                NcHelper.getVariableAttributes(variable, atts);

                //store data
                if (stringVariableColumn < 0 || stringVariableColumn > nColumns())
                    stringVariableColumn = nColumns();
                String sar[] = new String[nRows()];
                Arrays.fill(sar, pa.getString(0));
                addColumn(stringVariableColumn, stringVariableName, new StringArray(sar), atts);
            }

            //load the global metadata
            NcHelper.getGlobalAttributes(ncFile, globalAttributes());
            if (gridMappingAtts != null)
                globalAttributes.add(gridMappingAtts);

            //unpack 
            decodeCharsAndStrings();
            if (standardizeWhat > 0) {
                convertToUnsignedPAs();
                standardize(standardizeWhat);
            } else if (standardizeWhat == 0) {
                //do nothing
            } else {
                convertToUnsignedPAs();
                convertToStandardMissingValues();
            }

            if (reallyVerbose) msg +=  
                " finished. nColumns=" + nColumns() + " nRows=" + nRows() + 
                " TIME=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            ncFile.close(); 
            if (reallyVerbose) String2.log(msg);
        }

    }

    /**
     * This reads and flattens all specified nDimensional (1 or more) variables 
     * (which must have shared dimensions) into a table.
     * <br>Axis vars can't be String variables.
     * <br>Axis vars can be just dimensions (not actual variables).
     *
     * <p>If the fullName is an http address, the name needs to start with "http:\\" 
     * (upper or lower case) and the server needs to support "byte ranges"
     * (see ucar.nc2.NetcdfFile documentation).
     * 
     * @param fullName This may be a local file name, an "http:" address of a
     *    .nc file, an .ncml file (which must end with ".ncml"), or an opendap url.
     * @param loadVariableNames if null or length 0, all vars are read.
     *    <br>If a specified var isn't in the file, there won't be a column in the results file for it.
     *    <br>All dimension vars are automatically loaded.
     *    <br>0D and 1D vars in loadVariables are ignored (since they will be loaded automatically).
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat
     * @param constraintAxisVarName  or null if none.
     *    <br>This works if constraintAxisVar is sorted ascending (it is tested here); 
     *      otherwise the constraint is ignored.
     *    <br>This uses precision of 5 digits, so the constraint is very crude (but valid) 
     *      for time (e.g., seconds since 1970-01-01).
     * @param constraintMin  if variable is packed, this is packed. 
     * @param constraintMax  if variable is packed, this is packed.
     * @throws Exception if trouble.
     *    But if none of the specified loadVariableNames are present, 
     *    it is not an error and it returns an empty table.
     */
    public void readNDNc(String fullName, String loadVariableNames[], 
        int standardizeWhat, 
        String constraintAxisVarName, double constraintMin, double constraintMax) throws Exception {

        //clear the table
        clear();
        if (loadVariableNames == null)
            loadVariableNames = new String[0];
        String msg = "  Table.readNDNC " + fullName;
        if (debugMode) String2.log(msg + 
            "  loadVars:" + String2.toCSSVString(loadVariableNames) +
            (constraintAxisVarName == null? "" :
                "\n  constrain:" + constraintAxisVarName + " >=" + constraintMin + " <=" + constraintMax)); 
        long time = System.currentTimeMillis();
        String errorInMethod = String2.ERROR + " in Table.readNDNc " + fullName + ":\n";
        //get information
        NetcdfFile ncFile = NcHelper.openFile(fullName);
        Attributes gridMappingAtts = null;
        try {
            //load the global metadata
            NcHelper.getGlobalAttributes(ncFile, globalAttributes());

            //load the variables
            Variable loadVariables[] = null;
            Dimension loadDims[] = null;
            if (loadVariableNames.length == 0) {
                loadVariables = NcHelper.findMaxDVariables(ncFile, ""); //throws exception if no vars with dimensions
            } else {
                ArrayList varList = new ArrayList();
                ArrayList dimList = new ArrayList(); //just dims that aren't also variables
                for (int i = 0; i < loadVariableNames.length; i++) {
                    Variable variable = ncFile.findVariable(loadVariableNames[i]);
                    if (variable == null) {
                        Dimension dim = ncFile.findDimension(loadVariableNames[i]);
                        if (dim == null) {
                            if (verbose) String2.log("  var=" + loadVariableNames[i] + " not found");
                        } else {
                            dimList.add(dim);
                        }
                    } else {
                        varList.add(variable);
                    }
                }
                loadVariables = NcHelper.variableListToArray(varList);
                loadDims = NcHelper.dimensionListToArray(dimList);
                if (loadVariables.length == 0) {
                    int nDims = loadDims.length;
                    if (nDims == 0)
                        return; //empty table
                    //just load dimensions that aren't variables
                    int shape[] = new int[nDims];
                    IntArray iaa[] = new IntArray[nDims];
                    for (int i = 0; i < nDims; i++) {
                        shape[i] = loadDims[i].getLength();
                        iaa[i] = new IntArray();
                        addColumn(loadDims[i].getShortName(), iaa[i]); //no variable metadata
                    }
                    NDimensionalIndex ndi = new NDimensionalIndex(shape);
                    int current[] = ndi.getCurrent();
                    while (ndi.increment()) {
                        for (int i = 0; i < nDims; i++) 
                            iaa[i].add(current[i]);
                    }
                    decodeCharsAndStrings();
                    convertToUnsignedPAs();
                    //no metadata so no unpack
                    return;
                } 
            }

            //go through the variables
            int nAxes = -1;  //not set up yet
            int readOrigin[] = null;
            int axisLengths[] = null;
            for (int v = 0; v < loadVariables.length; v++) {
                Variable variable = loadVariables[v];
                boolean isChar = variable.getDataType() == DataType.CHAR;
                if (debugMode) 
                    String2.log("var#" + v + "=" + variable.getFullName());

                //is it a 0D variable?    
                if (variable.getRank() + (isChar? -1 : 0) == 0) { 
                    if (debugMode) String2.log("  skipping 0D var");
                    continue;
                }

                //is it an axis variable?    
                if (!isChar && variable.getRank() == 1 &&
                    variable.getDimension(0).getFullName().equals(variable.getFullName())) { //varName = dimName
                    if (debugMode) String2.log("  skipping axisVariable");
                    continue;
                }

                //if first non-axis variable, set up axis columns
                if (nAxes < 0) {

                    //set up dim variables                    
                    nAxes = variable.getRank() - (isChar? 1 : 0);
                    PrimitiveArray axisPAs[] = new PrimitiveArray[nAxes];
                    PrimitiveArray columnPAs[] = new PrimitiveArray[nAxes];
                    axisLengths = new int[nAxes];

                    List axisList = variable.getDimensions();                        
                    for (int a = 0; a < nAxes; a++) {
                        Dimension dimension = (Dimension)axisList.get(a);
                        String axisName = dimension.getFullName();
                        axisLengths[a] = dimension.getLength();
                        if (debugMode) String2.log("  found axisName=" + axisName + " size=" + axisLengths[a]);
                        Attributes atts = new Attributes();
                        Variable axisVariable = ncFile.findVariable(axisName);
                        if (axisVariable == null) {
                            //that's ok; set up dummy 0,1,2,3...
                            axisPAs[a] = 
                                axisLengths[a] < Byte.MAX_VALUE - 1?  new ByteArray( 0, axisLengths[a]-1) :
                                axisLengths[a] < Short.MAX_VALUE - 1? new ShortArray(0, axisLengths[a]-1) :
                                                                      new IntArray(  0, axisLengths[a]-1);
                        } else {
                            axisPAs[a] = NcHelper.getPrimitiveArray(axisVariable); 
                            NcHelper.getVariableAttributes(axisVariable, atts);
                        }
                        columnPAs[a] = PrimitiveArray.factory(axisPAs[a].elementType(), 1, false);
                        addColumn(a, axisName, columnPAs[a], atts);
                        standardizeColumn(standardizeWhat, a);
                    }    
                    readOrigin = new int[nAxes]; //all 0's
                    //readShape = axisLengths

                    //deal with constraintAxisVarName
                    int constraintCol = constraintAxisVarName == null? -1 : findColumnNumber(constraintAxisVarName);
                    int constraintFirst = -1;
                    int constraintLast = -1; 
                    if (constraintCol >= 0 && 
                        !Double.isNaN(constraintMin) && !Double.isNaN(constraintMax)) {
                        PrimitiveArray cpa = axisPAs[constraintCol];
                        String asc = cpa.isAscending();
                        if (asc.length() == 0) {
                            constraintFirst = cpa.binaryFindFirstGAE(0, cpa.size() - 1, 
                                PAOne.fromDouble(constraintMin), 5);
                            if (constraintFirst >= cpa.size())
                                constraintFirst = -1;
                            else constraintLast  = cpa.binaryFindLastLAE(constraintFirst, 
                                cpa.size() - 1, PAOne.fromDouble(constraintMax), 5);
                            if (debugMode) String2.log("  constraintAxisVar=" + constraintAxisVarName + 
                                " is ascending.  first=" + constraintFirst + 
                                " last(inclusive)=" + constraintLast);
                            if (constraintFirst >= 0 && constraintLast >= constraintFirst) {
                                //ok, use it
                                readOrigin[ constraintCol] = constraintFirst;
                                axisLengths[constraintCol] = constraintLast - constraintFirst + 1;
                                cpa.removeRange(constraintLast + 1, cpa.size());  
                                cpa.removeRange(0, constraintFirst);
                            }
                        } else {
                            if (debugMode) String2.log("  constraintAxisVar=" + constraintAxisVarName + 
                                " isn't ascending: " + asc);
                        }
                    }

                    //populate the axes columns
                    NDimensionalIndex ndi = new NDimensionalIndex(axisLengths);
                    Math2.ensureArraySizeOkay(ndi.size(), "Table.readNDNc");
                    int nRows = (int)ndi.size(); //safe since checked above
                    int current[] = ndi.getCurrent();
                    for (int a = 0; a < nAxes; a++) 
                        columnPAs[a].ensureCapacity(nRows);
                    while (ndi.increment()) {
                        for (int a = 0; a < nAxes; a++) {
                            //String2.log("  a=" + a + " current[a]=" + current[a] + 
                            //    " axisPAs[a].size=" + axisPAs[a].size());
                            //getDouble not getString since axisVars aren't strings, double is faster
                            columnPAs[a].addDouble(axisPAs[a].getDouble(current[a])); 
                        }
                    }
                }

                //ensure axes are as expected
                if (isChar) {
                    Test.ensureEqual(variable.getRank(), nAxes + 1,
                        errorInMethod + "Unexpected nDimensions for String variable: " + 
                        variable.getFullName());
                } else {
                    Test.ensureEqual(variable.getRank(), nAxes,
                        errorInMethod + "Unexpected nDimensions for numeric variable: " + 
                        variable.getFullName());
                }
                for (int a = 0; a < nAxes; a++) 
                    Test.ensureEqual(variable.getDimension(a).getFullName(), getColumnName(a),
                        errorInMethod + "Unexpected axis#" + a + 
                        " for variable=" + variable.getFullName());

                //get the data
                int tReadOrigin[] = readOrigin;
                int tReadShape[] = axisLengths;
                if (isChar && variable.getRank() == nAxes + 1) {
                    tReadOrigin = new int[nAxes + 1]; //all 0's
                    tReadShape  = new int[nAxes + 1];
                    System.arraycopy(readOrigin,  0, tReadOrigin, 0, nAxes);
                    System.arraycopy(axisLengths, 0, tReadShape, 0, nAxes);
                    tReadOrigin[nAxes] = 0;
                    tReadShape[nAxes] = variable.getDimension(nAxes).getLength();
                }
                Array array = variable.read(tReadOrigin, tReadShape); 
                PrimitiveArray pa = PrimitiveArray.factory(NcHelper.getArray(array)); 
                Test.ensureEqual(pa.size(), nRows(),
                    errorInMethod + "Unexpected nRows for " + variable.getFullName() + ".");

                //store data
                addColumn(variable.getFullName(), pa);
                NcHelper.getVariableAttributes(variable, columnAttributes(nColumns() - 1));

                //does this var point to the pseudo-data var with CF grid_mapping (projection) information?
                if (gridMappingAtts == null) {
                    gridMappingAtts = NcHelper.getGridMappingAtts(ncFile, 
                        columnAttributes(nColumns() - 1).getString("grid_mapping"));
                    if (gridMappingAtts != null)
                        globalAttributes.add(gridMappingAtts);
                }

            }

            //if the request is only for axis variables, set up axis columns
            //Note that request must have been for specific vars, since all vars would have found non-axis vars.
            if (nAxes < 0) { //no non-axis vars were requested; all vars are axis vars
                //This isn't quite right.  There may be other axes which weren't requested.
                //But in that case, this will at least return all distinct combinations 
                //  of the requested axis vars.

                //ensure names are available dimensions 
                //  !!they could be nDimensional vars that aren't in this file
                ArrayList dimensions = new ArrayList();
                for (int v = 0; v < loadVariableNames.length; v++) {
                    String axisName = loadVariableNames[v];
                    Dimension dimension = ncFile.findDimension(axisName);
                    if (dimension != null) 
                        dimensions.add(dimension);
                }

                if (dimensions.size() > 0) {

                    //set up dim variables                    
                    nAxes = dimensions.size();
                    PrimitiveArray axisPAs[] = new PrimitiveArray[nAxes];
                    PrimitiveArray columnPAs[] = new PrimitiveArray[nAxes];
                    axisLengths = new int[nAxes];

                    for (int a = 0; a < nAxes; a++) {
                        Dimension dimension = (Dimension)dimensions.get(a);
                        String axisName = dimension.getFullName();
                        Attributes atts = new Attributes();
                        axisLengths[a] = dimension.getLength();
                        if (debugMode) String2.log("  found axisName=" + axisName + " size=" + axisLengths[a]);
                        Variable axisVariable = ncFile.findVariable(axisName);
                        if (axisVariable == null) {
                            //that's ok; set up dummy 0,1,2,3...
                            axisPAs[a] = 
                                axisLengths[a] < Byte.MAX_VALUE - 1?  new ByteArray( 0, axisLengths[a]-1) :
                                axisLengths[a] < Short.MAX_VALUE - 1? new ShortArray(0, axisLengths[a]-1) :
                                                                      new IntArray(  0, axisLengths[a]-1);
                        } else {
                            axisPAs[a] = NcHelper.getPrimitiveArray(axisVariable); 
                            NcHelper.getVariableAttributes(axisVariable, atts);
                        }
                        columnPAs[a] = PrimitiveArray.factory(axisPAs[a].elementType(), 1, false);
                        addColumn(a, axisName, columnPAs[a], atts);
                        standardizeColumn(standardizeWhat, a);
                    }    
                    readOrigin = new int[nAxes]; //all 0's
                    //readShape = axisLengths

                    //deal with constraintAxisVarName
                    int constraintCol = constraintAxisVarName == null? -1 : findColumnNumber(constraintAxisVarName);
                    int constraintFirst = -1;
                    int constraintLast = -1; 
                    if (constraintCol >= 0 && 
                        !Double.isNaN(constraintMin) && !Double.isNaN(constraintMax)) {
                        PrimitiveArray cpa = axisPAs[constraintCol];
                        String asc = cpa.isAscending();
                        if (asc.length() == 0) {
                            constraintFirst = cpa.binaryFindFirstGAE(0, cpa.size() - 1, 
                                PAOne.fromDouble(constraintMin), 5);
                            if (constraintFirst >= cpa.size())
                                constraintFirst = -1;
                            else constraintLast  = cpa.binaryFindLastLAE(constraintFirst, 
                                cpa.size() - 1, PAOne.fromDouble(constraintMax), 5);
                            if (debugMode) String2.log("  constraintAxisVar=" + constraintAxisVarName + 
                                " is ascending.  first=" + constraintFirst + 
                                " last(inclusive)=" + constraintLast);
                            if (constraintFirst >= 0 && constraintLast >= constraintFirst) {
                                //ok, use it
                                readOrigin[ constraintCol] = constraintFirst;
                                axisLengths[constraintCol] = constraintLast - constraintFirst + 1;
                                cpa.removeRange(constraintLast + 1, cpa.size());  
                                cpa.removeRange(0, constraintFirst);
                            }
                        } else {
                            if (debugMode) String2.log("  constraintAxisVar=" + constraintAxisVarName + 
                                " isn't ascending: " + asc);
                        }
                    }

                    //populate the axes columns
                    NDimensionalIndex ndi = new NDimensionalIndex(axisLengths);
                    Math2.ensureArraySizeOkay(ndi.size(), "Table.readNDNc"); 
                    int nRows = (int)ndi.size(); //safe since checked above
                    int current[] = ndi.getCurrent();
                    for (int a = 0; a < nAxes; a++) 
                        columnPAs[a].ensureCapacity(nRows);
                    while (ndi.increment()) {
                        for (int a = 0; a < nAxes; a++) {
                            //String2.log("  a=" + a + " current[a]=" + current[a] + 
                            //    " axisPAs[a].size=" + axisPAs[a].size());
                            columnPAs[a].addFromPA(axisPAs[a], current[a]); 
                        }
                    }
                }
            }

            //load the 0D variables
            Group rootGroup = ncFile.getRootGroup();
            List rootGroupVariables = rootGroup.getVariables(); 
            int tnRows = nRows();
            for (int v = 0; v < rootGroupVariables.size(); v++) {
                Variable var = (Variable)rootGroupVariables.get(v);
                boolean isChar = var.getDataType() == DataType.CHAR;
                if (var.getRank() + (isChar? -1 : 0) == 0) {
                    //if loadVariableNames specified, skip var because not explicitly requested?
                    if (loadVariableNames.length > 0 && 
                        String2.indexOf(loadVariableNames, var.getShortName()) < 0)
                        continue;

                    //read it
                    PrimitiveArray pa = NcHelper.getPrimitiveArray(var);                    
                    //nc allows strings to be 0-terminated or padded with spaces, so always trimEnd
                    if (pa instanceof StringArray) 
                        pa.setString(0, String2.trimEnd(pa.getString(0)));
                    if (tnRows > 1) {
                        if (pa instanceof StringArray) 
                             pa.addNStrings(tnRows-1, pa.getString(0));
                        else pa.addNDoubles(tnRows-1, pa.getDouble(0));
                    }
    
                    Attributes atts = new Attributes();
                    NcHelper.getVariableAttributes(var, atts);
                    addColumn(nColumns(), var.getShortName(), pa, atts);
                    standardizeLastColumn(standardizeWhat);
                }
            }
            decodeCharsAndStrings();
            convertToUnsignedPAs();
            if (reallyVerbose) msg += " finished. nRows=" + nRows() + 
                " nCols=" + nColumns() + " time=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {            
            ncFile.close(); 
            if (reallyVerbose) String2.log(msg);
        }
    }


    /**
     * This reads and flattens a group of variables which share dimensions
     * from a multidimensional .nc file.  (A new alternative to readNDNc().)
     * One difference between using this and readNcCF: this doesn't require/expect
     * that the file follows the nc CF DSG MA standard.
     * <br>This does not unpack the values or convert to standardMissingValues.
     * <br>For strings, this always calls String2.trimEnd(s)
     * 
     * @param fullName This may be a local file name, an "http:" address of a
     *   .nc file, an .ncml file (which must end with ".ncml"), or an opendap url.
     *   <p>If the fullName is an http address, the name needs to start with "http://" 
     *   or "https://" (upper or lower case) and the server needs to support "byte ranges"
     *   (see ucar.nc2.NetcdfFile documentation). 
     *   But this is very slow, so not recommended.
     * @param loadVarNames  
     *   If loadVarNames is specified, those variables will be loaded.
     *   If loadVarNames isn't specified, this method reads vars which use
     *   the specified loadDimNames and scalar vars.
     *   <br>If a specified var isn't in the file, there won't be a column 
     *   in the results table for it and it isn't an error.
     * @param loadDimNames. If loadVarNames is specified, this is ignored.  
     *   If loadDimNames is used, all variables using any of these dimensions
     *   (and dimension-less variables) will be loaded, plus all scalar vars.
     *   Don't include string-length dimensions.
     *   Just include the last treatDimensionsAs dimension (if any).
     *   Almost always, there will be 1+ variables which use all of these dimensions.
     *   If a given dimension isn't it the file, it is removed from the list.
     *   If loadDimNames isn't specified (or size=0), this method finds the var which uses
     *     the most dimensions, and uses for loadDimNames.
     *   So if you want to get just the scalar vars, request a nonexistent
     *      dimension (e.g., ZZTOP).
     * @param treatDimensionsAs Lists of dimension names that 
     *   should be treated as another dimension (the last in each list).
     *   Within a list, all dimensions that are in the file must be the same length.
     *   E.g. "Lat,Lon,Time" says to treat Lat and Lon as if they were Time.       
     * @param getMetadata if true, global and variable metadata is read
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat
     * @param removeMVRows This removes any block of rows at the
     *   end of a group where all the values are missing_value, _FillValue,
     *   or the CoHort ...Array native missing value (or char=#32 for CharArrays).
     *   This is for the CF DSG Multidimensional Array file type and similar files.
     *   If true, this does the proper test and so always loads all the 
     *   max dim variables, so it may take extra time. 
     * @param conVars the names of the constraint variables. May be null.
     *   It is up to this method how much they will be used.
     *   Currently, the constraints are just used for *quick* tests to see if the
     *   file has no matching data.  
     *   If a conVar isn't in the loadVarNames (provided or derived),
     *   then the constraint isn't used.
     *   If standardizeWhat != 0, the constaints are applied to the unpacked variables.
     * @param conOps the operators for the constraints.
     *   All ERDDAP ops are supported. May be null.
     * @param conVals the values of the constraints. May be null.
     * @throws Exception if unexpected trouble.
     *    But if none of the specified loadVariableNames are present
     *    or a requested dimension's size=0, 
     *    it is not an error and it returns an empty table.
     */
    public void readMultidimNc(String fullName, 
        StringArray loadVarNames, 
        StringArray loadDimNames, 
        String treatDimensionsAs[][], //will be null if not used
        boolean getMetadata, //before 2016-11-29, this had a boolean trimStrings parameter, now it always trimEnd's all strings 
        int standardizeWhat, 
        boolean removeMVRows,
        StringArray conVars, StringArray conOps, StringArray conVals) throws Exception {

        //clear the table
        clear();
        if (loadVarNames == null)
            loadVarNames = new StringArray();
        if (loadDimNames == null)
            loadDimNames = new StringArray();
        if (standardizeWhat != 0 || removeMVRows)
            getMetadata = true;
        String msg = "  Table.readMultidimNc " + fullName + 
            "\n  loadVars=" + loadVarNames; 
        long time = System.currentTimeMillis();
        String warningInMethod = "Table.readMultidimNc read " + fullName + ":\n";
        boolean haveConstraints = 
            conVars != null && conVars.size() > 0 &&
            conOps  != null && conOps.size() == conVars.size() &&
            conVals != null && conVals.size() == conVars.size();
        if (treatDimensionsAs == null || treatDimensionsAs.length == 0) 
            treatDimensionsAs = null;
        int nd0 = treatDimensionsAs == null? 0 : treatDimensionsAs.length;
        if (nd0 > 0) {
            for (int d0 = 0; d0 < nd0; d0++) {
                if (treatDimensionsAs[d0] == null)
                    throw new RuntimeException(warningInMethod + 
                        "treatDimensionAs[" + d0 + "] is null!");
                else if (treatDimensionsAs[d0].length < 2) 
                    throw new RuntimeException(warningInMethod + 
                        "treatDimensionAs[" + d0 + "].length=" + 
                        treatDimensionsAs[d0].length + " must be >1: " +
                        String2.toCSSVString(treatDimensionsAs[d0]));
                if (debugMode) 
                    msg +=" treatDimensionsAs[" + d0 + "]=" + String2.toCSSVString(treatDimensionsAs[d0]); 
            }
        }

        //read the file
        NetcdfFile ncFile = NcHelper.openFile(fullName);
        Attributes gridMappingAtts = null;
        try {

            //load the global metadata
            if (getMetadata)
                NcHelper.getGlobalAttributes(ncFile, globalAttributes());

            //treatDimensionsAs
            Dimension tDimsAs[][] = null;
            if (nd0 > 0) {                
                tDimsAs = new Dimension[nd0][];
                for (int d0 = 0; d0 < nd0; d0++) {            
                    int nd1 = treatDimensionsAs[d0].length; 
                    tDimsAs[d0] = new Dimension[nd1];
                    int tDimsSize = -1;
                    for (int d1 = 0; d1 < nd1; d1++) { 
                        tDimsAs[d0][d1] = ncFile.findDimension(treatDimensionsAs[d0][d1]);
                        if (tDimsAs[d0][d1] == null) {
                            msg = warningInMethod + 
                                "treatDimensionAs[" + d0 + "][" + d1 + "]=" + treatDimensionsAs[d0][d1] + 
                                " isn't in the file.";
                            if (d1 == nd1-1) //the 'to' dim must be in the file
                                throw new RuntimeException(msg);
                            if (debugMode) String2.log(msg);
                            continue;
                        }
                        if (tDimsSize < 0)
                            tDimsSize = tDimsAs[d0][d1].getLength();
                        else Test.ensureEqual(tDimsAs[d0][d1].getLength(), tDimsSize, 
                            warningInMethod +
                            "All of the treatDimensionsAs dimensions (" + 
                            String2.toCSSVString(treatDimensionsAs[d0]) + 
                            ") must be the same length ([" + d0 + "][" + d1 + "]).");
                    }
                }
            }

            //In order to be able to tell the difference between multiDimensional 
            //char vars and String vars,
            //I need to know which dims are non-String-length dimensions.
            //This isn't perfect / fool-proof.
            //(It is done this way because it easier/more reliable to generate this list
            //than the list of string dimensions.)
            HashSet<Dimension> notStringLengthDims = new HashSet();
            List<Variable> allVars = ncFile.getVariables();
            int nAllVars = allVars.size();
            for (int v = 0; v < nAllVars; v++) {
                Variable tVar = allVars.get(v);
                List<Dimension> tDims = tVar.getDimensions(); //won't be null
                int tnDims = tDims.size();
                //here, assume the last dim of any multiDim char var
                //is the string length dimension, so skip it
                if (tVar.getDataType() == DataType.CHAR) 
                    tnDims--;
                for (int d = 0; d < tnDims; d++)
                    notStringLengthDims.add(tDims.get(d));
            }

            // *** first half: make loadVars
            ArrayList<Variable>  loadVars = new ArrayList(); //which we will actually load
            ArrayList<Dimension> loadDims = new ArrayList(); //which we actually need
            if (loadVarNames.size() > 0) {
                //loadVarNames was specified

                //gather the loadVars and loadDims (not including the aliases)
                loadDimNames.clear();
                for (int v = 0; v < loadVarNames.size(); v++) { 
                    Variable var = ncFile.findVariable(loadVarNames.get(v));
                    if (var == null) {
                        loadVarNames.remove(v--); //var not in file, so don't try to load it
                    } else {
                        loadVars.add(var);
                        List<Dimension> tDims = var.getDimensions(); //won't be null
                        boolean isCharArray = var.getDataType() == DataType.CHAR &&
                            tDims.size() > 0 && 
                            !notStringLengthDims.contains(tDims.get(tDims.size() - 1));
                        int ntDims = tDims.size() - (isCharArray? 1 : 0);
                        for (int d = 0; d < ntDims; d++) {
                            Dimension tDim = tDims.get(d);
                            if (loadDims.indexOf(tDim) < 0) {  //not yet in the list
                                for (int d0 = 0; d0 < nd0; d0++) {
                                    if (String2.indexOfObject(tDimsAs[d0], tDim) >= 0) { 
                                        //convert to the 'as' dimension
                                        tDim  = tDimsAs[d0][tDimsAs[d0].length - 1];
                                        break;
                                    }
                                }
                                if (loadDims.indexOf(tDim) < 0) {  //possibly different tDim not yet in the list
                                    loadDims.add(tDim);
                                    loadDimNames.add(tDim.getFullName());
                                }   
                            }
                        }
                    }
                }
                if (loadVars.size() == 0) {
                    if (verbose) String2.log(warningInMethod + 
                        "Returning an empty table because none of the requested variables are in the file. " +
                        "time=" + (System.currentTimeMillis() - time));
                    return;
                }

            } else {
                //loadVarNames wasn't specified

                if (loadDimNames.size() == 0) {
                    //loadDimNames wasn't specified either

                    //find var(s) that use the most dimensions
                    try {
                        Variable tVars[] = NcHelper.findMaxDVariables(ncFile, "");  //throws Exception if no vars with dimensions

                        //gather loadDims from the first of those vars 
                        //(so it won't include aliases)
                        Variable tVar = tVars[0];
                        List<Dimension> tDims = tVar.getDimensions(); //won't be null
                        boolean isCharArray = tVar.getDataType() == DataType.CHAR &&
                            tDims.size() > 0 && 
                            !notStringLengthDims.contains(tDims.get(tDims.size() - 1));
                        int ntDims = tDims.size() - (isCharArray? 1 : 0);
                        for (int d = 0; d < ntDims; d++) {
                            Dimension dim = tDims.get(d);
                            loadDims.add(dim);
                            loadDimNames.add(dim.getFullName());
                        }
                    } catch (Exception e) {
                        //FUTURE: read all static variables
                        String2.log("Table.readMultidimNc caught: " + e.toString());
                    }

                } else {
                    //loadDimNames was specified (it doesn't include aliases)
                    //gather the specified loadDims
                    for (int d = 0; d < loadDimNames.size(); d++) {
                        String dimName = loadDimNames.get(d);
                        Dimension dim = ncFile.findDimension(dimName);
                        if (dim == null) {
                            String2.log("Removing dimName=" + dimName + ": it isn't in the file.");
                            loadDimNames.remove(d--);
                        } else {
                            loadDims.add(dim);
                        }
                    }
                    if (loadDimNames.size() == 0) 
                        String2.log("None of the requested loadDimNames is in the file.");
                }

                //now, loadDims is known, but loadVars isn't
                //find vars that use any subset of loadDims (and no others)
                //including scalar vars
                boolean dimUsed[] = new boolean[loadDims.size()];
                LOADVARS_V:
                for (int v = 0; v < nAllVars; v++) {
                    Variable var = allVars.get(v);
                    List<Dimension> tDims = var.getDimensions(); //won't be null
                    boolean isCharArray = var.getDataType() == DataType.CHAR &&
                        tDims.size() > 0 && 
                        !notStringLengthDims.contains(tDims.get(tDims.size() - 1));
                    int ntDims = tDims.size() - (isCharArray? 1 : 0);
                    for (int d = 0; d < ntDims; d++) {
                        Dimension tDim = tDims.get(d);
                        int whichDim = loadDims.indexOf(tDim);
                        if (whichDim < 0) {
                            //is it one of the aliases?
                            for (int d0 = 0; d0 < nd0; d0++) {
                                if (String2.indexOfObject(tDimsAs[d0], tDim) >= 0) { 
                                    //change to the 'as' dimension?
                                    whichDim = loadDims.indexOf(tDimsAs[d0][tDimsAs[d0].length - 1]); 
                                    if (whichDim >= 0)
                                        break;
                                }
                            }
                        }
                        if (whichDim < 0)
                            continue LOADVARS_V;
                        dimUsed[whichDim] = true;
                    }
                    loadVars.add(var);
                    loadVarNames.add(var.getFullName());
                }
                if (loadVars.size() == 0) {
                    if (verbose) String2.log(warningInMethod +  
                        "Returning an empty table because there are no scalar variables " +
                        "and no variables in the file use any of these dimensions: " + 
                        loadDimNames + ". " +
                        "time=" + (System.currentTimeMillis() - time));
                    return;
                }

                //remove unused dimensions
                for (int d = loadDims.size() - 1; d >= 0; d--) { //backwards since may delete
                    if (!dimUsed[d])
                        loadDims.remove(d);
                }
                if (loadDims.size() == 0)
                    String2.log("After analysis, loadDims.size is now 0!");
            }

            //loadVars is known and only uses loadDims
            //loadDims is known and only has dims used by loadVars
            if (debugMode) String2.log(
                ">> loadVars=" + loadVarNames + 
              "\n>> loadDims=" + loadDimNames);
            int nLoadVars = loadVars.size();


            // *** quick reject file? (by testing constraints on small (scalar and 1D) vars)
//FUTURE: this could be a little smarter: maintain separate keep bitsets for each 1D var 
//(and for scalars) so that the constraints are cumulative for each dimension.
            PrimitiveArray knownPAs[]  = new PrimitiveArray[nLoadVars]; //read vars will be cached here
            Attributes     knownAtts[] = new Attributes[nLoadVars]; //read var's atts will be cached here
            if (haveConstraints) {
                int nCons = conVars.size();
                
                //go through the load vars looking for 0D or 1D vars that have constraints
                for (int v = 0; v < nLoadVars; v++) {
                    //is there at least 1 constraint of this var?
                    String varName = loadVarNames.get(v);
                    int con1 = conVars.indexOf(varName);
                    if (con1 < 0)
                        continue;

                    //is this a 0D or 1D var?
                    Variable tVar = loadVars.get(v);
                    List<Dimension> tDims = tVar.getDimensions(); //won't be null
                    boolean isCharArray = tVar.getDataType() == DataType.CHAR &&
                        tDims.size() > 0 && 
                        !notStringLengthDims.contains(tDims.get(tDims.size() - 1));
                    int ntDims = tDims.size() - (isCharArray? 1 : 0);
                    if (ntDims > 1)
                        continue;

                    //read info
                    PrimitiveArray pa = NcHelper.getPrimitiveArray(tVar, isCharArray);
                    if (pa instanceof StringArray) 
                        ((StringArray)pa).trimEndAll();
                    Attributes atts = new Attributes();
                    if (getMetadata)
                        NcHelper.getVariableAttributes(tVar, atts);
                    pa = atts.standardizeVariable(standardizeWhat, varName, pa);
                    knownPAs[v] = pa;
                    knownAtts[v] = atts;

                    //test constraints
                    BitSet keep = new BitSet();
                    keep.set(0, pa.size());
                    for (int con = con1; con < nCons; con++) {
                        if (!conVars.get(con).equals(varName))
                            continue;
                        if (pa.applyConstraint(false, //less precise, so more likely to pass the test
                            keep, conOps.get(con), conVals.get(con)) == 0) {
                            if (verbose) String2.log(warningInMethod +
                                "Returning an empty table because var=" + varName + 
                                " failed its constraints, including " + 
                                conOps.get(con) + conVals.get(con) +
                                ". time=" + (System.currentTimeMillis() - time) + "ms");
                            return;
                        }
                    }
                }
            }


            // *** second half: load the loadVars
            
            //find vars with all of the loadDims
            //If loadDims size=0, this finds scalar vars
            BitSet loaded = new BitSet(nLoadVars); //all false
            int shape[] = new int[loadDims.size()];
            ALL_DIMS_V:
            for (int v = 0; v < nLoadVars; v++) {
                Variable tVar = loadVars.get(v);
                List<Dimension> tDims = tVar.getDimensions(); //won't be null
                boolean isCharArray = tVar.getDataType() == DataType.CHAR &&
                    tDims.size() > 0 && 
                    !notStringLengthDims.contains(tDims.get(tDims.size() - 1));
                int ntDims = tDims.size() - (isCharArray? 1 : 0);
                if (ntDims != loadDims.size())
                    continue;
                if (nColumns() == 0) {
                    //first var with all dims: set loadDims to be in that order
                    for (int d = 0; d < ntDims; d++) {
                        Dimension dim = tDims.get(d);
                        for (int d0 = 0; d0 < nd0; d0++) {
                            if (String2.indexOfObject(tDimsAs[d0], dim) >= 0) {
                                //convert to the 'as' dimension
                                dim = tDimsAs[d0][tDimsAs[d0].length - 1]; 
                                break;
                            }
                        }
                        loadDims.set(d, dim); //perhaps change loadDims to different order
                        loadDimNames.set(d, dim.getFullName());
                        shape[d] = dim.getLength();
                        if (shape[d] == 0) {
                            if (verbose) String2.log(warningInMethod +
                                "Returning an empty table because dim=" + dim.getFullName() + 
                                "'s length=0! " +
                                "time=" + (System.currentTimeMillis() - time));
                            return;
                        }
                    }
                } else {
                    //subsequent vars
                    //ensure same order of same dims. If not, read the var in next section.
                    for (int d = 0; d < ntDims; d++) {
                        Dimension dim = tDims.get(d);
                        for (int d0 = 0; d0 < nd0; d0++) {
                            if (String2.indexOfObject(tDimsAs[d0], dim) >= 0) {
                                //convert to the 'as' dimension 
                                dim = tDimsAs[d0][tDimsAs[d0].length - 1];
                                break;
                            }
                        }
                        if (!loadDims.get(d).equals(dim)) 
                            continue ALL_DIMS_V;
                    }
                }
                //yes, load this var, it has all of the dimensions in the expected order
                PrimitiveArray pa = knownPAs[v];  //v is loadVars v
                Attributes atts   = knownAtts[v]; //v is loadVars v
                knownPAs[v]  = null;
                knownAtts[v] = null;
                if (pa == null) {
                    //String2.log(">> tVar=" + tVar.getFullName() + " isCharArray=" + isCharArray);
                    pa = NcHelper.getPrimitiveArray(tVar, isCharArray);
                    if (pa instanceof StringArray) 
                        ((StringArray)pa).trimEndAll();
                    atts = new Attributes();
                    if (getMetadata)
                        NcHelper.getVariableAttributes(tVar, atts);
                    pa = atts.standardizeVariable(standardizeWhat, tVar.getFullName(), pa);
                }
                loaded.set(v);
                addColumn(nColumns(), tVar.getFullName(), pa, atts);

                //does this var point to the pseudo-data var with CF grid_mapping (projection) information?
                if (getMetadata &&
                    gridMappingAtts == null) {
                    gridMappingAtts = NcHelper.getGridMappingAtts(ncFile, 
                        atts.getString("grid_mapping"));
                    if (gridMappingAtts != null)
                        globalAttributes.add(gridMappingAtts);
                }
            }
            if (debugMode) String2.log(Math2.memoryString() + "\n" +
                ">> this table after load varsWithAllDims:\n" + 
                dataToString(5));

            //if loadDims size is 0, we're done because all scalars have been read
            if (loadDims.size() == 0) {
                if (haveConstraints) {
                    BitSet keep = new BitSet();
                    keep.set(0, nRows()); //should be just 1 row, all true
                    int nAfter = tryToApplyConstraints(-1, conVars, conOps, conVals, keep);
                    if (nAfter == 0) {
                        if (verbose) String2.log(warningInMethod +
                            "Returning an empty table after applying constraints to scalars. " +
                            "time=" + (System.currentTimeMillis() - time));
                        clear();
                        return;
                    } //else: no need to justKeep() because there is 1 row and it is valid
                }
                return;  //empty table if no scalars
            }

            //make a table with index columns for all indices
            if (nColumns() == 0) {
                //no vars have all loadDims
                if (debugMode) String2.log(Math2.memoryString() + "\n" +
                    ">> no vars have all loadDims");
                for (int d = 0; d < loadDims.size(); d++) {
                    Dimension dim = loadDims.get(d);
                    shape[d] = dim.getLength();
                    if (shape[d] == 0) {
                        if (verbose) String2.log(warningInMethod +
                            "Returning an empty table because dim=" + dim.getFullName() + 
                            "'s length=0! " +
                            "time=" + (System.currentTimeMillis() - time));
                        return;
                    }
                }
            }
            Table allIndicesTable = new Table();
            allIndicesTable.addIndexColumns(shape);
            if (debugMode) String2.log(Math2.memoryString() + "\n" +
                ">> allIndicesTable=" + 
                allIndicesTable.dataToString(5));


            //*** removeMVRows
            if (removeMVRows && nColumns() > 0) {
                //ensure all vars that use all loadDims are loaded
                int onCols = nColumns();
                REMOVE_MV_V:
                for (int v = 0; v < nAllVars; v++) {
                    Variable tVar = allVars.get(v);
                    if (findColumnNumber(tVar.getFullName()) >= 0) //already in the table
                        continue;
                    List<Dimension> tDims = tVar.getDimensions(); //won't be null
                    boolean isCharArray = tVar.getDataType() == DataType.CHAR &&
                        tDims.size() > 0 && 
                        !notStringLengthDims.contains(tDims.get(tDims.size() - 1));
                    int ntDims = tDims.size() - (isCharArray? 1 : 0);
                    if (ntDims != loadDims.size())
                        continue;
                    //ensure same order of same dims 
                    for (int d = 0; d < ntDims; d++) {
                        Dimension dim = tDims.get(d);
                        for (int d0 = 0; d0 < nd0; d0++) {
                            if (String2.indexOfObject(tDimsAs[d0], dim) >= 0) {
                                //convert to the 'as' dimension 
                                dim = tDimsAs[d0][tDimsAs[d0].length - 1];
                                break;
                            }
                        }
                        if (!loadDims.get(d).equals(dim)) 
                            continue REMOVE_MV_V;
                    }
                    //yes, load this var TEMPORARILY, it has all of the dimensions in the expected order
                    //don't use knownPAs here: different vars and different v's.
                    PrimitiveArray pa = NcHelper.getPrimitiveArray(tVar, isCharArray);
                    //FUTURE: be smarter? just trim values that are STRING_LENGTH long?
                    if (pa instanceof StringArray)
                        ((StringArray)pa).trimEndAll();
                    Attributes atts = new Attributes();
                    NcHelper.getVariableAttributes(tVar, atts);   //needed for removeMVRows
                    pa = atts.standardizeVariable(standardizeWhat, tVar.getFullName(), pa);
                    addColumn(nColumns(), tVar.getFullName(), pa, atts);
                }

                //move all the allIndices columns into the main table
                int nLoadDims = loadDims.size();
                for (int d = 0; d < nLoadDims; d++) 
                    addColumn(d, allIndicesTable.getColumnName(d), 
                        allIndicesTable.getColumn(d), 
                        allIndicesTable.columnAttributes(d));
                int nColumns = nColumns(); //including indicesColumns
                int onRows = nRows();

                //gather the missing_value and _FillValue values for each column
                boolean isDouble[] = new boolean[nColumns];
                boolean isULong[]  = new boolean[nColumns];
                boolean isLong[]   = new boolean[nColumns];
                boolean isChar[]   = new boolean[nColumns];
                double doubleMvs[] = new double[nColumns];
                double doubleFvs[] = new double[nColumns];
                BigInteger ulongMvs[] = new BigInteger[nColumns];
                BigInteger ulongFvs[] = new BigInteger[nColumns];
                long   longMvs[]   = new long[nColumns];
                long   longFvs[]   = new long[nColumns];
                for (int c = nLoadDims; c < nColumns; c++) {
                    PrimitiveArray pa = columns.get(c);
                    isDouble[c] = pa instanceof FloatArray ||
                                  pa instanceof DoubleArray;
                    isULong[c]  = pa instanceof ULongArray;
                    isLong[c]   = pa.isIntegerType() && !(pa instanceof ULongArray);
                    isChar[c]   = pa instanceof CharArray;
                    if (isDouble[c]) {
                        doubleMvs[c] = columnAttributes(c).getDouble("missing_value");
                        doubleFvs[c] = columnAttributes(c).getDouble("_FillValue");
                    } else if (isULong[c]) {
                        ulongMvs[c] = columnAttributes(c).getULong("missing_value");
                        ulongFvs[c] = columnAttributes(c).getULong("_FillValue");
                    } else if (isLong[c]) {
                        longMvs[c] = columnAttributes(c).getLong("missing_value");
                        longFvs[c] = columnAttributes(c).getLong("_FillValue");
                    }
                }

                //walk backwards.   Work within each cycle of the last dim.
                BitSet keep = new BitSet();
                keep.set(0, onRows); //all true
                PrimitiveArray lastDimCol = columns.get(nLoadDims - 1);
                for (int row = onRows - 1; row >= 0; row--) { 
                    boolean hasData = false;
                    for (int c = nLoadDims; c < nColumns; c++) {
                        //if (debugMode && row > onRows - 200)
                        //    String2.log(">> row=" + row + " col=" + c + " " +
                        //        (isDouble[c]) + " " + (isLong[c]) + " " + (isChar[c]) + " " + 
                        //        " val=" + columns.get(c).getString(row));
                        if (isDouble[c]) {
                            double d = columns.get(c).getDouble(row);
                            if (Double.isNaN(d) || 
                                Math2.almostEqual(5, d, doubleMvs[c]) ||
                                Math2.almostEqual(5, d, doubleFvs[c])) { 
                            } else {
                                hasData = true;
                                break;
                            }
                        } else if (isULong[c]) {
                            BigInteger ul = columns.get(c).getULong(row);
                            if (ul.equals(ULongArray.MAX_VALUE) ||  //trouble: should test maxIsMV
                                ul.equals(ulongMvs[c]) ||
                                ul.equals(ulongFvs[c])) { 
                            } else {
                                hasData = true;
                                break;
                            }
                        } else if (isLong[c]) {
                            long tl = columns.get(c).getLong(row);
                            if (tl == Long.MAX_VALUE ||   //trouble: should test maxIsMV
                                tl == longMvs[c] ||
                                tl == longFvs[c]) { 
                            } else {
                                hasData = true;
                                break;
                            }
                        } else if (isChar[c]) {
                            int tc = columns.get(c).getInt(row);
                            if (tc == 0 ||
                                tc == 32 ||
                                tc == Integer.MAX_VALUE) {  //trouble: should test maxIsMV
                            } else {
                                hasData = true;
                                break;
                            }
                        } else {
                            //nc allows strings to be 0-terminated or padded with spaces, so always trimEnd
                            String s = String2.trimEnd(columns.get(c).getString(row));
                            if (s.length() > 0) { 
                                hasData = true;
                                break;
                            }
                        }
                    }
                    if (hasData) {
                        //jump to next group
                        while (lastDimCol.getInt(row) > 0)
                            row--; //the loop's row-- will get to next group
                    } else {
                        keep.clear(row);
                    }
                }
                if (debugMode) { String2.log(">> removeMVRows nRows before=" + onRows + 
                        " after=" + keep.cardinality());
                    //one time debugging:
                    if (false) {
                        PrimitiveArray pa = getColumn(nLoadDims);
                        for (int row = 0; row < onRows; row++) {
                            if (keep.get(row) && pa.getDouble(row) == -99999) 
                                String2.log(">> remaining row with mv:\n" + //in debugMode
                                    dataToString(row-1, row+2));
                        }
                    }
                }

                //remove index columns and data columns just added for the MV testing
                removeColumns(0, nLoadDims);
                removeColumns(onCols, nColumns()); 

                //apply constraints
                if (haveConstraints) {
                    tryToApplyConstraints(-1, conVars, conOps, conVals, keep);
                    if (debugMode) String2.log(
                        ">> removeMVRows + constraints nRows before=" + onRows + 
                        " after=" + keep.cardinality());
                }

                //just keep
                justKeep(keep); 
                allIndicesTable.justKeep(keep); 
                if (nRows() == 0) {
                    if (verbose) String2.log(warningInMethod +
                        "Returning an empty table after removeMVRows and applying constraints. " +
                        "time=" + (System.currentTimeMillis() - time));
                    clear();
                    return;
                }

            } else if (haveConstraints && nColumns() > 0) {
                //apply constraints to vars that have all loadDims
                int onRows = nRows();
                BitSet keep = new BitSet();
                keep.set(0, onRows); //all true
                int nAfter = tryToApplyConstraints(-1, conVars, conOps, conVals, keep);
                if (nAfter == 0) {
                    if (verbose) String2.log(warningInMethod +
                        "Returning an empty table after applying constraints. " +
                        "time=" + (System.currentTimeMillis() - time));
                    clear();
                    return;
                }
                if (debugMode)
                    String2.log(Math2.memoryString() + "\n" +
                        ">> after bigVar constraints, justKeep nRows before=" + 
                        onRows + " after=" + nAfter);
                justKeep(keep); 
                allIndicesTable.justKeep(keep); 
            } 

            //read all of the other variables:
            //repeatedly, read batches of vars with same dimensions, and JOIN to main table
//FUTURE: it would be better if this looked for groups of vars that are constrained FIRST.
            while (loaded.cardinality() < nLoadVars) {
                Table lut = new Table(); //look up table which will be JOINed into main table
                List<Dimension> cDims = null;
                int ncDims = -1;

                BATCH_V:
                for (int v = 0; v < nLoadVars; v++) {
                    if (loaded.get(v))
                        continue;
                    //if (debugMode) {
                    //    String2.log(">> v=" + v + " cDims==null?" + (cDims==null) +
                    //        " lut: nCols=" + lut.nColumns() + " nRows=" + lut.nRows());
                    //    String2.log(">> lut=" + lut.dataToString(5));
                    //}

                    //look for an unloaded var (and other vars with same dimensions)
                    Variable tVar = loadVars.get(v);
                    List<Dimension> tDims = tVar.getDimensions(); //won't be null
                    boolean isCharArray = tVar.getDataType() == DataType.CHAR &&
                        tDims.size() > 0 && 
                        !notStringLengthDims.contains(tDims.get(tDims.size() - 1));
                    int ntDims = tDims.size() - (isCharArray? 1 : 0);
                    if (cDims == null) {
                        //this is the first variable found in this loop
                        cDims = tDims;
                        ncDims = ntDims;
                        int cShape[] = new int[ncDims];
                        for (int d = 0; d < ncDims; d++) {
                            //which dim is it in loadDims?
                            Dimension cDim = cDims.get(d);
                            for (int d0 = 0; d0 < nd0; d0++) {
                                if (String2.indexOfObject(tDimsAs[d0], cDim) >= 0) {
                                    //convert to the 'as' dimension 
                                    cDim = tDimsAs[d0][tDimsAs[d0].length - 1];
                                    break;
                                }
                            }
                            cShape[d] = cDim.getLength();  
                            int whichDim = loadDims.indexOf(cDim);
                            //insert that index in main table
                            addColumn(d, "_index_" + whichDim, 
                                allIndicesTable.getColumn(whichDim)); //will throw error if whichDim=-1
                        }

                        //insert index columns in lut
                        if (ncDims == 0) {
                            //if scalar vars, make key columns with 0's
                            //in lut
                            lut.addColumn(0, "_scalar_", new IntArray(new int[]{0}), 
                                new Attributes());
                            //and in main table
                            IntArray ia = new IntArray(nRows(), false);
                            ia.addN(nRows(), 0);
                            //String2.log("nRows=" + nRows() + " ia.size=" + ia.size());
                            addColumn(0, "_scalar_", ia, new Attributes());
                        } else {
                            lut.addIndexColumns(cShape);
                        }

                    } else {
                        //does this var have the exact same dimensions, in same order?
                        if (ntDims != ncDims)
                            continue BATCH_V;
                        for (int d = 0; d < ncDims; d++) {
                            Dimension dim = tDims.get(d);
                            for (int d0 = 0; d0 < nd0; d0++) {
                                if (String2.indexOfObject(tDimsAs[d0], dim) >= 0) {
                                    //convert to the 'as' dimension 
                                    dim = tDimsAs[d0][tDimsAs[d0].length - 1];
                                    break;
                                }
                            }
                            if (!cDims.get(d).equals(dim)) 
                                continue BATCH_V;
                        }
                    }

                    //read this var into lut
                    PrimitiveArray pa = knownPAs[v]; //v is loadVars v
                    Attributes atts   = knownAtts[v];
                    knownPAs[v] = null;
                    knownAtts[v] = null;
                    if (pa == null) {
                        pa = NcHelper.getPrimitiveArray(tVar, isCharArray);
                        if (pa instanceof StringArray)
                            ((StringArray)pa).trimEndAll();
                        atts = new Attributes();
                        if (getMetadata)
                            NcHelper.getVariableAttributes(tVar, atts);
                        pa = atts.standardizeVariable(standardizeWhat, loadVarNames.get(v), pa);
                    }
                    loaded.set(v);
                    lut.addColumn(lut.nColumns(), loadVarNames.get(v), 
                        pa, atts);
                }

                //apply constraints to lut
                if (haveConstraints) {
                    int onLutRows = lut.nRows();
                    BitSet keep = new BitSet();
                    keep.set(0, onLutRows); //all true
                    int nAfter = lut.tryToApplyConstraints(-1, conVars, conOps, conVals, keep);
                    if (nAfter == 0) {
                        if (verbose) String2.log(warningInMethod +
                            "Returning an empty table after applying constraints to lut. " +
                            "time=" + (System.currentTimeMillis() - time));
                        clear();
                        return;
                    }
                    lut.justKeep(keep); 
                    if (debugMode)
                        String2.log(Math2.memoryString() + "\n" +
                            ">> after lut constraints, justKeep lut.nRows before=" + 
                            onLutRows + " after=" + nAfter);
                }

                //JOIN lut into main table
                //if (debugMode) String2.log(">> lut=\n" + lut.dataToString(5));
                int nMatchingCols = Math.max(1, ncDims); //even scalars have 1 matching column
                BitSet keep = join(nMatchingCols, 0, "", lut); //"" = mvKey not needed
                //remove the index columns from the main table
                removeColumns(0, nMatchingCols); 
                //if (debugMode) String2.log(">> this table after join:\n" + dataToString(5));

                //remove unmatched rows
                int tnRows = keep.cardinality();
                if (tnRows == 0) {
                    clear();
                    if (verbose) String2.log(warningInMethod +
                        "Returning an empty table after a join. " +
                        "time=" + (System.currentTimeMillis() - time));
                    return;
                }
                justKeep(keep);
                allIndicesTable.justKeep(keep);
            }
            //and Bob's your uncle! we have all of the data

            //this will be either the order that was requested, or their order in the file
            reorderColumns(loadVarNames, false); //discardOthers=false, should be irrelevant
           
            decodeCharsAndStrings();
            convertToUnsignedPAs();

            if (reallyVerbose) msg += 
                " finished. nRows=" + nRows() + " nCols=" + nColumns() + 
                " time=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally  {
            ncFile.close(); 
            if (debugMode) msg += "\n" + Math2.memoryString();                
            if (reallyVerbose) String2.log(msg);
        }
    }

    /**
     * Test readMultidimNc with treatDimensionsAs specified. 
     */
    public static void testHardReadMultidimNc() throws Exception {
        String fileName = String2.unitTestDataDir + "nc/GLsubdir/GL_201207_TS_DB_44761.nc";
        String2.log("\n*** Table.testHardReadMultidimNc(" + fileName + ")");
        Table.debugMode = true;
        Table table = new Table();
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readMultidimNc(fileName, 
            StringArray.fromCSV("TIME,LATITUDE,LONGITUDE,DEPTH,TEMP,TEMP_DM"), //loadVarNames, 
            null, //loadDimNames, 
            new String[][]{{"LATITUDE","LONGITUDE","TIME"}}, //treatDimensionsAs
            true, //getMetadata,
            0, //standardizeWhat, 
            true, //removeMVRows,
            null, null, null); //conVars, conOps, conVals
        String2.log(table.toString(5));
        String results = table.dataToString(5);
        String expected = 
"TIME,LATITUDE,LONGITUDE,DEPTH,TEMP,TEMP_DM\n" +
"22837.541666666668,48.309,-44.112,-99999.0,12.6,R\n" +
"22837.583333333332,48.313,-44.111,-99999.0,12.6,R\n" +
"22837.625,48.317,-44.107,-99999.0,12.7,R\n" +
"22837.666666666668,48.318,-44.103,-99999.0,13.0,R\n" +
"22837.708333333332,48.315,-44.097,-99999.0,13.1,R\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //time
        Test.ensureEqual(table.getColumnName(0), "TIME", "");
        Test.ensureEqual(table.columnAttributes(0).getString("units"), 
            "days since 1950-01-01T00:00:00Z", "results=\n" + results);
        Test.ensureEqual(table.columnAttributes(0).getDouble("valid_min"), 
            0.0, "results=\n" + results);
        Test.ensureEqual(table.columnAttributes(0).getDouble("valid_max"), 
            90000.0, "results=\n" + results);
        //depth
        Test.ensureEqual(table.getColumnName(3), "DEPTH", "");
        Test.ensureEqual(table.columnAttributes(3).getFloat("_FillValue"), 
            -99999f, "results=\n" + results);
        Test.ensureEqual(table.columnAttributes(3).getString("units"), 
            "meter", "results=\n" + results);
        //temp
        Test.ensureEqual(table.getColumnName(4), "TEMP", "");
        Test.ensureEqual(table.columnAttributes(4).getFloat("_FillValue"), 
            9.96921E36f, "results=\n" + results);
        Test.ensureEqual(table.columnAttributes(4).getString("units"), 
            "degree_Celsius", "results=\n" + results);


        //standardizeWhat
        table.clear();
        table.readMultidimNc(fileName, 
            StringArray.fromCSV("TIME,LATITUDE,LONGITUDE,DEPTH,TEMP,TEMP_DM"), //loadVarNames, 
            null, //loadDimNames, 
            new String[][]{{"LATITUDE","LONGITUDE","TIME"}}, //treatDimensionsAs
            true, //getMetadata,
            1+2+4096, //standardizeWhat, 
            true, //removeMVRows,
            null, null, null); //conVars, conOps, conVals
        String2.log(table.toString(5));
        results = table.dataToString(5);
        expected = 
"TIME,LATITUDE,LONGITUDE,DEPTH,TEMP,TEMP_DM\n" +
"1.3420116E9,48.309,-44.112,,12.6,R\n" +
"1.3420152E9,48.313,-44.111,,12.6,R\n" +
"1.3420188E9,48.317,-44.107,,12.7,R\n" +
"1.3420224E9,48.318,-44.103,,13.0,R\n" +
"1.342026E9,48.315,-44.097,,13.1,R\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //time
        Test.ensureEqual(table.getColumnName(0), "TIME", "");
        Test.ensureEqual(table.columnAttributes(0).getString("units"), 
            "seconds since 1970-01-01T00:00:00Z", "results=\n" + results);
        Test.ensureEqual(table.columnAttributes(0).getDouble("valid_min"), 
            -6.31152E8, "results=\n" + results);
        Test.ensureEqual(table.columnAttributes(0).getDouble("valid_max"), 
            7.144848E9, "results=\n" + results);
        //depth
        Test.ensureEqual(table.getColumnName(3), "DEPTH", "");
        Test.ensureEqual(table.columnAttributes(3).getFloat("_FillValue"), 
            Float.NaN, "results=\n" + results);
        Test.ensureEqual(table.columnAttributes(3).getString("units"), 
            "m", "results=\n" + results);
        //temp
        Test.ensureEqual(table.getColumnName(4), "TEMP", "");
        Test.ensureEqual(table.columnAttributes(4).getFloat("_FillValue"), 
            Float.NaN, "results=\n" + results);
        Test.ensureEqual(table.columnAttributes(4).getString("units"), 
            "degree_C", "results=\n" + results);
        
        
        Table.debugMode = false;
    }



    /**
     * This standardizes every column. See Attributes.unpackVariable for details.
     */
    public void standardize(int standardizeWhat) throws Exception {
        int nCols = nColumns();
        for (int col = 0; col < nCols; col++)
            standardizeColumn(standardizeWhat, col);
    }

    /**
     * This unpacks one column. See Attributes.unpackVariable for details.
     */
    public void standardizeColumn(int standardizeWhat, int col) throws Exception {
        if (standardizeWhat > 0)
            setColumn(col, 
                columnAttributes(col).standardizeVariable(standardizeWhat, getColumnName(col), getColumn(col)));
    }
    public void standardizeLastColumn(int standardizeWhat) throws Exception {
        standardizeColumn(standardizeWhat, nColumns() - 1);
    }



    /** 
     * This inserts columns starting at column #0 with the indices for the
     * specified shape (0, 1, 2, ..., for each dimension in shape[]).
     *
     * @param shape 
     * @throws RuntimeException if this requires &gt;= Integer.MAX_VALUE rows.
     */
    public void addIndexColumns(int shape[]) {
        if (shape == null || shape.length ==0)
            return;
        int nDims = shape.length;
        IntArray indexPAs[] = new IntArray[nDims];
        NDimensionalIndex ndIndex = new NDimensionalIndex(shape);
        long totalSizeL = ndIndex.size();
        if (totalSizeL >= Integer.MAX_VALUE)
            throw new RuntimeException("Too many rows of data.");
        int totalSize = Math2.narrowToInt(totalSizeL); 
        for (int d = 0; d < nDims; d++) {
            indexPAs[d] = new IntArray(totalSize, false);
            addColumn(d, "_index_" + d, indexPAs[d], new Attributes());
        }
        int current[] = ndIndex.getCurrent();
        while (ndIndex.increment()) {
            for (int d = 0; d < nDims; d++) 
                indexPAs[d].add(current[d]);
        }
    }

    public static void testAddIndexColumns() throws Exception {
        Table table = new Table();
        table.addIndexColumns(new int[]{3,2,4});
        String results = table.dataToString();
        String expected = 
"_index_0,_index_1,_index_2\n" +
"0,0,0\n" +
"0,0,1\n" +
"0,0,2\n" +
"0,0,3\n" +
"0,1,0\n" +
"0,1,1\n" +
"0,1,2\n" +
"0,1,3\n" +
"1,0,0\n" +
"1,0,1\n" +
"1,0,2\n" +
"1,0,3\n" +
"1,1,0\n" +
"1,1,1\n" +
"1,1,2\n" +
"1,1,3\n" +
"2,0,0\n" +
"2,0,1\n" +
"2,0,2\n" +
"2,0,3\n" +
"2,1,0\n" +
"2,1,1\n" +
"2,1,2\n" +
"2,1,3\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
    }


    /** This tests readMultidimNc by reading an Argo Profile file. */
    public static void testReadMultidimNc() throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebugMode = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadMultidimNc");
        Table table = new Table();
        //ftp://ftp.ifremer.fr/ifremer/argo/dac/csio/2901175/2901175_prof.nc
        String fiName = String2.unitTestDataDir + "nc/2901175_prof.nc";
        String2.log(NcHelper.ncdump(fiName, "-h"));
        String results, expectedStart, expectedEnd;
        /* */

        //** don't specify varNames or dimNames -- it find vars with most dims
        table.readMultidimNc(fiName, new StringArray(), new StringArray(), null, 
            true, 0, false, //readMetadata, standardizeWhat=0, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
//static vars and vars like  char SCIENTIFIC_CALIB_COEFFICIENT(N_PROF=254, N_CALIB=1, N_PARAM=3, STRING256=256);
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,STATION_PARAMETERS,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PARAMETER,SCIENTIFIC_CALIB_EQUATION,SCIENTIFIC_CALIB_COEFFICIENT,SCIENTIFIC_CALIB_COMMENT,SCIENTIFIC_CALIB_DATE\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,PRES,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,PRES,PRES_ADJUSTED = PRES - dP,dP =  0.1 dbar.,Pressures adjusted by using pressure offset at the sea surface. The quoted error is manufacturer specified accuracy in dbar.,20110628060155\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,TEMP,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,TEMP,none,none,The quoted error is manufacturer specified accuracy with respect to ITS-90 at time of laboratory calibration.,20110628060155\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,PSAL,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,PSAL,\"PSAL_ADJUSTED = sw_salt( sw_cndr(PSAL,TEMP,PRES), TEMP, PRES_ADJUSTED ); PSAL_ADJ corrects conductivity cell therm mass (CTM), Johnson et al, 2007, JAOT;\",\"same as for PRES_ADJUSTED; CTL: alpha=0.0267, tau=18.6;\",No significant salinity drift detected; SBE sensor accuracy,20110628060155\n" +
"...\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 762, "nRows"); //254*3

        //* same but quick reject based on constraint
        table.readMultidimNc(fiName, new StringArray(), new StringArray(), null,
            true, 0, false, //readMetadata, standardizeWhat=0, removeMVRows
            StringArray.fromCSV("FORMAT_VERSION,FORMAT_VERSION"), //conVars
            StringArray.fromCSV("=,="), //conOps
            StringArray.fromCSV("3.1,3.2")); //conVals
        Test.ensureEqual(table.nRows(), 0, "nRows"); 


        //* test don't removeMVRows
        table.readMultidimNc(fiName, null, 
            StringArray.fromCSV("ZZTOP, N_PROF, N_LEVELS"), 
            null, 
            true, 0, false, //readMetadata, standardizeWhat=0, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.toString(3);
        expectedStart = 
"{\n" +
"dimensions:\n" +
"\trow = 18034 ;\n" +
"\tDATA_TYPE_strlen = 12 ;\n" +
"\tFORMAT_VERSION_strlen = 3 ;\n" +
"\tHANDBOOK_VERSION_strlen = 3 ;\n" +
"\tREFERENCE_DATE_TIME_strlen = 14 ;\n" +
"\tDATE_CREATION_strlen = 14 ;\n" +
"\tDATE_UPDATE_strlen = 14 ;\n" +
"\tPLATFORM_NUMBER_strlen = 7 ;\n" +
"\tPROJECT_NAME_strlen = 18 ;\n" +
"\tPI_NAME_strlen = 11 ;\n" +
"\tDATA_CENTRE_strlen = 2 ;\n" +
"\tDC_REFERENCE_strlen = 14 ;\n" +
"\tDATA_STATE_INDICATOR_strlen = 2 ;\n" +
"\tPLATFORM_TYPE_strlen = 4 ;\n" +
"\tFLOAT_SERIAL_NO_strlen = 13 ;\n" +
"\tFIRMWARE_VERSION_strlen = 6 ;\n" +
"\tWMO_INST_TYPE_strlen = 3 ;\n" +
"\tPOSITIONING_SYSTEM_strlen = 5 ;\n" +
"\tVERTICAL_SAMPLING_SCHEME_strlen = 26 ;\n" +
"variables:\n" +
"\tchar DATA_TYPE(row, DATA_TYPE_strlen) ;\n" +
"\t\tDATA_TYPE:conventions = \"Argo reference table 1\" ;\n" +
"\t\tDATA_TYPE:long_name = \"Data type\" ;\n" +
"\tchar FORMAT_VERSION(row, FORMAT_VERSION_strlen) ;\n" +
"\t\tFORMAT_VERSION:long_name = \"File format version\" ;\n" +
"\tchar HANDBOOK_VERSION(row, HANDBOOK_VERSION_strlen) ;\n" +
"\t\tHANDBOOK_VERSION:long_name = \"Data handbook version\" ;\n" +
"\tchar REFERENCE_DATE_TIME(row, REFERENCE_DATE_TIME_strlen) ;\n" +
"\t\tREFERENCE_DATE_TIME:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tREFERENCE_DATE_TIME:long_name = \"Date of reference for Julian days\" ;\n" +
"\tchar DATE_CREATION(row, DATE_CREATION_strlen) ;\n" +
"\t\tDATE_CREATION:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tDATE_CREATION:long_name = \"Date of file creation\" ;\n" +
"\tchar DATE_UPDATE(row, DATE_UPDATE_strlen) ;\n" +
"\t\tDATE_UPDATE:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tDATE_UPDATE:long_name = \"Date of update of this file\" ;\n" +
"\tchar PLATFORM_NUMBER(row, PLATFORM_NUMBER_strlen) ;\n" +
"\t\tPLATFORM_NUMBER:conventions = \"WMO float identifier : A9IIIII\" ;\n" +
"\t\tPLATFORM_NUMBER:long_name = \"Float unique identifier\" ;\n" +
"\tchar PROJECT_NAME(row, PROJECT_NAME_strlen) ;\n" +
"\t\tPROJECT_NAME:long_name = \"Name of the project\" ;\n" +
"\tchar PI_NAME(row, PI_NAME_strlen) ;\n" +
"\t\tPI_NAME:long_name = \"Name of the principal investigator\" ;\n" +
"\tint CYCLE_NUMBER(row) ;\n" +
"\t\tCYCLE_NUMBER:_FillValue = 99999 ;\n" +
"\t\tCYCLE_NUMBER:conventions = \"0...N, 0 : launch cycle (if exists), 1 : first complete cycle\" ;\n" +
"\t\tCYCLE_NUMBER:long_name = \"Float cycle number\" ;\n" +
"\tchar DIRECTION(row) ;\n" +
"\t\tDIRECTION:conventions = \"A: ascending profiles, D: descending profiles\" ;\n" +
"\t\tDIRECTION:long_name = \"Direction of the station profiles\" ;\n" +
"\tchar DATA_CENTRE(row, DATA_CENTRE_strlen) ;\n" +
"\t\tDATA_CENTRE:conventions = \"Argo reference table 4\" ;\n" +
"\t\tDATA_CENTRE:long_name = \"Data centre in charge of float data processing\" ;\n" +
"\tchar DC_REFERENCE(row, DC_REFERENCE_strlen) ;\n" +
"\t\tDC_REFERENCE:conventions = \"Data centre convention\" ;\n" +
"\t\tDC_REFERENCE:long_name = \"Station unique identifier in data centre\" ;\n" +
"\tchar DATA_STATE_INDICATOR(row, DATA_STATE_INDICATOR_strlen) ;\n" +
"\t\tDATA_STATE_INDICATOR:conventions = \"Argo reference table 6\" ;\n" +
"\t\tDATA_STATE_INDICATOR:long_name = \"Degree of processing the data have passed through\" ;\n" +
"\tchar DATA_MODE(row) ;\n" +
"\t\tDATA_MODE:conventions = \"R : real time; D : delayed mode; A : real time with adjustment\" ;\n" +
"\t\tDATA_MODE:long_name = \"Delayed mode or real time data\" ;\n" +
"\tchar PLATFORM_TYPE(row, PLATFORM_TYPE_strlen) ;\n" +
"\t\tPLATFORM_TYPE:conventions = \"Argo reference table 23\" ;\n" +
"\t\tPLATFORM_TYPE:long_name = \"Type of float\" ;\n" +
"\tchar FLOAT_SERIAL_NO(row, FLOAT_SERIAL_NO_strlen) ;\n" +
"\t\tFLOAT_SERIAL_NO:long_name = \"Serial number of the float\" ;\n" +
"\tchar FIRMWARE_VERSION(row, FIRMWARE_VERSION_strlen) ;\n" +
"\t\tFIRMWARE_VERSION:long_name = \"Instrument firmware version\" ;\n" +
"\tchar WMO_INST_TYPE(row, WMO_INST_TYPE_strlen) ;\n" +
"\t\tWMO_INST_TYPE:conventions = \"Argo reference table 8\" ;\n" +
"\t\tWMO_INST_TYPE:long_name = \"Coded instrument type\" ;\n" +
"\tdouble JULD(row) ;\n" +
"\t\tJULD:_FillValue = 999999.0 ;\n" +
"\t\tJULD:axis = \"T\" ;\n" +
"\t\tJULD:conventions = \"Relative julian days with decimal part (as parts of day)\" ;\n" +
"\t\tJULD:long_name = \"Julian day (UTC) of the station relative to REFERENCE_DATE_TIME\" ;\n" +
"\t\tJULD:resolution = 0.0 ;\n" +
"\t\tJULD:standard_name = \"time\" ;\n" +
"\t\tJULD:units = \"days since 1950-01-01 00:00:00 UTC\" ;\n" +
"\tchar JULD_QC(row) ;\n" +
"\t\tJULD_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tJULD_QC:long_name = \"Quality on date and time\" ;\n" +
"\tdouble JULD_LOCATION(row) ;\n" +
"\t\tJULD_LOCATION:_FillValue = 999999.0 ;\n" +
"\t\tJULD_LOCATION:conventions = \"Relative julian days with decimal part (as parts of day)\" ;\n" +
"\t\tJULD_LOCATION:long_name = \"Julian day (UTC) of the location relative to REFERENCE_DATE_TIME\" ;\n" +
"\t\tJULD_LOCATION:resolution = 0.0 ;\n" +
"\t\tJULD_LOCATION:units = \"days since 1950-01-01 00:00:00 UTC\" ;\n" +
"\tdouble LATITUDE(row) ;\n" +
"\t\tLATITUDE:_FillValue = 99999.0 ;\n" +
"\t\tLATITUDE:axis = \"Y\" ;\n" +
"\t\tLATITUDE:long_name = \"Latitude of the station, best estimate\" ;\n" +
"\t\tLATITUDE:standard_name = \"latitude\" ;\n" +
"\t\tLATITUDE:units = \"degree_north\" ;\n" +
"\t\tLATITUDE:valid_max = 90.0 ;\n" +
"\t\tLATITUDE:valid_min = -90.0 ;\n" +
"\tdouble LONGITUDE(row) ;\n" +
"\t\tLONGITUDE:_FillValue = 99999.0 ;\n" +
"\t\tLONGITUDE:axis = \"X\" ;\n" +
"\t\tLONGITUDE:long_name = \"Longitude of the station, best estimate\" ;\n" +
"\t\tLONGITUDE:standard_name = \"longitude\" ;\n" +
"\t\tLONGITUDE:units = \"degree_east\" ;\n" +
"\t\tLONGITUDE:valid_max = 180.0 ;\n" +
"\t\tLONGITUDE:valid_min = -180.0 ;\n" +
"\tchar POSITION_QC(row) ;\n" +
"\t\tPOSITION_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tPOSITION_QC:long_name = \"Quality on position (latitude and longitude)\" ;\n" +
"\tchar POSITIONING_SYSTEM(row, POSITIONING_SYSTEM_strlen) ;\n" +
"\t\tPOSITIONING_SYSTEM:long_name = \"Positioning system\" ;\n" +
"\tchar PROFILE_PRES_QC(row) ;\n" +
"\t\tPROFILE_PRES_QC:conventions = \"Argo reference table 2a\" ;\n" +
"\t\tPROFILE_PRES_QC:long_name = \"Global quality flag of PRES profile\" ;\n" +
"\tchar PROFILE_TEMP_QC(row) ;\n" +
"\t\tPROFILE_TEMP_QC:conventions = \"Argo reference table 2a\" ;\n" +
"\t\tPROFILE_TEMP_QC:long_name = \"Global quality flag of TEMP profile\" ;\n" +
"\tchar PROFILE_PSAL_QC(row) ;\n" +
"\t\tPROFILE_PSAL_QC:conventions = \"Argo reference table 2a\" ;\n" +
"\t\tPROFILE_PSAL_QC:long_name = \"Global quality flag of PSAL profile\" ;\n" +
"\tchar VERTICAL_SAMPLING_SCHEME(row, VERTICAL_SAMPLING_SCHEME_strlen) ;\n" +
"\t\tVERTICAL_SAMPLING_SCHEME:conventions = \"Argo reference table 16\" ;\n" +
"\t\tVERTICAL_SAMPLING_SCHEME:long_name = \"Vertical sampling scheme\" ;\n" +
"\tint CONFIG_MISSION_NUMBER(row) ;\n" +
"\t\tCONFIG_MISSION_NUMBER:_FillValue = 99999 ;\n" +
"\t\tCONFIG_MISSION_NUMBER:conventions = \"1...N, 1 : first complete mission\" ;\n" +
"\t\tCONFIG_MISSION_NUMBER:long_name = \"Unique number denoting the missions performed by the float\" ;\n" +
"\tfloat PRES(row) ;\n" +
"\t\tPRES:_FillValue = 99999.0f ;\n" +
"\t\tPRES:axis = \"Z\" ;\n" +
"\t\tPRES:C_format = \"%7.1f\" ;\n" +
"\t\tPRES:FORTRAN_format = \"F7.1\" ;\n" +
"\t\tPRES:long_name = \"Sea water pressure, equals 0 at sea-level\" ;\n" +
"\t\tPRES:resolution = 1.0f ;\n" +
"\t\tPRES:standard_name = \"sea_water_pressure\" ;\n" +
"\t\tPRES:units = \"decibar\" ;\n" +
"\t\tPRES:valid_max = 12000.0f ;\n" +
"\t\tPRES:valid_min = 0.0f ;\n" +
"\tchar PRES_QC(row) ;\n" +
"\t\tPRES_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tPRES_QC:long_name = \"quality flag\" ;\n" +
"\tfloat PRES_ADJUSTED(row) ;\n" +
"\t\tPRES_ADJUSTED:_FillValue = 99999.0f ;\n" +
"\t\tPRES_ADJUSTED:axis = \"Z\" ;\n" +
"\t\tPRES_ADJUSTED:C_format = \"%7.1f\" ;\n" +
"\t\tPRES_ADJUSTED:FORTRAN_format = \"F7.1\" ;\n" +
"\t\tPRES_ADJUSTED:long_name = \"Sea water pressure, equals 0 at sea-level\" ;\n" +
"\t\tPRES_ADJUSTED:resolution = 1.0f ;\n" +
"\t\tPRES_ADJUSTED:standard_name = \"sea_water_pressure\" ;\n" +
"\t\tPRES_ADJUSTED:units = \"decibar\" ;\n" +
"\t\tPRES_ADJUSTED:valid_max = 12000.0f ;\n" +
"\t\tPRES_ADJUSTED:valid_min = 0.0f ;\n" +
"\tchar PRES_ADJUSTED_QC(row) ;\n" +
"\t\tPRES_ADJUSTED_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tPRES_ADJUSTED_QC:long_name = \"quality flag\" ;\n" +
"\tfloat PRES_ADJUSTED_ERROR(row) ;\n" +
"\t\tPRES_ADJUSTED_ERROR:_FillValue = 99999.0f ;\n" +
"\t\tPRES_ADJUSTED_ERROR:C_format = \"%7.1f\" ;\n" +
"\t\tPRES_ADJUSTED_ERROR:FORTRAN_format = \"F7.1\" ;\n" +
"\t\tPRES_ADJUSTED_ERROR:long_name = \"Contains the error on the adjusted values as determined by the delayed mode QC process\" ;\n" +
"\t\tPRES_ADJUSTED_ERROR:resolution = 1.0f ;\n" +
"\t\tPRES_ADJUSTED_ERROR:units = \"decibar\" ;\n" +
"\tfloat TEMP(row) ;\n" +
"\t\tTEMP:_FillValue = 99999.0f ;\n" +
"\t\tTEMP:C_format = \"%9.3f\" ;\n" +
"\t\tTEMP:FORTRAN_format = \"F9.3\" ;\n" +
"\t\tTEMP:long_name = \"Sea temperature in-situ ITS-90 scale\" ;\n" +
"\t\tTEMP:resolution = 0.001f ;\n" +
"\t\tTEMP:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTEMP:units = \"degree_Celsius\" ;\n" +
"\t\tTEMP:valid_max = 40.0f ;\n" +
"\t\tTEMP:valid_min = -2.5f ;\n" +
"\tchar TEMP_QC(row) ;\n" +
"\t\tTEMP_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tTEMP_QC:long_name = \"quality flag\" ;\n" +
"\tfloat TEMP_ADJUSTED(row) ;\n" +
"\t\tTEMP_ADJUSTED:_FillValue = 99999.0f ;\n" +
"\t\tTEMP_ADJUSTED:C_format = \"%9.3f\" ;\n" +
"\t\tTEMP_ADJUSTED:FORTRAN_format = \"F9.3\" ;\n" +
"\t\tTEMP_ADJUSTED:long_name = \"Sea temperature in-situ ITS-90 scale\" ;\n" +
"\t\tTEMP_ADJUSTED:resolution = 0.001f ;\n" +
"\t\tTEMP_ADJUSTED:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTEMP_ADJUSTED:units = \"degree_Celsius\" ;\n" +
"\t\tTEMP_ADJUSTED:valid_max = 40.0f ;\n" +
"\t\tTEMP_ADJUSTED:valid_min = -2.5f ;\n" +
"\tchar TEMP_ADJUSTED_QC(row) ;\n" +
"\t\tTEMP_ADJUSTED_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tTEMP_ADJUSTED_QC:long_name = \"quality flag\" ;\n" +
"\tfloat TEMP_ADJUSTED_ERROR(row) ;\n" +
"\t\tTEMP_ADJUSTED_ERROR:_FillValue = 99999.0f ;\n" +
"\t\tTEMP_ADJUSTED_ERROR:C_format = \"%9.3f\" ;\n" +
"\t\tTEMP_ADJUSTED_ERROR:FORTRAN_format = \"F9.3\" ;\n" +
"\t\tTEMP_ADJUSTED_ERROR:long_name = \"Contains the error on the adjusted values as determined by the delayed mode QC process\" ;\n" +
"\t\tTEMP_ADJUSTED_ERROR:resolution = 0.001f ;\n" +
"\t\tTEMP_ADJUSTED_ERROR:units = \"degree_Celsius\" ;\n" +
"\tfloat PSAL(row) ;\n" +
"\t\tPSAL:_FillValue = 99999.0f ;\n" +
"\t\tPSAL:C_format = \"%9.3f\" ;\n" +
"\t\tPSAL:FORTRAN_format = \"F9.3\" ;\n" +
"\t\tPSAL:long_name = \"Practical salinity\" ;\n" +
"\t\tPSAL:resolution = 0.001f ;\n" +
"\t\tPSAL:standard_name = \"sea_water_salinity\" ;\n" +
"\t\tPSAL:units = \"psu\" ;\n" +
"\t\tPSAL:valid_max = 41.0f ;\n" +
"\t\tPSAL:valid_min = 2.0f ;\n" +
"\tchar PSAL_QC(row) ;\n" +
"\t\tPSAL_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tPSAL_QC:long_name = \"quality flag\" ;\n" +
"\tfloat PSAL_ADJUSTED(row) ;\n" +
"\t\tPSAL_ADJUSTED:_FillValue = 99999.0f ;\n" +
"\t\tPSAL_ADJUSTED:C_format = \"%9.3f\" ;\n" +
"\t\tPSAL_ADJUSTED:FORTRAN_format = \"F9.3\" ;\n" +
"\t\tPSAL_ADJUSTED:long_name = \"Practical salinity\" ;\n" +
"\t\tPSAL_ADJUSTED:resolution = 0.001f ;\n" +
"\t\tPSAL_ADJUSTED:standard_name = \"sea_water_salinity\" ;\n" +
"\t\tPSAL_ADJUSTED:units = \"psu\" ;\n" +
"\t\tPSAL_ADJUSTED:valid_max = 41.0f ;\n" +
"\t\tPSAL_ADJUSTED:valid_min = 2.0f ;\n" +
"\tchar PSAL_ADJUSTED_QC(row) ;\n" +
"\t\tPSAL_ADJUSTED_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tPSAL_ADJUSTED_QC:long_name = \"quality flag\" ;\n" +
"\tfloat PSAL_ADJUSTED_ERROR(row) ;\n" +
"\t\tPSAL_ADJUSTED_ERROR:_FillValue = 99999.0f ;\n" +
"\t\tPSAL_ADJUSTED_ERROR:C_format = \"%9.3f\" ;\n" +
"\t\tPSAL_ADJUSTED_ERROR:FORTRAN_format = \"F9.3\" ;\n" +
"\t\tPSAL_ADJUSTED_ERROR:long_name = \"Contains the error on the adjusted values as determined by the delayed mode QC process\" ;\n" +
"\t\tPSAL_ADJUSTED_ERROR:resolution = 0.001f ;\n" +
"\t\tPSAL_ADJUSTED_ERROR:units = \"psu\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:Conventions = \"Argo-3.1 CF-1.6\" ;\n" +
"\t\t:featureType = \"trajectoryProfile\" ;\n" +
"\t\t:history = \"2016-04-15T20:47:22Z creation\" ;\n" +
"\t\t:institution = \"Coriolis GDAC\" ;\n" +
"\t\t:references = \"http://www.argodatamgt.org/Documentation\" ;\n" +
"\t\t:source = \"Argo float\" ;\n" +
"\t\t:title = \"Argo float vertical profile\" ;\n" +
"\t\t:user_manual_version = \"3.1\" ;\n" +
"}\n";
        Test.ensureEqual(results.substring(0, expectedStart.length()), expectedStart, "results=\n" + results);

        results = table.dataToString(3);
        expectedStart = 
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PRES,PRES_QC,PRES_ADJUSTED,PRES_ADJUSTED_QC,PRES_ADJUSTED_ERROR,TEMP,TEMP_QC,TEMP_ADJUSTED,TEMP_ADJUSTED_QC,TEMP_ADJUSTED_ERROR,PSAL,PSAL_QC,PSAL_ADJUSTED,PSAL_ADJUSTED_QC,PSAL_ADJUSTED_ERROR\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,5.9,1,5.8,1,2.4,24.989,1,24.989,1,0.002,34.555,1,34.55511,1,0.01\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,10.0,1,9.9,1,2.4,24.99,1,24.99,1,0.002,34.554,1,34.55505,1,0.01\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,20.1,1,20.0,1,2.4,24.69,1,24.69,1,0.002,34.56,1,34.56191,1,0.01\n" +
"...\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 18034, "nRows"); //254*71
 
        //and the end of that table
        table.removeRows(0, table.nRows() - 3);
        results = table.dataToString(5);
        expectedEnd = 
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PRES,PRES_QC,PRES_ADJUSTED,PRES_ADJUSTED_QC,PRES_ADJUSTED_ERROR,TEMP,TEMP_QC,TEMP_ADJUSTED,TEMP_ADJUSTED_QC,TEMP_ADJUSTED_ERROR,PSAL,PSAL_QC,PSAL_ADJUSTED,PSAL_ADJUSTED_QC,PSAL_ADJUSTED_ERROR\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,256,A,HZ,0066_80617_256,2B,A,APEX,4136,013108,846,24210.44662037037,1,24210.44662037037,26.587,154.853,1,ARGOS,A,A,A,Primary sampling: discrete,1,1899.9,1,1899.3,1,99999.0,2.055,1,2.055,1,99999.0,34.612,1,34.612,1,99999.0\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,256,A,HZ,0066_80617_256,2B,A,APEX,4136,013108,846,24210.44662037037,1,24210.44662037037,26.587,154.853,1,ARGOS,A,A,A,Primary sampling: discrete,1,1950.0,1,1949.4,1,99999.0,2.014,1,2.014,1,99999.0,34.617,1,34.617,1,99999.0\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,256,A,HZ,0066_80617_256,2B,A,APEX,4136,013108,846,24210.44662037037,1,24210.44662037037,26.587,154.853,1,ARGOS,A,A,A,Primary sampling: discrete,1,99999.0,\" \",99999.0,\" \",99999.0,99999.0,\" \",99999.0,\" \",99999.0,99999.0,\" \",99999.0,\" \",99999.0\n";
        Test.ensureEqual(results, expectedEnd, "results=\n" + results);


        //* test do removeMVRows
        table.readMultidimNc(fiName, null, StringArray.fromCSV("ZZTOP, N_PROF, N_LEVELS"), null, 
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows");

         //and test data at the end of that table
        table.removeRows(0, table.nRows() - 3);
        results = table.dataToString(5);
        expectedEnd = 
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PRES,PRES_QC,PRES_ADJUSTED,PRES_ADJUSTED_QC,PRES_ADJUSTED_ERROR,TEMP,TEMP_QC,TEMP_ADJUSTED,TEMP_ADJUSTED_QC,TEMP_ADJUSTED_ERROR,PSAL,PSAL_QC,PSAL_ADJUSTED,PSAL_ADJUSTED_QC,PSAL_ADJUSTED_ERROR\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,256,A,HZ,0066_80617_256,2B,A,APEX,4136,013108,846,24210.44662037037,1,24210.44662037037,26.587,154.853,1,ARGOS,A,A,A,Primary sampling: discrete,1,1850.0,1,1849.4,1,99999.0,2.106,1,2.106,1,99999.0,34.604,1,34.604,1,99999.0\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,256,A,HZ,0066_80617_256,2B,A,APEX,4136,013108,846,24210.44662037037,1,24210.44662037037,26.587,154.853,1,ARGOS,A,A,A,Primary sampling: discrete,1,1899.9,1,1899.3,1,99999.0,2.055,1,2.055,1,99999.0,34.612,1,34.612,1,99999.0\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,256,A,HZ,0066_80617_256,2B,A,APEX,4136,013108,846,24210.44662037037,1,24210.44662037037,26.587,154.853,1,ARGOS,A,A,A,Primary sampling: discrete,1,1950.0,1,1949.4,1,99999.0,2.014,1,2.014,1,99999.0,34.617,1,34.617,1,99999.0\n";
        Test.ensureEqual(results, expectedEnd, "results=\n" + results);

        //* same but quick reject based on constraint   LAT,LON 26.587,154.853
        //*** this takes 9ms while test above takes 99ms!
        table.readMultidimNc(fiName, null, StringArray.fromCSV("ZZTOP, N_PROF, N_LEVELS"), null, 
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            StringArray.fromCSV("LATITUDE"), //conVars
            StringArray.fromCSV("="), //conOps
            StringArray.fromCSV("45")); //conVals
        Test.ensureEqual(table.nRows(), 0, "nRows"); 

        //* test different dim order (should be rearranged so the same)
        table.readMultidimNc(fiName, null, StringArray.fromCSV("N_LEVELS, ZZTOP, N_PROF"), null, 
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows");
 
        //and test data at the end of that table
        table.removeRows(0, table.nRows() - 3);
        results = table.dataToString(5);
        Test.ensureEqual(results, expectedEnd, "results=\n" + results);

        //* test read all and constrain PLATFORM_NUMBER
        //Roland reported this problem 2016-06-21: returned 0 rows, saying:
        //"Returning an empty table because var=PLATFORM_NUMBER failed its constraints, including =2901175. time=0" 

        table.readMultidimNc(fiName, StringArray.fromCSV(
            "DATA_TYPE, FORMAT_VERSION, HANDBOOK_VERSION, REFERENCE_DATE_TIME, DATE_CREATION, " +
            "DATE_UPDATE, PLATFORM_NUMBER, PROJECT_NAME, PI_NAME, CYCLE_NUMBER, DIRECTION, " +
            "DATA_CENTRE, DC_REFERENCE, DATA_STATE_INDICATOR, DATA_MODE, PLATFORM_TYPE, " +
            "FLOAT_SERIAL_NO, FIRMWARE_VERSION, WMO_INST_TYPE, JULD, JULD_QC, JULD_LOCATION, " +
            "LATITUDE, LONGITUDE, POSITION_QC, POSITIONING_SYSTEM, PROFILE_PRES_QC, " +
            "PROFILE_TEMP_QC, PROFILE_PSAL_QC, VERTICAL_SAMPLING_SCHEME, " +
            "CONFIG_MISSION_NUMBER, PRES, PRES_QC, PRES_ADJUSTED, PRES_ADJUSTED_QC, " +
            "PRES_ADJUSTED_ERROR, TEMP, TEMP_QC, TEMP_ADJUSTED, TEMP_ADJUSTED_QC, " +
            "TEMP_ADJUSTED_ERROR, PSAL, PSAL_QC, PSAL_ADJUSTED, PSAL_ADJUSTED_QC, " +
            "PSAL_ADJUSTED_ERROR"), null, null,
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            StringArray.fromCSV("PLATFORM_NUMBER"),  //conVars, conOps, conVals
            StringArray.fromCSV("="),
            StringArray.fromCSV("2901175")); 
        results = table.dataToString(3);
        expectedStart = 
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION," +
"DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,CYCLE_NUMBER,DIRECTION,DATA_CENTRE," +
"DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO," +
"FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE," +
"POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC," +
"VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PRES,PRES_QC,PRES_ADJUSTED," +
"PRES_ADJUSTED_QC,PRES_ADJUSTED_ERROR,TEMP,TEMP_QC,TEMP_ADJUSTED,TEMP_ADJUSTED_QC," +
"TEMP_ADJUSTED_ERROR,PSAL,PSAL_QC,PSAL_ADJUSTED,PSAL_ADJUSTED_QC,PSAL_ADJUSTED_ERROR\n" +

"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175," +
"CHINA ARGO PROJECT,JIANPING XU,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846," +
"21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1," +
"ARGOS,A,A,A,,1,5.9,1,5.8,1,2.4,24.989,1,24.989,1,0.002,34.555,1,34.55511," +
"1,0.01\n" +

"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175," +
"CHINA ARGO PROJECT,JIANPING XU,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846," +
"21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1," +
"ARGOS,A,A,A,,1,10.0,1,9.9,1,2.4,24.99,1,24.99,1,0.002,34.554,1,34.55505," +
"1,0.01\n" +

"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175," +
"CHINA ARGO PROJECT,JIANPING XU,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846," +
"21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1," +
"ARGOS,A,A,A,,1,20.1,1,20.0,1,2.4,24.69,1,24.69,1,0.002,34.56,1,34.56191," +
"1,0.01\n" +
"...\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows"); //same as when all variables were explicitly loaded



        //* test different varNames
        table.readMultidimNc(fiName, 
            StringArray.fromCSV("DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PRES,PRES_QC,PRES_ADJUSTED,PRES_ADJUSTED_QC,PRES_ADJUSTED_ERROR,TEMP,TEMP_QC,TEMP_ADJUSTED,TEMP_ADJUSTED_QC,TEMP_ADJUSTED_ERROR,PSAL,PSAL_QC,PSAL_ADJUSTED,PSAL_ADJUSTED_QC,PSAL_ADJUSTED_ERROR"), 
            null, null, 
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows");
 
        //and test data at the end of that table
        table.removeRows(0, table.nRows() - 3);
        results = table.dataToString(5);
        Test.ensureEqual(results, expectedEnd, "results=\n" + results);


        //* test do removeMVRows when loadVariables is limited (to ensure all are loaded for the test)
        table.readMultidimNc(fiName, StringArray.fromCSV("LONGITUDE,PRES,PSAL_ADJUSTED_ERROR"), 
            null, null,
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
"LONGITUDE,PRES,PSAL_ADJUSTED_ERROR\n" +
"123.36499786376953,5.9,0.01\n" +
"123.36499786376953,10.0,0.01\n" +
"123.36499786376953,20.1,0.01\n" +
"...\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows"); //same as when all variables were explicitly loaded
 
        //and test data at the end of that table
        table.removeRows(0, table.nRows() - 3);
        results = table.dataToString(5);
        expectedEnd = 
"LONGITUDE,PRES,PSAL_ADJUSTED_ERROR\n" + 
"154.853,1850.0,99999.0\n" +  //these rows were're removed because other full-dim vars had values
"154.853,1899.9,99999.0\n" +
"154.853,1950.0,99999.0\n";   
        Test.ensureEqual(results, expectedEnd, "results=\n" + results);


        //* test read JULD
        table.readMultidimNc(fiName, StringArray.fromCSV("JULD"), null, null,
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
"JULD\n" +
"21660.34238425926\n" +
"21670.351828703704\n" +
"21680.386898148146\n" +
"...\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 254, "nRows"); //same as when all variables were explicitly loaded

        table.removeRows(0, 251);
        results = table.dataToString(1000);
        expectedStart = 
"JULD\n" +
"24190.451828703703\n" +
"24200.381412037037\n" +
"24210.44662037037\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
 

        //* test read JULD && PRES
        table.readMultidimNc(fiName, StringArray.fromCSV("JULD,PRES"), null, null,
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
"JULD,PRES\n" +
"21660.34238425926,5.9\n" + //JULD is correctly JOINed
"21660.34238425926,10.0\n" +
"21660.34238425926,20.1\n" +
"...\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows"); //same as when all variables were explicitly loaded

        table.removeRows(0, 17263);
        results = table.dataToString(1000);
        expectedStart = 
"JULD,PRES\n" +
"24210.44662037037,1850.0\n" + //JULD is correctly JOINed
"24210.44662037037,1899.9\n" +
"24210.44662037037,1950.0\n";
         Test.ensureEqual(results, expectedStart, "results=\n" + results);
 

        //* test read just static vars, in a different order 
        table.readMultidimNc(fiName, 
            StringArray.fromCSV("HANDBOOK_VERSION,FORMAT_VERSION,DATA_TYPE"), 
            null, null, 
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
"HANDBOOK_VERSION,FORMAT_VERSION,DATA_TYPE\n" +
"1.2,3.1,Argo profile\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);


        //* test read 0 dim variable -> empty table
        table.readMultidimNc(fiName, 
            StringArray.fromCSV("HISTORY_INSTITUTION"), 
            null, null, 
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");

        //* test read non-existent dim -> just scalar vars
        table.readMultidimNc(fiName, 
            null, StringArray.fromCSV("ZZTOP"), null, 
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);

        //* test read non-existent Var -> empty table
        table.readMultidimNc(fiName, 
            StringArray.fromCSV("ZZTOP"), null, null, 
            true, 0, true, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");


        //done
        /* */
        debugMode = oDebugMode;
    }

    /** This tests unpack by reading an Argo Profile file. */
    public static void testUnpack() throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebugMode = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testUnpack");
        Table table = new Table();
        //ftp://ftp.ifremer.fr/ifremer/argo/dac/csio/2901175/2901175_prof.nc
        String fiName = String2.unitTestDataDir + "nc/2901175_prof.nc";
        String results, expected;

        //** test the original packed format for comparison
        table.readMultidimNc(fiName, new StringArray(), new StringArray(), null, 
            true, 0, false, //readMetadata, unpack, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.toString(3);
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 762 ;\n" +
"\tDATA_TYPE_strlen = 12 ;\n" +
"\tFORMAT_VERSION_strlen = 3 ;\n" +
"\tHANDBOOK_VERSION_strlen = 3 ;\n" +
"\tREFERENCE_DATE_TIME_strlen = 14 ;\n" +
"\tDATE_CREATION_strlen = 14 ;\n" +
"\tDATE_UPDATE_strlen = 14 ;\n" +
"\tPLATFORM_NUMBER_strlen = 7 ;\n" +
"\tPROJECT_NAME_strlen = 18 ;\n" +
"\tPI_NAME_strlen = 11 ;\n" +
"\tSTATION_PARAMETERS_strlen = 4 ;\n" +
"\tDATA_CENTRE_strlen = 2 ;\n" +
"\tDC_REFERENCE_strlen = 14 ;\n" +
"\tDATA_STATE_INDICATOR_strlen = 2 ;\n" +
"\tPLATFORM_TYPE_strlen = 4 ;\n" +
"\tFLOAT_SERIAL_NO_strlen = 13 ;\n" +
"\tFIRMWARE_VERSION_strlen = 6 ;\n" +
"\tWMO_INST_TYPE_strlen = 3 ;\n" +
"\tPOSITIONING_SYSTEM_strlen = 5 ;\n" +
"\tVERTICAL_SAMPLING_SCHEME_strlen = 26 ;\n" +
"\tPARAMETER_strlen = 4 ;\n" +
"\tSCIENTIFIC_CALIB_EQUATION_strlen = 153 ;\n" +
"\tSCIENTIFIC_CALIB_COEFFICIENT_strlen = 55 ;\n" +
"\tSCIENTIFIC_CALIB_COMMENT_strlen = 124 ;\n" +
"\tSCIENTIFIC_CALIB_DATE_strlen = 14 ;\n" +
"variables:\n" +
"\tchar DATA_TYPE(row, DATA_TYPE_strlen) ;\n" +
"\t\tDATA_TYPE:conventions = \"Argo reference table 1\" ;\n" +
"\t\tDATA_TYPE:long_name = \"Data type\" ;\n" +
"\tchar FORMAT_VERSION(row, FORMAT_VERSION_strlen) ;\n" +
"\t\tFORMAT_VERSION:long_name = \"File format version\" ;\n" +
"\tchar HANDBOOK_VERSION(row, HANDBOOK_VERSION_strlen) ;\n" +
"\t\tHANDBOOK_VERSION:long_name = \"Data handbook version\" ;\n" +
"\tchar REFERENCE_DATE_TIME(row, REFERENCE_DATE_TIME_strlen) ;\n" +
"\t\tREFERENCE_DATE_TIME:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tREFERENCE_DATE_TIME:long_name = \"Date of reference for Julian days\" ;\n" +
"\tchar DATE_CREATION(row, DATE_CREATION_strlen) ;\n" +
"\t\tDATE_CREATION:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tDATE_CREATION:long_name = \"Date of file creation\" ;\n" +
"\tchar DATE_UPDATE(row, DATE_UPDATE_strlen) ;\n" +
"\t\tDATE_UPDATE:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tDATE_UPDATE:long_name = \"Date of update of this file\" ;\n" +
"\tchar PLATFORM_NUMBER(row, PLATFORM_NUMBER_strlen) ;\n" +
"\t\tPLATFORM_NUMBER:conventions = \"WMO float identifier : A9IIIII\" ;\n" +
"\t\tPLATFORM_NUMBER:long_name = \"Float unique identifier\" ;\n" +
"\tchar PROJECT_NAME(row, PROJECT_NAME_strlen) ;\n" +
"\t\tPROJECT_NAME:long_name = \"Name of the project\" ;\n" +
"\tchar PI_NAME(row, PI_NAME_strlen) ;\n" +
"\t\tPI_NAME:long_name = \"Name of the principal investigator\" ;\n" +
"\tchar STATION_PARAMETERS(row, STATION_PARAMETERS_strlen) ;\n" +
"\t\tSTATION_PARAMETERS:conventions = \"Argo reference table 3\" ;\n" +
"\t\tSTATION_PARAMETERS:long_name = \"List of available parameters for the station\" ;\n" +
"\tint CYCLE_NUMBER(row) ;\n" +
"\t\tCYCLE_NUMBER:_FillValue = 99999 ;\n" +
"\t\tCYCLE_NUMBER:conventions = \"0...N, 0 : launch cycle (if exists), 1 : first complete cycle\" ;\n" +
"\t\tCYCLE_NUMBER:long_name = \"Float cycle number\" ;\n" +
"\tchar DIRECTION(row) ;\n" +
"\t\tDIRECTION:conventions = \"A: ascending profiles, D: descending profiles\" ;\n" +
"\t\tDIRECTION:long_name = \"Direction of the station profiles\" ;\n" +
"\tchar DATA_CENTRE(row, DATA_CENTRE_strlen) ;\n" +
"\t\tDATA_CENTRE:conventions = \"Argo reference table 4\" ;\n" +
"\t\tDATA_CENTRE:long_name = \"Data centre in charge of float data processing\" ;\n" +
"\tchar DC_REFERENCE(row, DC_REFERENCE_strlen) ;\n" +
"\t\tDC_REFERENCE:conventions = \"Data centre convention\" ;\n" +
"\t\tDC_REFERENCE:long_name = \"Station unique identifier in data centre\" ;\n" +
"\tchar DATA_STATE_INDICATOR(row, DATA_STATE_INDICATOR_strlen) ;\n" +
"\t\tDATA_STATE_INDICATOR:conventions = \"Argo reference table 6\" ;\n" +
"\t\tDATA_STATE_INDICATOR:long_name = \"Degree of processing the data have passed through\" ;\n" +
"\tchar DATA_MODE(row) ;\n" +
"\t\tDATA_MODE:conventions = \"R : real time; D : delayed mode; A : real time with adjustment\" ;\n" +
"\t\tDATA_MODE:long_name = \"Delayed mode or real time data\" ;\n" +
"\tchar PLATFORM_TYPE(row, PLATFORM_TYPE_strlen) ;\n" +
"\t\tPLATFORM_TYPE:conventions = \"Argo reference table 23\" ;\n" +
"\t\tPLATFORM_TYPE:long_name = \"Type of float\" ;\n" +
"\tchar FLOAT_SERIAL_NO(row, FLOAT_SERIAL_NO_strlen) ;\n" +
"\t\tFLOAT_SERIAL_NO:long_name = \"Serial number of the float\" ;\n" +
"\tchar FIRMWARE_VERSION(row, FIRMWARE_VERSION_strlen) ;\n" +
"\t\tFIRMWARE_VERSION:long_name = \"Instrument firmware version\" ;\n" +
"\tchar WMO_INST_TYPE(row, WMO_INST_TYPE_strlen) ;\n" +
"\t\tWMO_INST_TYPE:conventions = \"Argo reference table 8\" ;\n" +
"\t\tWMO_INST_TYPE:long_name = \"Coded instrument type\" ;\n" +
"\tdouble JULD(row) ;\n" +
"\t\tJULD:_FillValue = 999999.0 ;\n" +
"\t\tJULD:axis = \"T\" ;\n" +
"\t\tJULD:conventions = \"Relative julian days with decimal part (as parts of day)\" ;\n" +
"\t\tJULD:long_name = \"Julian day (UTC) of the station relative to REFERENCE_DATE_TIME\" ;\n" +
"\t\tJULD:resolution = 0.0 ;\n" +
"\t\tJULD:standard_name = \"time\" ;\n" +
"\t\tJULD:units = \"days since 1950-01-01 00:00:00 UTC\" ;\n" +
"\tchar JULD_QC(row) ;\n" +
"\t\tJULD_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tJULD_QC:long_name = \"Quality on date and time\" ;\n" +
"\tdouble JULD_LOCATION(row) ;\n" +
"\t\tJULD_LOCATION:_FillValue = 999999.0 ;\n" +
"\t\tJULD_LOCATION:conventions = \"Relative julian days with decimal part (as parts of day)\" ;\n" +
"\t\tJULD_LOCATION:long_name = \"Julian day (UTC) of the location relative to REFERENCE_DATE_TIME\" ;\n" +
"\t\tJULD_LOCATION:resolution = 0.0 ;\n" +
"\t\tJULD_LOCATION:units = \"days since 1950-01-01 00:00:00 UTC\" ;\n" +
"\tdouble LATITUDE(row) ;\n" +
"\t\tLATITUDE:_FillValue = 99999.0 ;\n" +
"\t\tLATITUDE:axis = \"Y\" ;\n" +
"\t\tLATITUDE:long_name = \"Latitude of the station, best estimate\" ;\n" +
"\t\tLATITUDE:standard_name = \"latitude\" ;\n" +
"\t\tLATITUDE:units = \"degree_north\" ;\n" +
"\t\tLATITUDE:valid_max = 90.0 ;\n" +
"\t\tLATITUDE:valid_min = -90.0 ;\n" +
"\tdouble LONGITUDE(row) ;\n" +
"\t\tLONGITUDE:_FillValue = 99999.0 ;\n" +
"\t\tLONGITUDE:axis = \"X\" ;\n" +
"\t\tLONGITUDE:long_name = \"Longitude of the station, best estimate\" ;\n" +
"\t\tLONGITUDE:standard_name = \"longitude\" ;\n" +
"\t\tLONGITUDE:units = \"degree_east\" ;\n" +
"\t\tLONGITUDE:valid_max = 180.0 ;\n" +
"\t\tLONGITUDE:valid_min = -180.0 ;\n" +
"\tchar POSITION_QC(row) ;\n" +
"\t\tPOSITION_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tPOSITION_QC:long_name = \"Quality on position (latitude and longitude)\" ;\n" +
"\tchar POSITIONING_SYSTEM(row, POSITIONING_SYSTEM_strlen) ;\n" +
"\t\tPOSITIONING_SYSTEM:long_name = \"Positioning system\" ;\n" +
"\tchar PROFILE_PRES_QC(row) ;\n" +
"\t\tPROFILE_PRES_QC:conventions = \"Argo reference table 2a\" ;\n" +
"\t\tPROFILE_PRES_QC:long_name = \"Global quality flag of PRES profile\" ;\n" +
"\tchar PROFILE_TEMP_QC(row) ;\n" +
"\t\tPROFILE_TEMP_QC:conventions = \"Argo reference table 2a\" ;\n" +
"\t\tPROFILE_TEMP_QC:long_name = \"Global quality flag of TEMP profile\" ;\n" +
"\tchar PROFILE_PSAL_QC(row) ;\n" +
"\t\tPROFILE_PSAL_QC:conventions = \"Argo reference table 2a\" ;\n" +
"\t\tPROFILE_PSAL_QC:long_name = \"Global quality flag of PSAL profile\" ;\n" +
"\tchar VERTICAL_SAMPLING_SCHEME(row, VERTICAL_SAMPLING_SCHEME_strlen) ;\n" +
"\t\tVERTICAL_SAMPLING_SCHEME:conventions = \"Argo reference table 16\" ;\n" +
"\t\tVERTICAL_SAMPLING_SCHEME:long_name = \"Vertical sampling scheme\" ;\n" +
"\tint CONFIG_MISSION_NUMBER(row) ;\n" +
"\t\tCONFIG_MISSION_NUMBER:_FillValue = 99999 ;\n" +
"\t\tCONFIG_MISSION_NUMBER:conventions = \"1...N, 1 : first complete mission\" ;\n" +
"\t\tCONFIG_MISSION_NUMBER:long_name = \"Unique number denoting the missions performed by the float\" ;\n" +
"\tchar PARAMETER(row, PARAMETER_strlen) ;\n" +
"\t\tPARAMETER:conventions = \"Argo reference table 3\" ;\n" +
"\t\tPARAMETER:long_name = \"List of parameters with calibration information\" ;\n" +
"\tchar SCIENTIFIC_CALIB_EQUATION(row, SCIENTIFIC_CALIB_EQUATION_strlen) ;\n" +
"\t\tSCIENTIFIC_CALIB_EQUATION:long_name = \"Calibration equation for this parameter\" ;\n" +
"\tchar SCIENTIFIC_CALIB_COEFFICIENT(row, SCIENTIFIC_CALIB_COEFFICIENT_strlen) ;\n" +
"\t\tSCIENTIFIC_CALIB_COEFFICIENT:long_name = \"Calibration coefficients for this equation\" ;\n" +
"\tchar SCIENTIFIC_CALIB_COMMENT(row, SCIENTIFIC_CALIB_COMMENT_strlen) ;\n" +
"\t\tSCIENTIFIC_CALIB_COMMENT:long_name = \"Comment applying to this parameter calibration\" ;\n" +
"\tchar SCIENTIFIC_CALIB_DATE(row, SCIENTIFIC_CALIB_DATE_strlen) ;\n" +
"\t\tSCIENTIFIC_CALIB_DATE:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tSCIENTIFIC_CALIB_DATE:long_name = \"Date of calibration\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:Conventions = \"Argo-3.1 CF-1.6\" ;\n" +
"\t\t:featureType = \"trajectoryProfile\" ;\n" +
"\t\t:history = \"2016-04-15T20:47:22Z creation\" ;\n" +
"\t\t:institution = \"Coriolis GDAC\" ;\n" +
"\t\t:references = \"http://www.argodatamgt.org/Documentation\" ;\n" +
"\t\t:source = \"Argo float\" ;\n" +
"\t\t:title = \"Argo float vertical profile\" ;\n" +
"\t\t:user_manual_version = \"3.1\" ;\n" +
"}\n" +
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,STATION_PARAMETERS,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PARAMETER,SCIENTIFIC_CALIB_EQUATION,SCIENTIFIC_CALIB_COEFFICIENT,SCIENTIFIC_CALIB_COMMENT,SCIENTIFIC_CALIB_DATE\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,PRES,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,PRES,PRES_ADJUSTED = PRES - dP,dP =  0.1 dbar.,Pressures adjusted by using pressure offset at the sea surface. The quoted error is manufacturer specified accuracy in dbar.,20110628060155\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,TEMP,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,TEMP,none,none,The quoted error is manufacturer specified accuracy with respect to ITS-90 at time of laboratory calibration.,20110628060155\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,PSAL,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,PSAL,\"PSAL_ADJUSTED = sw_salt( sw_cndr(PSAL,TEMP,PRES), TEMP, PRES_ADJUSTED ); PSAL_ADJ corrects conductivity cell therm mass (CTM), Johnson et al, 2007, JAOT;\",\"same as for PRES_ADJUSTED; CTL: alpha=0.0267, tau=18.6;\",No significant salinity drift detected; SBE sensor accuracy,20110628060155\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //** don't specify varNames or dimNames -- it find vars with most dims
        table.readMultidimNc(fiName, new StringArray(), new StringArray(), null, 
            true, 3, false, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.toString(3);
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 762 ;\n" +
"\tDATA_TYPE_strlen = 12 ;\n" +
"\tFORMAT_VERSION_strlen = 3 ;\n" +
"\tHANDBOOK_VERSION_strlen = 3 ;\n" +
"\tREFERENCE_DATE_TIME_strlen = 14 ;\n" +
"\tDATE_CREATION_strlen = 14 ;\n" +
"\tDATE_UPDATE_strlen = 14 ;\n" +
"\tPLATFORM_NUMBER_strlen = 7 ;\n" +
"\tPROJECT_NAME_strlen = 18 ;\n" +
"\tPI_NAME_strlen = 11 ;\n" +
"\tSTATION_PARAMETERS_strlen = 4 ;\n" +
"\tDATA_CENTRE_strlen = 2 ;\n" +
"\tDC_REFERENCE_strlen = 14 ;\n" +
"\tDATA_STATE_INDICATOR_strlen = 2 ;\n" +
"\tPLATFORM_TYPE_strlen = 4 ;\n" +
"\tFLOAT_SERIAL_NO_strlen = 13 ;\n" +
"\tFIRMWARE_VERSION_strlen = 6 ;\n" +
"\tWMO_INST_TYPE_strlen = 3 ;\n" +
"\tPOSITIONING_SYSTEM_strlen = 5 ;\n" +
"\tVERTICAL_SAMPLING_SCHEME_strlen = 26 ;\n" +
"\tPARAMETER_strlen = 4 ;\n" +
"\tSCIENTIFIC_CALIB_EQUATION_strlen = 153 ;\n" +
"\tSCIENTIFIC_CALIB_COEFFICIENT_strlen = 55 ;\n" +
"\tSCIENTIFIC_CALIB_COMMENT_strlen = 124 ;\n" +
"\tSCIENTIFIC_CALIB_DATE_strlen = 14 ;\n" +
"variables:\n" +
"\tchar DATA_TYPE(row, DATA_TYPE_strlen) ;\n" +
"\t\tDATA_TYPE:conventions = \"Argo reference table 1\" ;\n" +
"\t\tDATA_TYPE:long_name = \"Data type\" ;\n" +
"\tchar FORMAT_VERSION(row, FORMAT_VERSION_strlen) ;\n" +
"\t\tFORMAT_VERSION:long_name = \"File format version\" ;\n" +
"\tchar HANDBOOK_VERSION(row, HANDBOOK_VERSION_strlen) ;\n" +
"\t\tHANDBOOK_VERSION:long_name = \"Data handbook version\" ;\n" +
"\tchar REFERENCE_DATE_TIME(row, REFERENCE_DATE_TIME_strlen) ;\n" +
"\t\tREFERENCE_DATE_TIME:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tREFERENCE_DATE_TIME:long_name = \"Date of reference for Julian days\" ;\n" +
"\tchar DATE_CREATION(row, DATE_CREATION_strlen) ;\n" +
"\t\tDATE_CREATION:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tDATE_CREATION:long_name = \"Date of file creation\" ;\n" +
"\tchar DATE_UPDATE(row, DATE_UPDATE_strlen) ;\n" +
"\t\tDATE_UPDATE:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tDATE_UPDATE:long_name = \"Date of update of this file\" ;\n" +
"\tchar PLATFORM_NUMBER(row, PLATFORM_NUMBER_strlen) ;\n" +
"\t\tPLATFORM_NUMBER:conventions = \"WMO float identifier : A9IIIII\" ;\n" +
"\t\tPLATFORM_NUMBER:long_name = \"Float unique identifier\" ;\n" +
"\tchar PROJECT_NAME(row, PROJECT_NAME_strlen) ;\n" +
"\t\tPROJECT_NAME:long_name = \"Name of the project\" ;\n" +
"\tchar PI_NAME(row, PI_NAME_strlen) ;\n" +
"\t\tPI_NAME:long_name = \"Name of the principal investigator\" ;\n" +
"\tchar STATION_PARAMETERS(row, STATION_PARAMETERS_strlen) ;\n" +
"\t\tSTATION_PARAMETERS:conventions = \"Argo reference table 3\" ;\n" +
"\t\tSTATION_PARAMETERS:long_name = \"List of available parameters for the station\" ;\n" +
"\tint CYCLE_NUMBER(row) ;\n" +
"\t\tCYCLE_NUMBER:_FillValue = 2147483647 ;\n" +
"\t\tCYCLE_NUMBER:conventions = \"0...N, 0 : launch cycle (if exists), 1 : first complete cycle\" ;\n" +
"\t\tCYCLE_NUMBER:long_name = \"Float cycle number\" ;\n" +
"\tchar DIRECTION(row) ;\n" +
"\t\tDIRECTION:conventions = \"A: ascending profiles, D: descending profiles\" ;\n" +
"\t\tDIRECTION:long_name = \"Direction of the station profiles\" ;\n" +
"\tchar DATA_CENTRE(row, DATA_CENTRE_strlen) ;\n" +
"\t\tDATA_CENTRE:conventions = \"Argo reference table 4\" ;\n" +
"\t\tDATA_CENTRE:long_name = \"Data centre in charge of float data processing\" ;\n" +
"\tchar DC_REFERENCE(row, DC_REFERENCE_strlen) ;\n" +
"\t\tDC_REFERENCE:conventions = \"Data centre convention\" ;\n" +
"\t\tDC_REFERENCE:long_name = \"Station unique identifier in data centre\" ;\n" +
"\tchar DATA_STATE_INDICATOR(row, DATA_STATE_INDICATOR_strlen) ;\n" +
"\t\tDATA_STATE_INDICATOR:conventions = \"Argo reference table 6\" ;\n" +
"\t\tDATA_STATE_INDICATOR:long_name = \"Degree of processing the data have passed through\" ;\n" +
"\tchar DATA_MODE(row) ;\n" +
"\t\tDATA_MODE:conventions = \"R : real time; D : delayed mode; A : real time with adjustment\" ;\n" +
"\t\tDATA_MODE:long_name = \"Delayed mode or real time data\" ;\n" +
"\tchar PLATFORM_TYPE(row, PLATFORM_TYPE_strlen) ;\n" +
"\t\tPLATFORM_TYPE:conventions = \"Argo reference table 23\" ;\n" +
"\t\tPLATFORM_TYPE:long_name = \"Type of float\" ;\n" +
"\tchar FLOAT_SERIAL_NO(row, FLOAT_SERIAL_NO_strlen) ;\n" +
"\t\tFLOAT_SERIAL_NO:long_name = \"Serial number of the float\" ;\n" +
"\tchar FIRMWARE_VERSION(row, FIRMWARE_VERSION_strlen) ;\n" +
"\t\tFIRMWARE_VERSION:long_name = \"Instrument firmware version\" ;\n" +
"\tchar WMO_INST_TYPE(row, WMO_INST_TYPE_strlen) ;\n" +
"\t\tWMO_INST_TYPE:conventions = \"Argo reference table 8\" ;\n" +
"\t\tWMO_INST_TYPE:long_name = \"Coded instrument type\" ;\n" +
"\tdouble JULD(row) ;\n" +
"\t\tJULD:_FillValue = NaN ;\n" +
"\t\tJULD:axis = \"T\" ;\n" +
"\t\tJULD:conventions = \"Relative julian days with decimal part (as parts of day)\" ;\n" +
"\t\tJULD:long_name = \"Julian day (UTC) of the station relative to REFERENCE_DATE_TIME\" ;\n" +
"\t\tJULD:resolution = 0.0 ;\n" +
"\t\tJULD:standard_name = \"time\" ;\n" +
"\t\tJULD:units = \"seconds since 1970-01-01T00:00:00Z\" ;\n" +
"\tchar JULD_QC(row) ;\n" +
"\t\tJULD_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tJULD_QC:long_name = \"Quality on date and time\" ;\n" +
"\tdouble JULD_LOCATION(row) ;\n" +
"\t\tJULD_LOCATION:_FillValue = NaN ;\n" +
"\t\tJULD_LOCATION:conventions = \"Relative julian days with decimal part (as parts of day)\" ;\n" +
"\t\tJULD_LOCATION:long_name = \"Julian day (UTC) of the location relative to REFERENCE_DATE_TIME\" ;\n" +
"\t\tJULD_LOCATION:resolution = 0.0 ;\n" +
"\t\tJULD_LOCATION:units = \"seconds since 1970-01-01T00:00:00Z\" ;\n" +
"\tdouble LATITUDE(row) ;\n" +
"\t\tLATITUDE:_FillValue = NaN ;\n" +
"\t\tLATITUDE:axis = \"Y\" ;\n" +
"\t\tLATITUDE:long_name = \"Latitude of the station, best estimate\" ;\n" +
"\t\tLATITUDE:standard_name = \"latitude\" ;\n" +
"\t\tLATITUDE:units = \"degree_north\" ;\n" +
"\t\tLATITUDE:valid_max = 90.0 ;\n" +
"\t\tLATITUDE:valid_min = -90.0 ;\n" +
"\tdouble LONGITUDE(row) ;\n" +
"\t\tLONGITUDE:_FillValue = NaN ;\n" +
"\t\tLONGITUDE:axis = \"X\" ;\n" +
"\t\tLONGITUDE:long_name = \"Longitude of the station, best estimate\" ;\n" +
"\t\tLONGITUDE:standard_name = \"longitude\" ;\n" +
"\t\tLONGITUDE:units = \"degree_east\" ;\n" +
"\t\tLONGITUDE:valid_max = 180.0 ;\n" +
"\t\tLONGITUDE:valid_min = -180.0 ;\n" +
"\tchar POSITION_QC(row) ;\n" +
"\t\tPOSITION_QC:conventions = \"Argo reference table 2\" ;\n" +
"\t\tPOSITION_QC:long_name = \"Quality on position (latitude and longitude)\" ;\n" +
"\tchar POSITIONING_SYSTEM(row, POSITIONING_SYSTEM_strlen) ;\n" +
"\t\tPOSITIONING_SYSTEM:long_name = \"Positioning system\" ;\n" +
"\tchar PROFILE_PRES_QC(row) ;\n" +
"\t\tPROFILE_PRES_QC:conventions = \"Argo reference table 2a\" ;\n" +
"\t\tPROFILE_PRES_QC:long_name = \"Global quality flag of PRES profile\" ;\n" +
"\tchar PROFILE_TEMP_QC(row) ;\n" +
"\t\tPROFILE_TEMP_QC:conventions = \"Argo reference table 2a\" ;\n" +
"\t\tPROFILE_TEMP_QC:long_name = \"Global quality flag of TEMP profile\" ;\n" +
"\tchar PROFILE_PSAL_QC(row) ;\n" +
"\t\tPROFILE_PSAL_QC:conventions = \"Argo reference table 2a\" ;\n" +
"\t\tPROFILE_PSAL_QC:long_name = \"Global quality flag of PSAL profile\" ;\n" +
"\tchar VERTICAL_SAMPLING_SCHEME(row, VERTICAL_SAMPLING_SCHEME_strlen) ;\n" +
"\t\tVERTICAL_SAMPLING_SCHEME:conventions = \"Argo reference table 16\" ;\n" +
"\t\tVERTICAL_SAMPLING_SCHEME:long_name = \"Vertical sampling scheme\" ;\n" +
"\tint CONFIG_MISSION_NUMBER(row) ;\n" +
"\t\tCONFIG_MISSION_NUMBER:_FillValue = 2147483647 ;\n" +
"\t\tCONFIG_MISSION_NUMBER:conventions = \"1...N, 1 : first complete mission\" ;\n" +
"\t\tCONFIG_MISSION_NUMBER:long_name = \"Unique number denoting the missions performed by the float\" ;\n" +
"\tchar PARAMETER(row, PARAMETER_strlen) ;\n" +
"\t\tPARAMETER:conventions = \"Argo reference table 3\" ;\n" +
"\t\tPARAMETER:long_name = \"List of parameters with calibration information\" ;\n" +
"\tchar SCIENTIFIC_CALIB_EQUATION(row, SCIENTIFIC_CALIB_EQUATION_strlen) ;\n" +
"\t\tSCIENTIFIC_CALIB_EQUATION:long_name = \"Calibration equation for this parameter\" ;\n" +
"\tchar SCIENTIFIC_CALIB_COEFFICIENT(row, SCIENTIFIC_CALIB_COEFFICIENT_strlen) ;\n" +
"\t\tSCIENTIFIC_CALIB_COEFFICIENT:long_name = \"Calibration coefficients for this equation\" ;\n" +
"\tchar SCIENTIFIC_CALIB_COMMENT(row, SCIENTIFIC_CALIB_COMMENT_strlen) ;\n" +
"\t\tSCIENTIFIC_CALIB_COMMENT:long_name = \"Comment applying to this parameter calibration\" ;\n" +
"\tchar SCIENTIFIC_CALIB_DATE(row, SCIENTIFIC_CALIB_DATE_strlen) ;\n" +
"\t\tSCIENTIFIC_CALIB_DATE:conventions = \"YYYYMMDDHHMISS\" ;\n" +
"\t\tSCIENTIFIC_CALIB_DATE:long_name = \"Date of calibration\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:Conventions = \"Argo-3.1 CF-1.6\" ;\n" +
"\t\t:featureType = \"trajectoryProfile\" ;\n" +
"\t\t:history = \"2016-04-15T20:47:22Z creation\" ;\n" +
"\t\t:institution = \"Coriolis GDAC\" ;\n" +
"\t\t:references = \"http://www.argodatamgt.org/Documentation\" ;\n" +
"\t\t:source = \"Argo float\" ;\n" +
"\t\t:title = \"Argo float vertical profile\" ;\n" +
"\t\t:user_manual_version = \"3.1\" ;\n" +
"}\n" +
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,STATION_PARAMETERS,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PARAMETER,SCIENTIFIC_CALIB_EQUATION,SCIENTIFIC_CALIB_COEFFICIENT,SCIENTIFIC_CALIB_COMMENT,SCIENTIFIC_CALIB_DATE\n" +
//from raw file                                                                                                                                                 dif JULD_LOCATION   dif JULD_LOCATION                                                                   
//"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,PRES,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,PRES,PRES_ADJUSTED = PRES - dP,dP =  0.1 dbar.,Pressures adjusted by using pressure offset at the sea surface. The quoted error is manufacturer specified accuracy in dbar.,20110628060155\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,PRES,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,1.240301582E9,1,1.240301812E9,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,PRES,PRES_ADJUSTED = PRES - dP,dP =  0.1 dbar.,Pressures adjusted by using pressure offset at the sea surface. The quoted error is manufacturer specified accuracy in dbar.,20110628060155\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,TEMP,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,1.240301582E9,1,1.240301812E9,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,TEMP,none,none,The quoted error is manufacturer specified accuracy with respect to ITS-90 at time of laboratory calibration.,20110628060155\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,PSAL,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,1.240301582E9,1,1.240301812E9,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,PSAL,\"PSAL_ADJUSTED = sw_salt( sw_cndr(PSAL,TEMP,PRES), TEMP, PRES_ADJUSTED ); PSAL_ADJ corrects conductivity cell therm mass (CTM), Johnson et al, 2007, JAOT;\",\"same as for PRES_ADJUSTED; CTL: alpha=0.0267, tau=18.6;\",No significant salinity drift detected; SBE sensor accuracy,20110628060155\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);



        //done
        /* */
        debugMode = oDebugMode;
    }


    /** This tests readVlenNc. */
    public static void testReadVlenNc() throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebugMode = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadVlenNc");
        Table table = new Table();
        String fiName = String2.unitTestBigDataDir + "nccf/vlen/rr2_vlen_test.nc";
        String2.log(NcHelper.ncdump(fiName, "-h"));
        String results, expectedStart, expectedEnd;
        /* */

        //** don't specify varNames or dimNames -- it find vars with most dims
        table.readMultidimNc(fiName, new StringArray(), new StringArray(), null, 
            true, 0, false, //readMetadata, standardizeWhat, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
//static vars and vars like  char SCIENTIFIC_CALIB_COEFFICIENT(N_PROF=254, N_CALIB=1, N_PARAM=3, STRING256=256);
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,STATION_PARAMETERS,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PARAMETER,SCIENTIFIC_CALIB_EQUATION,SCIENTIFIC_CALIB_COEFFICIENT,SCIENTIFIC_CALIB_COMMENT,SCIENTIFIC_CALIB_DATE\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,PRES,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,PRES,PRES_ADJUSTED = PRES - dP,dP =  0.1 dbar.,Pressures adjusted by using pressure offset at the sea surface. The quoted error is manufacturer specified accuracy in dbar.,20110628060155\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,TEMP,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,TEMP,none,none,The quoted error is manufacturer specified accuracy with respect to ITS-90 at time of laboratory calibration.,20110628060155\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,PSAL,1,A,HZ,0066_80617_001,2C,D,,APEX_SBE_4136,,846,21660.34238425926,1,21660.345046296297,21.513999938964844,123.36499786376953,1,ARGOS,A,A,A,,1,PSAL,\"PSAL_ADJUSTED = sw_salt( sw_cndr(PSAL,TEMP,PRES), TEMP, PRES_ADJUSTED ); PSAL_ADJ corrects conductivity cell therm mass (CTM), Johnson et al, 2007, JAOT;\",\"same as for PRES_ADJUSTED; CTL: alpha=0.0267, tau=18.6;\",No significant salinity drift detected; SBE sensor accuracy,20110628060155\n" +
"...\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 762, "nRows"); //254*3
/*
        //* same but quick reject based on constraint
        table.readVlenNc(fiName, new StringArray(), new StringArray(), 
            true, false, //readMetadata, removeMVRows
            StringArray.fromCSV("FORMAT_VERSION,FORMAT_VERSION"), //conVars
            StringArray.fromCSV("=,="), //conOps
            StringArray.fromCSV("3.1,3.2")); //conVals
        Test.ensureEqual(table.nRows(), 0, "nRows"); 



        //* test do removeMVRows
        table.readVlenNc(fiName, null, StringArray.fromCSV("ZZTOP, N_PROF, N_LEVELS"), 
            true, false, //readMetadata, removeMVRows
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3, true);
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows");

         //and test data at the end of that table
        table.removeRows(0, table.nRows() - 3);
        results = table.dataToString(5);
        expectedEnd = 
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PRES,PRES_QC,PRES_ADJUSTED,PRES_ADJUSTED_QC,PRES_ADJUSTED_ERROR,TEMP,TEMP_QC,TEMP_ADJUSTED,TEMP_ADJUSTED_QC,TEMP_ADJUSTED_ERROR,PSAL,PSAL_QC,PSAL_ADJUSTED,PSAL_ADJUSTED_QC,PSAL_ADJUSTED_ERROR\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,256,A,HZ,0066_80617_256,2B,A,APEX,4136,013108,846,24210.44662037037,1,24210.44662037037,26.587,154.853,1,ARGOS,A,A,A,Primary sampling: discrete,1,1850.0,1,1849.4,1,99999.0,2.106,1,2.106,1,99999.0,34.604,1,34.604,1,99999.0\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,256,A,HZ,0066_80617_256,2B,A,APEX,4136,013108,846,24210.44662037037,1,24210.44662037037,26.587,154.853,1,ARGOS,A,A,A,Primary sampling: discrete,1,1899.9,1,1899.3,1,99999.0,2.055,1,2.055,1,99999.0,34.612,1,34.612,1,99999.0\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722,2901175,CHINA ARGO PROJECT,JIANPING XU,256,A,HZ,0066_80617_256,2B,A,APEX,4136,013108,846,24210.44662037037,1,24210.44662037037,26.587,154.853,1,ARGOS,A,A,A,Primary sampling: discrete,1,1950.0,1,1949.4,1,99999.0,2.014,1,2.014,1,99999.0,34.617,1,34.617,1,99999.0\n";
        Test.ensureEqual(results, expectedEnd, "results=\n" + results);

        //* same but quick reject based on constraint   LAT,LON 26.587,154.853
        //*** this takes 9ms while test above takes 99ms!
        table.readVlenNc(fiName, null, StringArray.fromCSV("ZZTOP, N_PROF, N_LEVELS"), 
            true,  //readMetadata,
            StringArray.fromCSV("LATITUDE"), //conVars
            StringArray.fromCSV("="), //conOps
            StringArray.fromCSV("45")); //conVals
        Test.ensureEqual(table.nRows(), 0, "nRows"); 

        //* test different dim order (should be rearranged so the same)
        table.readVlenNc(fiName, null, StringArray.fromCSV("N_LEVELS, ZZTOP, N_PROF"), 
            true,   //readMetadata, 
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3, true);
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows");
 
        //and test data at the end of that table
        table.removeRows(0, table.nRows() - 3);
        results = table.dataToString(5, true);
        Test.ensureEqual(results, expectedEnd, "results=\n" + results);


        //* test different varNames
        table.readVlenNc(fiName, 
            StringArray.fromCSV("DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE,PLATFORM_NUMBER,PROJECT_NAME,PI_NAME,CYCLE_NUMBER,DIRECTION,DATA_CENTRE,DC_REFERENCE,DATA_STATE_INDICATOR,DATA_MODE,PLATFORM_TYPE,FLOAT_SERIAL_NO,FIRMWARE_VERSION,WMO_INST_TYPE,JULD,JULD_QC,JULD_LOCATION,LATITUDE,LONGITUDE,POSITION_QC,POSITIONING_SYSTEM,PROFILE_PRES_QC,PROFILE_TEMP_QC,PROFILE_PSAL_QC,VERTICAL_SAMPLING_SCHEME,CONFIG_MISSION_NUMBER,PRES,PRES_QC,PRES_ADJUSTED,PRES_ADJUSTED_QC,PRES_ADJUSTED_ERROR,TEMP,TEMP_QC,TEMP_ADJUSTED,TEMP_ADJUSTED_QC,TEMP_ADJUSTED_ERROR,PSAL,PSAL_QC,PSAL_ADJUSTED,PSAL_ADJUSTED_QC,PSAL_ADJUSTED_ERROR"), 
            null, 
            true,   //readMetadata, 
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3, true);
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows");
 
        //and test data at the end of that table
        table.removeRows(0, table.nRows() - 3);
        results = table.dataToString(5, true);
        Test.ensureEqual(results, expectedEnd, "results=\n" + results);


        //* test read JULD
        table.readVlenNc(fiName, StringArray.fromCSV("JULD"), null,
            true,  //readMetadata,  
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
"JULD\n" +
"21660.34238425926\n" +
"21670.351828703704\n" +
"21680.386898148146\n" +
"...\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 254, "nRows"); //same as when all variables were explicitly loaded

        table.removeRows(0, 251);
        results = table.dataToString(1000);
        expectedStart = 
"JULD\n" +
"24190.451828703703\n" +
"24200.381412037037\n" +
"24210.44662037037\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
 

        //* test read JULD && PRES
        table.readVlenNc(fiName, StringArray.fromCSV("JULD,PRES"), null,
            true,   //readMetadata,
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
"JULD,PRES\n" +
"21660.34238425926,5.9\n" + //JULD is correctly JOINed
"21660.34238425926,10.0\n" +
"21660.34238425926,20.1\n" +
"...\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 17266, "nRows"); //same as when all variables were explicitly loaded

        table.removeRows(0, 17263);
        results = table.dataToString(1000);
        expectedStart = 
"JULD,PRES\n" +
"24210.44662037037,1850.0\n" + //JULD is correctly JOINed
"24210.44662037037,1899.9\n" +
"24210.44662037037,1950.0\n";
         Test.ensureEqual(results, expectedStart, "results=\n" + results);
 

        //* test read just static vars, in a different order 
        table.readVlenNc(fiName, 
            StringArray.fromCSV("HANDBOOK_VERSION,FORMAT_VERSION,DATA_TYPE"), 
            null, 
            true,  //readMetadata, 
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
"HANDBOOK_VERSION,FORMAT_VERSION,DATA_TYPE\n" +
"1.2,3.1,Argo profile\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);


        //* test read 0 dim variable -> empty table
        table.readVlenNc(fiName, 
            StringArray.fromCSV("HISTORY_INSTITUTION"), 
            null, 
            true,  //readMetadata,  
            null, null, null); //conVars, conOps, conVals
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");

        //* test read non-existent dim -> just scalar vars
        table.readVlenNc(fiName, 
            null, 
            StringArray.fromCSV("ZZTOP"), 
            true,   //readMetadata, 
            null, null, null); //conVars, conOps, conVals
        results = table.dataToString(3);
        expectedStart = 
"DATA_TYPE,FORMAT_VERSION,HANDBOOK_VERSION,REFERENCE_DATE_TIME,DATE_CREATION,DATE_UPDATE\n" +
"Argo profile,3.1,1.2,19500101000000,20090422121913,20160415204722\n";
        Test.ensureEqual(results, expectedStart, "results=\n" + results);

        //* test read non-existent Var -> empty table
        table.readVlenNc(fiName, 
            StringArray.fromCSV("ZZTOP"), 
            null, 
            true,   //readMetadata,
            null, null, null); //conVars, conOps, conVals
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");


        //done
        /* */
        debugMode = oDebugMode;
    }

    /** This tests readNDNC. */
    public static void testReadNDNc() throws Exception {
        verbose = true;
        reallyVerbose = true;
        String2.log("\n*** Table.testReadNDNc");
        Table table = new Table();
        String results, expected;

        //test  no vars specified,  4D,  only 2nd dim has >1 value,  getMetadata
        String fiName = "c:/u00/data/points/erdCalcofiSubsurface/1950/subsurface_19500106_69_144.nc";
        table.readNDNc(fiName, null, 0,  //standardizeWhat=0
            null, 0, 0);
        results = table.toString();
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 16 ;\n" +
"variables:\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:units = \"seconds since 1948-1-1\" ;\n" +
"\tfloat depth(row) ;\n" +
"\t\tdepth:long_name = \"depth index\" ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:_FillValue = -999.0f ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:missing_value = -999.0f ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:_FillValue = -999.0f ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:missing_value = -999.0f ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tint stationyear(row) ;\n" +
"\t\tstationyear:_FillValue = -9999 ;\n" +
"\t\tstationyear:long_name = \"Station Year\" ;\n" +
"\t\tstationyear:missing_value = -9999 ;\n" +
"\t\tstationyear:units = \"years\" ;\n" +
"\tint stationmonth(row) ;\n" +
"\t\tstationmonth:_FillValue = -9999 ;\n" +
"\t\tstationmonth:long_name = \"Station Month\" ;\n" +
"\t\tstationmonth:missing_value = -9999 ;\n" +
"\t\tstationmonth:units = \"months\" ;\n" +
"\tint stationday(row) ;\n" +
"\t\tstationday:_FillValue = -9999 ;\n" +
"\t\tstationday:long_name = \"Station Day\" ;\n" +
"\t\tstationday:missing_value = -9999 ;\n" +
"\t\tstationday:units = \"days\" ;\n" +
"\tint stime(row) ;\n" +
"\t\tstime:_FillValue = -9999 ;\n" +
"\t\tstime:long_name = \"Cast Time (GMT)\" ;\n" +
"\t\tstime:missing_value = -9999 ;\n" +
"\t\tstime:units = \"GMT\" ;\n" +
"\tfloat stationline(row) ;\n" +
"\t\tstationline:_FillValue = -999.0f ;\n" +
"\t\tstationline:long_name = \"CALCOFI Line Number\" ;\n" +
"\t\tstationline:missing_value = -999.0f ;\n" +
"\t\tstationline:units = \"number\" ;\n" +
"\tfloat stationnum(row) ;\n" +
"\t\tstationnum:_FillValue = -999.0f ;\n" +
"\t\tstationnum:long_name = \"CALCOFI Station Number\" ;\n" +
"\t\tstationnum:missing_value = -999.0f ;\n" +
"\t\tstationnum:units = \"number\" ;\n" +
"\tfloat temperature(row) ;\n" +
"\t\ttemperature:_FillValue = -999.0f ;\n" +
"\t\ttemperature:has_data = 1 ;\n" +
"\t\ttemperature:long_name = \"Temperature\" ;\n" +
"\t\ttemperature:missing_value = -999.0f ;\n" +
"\t\ttemperature:units = \"degC\" ;\n" +
"\tfloat salinity(row) ;\n" +
"\t\tsalinity:_FillValue = -999.0f ;\n" +
"\t\tsalinity:has_data = 1 ;\n" +
"\t\tsalinity:long_name = \"Salinity\" ;\n" +
"\t\tsalinity:missing_value = -999.0f ;\n" +
"\t\tsalinity:units = \"PSU\" ;\n" +
"\tfloat pressure(row) ;\n" +
"\t\tpressure:_FillValue = -999.0f ;\n" +
"\t\tpressure:has_data = 0 ;\n" +
"\t\tpressure:long_name = \"Pressure\" ;\n" +
"\t\tpressure:missing_value = -999.0f ;\n" +
"\t\tpressure:units = \"decibars\" ;\n" +
"\tfloat oxygen(row) ;\n" +
"\t\toxygen:_FillValue = -999.0f ;\n" +
"\t\toxygen:has_data = 1 ;\n" +
"\t\toxygen:long_name = \"Oxygen\" ;\n" +
"\t\toxygen:missing_value = -999.0f ;\n" +
"\t\toxygen:units = \"milliliters/liter\" ;\n" +
"\tfloat po4(row) ;\n" +
"\t\tpo4:_FillValue = -999.0f ;\n" +
"\t\tpo4:has_data = 1 ;\n" +
"\t\tpo4:long_name = \"Phosphate\" ;\n" +
"\t\tpo4:missing_value = -999.0f ;\n" +
"\t\tpo4:units = \"ugram-atoms/liter\" ;\n" +
"\tfloat silicate(row) ;\n" +
"\t\tsilicate:_FillValue = -999.0f ;\n" +
"\t\tsilicate:has_data = 0 ;\n" +
"\t\tsilicate:long_name = \"Silicate\" ;\n" +
"\t\tsilicate:missing_value = -999.0f ;\n" +
"\t\tsilicate:units = \"ugram-atoms/liter\" ;\n" +
"\tfloat no2(row) ;\n" +
"\t\tno2:_FillValue = -999.0f ;\n" +
"\t\tno2:has_data = 0 ;\n" +
"\t\tno2:long_name = \"Nitrite\" ;\n" +
"\t\tno2:missing_value = -999.0f ;\n" +
"\t\tno2:units = \"ugram-atoms/liter\" ;\n" +
"\tfloat no3(row) ;\n" +
"\t\tno3:_FillValue = -999.0f ;\n" +
"\t\tno3:has_data = 0 ;\n" +
"\t\tno3:long_name = \"Nitrate\" ;\n" +
"\t\tno3:missing_value = -999.0f ;\n" +
"\t\tno3:units = \"ugram-atoms/liter\" ;\n" +
"\tfloat nh3(row) ;\n" +
"\t\tnh3:_FillValue = -999.0f ;\n" +
"\t\tnh3:has_data = 0 ;\n" +
"\t\tnh3:long_name = \"Ammonia\" ;\n" +
"\t\tnh3:missing_value = -999.0f ;\n" +
"\t\tnh3:units = \"ugram-atoms/liter\" ;\n" +
"\tfloat chl(row) ;\n" +
"\t\tchl:_FillValue = -999.0f ;\n" +
"\t\tchl:has_data = 0 ;\n" +
"\t\tchl:long_name = \"Chlorophyll-a\" ;\n" +
"\t\tchl:missing_value = -999.0f ;\n" +
"\t\tchl:units = \"milligrams/meter**3\" ;\n" +
"\tfloat dark(row) ;\n" +
"\t\tdark:_FillValue = -999.0f ;\n" +
"\t\tdark:has_data = 0 ;\n" +
"\t\tdark:long_name = \"Dark Bottle C14 Assimilation\" ;\n" +
"\t\tdark:missing_value = -999.0f ;\n" +
"\t\tdark:units = \"milligrams/meter**3/experiment\" ;\n" +
"\tfloat primprod(row) ;\n" +
"\t\tprimprod:_FillValue = -999.0f ;\n" +
"\t\tprimprod:has_data = 0 ;\n" +
"\t\tprimprod:long_name = \"Mean Primary Production (C14 Assimilation)\" ;\n" +
"\t\tprimprod:missing_value = -999.0f ;\n" +
"\t\tprimprod:units = \"milligrams/meter**3/experiment\" ;\n" +
"\tfloat lightpercent(row) ;\n" +
"\t\tlightpercent:_FillValue = -999.0f ;\n" +
"\t\tlightpercent:has_data = 0 ;\n" +
"\t\tlightpercent:long_name = \"Percent Light (for incubations)\" ;\n" +
"\t\tlightpercent:missing_value = -999.0f ;\n" +
"\t\tlightpercent:units = \"milligrams/meter**3/experiment\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:history = \"created by ERD from Matlab database created by Andrew Leising  from the CalCOFI Physical data\" ;\n" +
"\t\t:title = \"CalCOFI Physical Observations, 1949-2001\" ;\n" +
"}\n" +
"time,depth,lat,lon,stationyear,stationmonth,stationday,stime,stationline,stationnum,temperature,salinity,pressure,oxygen,po4,silicate,no2,no3,nh3,chl,dark,primprod,lightpercent\n" +
"6.3612E7,0.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,16.19,33.6,-999.0,5.3,0.42,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,22.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,16.18,33.6,-999.0,5.26,0.38,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,49.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,16.2,33.6,-999.0,5.3,0.36,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,72.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,14.95,33.58,-999.0,5.51,0.37,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,98.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,13.02,33.35,-999.0,5.35,0.45,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,147.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,11.45,33.36,-999.0,4.99,0.81,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,194.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,9.32,33.55,-999.0,4.47,1.19,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,241.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,8.51,33.85,-999.0,4.02,1.51,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,287.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,7.74,33.95,-999.0,3.48,1.76,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,384.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,6.42,33.97,-999.0,2.55,2.15,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,477.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,5.35,34.04,-999.0,1.29,2.48,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,576.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,4.83,34.14,-999.0,0.73,2.73,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,673.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,4.44,34.22,-999.0,0.48,2.9,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,768.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,4.15,34.31,-999.0,0.37,2.87,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,969.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,3.67,34.43,-999.0,0.49,2.8,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n" +
"6.3612E7,1167.0,33.31667,-128.53333,1950,1,6,600,69.0,144.0,3.3,34.49,-999.0,0.66,2.7,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0,-999.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test specify vars (including out-of-order axis var, and nonsense var), !getMetadata
        table.readNDNc(fiName, new String[]{"temperature", "lat", "salinity", "junk"}, 0,  //standardizeWhat=0
             "depth", 100, 200);
        results = table.dataToString();
        expected = 
"time,depth,lat,lon,temperature,salinity\n" +
"6.3612E7,147.0,33.31667,-128.53333,11.45,33.36\n" +
"6.3612E7,194.0,33.31667,-128.53333,9.32,33.55\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test String vars 
        fiName = "c:/data/_erddapBPD/copy/cPostDet3/BARBARAx20BLOCK/LAMNAx20DITROPIS/Nx2fA/52038_A69-1303_1059305.nc";
        table.readNDNc(fiName, null, 0,  //standardizeWhat=0
            null, 0, 0);
        results = table.dataToString(4);
        expected = 
"row,unique_tag_id,PI,longitude,latitude,time,bottom_depth,common_name,date_public,line,position_on_subarray,project,riser_height,role,scientific_name,serial_number,stock,surgery_time,surgery_location,tagger\n" +
"0,52038_A69-1303_1059305,BARBARA BLOCK,-146.1137,60.7172,1.2192849E9,,SALMON SHARK,1.273271649385E9,,,HOPKINS MARINE STATION,,BLOCK_BARBARA_LAMNA_DITROPIS_N/A,LAMNA DITROPIS,1059305,N/A,1.2192156E9,\"PORT GRAVINA, PRINCE WILLIAM SOUND\",\n" +
"1,52038_A69-1303_1059305,BARBARA BLOCK,-146.32355,60.66713,1.233325298E9,127.743902439024,SALMON SHARK,1.273271649385E9,PORT GRAVINA,6,HOPKINS MARINE STATION,,BLOCK_BARBARA_LAMNA_DITROPIS_N/A,LAMNA DITROPIS,1059305,N/A,1.2192156E9,\"PORT GRAVINA, PRINCE WILLIAM SOUND\",\n" +
"2,52038_A69-1303_1059305,BARBARA BLOCK,-146.32355,60.66713,1.233325733E9,127.743902439024,SALMON SHARK,1.273271649385E9,PORT GRAVINA,6,HOPKINS MARINE STATION,,BLOCK_BARBARA_LAMNA_DITROPIS_N/A,LAMNA DITROPIS,1059305,N/A,1.2192156E9,\"PORT GRAVINA, PRINCE WILLIAM SOUND\",\n" +
"3,52038_A69-1303_1059305,BARBARA BLOCK,-146.32355,60.66713,1.233325998E9,127.743902439024,SALMON SHARK,1.273271649385E9,PORT GRAVINA,6,HOPKINS MARINE STATION,,BLOCK_BARBARA_LAMNA_DITROPIS_N/A,LAMNA DITROPIS,1059305,N/A,1.2192156E9,\"PORT GRAVINA, PRINCE WILLIAM SOUND\",\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test 4D but request axis vars only, with constraints
        fiName = "/u00/data/points/ndbcMetOldStyle/NDBC_51001_met.nc"; //implied c:
        table.readNDNc(fiName, new String[]{"LON", "LAT", "TIME"}, 0,  //standardizeWhat=0
            "TIME", 1.2051936e9, 1.20528e9);
        results = table.dataToString(4);
        expected = 
//"LON, LAT, TIME\n" +   //pre 2011-07-28
//"-162.21, 23.43, 1.2051828E9\n" +
//"-162.21, 23.43, 1.2051864E9\n" +
//"-162.21, 23.43, 1.20519E9\n" +
//"-162.21, 23.43, 1.2051936E9\n";
"LON,LAT,TIME\n" +
"-162.279,23.445,1.20519E9\n" +    //pre 2013-06-20 last 9 was 828
"-162.279,23.445,1.2051936E9\n" +  //and 936 was 864
"-162.279,23.445,1.2051972E9\n" +  //and 972 was 9
"-162.279,23.445,1.2052008E9\n" +
"...\n";   //and 2008 was 1936
        Test.ensureEqual(results, expected, "results=\n" + results);
       
    }

        
    /** This tests readNDNC. */
    public static void testReadNDNc2() throws Exception {
        verbose = true;
        reallyVerbose = true;
        String2.log("\n*** Table.testReadNDNc2");
        String fiName = "c:/data/wod/monthly/APB/199804-199804/wod_008015632O.nc";
        Table table = new Table();
        String results, expected;

        //test  no vars specified
        table.readNDNc(fiName, null, 0,  //standardizeWhat=0
            null, 0, 0);
        results = table.toString();
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 11 ;\n" +
"\tWOD_cruise_identifier_strlen = 8 ;\n" +
"\tProject_strlen = 49 ;\n" +
"\tdataset_strlen = 14 ;\n" +
"variables:\n" +
"\tfloat z(row) ;\n" +
"\t\tz:long_name = \"depth_below_sea_level\" ;\n" +
"\t\tz:positive = \"down\" ;\n" +
"\t\tz:standard_name = \"altitude\" ;\n" +
"\t\tz:units = \"m\" ;\n" +
"\tfloat Temperature(row) ;\n" +
"\t\tTemperature:coordinates = \"time lat lon z\" ;\n" +
"\t\tTemperature:flag_definitions = \"WODfp\" ;\n" +
"\t\tTemperature:grid_mapping = \"crs\" ;\n" +
"\t\tTemperature:Instrument_(WOD_code) = \"UNDERWAY: MK3 data recording tag (Wildlife Computers) mounted on elephant seal\" ;\n" +
"\t\tTemperature:long_name = \"Temperature\" ;\n" +
"\t\tTemperature:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:units = \"degree_C\" ;\n" +
"\t\tTemperature:WODprofile_flag = 9 ;\n" +
"\tint Temperature_sigfigs(row) ;\n" +
"\tint Temperature_WODflag(row) ;\n" +
"\t\tTemperature_WODflag:flag_definitions = \"WODf\" ;\n" +
"\tchar WOD_cruise_identifier(row, WOD_cruise_identifier_strlen) ;\n" +
"\t\tWOD_cruise_identifier:comment = \"two byte country code + WOD cruise number (unique to country code)\" ;\n" +
"\t\tWOD_cruise_identifier:country = \"UNITED STATES\" ;\n" +
"\t\tWOD_cruise_identifier:long_name = \"WOD_cruise_identifier\" ;\n" +
"\tint wod_unique_cast(row) ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:axis = \"Y\" ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:standard_name = \"latitude\" ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:axis = \"X\" ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:standard_name = \"longitude\" ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:axis = \"T\" ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:units = \"days since 1770-01-01 00:00:00\" ;\n" +
"\tint date(row) ;\n" +
"\t\tdate:comment = \"YYYYMMDD\" ;\n" +
"\t\tdate:long_name = \"date\" ;\n" +
"\tfloat GMT_time(row) ;\n" +
"\t\tGMT_time:long_name = \"GMT_time\" ;\n" +
"\tint Access_no(row) ;\n" +
"\t\tAccess_no:comment = \"used to find original data at NODC\" ;\n" +
"\t\tAccess_no:long_name = \"NODC_accession_number\" ;\n" +
"\t\tAccess_no:units = \"NODC_code\" ;\n" +
"\tchar Project(row, Project_strlen) ;\n" +
"\t\tProject:comment = \"name or acronym of project under which data were measured\" ;\n" +
"\t\tProject:long_name = \"Project_name\" ;\n" +
"\tchar dataset(row, dataset_strlen) ;\n" +
"\t\tdataset:long_name = \"WOD_dataset\" ;\n" +
"\tfloat ARGOS_last_fix(row) ;\n" +
"\t\tARGOS_last_fix:units = \"hours\" ;\n" +
"\tfloat ARGOS_next_fix(row) ;\n" +
"\t\tARGOS_next_fix:units = \"hours\" ;\n" +
"\tint crs(row) ;\n" +
"\t\tcrs:epsg_code = \"EPSG:4326\" ;\n" +
"\t\tcrs:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\tcrs:inverse_flattening = 298.25723f ;\n" +
"\t\tcrs:longitude_of_prime_meridian = 0.0f ;\n" +
"\t\tcrs:semi_major_axis = 6378137.0f ;\n" +
"\tint profile(row) ;\n" +
"\tint WODf(row) ;\n" +
"\t\tWODf:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tWODf:flag_values = \"0 1 2 3 4 5 6 7 8 9\" ;\n" +
"\t\tWODf:long_name = \"WOD_observation_flag\" ;\n" +
"\tint WODfp(row) ;\n" +
"\t\tWODfp:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tWODfp:flag_values = \"0 1 2 3 4 5 6 7 8 9\" ;\n" +
"\t\tWODfp:long_name = \"WOD_profile_flag\" ;\n" +
"\tint WODfd(row) ;\n" +
"\t\tWODfd:flag_meanings = \"accepted duplicate_or_inversion density_inversion\" ;\n" +
"\t\tWODfd:flag_values = \"0 1 2\" ;\n" +
"\t\tWODfd:long_name = \"WOD_depth_level_\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cf_role = \"profile_id\" ;\n" +
"\t\t:Conventions = \"CF-1.5\" ;\n" +
"\t\t:featureType = \"profile\" ;\n" +
"\t\t:grid_mapping_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:grid_mapping_inverse_flattening = 298.25723f ;\n" +
"\t\t:grid_mapping_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:grid_mapping_semi_major_axis = 6378137.0f ;\n" +
"\t\t:Metadata_Conventions = \"Unidata Dataset Discovery v1.0\" ;\n" +
"\t\t:standard_name_vocabulary = \"CF-1.5\" ;\n" +
"}\n" +
"z,Temperature,Temperature_sigfigs,Temperature_WODflag,WOD_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Project,dataset,ARGOS_last_fix,ARGOS_next_fix,crs,profile,WODf,WODfp,WODfd\n" +
"0.0,7.9,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"10.0,7.9,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"42.0,7.8,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"76.0,7.8,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"120.0,7.8,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"166.0,7.5,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"212.0,7.0,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"260.0,6.5,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"308.0,5.8,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"354.0,5.2,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n" +
"402.0,4.9,2,0,US025547,8015632,45.28,-142.24,83369.90625,19980403,21.81665,573,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES),animal mounted,4.836731,14.149658,-2147483647,-2147483647,-2147483647,-2147483647,-2147483647\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test specify 0D and 1D data vars (out-of-order, implied axis var, and nonsense var), !getMetadata
        table.readNDNc(fiName, new String[]{
            "lon", "lat", "time", "Temperature", "WOD_cruise_identifier", "junk"}, 0,  //standardizeWhat=0
             "z", 100, 200);
        results = table.dataToString();
        expected = 
"z,Temperature,WOD_cruise_identifier,lat,lon,time\n" +
"120.0,7.8,US025547,45.28,-142.24,83369.90625\n" +
"166.0,7.5,US025547,45.28,-142.24,83369.90625\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //request axis vars only, with constraints
        table.readNDNc(fiName, new String[]{"z"}, 0,  //standardizeWhat=0
            "z", 100, 200);
        results = table.dataToString();
        expected = 
"z\n" +
"120.0\n" +
"166.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        
        //request 0D vars only, with constraints (ignored)
        table.readNDNc(fiName, new String[]{
            "WOD_cruise_identifier", "Project", "junk", "lon", "lat"}, 0,  //standardizeWhat=0
            "z", 100, 200);
        results = table.dataToString();
        expected = 
"WOD_cruise_identifier,lat,lon,Project\n" +
"US025547,45.28,-142.24,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES)\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        
        //request axis var and 0D vars only, with constraints
        table.readNDNc(fiName, new String[]{
            "WOD_cruise_identifier", "Project", "z", "junk", "lon", "lat"}, 0,  //standardizeWhat=0
            "z", 100, 200);
        results = table.dataToString();
        expected = 
"z,WOD_cruise_identifier,lat,lon,Project\n" +
"120.0,US025547,45.28,-142.24,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES)\n" +
"166.0,US025547,45.28,-142.24,AUTONOMOUS PINNIPED ENVIRONMENTAL SAMPLERS (APES)\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        
    }

    /** Used by readNcCF */
    private int checkConsistent(String errorInMethod, String varName,
        int oldValue, int newValue) {
        if (oldValue >= 0 && oldValue != newValue)
            throw new SimpleException(errorInMethod + 
                "The dimensions of variable=" + varName + 
                " are inconsistent with previous variables.");
        return newValue;
    }

    /**
     * This reads and flattens all specified variables from a .nc CF DSG file into a table.
     * <br>This does not unpack the values or convert to standardMissingValues.
     * 
     * @param fullName The full name of a local file.
     * @param loadVariableNames if null or length 0, all vars are read.
     *    <br>Any specified name must be the fullName, e.g., group1/var1
     *    <br>!!!!! conNames MUST be included in loadVariableNames.
     *     This code is written to handle them if not included, but the number of tests
     *     to verify is astronomical.
     *     !!!!! If loadVariableNames lists var names, then an error will be thrown
     *        if a conName isn't in loadVariableNames. Thankfully, ERDDAP specified loadVariableNames.
     *     !!!!! But if loadVariableNames aren't listed, THIS METHOD DOESN'T CHECK!
     *    <br>The results will only include loadVariableNames columns, in the specified order.
     *    <br>If a loadVariableName var isn't in the file, 
     *       there won't be a column in the results file for it.
     *    <br>Don't include the indexVar or rowSizeVar in loadVariableNames.
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat
     * @param conNames  the source names for the e.g., profile_id, lon, lat, time variables that
     *     will be constrained.   (Or null or size()==0 if no constraints.)
     * @param conOps  The corresponding operators.
     *     Remember that regex constraints will be tested on the source values!
     * @param conValues  The corresponding values.
     * @throws Exception if trouble.
     *    No matching data is not an error and returns an empty table (0 rows and 0 columns).
     */
    public void readNcCF(String fullName, StringArray loadVariableNames, 
        int standardizeWhat,
        StringArray conNames, StringArray conOps, StringArray conValues) throws Exception {
        //FUTURE optimization: instead of reading all of 1D obs variables,
        //find first and last set bit in obsKeep, just read a range of values,
        //then apply obsKeep.

        if (loadVariableNames == null) 
            loadVariableNames = new StringArray();
        if (conNames == null) 
            conNames = new StringArray();
        String msg = "  Table.readNcCF " + fullName;
        if (debugMode)
            msg += "  loadVars: " + loadVariableNames.toString(); 
        //String2.log("DEBUG:\n" + NcHelper.ncdump(fullName, "-h"));
        long time = System.currentTimeMillis();
        String errorInMethod = String2.ERROR + " in Table.readNcCF " + fullName + ":\n";
        int nCon = conNames.size();
        if (nCon > 0) {
            if (conOps    == null || conOps.size()    != nCon ||
                conValues == null || conValues.size() != nCon)
                throw new SimpleException(errorInMethod + 
                    "constraints parameters have different sizes: " +
                    "conNames=("  + conNames + "), " +
                    "conOps=("    + conOps + "), " +
                    "conValues=(" + conValues + ").");
            if (debugMode)
                msg += "  Debug: " + nCon + " constraints: " + conNames + " " + conOps + " " + conValues + "\n";
        } else {
            if (debugMode)
                msg += "  Debug: 0 constraints\n";
        }
        if (ncCFcc != null) ncCFcc.set(0);
       

        //clear the table
        clear();

        //if loadVariableNames was specified, 
        if (loadVariableNames.size() > 0) {
            //ENSURE all conNames are in loadVariableNames
            HashSet loadVarHS = loadVariableNames.toHashSet();
            for (int c = 0; c < conNames.size(); c++) {
                if (!loadVarHS.contains(conNames.get(c)))
                    throw new RuntimeException(errorInMethod +
                        "All constraint varNames must be in loadVariableNames. \"" + 
                        conNames.get(c) + "\" isn't in " + loadVariableNames.toString() + ".");
            }
        }

        NetcdfFile ncFile = NcHelper.openFile(fullName); 
        Attributes gridMappingAtts = null;
        String readAs = null;
        try {
            /* 
            //2012-07 CURRENTLY THE NETCDF-JAVA featureDataset APPROACH ISN'T WORKING. 
            //I EMAILED JOHN CARON.
            //Approach: Rely on netcdf-java FeatureDataset to "understand", read, 
            //and flatten the data.               
            ncDataset = new NetcdfDataset(ncFile, false);  //enhance 
            Formatter formatter = new Formatter();
            PointDatasetStandardFactory pdsFactory = new PointDatasetStandardFactory();
            Object analyser = pdsFactory.isMine(
                FeatureType.ANY_POINT, ncDataset, formatter); //throws IOException if trouble
            fDataset = pdsFactory.open(FeatureType.ANY_POINT, ncDataset, analyser, null, formatter);
            //...

            //I do care if this throws exception
            fDataset.close(); 
            */

            //My approach: low level.  I parse and analyze the files.

            //Get featureType from globalAttributes.   
            //Match it to values in CF standard table 9.1.
            NcHelper.getGlobalAttributes(ncFile, globalAttributes());
            String featureType = globalAttributes().getString("featureType");
            if (featureType == null) //cdm allows these aliases
                featureType = globalAttributes().getString("CF:featureType");
            if (featureType == null)
                featureType = globalAttributes().getString("CF:feature_type");
            featureType = featureType == null? "null" : featureType.toLowerCase(); //case insensitive
            boolean pointType = featureType.equals("point");
            boolean profileType = featureType.equals("profile");
            boolean timeSeriesType = featureType.equals("timeseries");
            boolean trajectoryType = featureType.equals("trajectory");
            boolean timeSeriesProfileType = featureType.equals("timeseriesprofile");
            boolean trajectoryProfileType = featureType.equals("trajectoryprofile");
            int nLevels = 
                pointType? 0 :
                profileType || timeSeriesType || trajectoryType? 1 :
                timeSeriesProfileType || trajectoryProfileType? 2:
                -1;
            if (nLevels == -1)
                throw new SimpleException(errorInMethod + 
                    "featureType=" + featureType + " isn't a valid CF featureType." +
                String2.annotatedString(featureType));

            //make ERDDAP-preferred capitalization, e.g., cdm_data_type = TimeSeriesProfile 
            String cdmName = Character.toUpperCase(featureType.charAt(0)) + featureType.substring(1);
            cdmName = String2.replaceAll(cdmName, "series",  "Series");
            cdmName = String2.replaceAll(cdmName, "profile", "Profile");
            globalAttributes.set("cdm_data_type", cdmName);

            //make ERDDAP-style cdm_..._variables 
            String cdmOuterName = "cdm_" + 
                (timeSeriesProfileType || trajectoryProfileType?
                    featureType.substring(0, featureType.length() - 7) : featureType) +
                "_variables";
            String cdmInnerName = timeSeriesProfileType || trajectoryProfileType?
                "cdm_profile_variables" : null;

            //deal with pointType
            if (pointType) {
                if (ncCFcc != null) ncCFcc.set(1);
                ncFile.close();
                ncFile = null;
                if (debugMode) msg += "PointType.  loadVars=" + loadVariableNames + "\n";
                StringArray loadCon = new StringArray(loadVariableNames);
                if (loadCon.size() > 0) //if loadVars specified, then add conNames
                    loadCon.append(conNames);
                //readNDNc always includes scalar vars
                readNDNc(fullName, (loadCon.toHashSet()).toArray(new String[0]), 
                    0,  //standardizeWhat=0
                    null, 0, 0);

                //finish up
                tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
                if (nRows() == 0)
                    removeAllColumns();
                else if (loadVariableNames.size() > 0)
                    reorderColumns(loadVariableNames, true); //discard others
                if (reallyVerbose) msg += " finished (nLevels=0, pointType)." +
                    " nRows=" + nRows() + " nCols=" + nColumns() + 
                    " time=" + (System.currentTimeMillis() - time) + "ms";
                if (debugMode) ensureValid();
                decodeCharsAndStrings();
                convertToUnsignedPAs();
                return;
            }

            //if loadVariableNames was specified, 
            if (loadVariableNames.size() > 0) {
                //remove any vars not in this file
                BitSet keepV = new BitSet();
                for (int v = 0; v < loadVariableNames.size(); v++) 
                    keepV.set(v, ncFile.findVariable(loadVariableNames.get(v)) != null);
                if (keepV.cardinality() == 0) {
                    msg += "\nNone of the loadVariableNames are in this file: " + 
                        loadVariableNames.toString() + ".";
                    return; //return an empty table
                }
                loadVariableNames.justKeep(keepV);
            }

            //find all dimensions
            List dimsList = ncFile.getDimensions();
            int nDims = dimsList.size();
            String dimNames[] = new String[nDims];
            for (int d = 0; d < nDims; d++) {
                dimNames[d] = ((Dimension)dimsList.get(d)).getFullName(); //may be null
                if (dimNames[d] == null)
                    dimNames[d] = "";
            } 
            //outerDim and obsDim are always used.  innerDim only used for nLevels=2
            int outerDim = -1, innerDim = -1, obsDim = -1; 

            //find out about all vars
            List varsList = ncFile.getVariables(); //all vars in all groups
            int nVars = varsList.size();
            Variable vars[] = new Variable[nVars];
            String varNames[] = new String[nVars];
            boolean varInLoadOrConVariables[] = new boolean[nVars];
            boolean varIsChar[] = new boolean[nVars];
            int varNDims[] = new int[nVars];  //not counting nchars dimension
            boolean varUsesDim[][] = new boolean[nVars][nDims + 1];  //all are false  (+1 for scalarDim)
            //pseudo dimension for scalar variables (used in level 2 ragged files if indexVar is missing)
            int scalarDim = nDims;  
            boolean hasScalarVars = false;
            Attributes varAtts[] = new Attributes[nVars];
            int rowSizeVar = -1; //e.g., in level 1 contiguous and level 2 ragged files
            boolean rowSizeVarIsRequired = false; //is current rowSizeVar required for a loadVar?
            int indexVar   = -1; //e.g., in level 1 indexed and most level 2 ragged files
            boolean loadVariableNamesWasEmpty = loadVariableNames.size() == 0;
            int nLoadOrConVariablesInFile = 0;
            String firstSampleDimName = null;
            //if (debugMode) String2.log("Debug: nVars=" + nVars);
            for (int v = 0; v < nVars; v++) {
                if (ncCFcc != null) ncCFcc.set(2);
                vars[v] = (Variable)varsList.get(v);                
                varNames[v] = vars[v].getFullName();
                varIsChar[v] = vars[v].getDataType() == DataType.CHAR;
                int rank = vars[v].getRank();
                varNDims[v] = rank - (varIsChar[v]? 1 : 0);
                varAtts[v] = new Attributes();
                NcHelper.getVariableAttributes(vars[v], varAtts[v]);
                //String2.log("Debug: loadVarNames.see v[" + v + "]=" + varNames[v] + "  nNonCharDims=" + varNDims[v]);
                //2016-06-07 scalar continue was here

                //does this var point to the pseudo-data var with CF grid_mapping (projection) information?
                if (gridMappingAtts == null) {
                    gridMappingAtts = NcHelper.getGridMappingAtts(ncFile, 
                        varAtts[v].getString("grid_mapping"));
                    if (gridMappingAtts != null)
                        globalAttributes.add(gridMappingAtts);
                }

                //add to nLoadOrConVariablesInFile
                //!!!Note that I don't detect vars with unexpected dimensions
                //partly because file type isn't known at this point.
                //But var dimensions are always checked when the var is read,
                //so other vars will simply be skipped. (Better if warning/error.)
                if (loadVariableNamesWasEmpty) {
                    //String2.log("Debug: loadVarNames.add v[" + v + "]=" + varNames[v]);
                    loadVariableNames.add(varNames[v]);
                    varInLoadOrConVariables[v] = true;
                } else {
                    varInLoadOrConVariables[v] = 
                        loadVariableNames.indexOf(varNames[v]) >= 0 ||
                        conNames.indexOf(varNames[v]) >= 0;
                }
                if (varInLoadOrConVariables[v]) 
                    nLoadOrConVariablesInFile++;

                //scalars  
                if (varNDims[v] <= 0) {
                    if (ncCFcc != null) ncCFcc.set(3);
                    hasScalarVars = true;
                    varNDims[v] = 1;
                    varUsesDim[v][scalarDim] = true;
                    continue;
                }

                //go through the dimensions
                for (int d = 0; d < varNDims[v]; d++) {
                    if (ncCFcc != null) ncCFcc.set(4);
                    int whichDim = dimsList.indexOf(vars[v].getDimension(d));
                    if (whichDim >= 0) {//a shared dim
                        if (ncCFcc != null) ncCFcc.set(12);
                        varUsesDim[v][whichDim] = true;
                    }

                    //detect multiDim dimensions
                    if (nLevels == 1 && varNDims[v] == 2) {
                        if (ncCFcc != null) ncCFcc.set(10);
                        if (d == 0) {
                            if (ncCFcc != null) ncCFcc.set(5);
                            outerDim = checkConsistent(errorInMethod, varNames[v], outerDim, whichDim);
                        }
                        if (d == 1) {
                            if (ncCFcc != null) ncCFcc.set(6);
                            obsDim   = checkConsistent(errorInMethod, varNames[v], obsDim,   whichDim);
                        }
                    } else if (nLevels == 2 && varNDims[v] == 3) {
                        if (ncCFcc != null) ncCFcc.set(11);
                        if (d == 0) {
                            if (ncCFcc != null) ncCFcc.set(7);
                            outerDim = checkConsistent(errorInMethod, varNames[v], outerDim, whichDim);
                        }
                        if (d == 1) {
                            if (ncCFcc != null) ncCFcc.set(8);
                            innerDim = checkConsistent(errorInMethod, varNames[v], innerDim, whichDim);
                        }
                        if (d == 2) {
                            if (ncCFcc != null) ncCFcc.set(9);
                            obsDim   = checkConsistent(errorInMethod, varNames[v], obsDim,   whichDim);
                        }
                    }
                }

                //isContiguous? look for rowSizeVar with sample_dimension attribute
                //If file has multiple sample_dimension's, 
                //  use the one used by the loadVars (if specified), 
                //  else use the first one found (and skip the others).
                //  See testReadNcCF7SampleDims()
                String sd = varAtts[v].getString("sample_dimension");
                //if (firstSampleDimName == null)
                //    firstSampleDimName = sd;

                //determine if this particular sample_dimension isRequired for a loadVar
                boolean isRequired = false;
                if (sd != null && 
                    !loadVariableNamesWasEmpty) { //loadVars was specified
                    //if already have one, don't keepGoing/ skip this one
                    if (debugMode) msg += "\nDebug:          sample_dimension=" + sd;
                    //is this sample_dimension used (and thus, required) by any of the loadVars?
                    for (int lvi = 0; lvi < loadVariableNames.size(); lvi++) {
                        Variable var = ncFile.findVariable(loadVariableNames.get(lvi)); //won't be null
                        if (var.getRank() > 0 && sd.equals(var.getDimension(0).getFullName())) {
                            if (debugMode) msg += "\nDebug: sample_dimension=" + 
                                sd + " isRequired by loadVar=" + loadVariableNames.get(lvi);
                            isRequired = true;
                            break; //lvi
                        }
                    }
                }

                if (rowSizeVarIsRequired && isRequired) {
                    //2 different sample_dimensions are required by loadVariableNames!
                    throw new SimpleException(errorInMethod + 
                        "Invalid request: loadVariables includes variables " +
                        "that use two different sample_dimension's (" + 
                        (obsDim >= 0? dimNames[obsDim] : "null") +  //null shouldn't happen
                        " and " + sd + ").");
                } else if (sd != null && !isRequired && rowSizeVar >= 0) {
                    //skip this sample_dimension
                    if (debugMode) msg += "\nDebug: skipping sample_dimension=" + sd;
                    sd = null;
                    
                } else if (sd != null && (isRequired || rowSizeVar < 0)) { 
                    //keep this sample_dimension info  (If !isRequired, then may be temporary.)
                    if (debugMode) msg += "\nDebug:  keeping sample_dimension=" + sd;

                    if (ncCFcc != null) ncCFcc.set(13);
                    rowSizeVar = v;
                    rowSizeVarIsRequired = isRequired;
                    //this is an internal variable. Request can't include it or constrain it.
                    if (varInLoadOrConVariables[v]) {
                        varInLoadOrConVariables[v] = false;
                        nLoadOrConVariablesInFile--;
                        int i = loadVariableNames.indexOf(varNames[v]);
                        if (i >= 0)
                            loadVariableNames.remove(i);
                        i = conNames.indexOf(varNames[v]);
                        if (i >= 0) {
                            conNames.remove(i);
                            conOps.remove(i);
                            conValues.remove(i);
                        }
                    }

                    //sample_dimension
                    obsDim = String2.indexOf(dimNames, sd);
                    if (obsDim < 0)
                        throw new SimpleException(errorInMethod + 
                            "Invalid file: file says sample_dimension is " + sd + 
                            ", but there is no dimension with that name.");

                    //outerDim or innerDim
                    int whichDim = dimsList.indexOf(vars[v].getDimension(0));
                    if (whichDim < 0) 
                        throw new SimpleException(errorInMethod +
                            "variable=" + varNames[v] + "'s dimension #0 isn't a shared dimension.");
                    if (nLevels == 1) outerDim = whichDim;
                    else              innerDim = whichDim; //nLevels == 2
                }

                //isIndexed? look for indexVar with instance_dimension attribute
                String id = varAtts[v].getString("instance_dimension");
                if (id != null) {
                    if (indexVar >= 0)
                        throw new SimpleException(errorInMethod + 
                            "Invalid file: two variables (" + 
                            varNames[indexVar] + " and " + 
                            varNames[v] + ") have an instance_dimension attribute.");
                    //this is an internal variable in the file. Request can't request it or constrain it.
                    if (ncCFcc != null) ncCFcc.set(14);
                    indexVar = v;
                    if (varInLoadOrConVariables[v]) {
                        if (ncCFcc != null) ncCFcc.set(15);
                        varInLoadOrConVariables[v] = false;
                        nLoadOrConVariablesInFile--;
                        int i = loadVariableNames.indexOf(varNames[v]);
                        if (i >= 0)
                            loadVariableNames.remove(i);
                        i = conNames.indexOf(varNames[v]);
                        if (i >= 0) {
                            conNames.remove(i);
                            conOps.remove(i);
                            conValues.remove(i);
                        }
                    }

                    //intance_dimension
                    outerDim = String2.indexOf(dimNames, id);
                    if (outerDim < 0)
                        throw new SimpleException(errorInMethod + 
                            "Invalid file: file says instance_dimension is " + id + 
                            ", but there is no dimension with that name.");

                    //its dim 
                    int whichDim = dimsList.indexOf(vars[v].getDimension(0));
                    if (whichDim < 0) 
                        throw new SimpleException(errorInMethod +
                            "variable=" + varNames[v] + "'s dimension #0 isn't a shared dimension.");
                    if (nLevels == 1) obsDim   = whichDim;
                    else              innerDim = whichDim; //nLevels == 2
                }
            }

            if (debugMode && loadVariableNamesWasEmpty) 
                msg += "\n  Debug: #1 loadVars (was empty): " + loadVariableNames.toString();

            Dimension outerDimDim = outerDim < 0? null : (Dimension)dimsList.get(outerDim);     
            Dimension innerDimDim = innerDim < 0? null : (Dimension)dimsList.get(innerDim);
            Dimension obsDimDim   = obsDim   < 0? null : (Dimension)dimsList.get(obsDim);
            String outerDimName  = outerDim < 0? "" : outerDimDim.getFullName(); //may be null
            String innerDimName  = innerDim < 0? "" : innerDimDim.getFullName();
            String obsDimName    = obsDim   < 0? "" : obsDimDim.getFullName(); 
            String scalarDimName = "scalar"; 
            int outerDimSize  = outerDimDim == null? -1 : outerDimDim.getLength();
            int innerDimSize  = innerDimDim == null? -1 : innerDimDim.getLength();
            int obsDimSize    = obsDimDim   == null? -1 : obsDimDim.getLength();
            int scalarDimSize = 1;

            //if outerDim not found, try using scalarDim (scalar vars)
            if (outerDim == -1 && hasScalarVars) {
                if (ncCFcc != null) { //some things removed, so 3 flags are set
                    ncCFcc.set(16); 
                    ncCFcc.set(17);  
                    ncCFcc.set(18);
                }
                outerDim     = scalarDim;
                outerDimName = scalarDimName;
                outerDimSize = scalarDimSize;
            }

            //Deal with nLevels=1 or 2, outerDim=scalarDim: 
            //  find obsDim (and innerDim for nLevels=2)
            if (rowSizeVar < 0 && indexVar < 0 &&
                outerDim == scalarDim && innerDim < 0 && obsDim < 0) {

                //if nLevels=1, read via readNDNc
                if (ncCFcc != null) ncCFcc.set(19);
                if (nLevels == 1) {
                    if (debugMode) String2.log("  Debug: nLevels=1, outerDim=scalarDim, read via readNDNc");
                    if (ncCFcc != null) ncCFcc.set(20);
                    ncFile.close();
                    ncFile = null;
                    StringArray loadCon = new StringArray(loadVariableNames);
                    if (loadCon.size() > 0) //if loadVars specified, then add conNames
                        loadCon.append(conNames);
                    //readNDNc always includes scalar vars
                    readNDNc(fullName, (loadCon.toHashSet()).toArray(new String[0]), 
                        0,  //standardizeWhat=0
                        null, 0, 0);

                    //finish up
                    tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
                    if (nRows() == 0)
                        removeAllColumns();
                    else reorderColumns(loadVariableNames, true); //discard others
                    if (reallyVerbose) String2.log("  readNcCF finished (nLevels=1, readNDNc). " +
                        " fileName=" + fullName + 
                        " nRows=" + nRows() + " nCols=" + nColumns() + 
                        " time=" + (System.currentTimeMillis() - time) + "ms");
                    if (debugMode) ensureValid();
                    decodeCharsAndStrings();
                    convertToUnsignedPAs();
                    return;
                }

                //if nLevels == 2
                if (debugMode) String2.log("  Debug: nLevels=2, outerDim=scalarDim");
                for (int v = 0; v < nVars; v++) {
                    //first: go through the dimensions
                    if (ncCFcc != null) ncCFcc.set(21);
                    for (int d = 0; d < varNDims[v]; d++) {
                        if (ncCFcc != null) ncCFcc.set(22);
                        int whichDim = dimsList.indexOf(vars[v].getDimension(d));
                        if (whichDim >= 0) {  //not scalarDim
                            if (varNDims[v] == 2) { //var[innerDim][obsDim]
                                if (ncCFcc != null) ncCFcc.set(23);
                                if (d == 0) {
                                    if (ncCFcc != null) ncCFcc.set(24);
                                    innerDim = checkConsistent(errorInMethod, varNames[v], innerDim, whichDim);
                                }
                                if (d == 1) {
                                    if (ncCFcc != null) ncCFcc.set(25);
                                    obsDim   = checkConsistent(errorInMethod, varNames[v], obsDim,   whichDim);
                                }
                            }
                        }
                    }

                    //second: trick code below into adding outerDim=scalarDim to all vars
                    //  (scalar vars already have it)(vars using other dims don't)
                    if (!varUsesDim[v][scalarDim]) {
                        if (ncCFcc != null) ncCFcc.set(26);
                        varUsesDim[v][scalarDim] = true;
                        varNDims[v]++;
                    }
                }

                if (innerDim < 0 || outerDim < 0) 
                    throw new SimpleException(errorInMethod + 
                        "Invalid file: nLevels=2, outerDim=scalarDim, but can't find " +
                        "variable[innerDim][obsDim].  innerDim=" + innerDim + " obsDim=" + obsDim);
                obsDimDim     = (Dimension)dimsList.get(obsDim);
                obsDimName    = obsDimDim.getFullName(); 
                obsDimSize    = obsDimDim.getLength();
                innerDimDim   = (Dimension)dimsList.get(innerDim);
                innerDimName  = innerDimDim.getFullName();
                innerDimSize  = innerDimDim.getLength();

                //now that innerDim and outerDim are known, find 1D vars that use them
                if (loadVariableNamesWasEmpty) { 
                    if (debugMode) String2.log("  Debug: find 1D vars that use inner or outerDim");
                    for (int v = 0; v < nVars; v++) {
                        //first: go through the dimensions
                        if (varNDims[v] != 1)
                            continue;
                        int whichDim = dimsList.indexOf(vars[v].getDimension(0));
                        if (whichDim == innerDim ||
                            whichDim == outerDim) {  //not scalarDim
                            if (loadVariableNames.indexOf(varNames[v]) < 0) {
                                loadVariableNames.add(varNames[v]);
                                if (!varInLoadOrConVariables[v]) {
                                    varInLoadOrConVariables[v] = true;
                                    nLoadOrConVariablesInFile++;
                                }
                            }

                            //second: trick code below into adding outerDim=scalarDim to all vars
                            //  (scalar vars already have it)(vars using other dims don't)
                            if (!varUsesDim[v][scalarDim]) {
                                varUsesDim[v][scalarDim] = true;
                                varNDims[v]++;
                            }
                        }
                    }
                }
            }


            if (debugMode) {
                if (loadVariableNamesWasEmpty) 
                    String2.log("  Debug: #2 loadVars (was empty): " + loadVariableNames.toString());
                String2.log(
                    "  Debug: nTotalVarsInFile=" + nVars + 
                    " nLoadOrConVarsInFile=" + nLoadOrConVariablesInFile + 
                    " vars: rowSize=" + (rowSizeVar < 0? "" : varNames[rowSizeVar]) + 
                    " index="    + (indexVar   < 0? "" : varNames[indexVar]) + "\n" +
                    "    dims: outer=" + outerDimName + "[" + outerDimSize + "]" +
                    " inner=" + innerDimName + "[" + innerDimSize + "]" +
                    " obs=" + obsDimName + "[" + obsDimSize + "]");
            }
            if (ncCFcc != null) ncCFcc.set(27);
            if (nLoadOrConVariablesInFile == 0) {
                if (verbose) String2.log("  readNcCF fileName=" + fullName + ": " + MustBe.THERE_IS_NO_DATA + 
                    " (no requested vars in the file)" + 
                    " time=" + (System.currentTimeMillis() - time) + "ms");
                removeAllColumns();
                return;
            }

            //ensure file is valid
            String notFound = null;
            if (outerDim == -1)                      notFound = "outer";
            else if (nLevels == 2 && innerDim == -1) notFound = "inner";
            else if (obsDim == -1)                   notFound = "observation";
            if (notFound != null)
                throw new SimpleException(errorInMethod +
                    "Invalid file: Unable to find the " + notFound + " dimension.");
            if (nLevels == 1 && rowSizeVar >= 0 && indexVar >= 0) 
                throw new SimpleException(errorInMethod +
                    "Invalid file: the file should have a variable with instance_dimension " +
                    "or a variable with sample_dimension, not both.");
            boolean multidimensional = indexVar < 0 && rowSizeVar < 0;

            //If (constraintVar!="" or constraintVar=(non-Number)) and var not in file,
            //  we know there can be no matching data in this file.
            //I would like to also reject if constraintVar=(finiteNumber), but it is 
            //  complicated because mv's are usually represented as finite values.
            //  so a missing var might get converted to all -999.
            for (int con = 0; con < nCon; con++) {
                //if conName is in the file, can't quick reject, so continue;
                if (ncCFcc != null) ncCFcc.set(28);
                String tConName = conNames.get(con);
                int v = String2.indexOf(varNames, tConName);
                if (v >= 0) {
                    if (ncCFcc != null) ncCFcc.set(29);
                    continue;
                }

                //There is no way to tell if a var not in the file is String or numeric.
                String tConOp = conOps.get(con);
                String tConValue = conValues.get(con);
                boolean rejectFile = false;

                //test e.g.,  station!=""         (NaN would be NaN)
                if ("!=".equals(tConOp)) {
                    if ("".equals(tConValue)) 
                        rejectFile = true;

                //test e.g.,  station=WXUSP      (if numeric, hard to test)
                } else if ("=".equals(tConOp)) {
                    if (tConValue.length() > 0 && !String2.isNumber(tConValue)) 
                        rejectFile = true;
                }

                if (rejectFile) {
                    if (ncCFcc != null) ncCFcc.set(30);
                    if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                        " fileName=" + fullName + 
                        " (var not in file: " + tConName + tConOp + tConValue + ")" + 
                        " time=" + (System.currentTimeMillis() - time) + "ms");
                    removeAllColumns();
                    return;
                }
            }

            //*** read outerDim variables into a table: all nLevels, all featureTypes
            if (debugMode) String2.log("  Debug: read outerDim variables into a table: all nLevels, all featureTypes");
            Table outerTable = new Table(); 
            int nLoadOrConVariablesInOuterTable = 0;
            StringArray subsetVars = new StringArray();
            for (int v = 0; v < nVars; v++) {
                //normally, get just varInLoadOrConVariables vars
                //but if multidimensional, get ALL outerDim vars !!!
                //if (debugMode) String2.log("  Debug: read outerTable v=" + varNames[v] + 
                //    " inLoadOrConVars=" + varInLoadOrConVariables[v] +
                //    " varNDims[v]=" + varNDims[v] + 
                //    " varUsesDim[v][outerDim]=" + varUsesDim[v][outerDim]);
                if (ncCFcc != null) ncCFcc.set(31);
                if ((varInLoadOrConVariables[v] || multidimensional) && 
                    varNDims[v] == 1 && varUsesDim[v][outerDim]) { //ensure correct dim
                    if (ncCFcc != null) ncCFcc.set(32);
                    if (varInLoadOrConVariables[v]) {
                        if (ncCFcc != null) ncCFcc.set(33);
                        nLoadOrConVariablesInOuterTable++;
                        if (varAtts[v].get("instance_dimension") == null)
                            //don't include if dimension, since var isn't in results table
                            subsetVars.add(varNames[v]); //so in file's order; that's consistent; that's good
                    }
                    outerTable.addColumn(outerTable.nColumns(), varNames[v], 
                        NcHelper.getPrimitiveArray(vars[v]), varAtts[v]);
                    outerTable.standardizeLastColumn(standardizeWhat);
                }
            }

            //add scalar vars 2016-06-06
            int ttNRows = Math.max(1, outerTable.nRows());
            for (int v = 0; v < nVars; v++) {
                if (varNDims[v] == 1 && varUsesDim[v][scalarDim] && //scalars are stored with odd info
                    (loadVariableNamesWasEmpty || varInLoadOrConVariables[v]) &&
                    outerTable.findColumnNumber(varNames[v]) < 0) {  //not already in table
                    nLoadOrConVariablesInOuterTable++;
                    if (varAtts[v].get("instance_dimension") == null)
                        //don't include if dimension, since var isn't in results table
                        subsetVars.add(varNames[v]); //so in file's order; that's consistent; that's good
                    PrimitiveArray pa = NcHelper.getPrimitiveArray(vars[v]);
                    //make doubly sure it is 1 element
                    if (pa.size() == 0)
                        pa.addString("");
                    else pa.removeRange(1, pa.size());            
                    pa = varAtts[v].standardizeVariable(standardizeWhat, varNames[v], pa); //before duplicating the strings
                    //duplicate the scalar to nRows
                    pa.addNStrings(ttNRows - 1, pa.getString(0)); 
                    outerTable.addColumn(outerTable.nColumns(), varNames[v], pa, varAtts[v]);

                }
            }

            if (debugMode) String2.log("  Debug: outerTable(nRows=" + outerTable.nRows() + 
                ") nLoadOrConVariablesInOuterTable=" + nLoadOrConVariablesInOuterTable + 
                " First <=3 rows:\n" + outerTable.dataToString(3));
            globalAttributes.set(cdmOuterName,      subsetVars.toString()); //may be "", that's okay
            if (cdmInnerName != null)
                globalAttributes.set(cdmInnerName,  "");  //nLevel=2 will set it properly below
            globalAttributes.set("subsetVariables", subsetVars.toString()); //nLevel=2 will set it properly below

            //apply constraints  (if there is data)
            BitSet outerKeep = null; //implies outerTable.nColumns = 0, so assume all are good
            int outerNGood = -1; //implies not tested, so assume all are good
            if (outerTable.nColumns() > 0) { //it will be for multidimensional

                if (ncCFcc != null) ncCFcc.set(34);
                if (multidimensional) {
                    if (ncCFcc != null) ncCFcc.set(35);
                    outerKeep = outerTable.rowsWithData();
                } else {
                    if (ncCFcc != null) ncCFcc.set(36);
                    outerKeep = new BitSet();
                    outerKeep.set(0, outerTable.nRows());
                }

                //apply user constraints
                outerNGood = outerTable.tryToApplyConstraints(-1, 
                    conNames, conOps, conValues, outerKeep);
                if (outerNGood == 0) {
                    if (ncCFcc != null) ncCFcc.set(37);
                    if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                        " fileName=" + fullName + " (outerNGood=0)" + 
                        " time=" + (System.currentTimeMillis() - time) + "ms");
                    removeAllColumns();
                    return;
                }
                //order of rows is important, so *don't* justKeep(outerKeep)

                //Are we done? Are those all the variables we need that are in the file?
                if (debugMode) String2.log("Debug: nLoadOrCon inFile=" + nLoadOrConVariablesInFile +
                    " inOuterTable=" + nLoadOrConVariablesInOuterTable);
                if (nLoadOrConVariablesInFile == nLoadOrConVariablesInOuterTable) {
                    outerTable.justKeep(outerKeep);
                    //globalAttributes already set
                    //copy outerTable to this table
                    if (ncCFcc != null) ncCFcc.set(38);
                    int noc = outerTable.nColumns();
                    for (int c = 0; c < noc; c++) 
                        addColumn(c, outerTable.getColumnName(c), 
                            outerTable.getColumn(c), outerTable.columnAttributes(c));

                    //finish up
                    tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
                    if (nRows() == 0)
                        removeAllColumns();
                    else reorderColumns(loadVariableNames, true); //discard others
                    if (reallyVerbose) String2.log("  readNcCF finished (nLevels=1, outerTable vars only)." +
                        " fileName=" + fullName + 
                        " nRows=" + nRows() + " nCols=" + nColumns() + 
                        " time=" + (System.currentTimeMillis() - time) + "ms");
                    if (debugMode) ensureValid();
                    decodeCharsAndStrings();
                    convertToUnsignedPAs();
                    return;
                }
            } //else if no outerTable columns, all outerTable features are considered good
            int outerTableNColumns = outerTable.nColumns();
            int outerTableNRows = outerTable.nRows();

            if (debugMode)
                String2.log(
                    "  Debug: outerTable has nCols=" + outerTableNColumns + 
                    " nRows=" + outerTableNRows + " nKeepRows=" + outerNGood + 
                    (outerTableNRows == 0? "" : 
                        "\n" + outerTable.dataToString(5))); 


            //*** read nLevels=1 obs data
            if (nLevels == 1) {
                if (debugMode) String2.log("  Debug: read nLevels=1 obs data");

                //request is for obs vars only (not feature data), so read all of the data 
                if (ncCFcc != null) ncCFcc.set(39);
                if (outerTableNColumns == 0 && !multidimensional) { //and so outerKeep=null
                    if (debugMode) String2.log("  Debug: obs vars only (not feature data), so read all of the data");
                    readAs = "obs vars only";
                    if (ncCFcc != null) ncCFcc.set(40);
                    for (int v = 0; v < nVars; v++) {       
                        if (varInLoadOrConVariables[v]) {
                            if (ncCFcc != null) ncCFcc.set(41);
                            int dim0 = dimsList.indexOf(vars[v].getDimension(0));
                            if (dim0 == obsDim) {   //ensure correct dim.  obsDim can't be scalardim
                                PrimitiveArray pa = NcHelper.getPrimitiveArray(vars[v]);
                                addColumn(nColumns(), varNames[v], pa, varAtts[v]);
                                standardizeLastColumn(standardizeWhat);
                            } else {
                                if (verbose) 
                                    String2.log("  !!! nLevels=1 readAs=" + readAs + 
                                        ": Unexpected dimension for " + varNames[v]);
                            }                               
                        }
                    }

                //read nLevels=1 indexed, contiguous, multi-dimensional obs variables
                } else {

                    //nLevels=1 indexed ragged array
                    if (ncCFcc != null) ncCFcc.set(42);
                    if (indexVar >= 0) {
                        if (debugMode) String2.log("  Debug: read nLevels=1 indexed ragged");
                        readAs = "indexed ragged";
                        if (ncCFcc != null) ncCFcc.set(43);

                        //insert the indexVar (which is the keyColumn) at col=0
                        PrimitiveArray indexVarPA = NcHelper.getPrimitiveArray(vars[indexVar]);               
                        addColumn(0, varNames[indexVar], indexVarPA, varAtts[indexVar]);
                        standardizeColumn(standardizeWhat, 0);
                        int indexMV = varAtts[indexVar].getInt("missing_value"); //MAX_VALUE if not defined
                        int indexFV = varAtts[indexVar].getInt("_FillValue");    //MAX_VALUE if not defined

                        //make obsKeep
                        //obsKeep Approach: indexVar makes this the only reasonable approach.
                        int tnRows = indexVarPA.size();
                        BitSet obsKeep = new BitSet(tnRows);  //all are false
                        for (int row = 0; row < tnRows; row++) {
                            //Index should be 0..n-1.
                            //Files with index 1..n shouldn't be a silent failure,
                            //since all index 1..n-1 will be used INCORRECTLY and 
                            //thus return incorrect results.
                            //So check for this
                            int index = indexVarPA.getInt(row);
                            if (index >= 0 && index < outerTableNRows) {
                                if (outerKeep.get(index)) //outerKeep=null handled above
                                    obsKeep.set(row);
                            } else if (index == indexMV || index == indexFV) {
                                //that's the right way to reserve space
                            } else {
                                throw new SimpleException(errorInMethod + 
                                    "Invalid file: The index values must be 0 - " + 
                                    (outerTableNRows - 1) + ", but " + 
                                    varNames[indexVar] + "[" + row + "]=" + index + ".");
                            }
                        }

                        indexVarPA.justKeep(obsKeep);
                        indexVarPA.trimToSize();
                        if (debugMode) String2.log("  Debug: nObsRows=" + tnRows + " nObsKeep=" + indexVarPA.size());

                        //read all of requested variable[obs]
                        //With indexed, we have to read entire var then apply obsKeep.
                        for (int v = 0; v < nVars; v++) {       
                            if (varInLoadOrConVariables[v] &&
                                varNDims[v] == 1 && varUsesDim[v][obsDim]) {  //ensure correct dim
                                PrimitiveArray pa = NcHelper.getPrimitiveArray(vars[v]);
                                pa.justKeep(obsKeep); //as each var read in, to save memory
                                pa.trimToSize();
                                addColumn(nColumns(), varNames[v], pa, varAtts[v]);
                                standardizeLastColumn(standardizeWhat);
                            }
                        }

                    //nLevels=1 contiguous ragged array     //read data for keep=true features
                    } else if (rowSizeVar >= 0) {
                        if (debugMode) String2.log("  Debug: nLevels=1 contiguous ragged array"); 
                        readAs = "contiguous ragged";
                        if (ncCFcc != null) ncCFcc.set(44);

                        //read the rowSizesPA
                        PrimitiveArray rowSizesPA = NcHelper.getPrimitiveArray(vars[rowSizeVar]);
                        //it's row sizes, so no need to unpack
                        int rowSizesMV = varAtts[rowSizeVar].getInt("missing_value");
                        int rowSizesFV = varAtts[rowSizeVar].getInt("_FillValue");
                        boolean hasMVFV = rowSizesMV != Integer.MAX_VALUE || 
                                          rowSizesFV != Integer.MAX_VALUE;

                        //make keyColumn (with row#'s in outerTable) and obsKeep
                        //obsKeep Approach: optimize for situation that takes longest 
                        //  (outerKeep all true).  This is also a very simple approach.
                        //This table is currently empty.
                        IntArray keyColumnPA = new IntArray();
                        addColumn(0, "keyColumn", keyColumnPA, new Attributes());
                        int startRow, endRow = 0; //endRow is exclusive
                        BitSet obsKeep = new BitSet(obsDimSize);  //all are false
                        String firstRowWithMVFV = null; //Missing Value or Fill Value
                        boolean warningWritten = false;
                        for (int outerRow = 0; outerRow < outerTableNRows; outerRow++) {
                            startRow = endRow;
                            int getNRows = rowSizesPA.getInt(outerRow);
                            if (hasMVFV) {
                                if (getNRows == rowSizesMV) {
                                    //They should be 0's. Treat as 0.
                                    if (firstRowWithMVFV == null) 
                                        firstRowWithMVFV = 
                                            "The rowSizes variable (" + varNames[rowSizeVar] + 
                                            ") has a missing_value [" + outerRow + "]=" + rowSizesMV;
                                    continue;
                                } else if (getNRows == rowSizesFV) {
                                    //They should be 0's. Treat as 0.
                                    if (firstRowWithMVFV == null) 
                                        firstRowWithMVFV = 
                                            "The rowSizes variable (" + varNames[rowSizeVar] + 
                                            ") has a _FillValue [" + outerRow + "]=" + rowSizesFV;
                                    continue;
                                } else if (firstRowWithMVFV != null) { 
                                    //mvfv already observed and this value isn't an mv or fv!
                                    //So the previous mvfv wasn't at the end!                                   
                                    if (!warningWritten) {
                                        String2.log("WARNING for contiguous ragged .nc CF file: " +
                                            firstRowWithMVFV +
                                            " and then a valid value [" + outerRow + "]=" + getNRows + 
                                            "!  ERDDAP interprets missing_values and _FillValues as 0, " +
                                            "which is what the file should have, not missing_values or _FillValues!");
                                        warningWritten = true;
                                    }
                                }
                            }
                            endRow += getNRows;
                            if (outerKeep.get(outerRow)) { //outerKeep=null handled above
                                keyColumnPA.addNInts(getNRows, outerRow); //so obsKeep already applied
                                obsKeep.set(startRow, endRow);
                            }
                        }
                        if (endRow < obsDimSize) {
                            String2.log( 
                                "WARNING for contiguous ragged file: " +
                                "The sum of the values in the rowSizes variable (" + 
                                varNames[rowSizeVar] + " sum=" + endRow + 
                                ") is less than the size of the observationDimension (" + 
                                obsDimName + " size=" + obsDimSize + ").\n" +
                                "I hope that is just unused extra space for future observations!");
                        } else if (endRow > obsDimSize) {
                            throw new SimpleException(errorInMethod + 
                                "Invalid contiguous ragged file: The sum of the values in the rowSizes variable (" + 
                                varNames[rowSizeVar] + " sum=" + endRow + 
                                ") is greater than the size of the observationDimension (" + 
                                obsDimName + " size=" + obsDimSize + ").");
                        }

                        //read the keep rows of requested variable[obs]
                        for (int v = 0; v < nVars; v++) {       
                            //String2.log("var[" + v + "]=" + varNames[v] + " ndim=" + varNDims[v] + " usesObsDim=" + varUsesDim[v][obsDim]);
                            if (varInLoadOrConVariables[v] &&
                                varNDims[v] == 1 && varUsesDim[v][obsDim]) {  //ensure correct dim
                                PrimitiveArray pa = NcHelper.getPrimitiveArray(vars[v]);
                                pa.justKeep(obsKeep); //as each var read in, to save memory
                                pa.trimToSize();
                                addColumn(nColumns(), varNames[v], pa, varAtts[v]);
                                standardizeLastColumn(standardizeWhat);
                            }
                        }
                        if (debugMode) {
                            String2.log("  Debug: keyColumnPA.size=" + keyColumnPA.size() + 
                                " obsKeep.cardinality=" + obsKeep.cardinality());
                            ensureValid();
                        }

                    //nLevels=1 multidimensional       //read data for keep=true features
                    } else {
                        if (debugMode) String2.log("  Debug: nLevels=1 multidimensional");
                        readAs = "multidim";
                        if (ncCFcc != null) ncCFcc.set(45);

                        //see unitTestDataDir/CFPointConventions/timeSeries/
                        //    timeSeries-Orthogonal-Multidimenstional-MultipleStations-H.2.1
                        //  which has outer=time[time],  
                        //    inner=lat,lon,alt,stationName[station], and
                        //    temperature[time][station]
                        Table innerTable = new Table();
                        int nLoadOrConVariablesInInnerTable = 0;
                        StringArray cdmInnerVars = new StringArray();
                        for (int v = 0; v < nVars; v++) {
                            //multidim: load all variable[obs]
                            if (varNDims[v] == 1 && varUsesDim[v][obsDim]) { //ensure correct dim
                                if (varInLoadOrConVariables[v]) {
                                    nLoadOrConVariablesInInnerTable++;
                                    cdmInnerVars.add(varNames[v]); //so in file's order; that's consistent; that's good
                                }
                                innerTable.addColumn(innerTable.nColumns(), varNames[v], 
                                    NcHelper.getPrimitiveArray(vars[v]), varAtts[v]);
                                innerTable.standardizeLastColumn(standardizeWhat);
                            }
                        }
                        int innerTableNColumns = innerTable.nColumns();
                        int innerTableNRows    = innerTable.nRows();               
                        BitSet innerKeep = null; //if null, assume all innerKeep are true
                        if (debugMode) String2.log("  Debug: innerTable nLoadOrConVarsInInnerTable=" + 
                            nLoadOrConVariablesInInnerTable + 
                            " nCols=" + innerTableNColumns + 
                            " (" + innerTable.getColumnNamesCSVString() + 
                            ") nRows=" + innerTableNRows);
                        if (innerTableNColumns > 0) {
                            if (ncCFcc != null) ncCFcc.set(46);

                            //apply constraints to innerTable  (but keep all innerTable rows)
                            innerKeep = innerTable.rowsWithData(); 
                            int innerNGood = innerTable.tryToApplyConstraints(-1, 
                                conNames, conOps, conValues, innerKeep);
                            if (innerNGood == 0) {
                                if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                                    " fileName=" + fullName + " (innerNGood=0)" + 
                                    " time=" + (System.currentTimeMillis() - time) + "ms");
                                removeAllColumns();
                                return;
                            }

                            //just keep the loadVariables columns of innerTable
                            innerTable.reorderColumns(loadVariableNames, true);  //discard others
                            innerTableNColumns = innerTable.nColumns();

                            //Are we done?  just outerTable + innerTable vars?
                            if (debugMode) String2.log(  "  Debug: nLoadOrConVariables InFile=" + nLoadOrConVariablesInFile +
                                " InOuter=" + nLoadOrConVariablesInOuterTable +
                                " InInner=" + nLoadOrConVariablesInInnerTable +
                                "\n    innerTable nColumns=" + innerTable.nColumns() + ": " +
                                    innerTable.getColumnNamesCSVString());
                            if (nLoadOrConVariablesInFile == nLoadOrConVariablesInOuterTable + 
                                                             nLoadOrConVariablesInInnerTable) { 
                                //user requested e.g., outer=station[10] and inner=time[810740], 
                                //  but user didn't request observations[station][time]
                                if (ncCFcc != null) ncCFcc.set(47);

                                //justKeep good rows of innerTable
                                innerTable.justKeep(innerKeep);
                                innerTableNRows = innerTable.nRows();

                                //make columns in this table paralleling innerTable
                                boolean justInnerTable = nLoadOrConVariablesInFile == nLoadOrConVariablesInInnerTable;
                                for (int col = 0; col < innerTableNColumns; col++) {
                                    addColumn(nColumns(), innerTable.getColumnName(col), 
                                        justInnerTable?
                                            innerTable.getColumn(col) :  //copy data
                                            PrimitiveArray.factory(      //don't copy data
                                                innerTable.getColumn(col).elementType(), 1024, false), 
                                        innerTable.columnAttributes(col));
                                }

                                //just want vars in innerTable?
                                if (justInnerTable) {
                                    //finish up
                                    if (ncCFcc != null) ncCFcc.set(48);
                                    tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
                                    if (nRows() == 0)
                                        removeAllColumns();
                                    else reorderColumns(loadVariableNames, true); //discard others
                                    if (reallyVerbose) String2.log("  readNcCF finished (nLevels=1, readAs=" + readAs + 
                                        ", just innerTable vars) fileName=" + fullName +  
                                        " nRows=" + nRows() + " nCols=" + nColumns() + 
                                        " time=" + (System.currentTimeMillis() - time) + "ms");
                                    if (debugMode) ensureValid();
                                    decodeCharsAndStrings();
                                    convertToUnsignedPAs();
                                    return;
                                }                               

                                if (nLoadOrConVariablesInOuterTable > 0) { 
                                    //join justKeep rows of outerTable (e.g., stations)
                                    if (ncCFcc != null) ncCFcc.set(49);
                                    if (outerKeep != null) {
                                        if (ncCFcc != null) ncCFcc.set(50);
                                        outerTable.justKeep(outerKeep);
                                    }
                                    outerTableNRows = outerTable.nRows();
                                    if (debugMode) {
                                        String2.log("  Debug: nRows outerTable=" + outerTableNRows +
                                            " innerTable=" + innerTableNRows + " this=" + nRows() + "\n" +
                                            "    cols outer=" + outerTable.getColumnNamesCSVString() +
                                            " inner=" + innerTable.getColumnNamesCSVString() +
                                            " this=" + getColumnNamesCSVString());
                                        outerTable.ensureValid();
                                        innerTable.ensureValid();
                                        ensureValid();
                                    }

                                    //make outerTableNRows copies of innerTable (e.g., time)
                                    //and the index to outerTable
                                    IntArray outerIndexPA = new IntArray();
                                    for (int oRow = 0; oRow < outerTableNRows; oRow++) {
                                        if (ncCFcc != null) ncCFcc.set(51);
                                        for (int iCol = 0; iCol < innerTableNColumns; iCol++) 
                                            getColumn(iCol).append(innerTable.getColumn(iCol));
                                        outerIndexPA.addN(innerTableNRows, oRow); //2015-05-26 add->addN !
                                    }
                                    addColumn(0, "outerIndex", outerIndexPA, new Attributes());
                                    if (debugMode) ensureValid();

                                    //join with outerTable (all constraints already applied)
                                    //insert row number in outerTable (to be the key column)
                                    PrimitiveArray keyPA = new IntArray(0, outerTableNRows - 1);
                                    outerTable.addColumn(0, "keyCol", keyPA, new Attributes());                       
                                    join(1, 0, "", outerTable);  //outerTable is lookUpTable
                                    removeColumn(0);  //remove the outerIndex
                                } //else no outer table columns needed

                                //finish up
                                tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
                                if (nRows() == 0)
                                    removeAllColumns();
                                else reorderColumns(loadVariableNames, true); //discard others
                                if (reallyVerbose) String2.log("  readNcCF finished (nLevels=1, readAs=" + readAs + 
                                    ", just outerTable+innerTable vars) fileName=" + fullName +  
                                    " nRows=" + nRows() + " nCols=" + nColumns() + 
                                    " time=" + (System.currentTimeMillis() - time) + "ms");
                                if (debugMode) ensureValid();
                                decodeCharsAndStrings();
                                convertToUnsignedPAs();
                                return;
                            }
                        }  //below, innerTable may have 0 or more columns

                        //make obsKeep (with outerKeep and innerKeep info) and
                        //make outerKeyColumn (with row#'s in outerTable) and 
                        //make innerKeyColumn (with row#'s in innerTable)
                        if (ncCFcc != null) ncCFcc.set(52);
                        BitSet obsKeep = new BitSet(outerDimSize * obsDimSize);  //all are false
                        IntArray outerKeyColumnPA = new IntArray(outerDimSize * obsDimSize, false);  
                        IntArray innerKeyColumnPA = new IntArray(outerDimSize * obsDimSize, false); 
                        int obsRow = 0;
                        for (int outerRow = 0; outerRow < outerDimSize; outerRow++) {
                            boolean oKeep = outerKeep == null || outerKeep.get(outerRow);
                            outerKeyColumnPA.addN(obsDimSize, outerRow);
                            for (int innerRow = 0; innerRow < obsDimSize; innerRow++) {
                                if (oKeep && (innerKeep == null || innerKeep.get(innerRow)))
                                    obsKeep.set(obsRow);
                                innerKeyColumnPA.add(innerRow);
                                obsRow++;
                            }
                        }
                        if (debugMode) String2.log("  Debug: outerKeep=" + 
                                                 String2.noLongerThanDots(outerKeep == null? "null" : outerKeep.toString(), 60) +
                            "\n    innerKeep=" + String2.noLongerThanDots(innerKeep == null? "null" : innerKeep.toString(), 60) +
                            "\n    obsKeep="   + String2.noLongerThanDots(  obsKeep.toString(), 60));

                        if (obsKeep.isEmpty()) {
                            if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                                " (nLevels=1, readAs=" + readAs + 
                                ", no match outer+inner constraints)" + 
                                " fileName=" + fullName + 
                                " time=" + (System.currentTimeMillis() - time) + "ms");
                            removeAllColumns();
                            return;
                        }                               

                        //apply obsKeep to outerKeyColumnPA and innerKeyColumnPA
                        outerKeyColumnPA.justKeep(obsKeep);  outerKeyColumnPA.trimToSize();
                        innerKeyColumnPA.justKeep(obsKeep);  innerKeyColumnPA.trimToSize();
                        if (debugMode) String2.log("  Debug: outerKeySize=" + outerKeyColumnPA.size() +
                            "  innerKeySize=" + innerKeyColumnPA.size());
                        //read the keep rows of requested variable[outer][obs]
                        for (int v = 0; v < nVars; v++) {       
                            if (ncCFcc != null) ncCFcc.set(53);
                            if (varInLoadOrConVariables[v] && 
                                varNDims[v] == 2 && 
                                varUsesDim[v][outerDim] && varUsesDim[v][obsDim]) { //dim order checked above
                                if (ncCFcc != null) ncCFcc.set(54);
                                PrimitiveArray pa = NcHelper.getPrimitiveArray(vars[v]);
                                if (debugMode) String2.log("  Debug: read var=" + varNames[v] + " pa.size=" + pa.size());
                                pa.justKeep(obsKeep); //as each var read in, to save memory
                                pa.trimToSize();
                                if (debugMode) String2.log("    trimmed pa.size=" + pa.size());
                                addColumn(nColumns(), varNames[v], pa, varAtts[v]);
                                standardizeLastColumn(standardizeWhat);
                            }
                        }

                        //Remove rows where all obs data is MV
                        //Rows with only outerTable or innerTable MVs have been removed by obsKeep above.
                        if (debugMode) String2.log("  Debug: before remove rows where all obs data is MV (nRows=" + 
                            nRows() + "):\n" + dataToString(3));
                        obsKeep = rowsWithData();
                        addColumn(0, "outerKeyColumn", outerKeyColumnPA, new Attributes());
                        addColumn(1, "innerKeyColumn", innerKeyColumnPA, new Attributes());
                        justKeep(obsKeep);
                        //String2.log("after read vars\n" + dataToString());
                        if (debugMode) { 
                            String2.log("  Debug: after removeRowsWithJustMVs nRows=" + nRows());
                            ensureValid();  //throws Exception if not
                        }
                        if (nRows() == 0) {
                            if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                                " (nLevels=1, readAs=" + readAs + ", after removeMVRows)"+ 
                                " fileName=" + fullName + 
                                " time=" + (System.currentTimeMillis() - time) + "ms");
                            removeAllColumns();
                            return;
                        }

                        //if innerTable.nColumns > 0, join it  (it has its original rows)
                        if (innerTable.nColumns() > 0) {
                            //insert row number in innerTable (to be the key column)
                            if (ncCFcc != null) ncCFcc.set(55);
                            PrimitiveArray keyPA = new IntArray(0, innerTable.nRows() - 1);
                            innerTable.addColumn(0, "innerKeyColumn", keyPA, new Attributes());                       
                            join(1, 1, "", innerTable);  //innerTable is lookUpTable 
                        }
                        removeColumn(1);  //remove the innerTable keyColumn

                    }
                    //here, this table col#0 is outerKeyColumn
                    //and outerTable has all original rows

                    //join to add the outerTable columns
                    //rearrange the outerTable columns to the loadVariables order
                    if (ncCFcc != null) ncCFcc.set(57);
                    outerTable.reorderColumns(loadVariableNames, true); //true, remove unrequested columns
                    outerTableNColumns = outerTable.nColumns();
                    outerTableNRows = outerTable.nRows();
                    if (outerTableNColumns > 0) {
                        //insert row number in outerTable (to be the key column)
                        if (ncCFcc != null) ncCFcc.set(56);
                        PrimitiveArray keyPA = new IntArray(0, outerTable.nRows() - 1);
                        outerTable.addColumn(0, "keyColumn", keyPA, new Attributes());                       
                        join(1, 0, "", outerTable);  //outerTable is lookUpTable 
                    }
                    removeColumn(0);  //remove the outerTable keyColumn
                }

                //finish up all nLevels=1 files
                if (nColumns() == 0) {
                    if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                        " (nLevels=1, readAs=" + readAs + ", nColumns=0)"+ 
                        " fileName=" + fullName + 
                        " time=" + (System.currentTimeMillis() - time) + "ms");
                    return;
                }

                //finish up
                if (ncCFcc != null) ncCFcc.set(58);
                tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
                if (nRows() == 0)
                    removeAllColumns();
                else reorderColumns(loadVariableNames, true); //discard others
                if (reallyVerbose) String2.log("  readNcCF finished (nLevels=1, readAs=" + readAs + 
                    ", all). fileName=" + fullName + 
                    " nRows=" + nRows() + " nCols=" + nColumns() +
                    " time=" + (System.currentTimeMillis() - time) + "ms");
                if (debugMode) ensureValid();
                decodeCharsAndStrings();
                convertToUnsignedPAs();
                return;
            }

            //*** nLevels=2 files
            Table innerTable = new Table();  //only gets varInLoadOrConVariables vars
            int innerTableNColumns, innerTableNRows; //may be 0


            //* read nLevels=2 ragged array files
            if ((indexVar >= 0 || outerDim == scalarDim) && rowSizeVar >= 0) {  
                if (debugMode) String2.log("  Debug: nLevels=2 files, ragged");
                readAs = "ragged";
                if (ncCFcc != null) ncCFcc.set(59);

                //read variable[innerDim] into innerTable
                StringArray cdmInnerVars = new StringArray();
                for (int v = 0; v < nVars; v++) {
                    if (ncCFcc != null) ncCFcc.set(60);
                    if (varInLoadOrConVariables[v] && 
                        varNDims[v] == 1 && varUsesDim[v][innerDim]) { //ensure correct dim
                        cdmInnerVars.add(varNames[v]); //so in file's order; that's consistent; that's good
                        innerTable.addColumn(innerTable.nColumns(), varNames[v], 
                            NcHelper.getPrimitiveArray(vars[v]), varAtts[v]);
                        innerTable.standardizeLastColumn(standardizeWhat);
                    }
                }
                innerTableNColumns = innerTable.nColumns(); //It has no index columns
                innerTableNRows    = innerTable.nRows();
                globalAttributes.set(cdmInnerName, cdmInnerVars.toString());      //may be "", that's okay
                subsetVars.append(cdmInnerVars);
                globalAttributes.set("subsetVariables", subsetVars.toString()); //may be "", that's okay

                //read the outerIndexPA from vars[indexVar] and ensure valid
                //next 3 lines: as if no indexVar (outerDim == scalarDim)
                PrimitiveArray outerIndexPA = PrimitiveArray.factory(PAType.INT, innerDimSize, "0");
                int indexMV = Integer.MAX_VALUE;
                int indexFV = Integer.MAX_VALUE;
                if (indexVar >= 0) {
                    //then replace if indexVar exists
                    if (ncCFcc != null) ncCFcc.set(61);
                    outerIndexPA = NcHelper.getPrimitiveArray(vars[indexVar]);
                    //no need to unpack the index var
                    indexMV = varAtts[indexVar].getInt("missing_value"); //MAX_VALUE if not defined
                    indexFV = varAtts[indexVar].getInt("_FillValue");    //MAX_VALUE if not defined
                }
                int outerIndexSize = outerIndexPA.size();
                if (outerTableNRows > 0) {
                    if (ncCFcc != null) ncCFcc.set(62);
                    for (int row = 0; row < outerIndexSize; row++) {
                        int index = outerIndexPA.getInt(row);
                        if (index >= 0 && index < outerTableNRows) {
                            //it's an index
                        } else if (index == indexMV || index == indexFV) {
                            //that's the right way to reserve space
                        } else {
                            throw new SimpleException(errorInMethod + 
                                "Invalid file: The index values must be 0 - " + 
                                (outerTableNRows - 1) + ", but " + 
                                varNames[indexVar] + "[" + row + "]=" + index + ".");
                        }
                    }
                }

                //set up innerKeep with outerIndex info.
                BitSet innerKeep = new BitSet(innerDimSize);  //includes outerKeep info
                if (outerKeep == null) {
                    if (ncCFcc != null) ncCFcc.set(63);
                    innerKeep.set(0, innerDimSize);
                } else {
                    if (ncCFcc != null) ncCFcc.set(64);
                    for (int i = 0; i < innerDimSize; i++) 
                        if (outerKeep.get(outerIndexPA.getInt(i)))
                            innerKeep.set(i);
                }

                //apply innerTable constraints  
                int keepNInner = -1;
                if (innerTableNColumns > 0) {
                    if (ncCFcc != null) ncCFcc.set(65);
                    keepNInner = innerTable.tryToApplyConstraints(-1, 
                        conNames, conOps, conValues, innerKeep);
                    if (keepNInner == 0) {
                        if (ncCFcc != null) ncCFcc.set(66);
                        if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                            " (nLevels=2, readAs=" + readAs + ", keepNInner=0)" + 
                            " fileName=" + fullName + " time=" + (System.currentTimeMillis() - time) + "ms");
                        removeAllColumns();
                        return;
                    }
                    //order of rows is important, so *don't* justKeep(innerKeep)
                } 
                if (debugMode) 
                    String2.log("  Debug: ragged innerTable has nCols=" + innerTableNColumns + 
                        " nRows=" + innerTableNRows + " nKeepRows=" + keepNInner + "\n" +
                        innerTable.dataToString()); 


                //Are we done? Are those all the variables we need that are in the file?
                if (nLoadOrConVariablesInFile == nLoadOrConVariablesInOuterTable + 
                                                 innerTableNColumns) {
                    //join with outerTable 
                    if (ncCFcc != null) ncCFcc.set(67);
                    if (outerTableNColumns > 0) {
                        if (ncCFcc != null) ncCFcc.set(68);
                        innerTable.addColumn(0, "outerIndex", outerIndexPA, new Attributes());
                        //insert row number in outerTable (to be the key column)
                        PrimitiveArray keyPA = new IntArray(0, outerTableNRows - 1);
                        outerTable.addColumn(0, "keyCol", keyPA, new Attributes());                       
                        innerTable.join(1, 0, "", outerTable);  //outerTable is lookUpTable
                        innerTable.removeColumn(0);  //remove the outerIndex
                    } 

                    //justKeep
                    innerTable.justKeep(innerKeep);  //includes outer and inner info

                    //globalAttributes already set
                    //copy innerTable to this table
                    int nic = innerTable.nColumns();
                    for (int c = 0; c < nic; c++) 
                        addColumn(c, innerTable.getColumnName(c), 
                            innerTable.getColumn(c), innerTable.columnAttributes(c));

                    //finish up
                    if (ncCFcc != null) ncCFcc.set(69);
                    tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
                    if (nRows() == 0)
                        removeAllColumns();
                    else reorderColumns(loadVariableNames, true); //discard others
                    if (reallyVerbose) String2.log("  readNcCF finished (nLevels=2, readAs=" + readAs + 
                        ", just outerTable+innerTable vars)." + 
                        " fileName=" + fullName + 
                        " nRows=" + nRows() + " nCols=" + nColumns() + 
                        " time=" + (System.currentTimeMillis() - time) + "ms");
                    if (debugMode) ensureValid();
                    decodeCharsAndStrings();
                    convertToUnsignedPAs();
                    return;
                }
               
                //make col#0=outerIndexColumn
                //and  col#1=innerIndexColumn (with row#'s in innerTable from rowSizesPA) 
                //and make obsKeep.
                //obsKeep Approach: optimize for situation that takes longest 
                //  (outerKeep and innerKeep all true).  This is also a very simple approach.
                if (ncCFcc != null) ncCFcc.set(70);
                PrimitiveArray rowSizesPA = NcHelper.getPrimitiveArray(vars[rowSizeVar]);
                //no need to unpack rowSizes
                IntArray outerIndexColumnPA = new IntArray();
                IntArray innerIndexColumnPA = new IntArray();  
                addColumn(0, "outerIndexCol", outerIndexColumnPA, new Attributes());
                addColumn(1, "innerIndexCol", innerIndexColumnPA, new Attributes());
                int startRow, endRow = 0; //endRow is exclusive
                BitSet obsKeep = new BitSet(obsDimSize);  //all are false
                int nRowSizes = rowSizesPA.size();
                for (int innerRow = 0; innerRow < nRowSizes; innerRow++) { //not innerTableNRows
                    startRow = endRow;
                    int getNRows = rowSizesPA.getInt(innerRow);
                    endRow += getNRows;
                    if (innerKeep.get(innerRow)) { //innerKeep always exists
                        //innerKeep always exists and includes outerKeep info
                        //outer/innerIndexColumnPA already have obsKeep applied
                        outerIndexColumnPA.addNInts(getNRows, outerIndexPA.getInt(innerRow));
                        innerIndexColumnPA.addNInts(getNRows, innerRow);   
                        
                        //obsKeep has a bit for each obs row
                        obsKeep.set(startRow, endRow);
                    }
                }
                if (debugMode) String2.log(
                    "  Debug: outerIndexCol[obs]=" + outerIndexColumnPA.toString() + 
                    "\ninnerIndexCol[obs]=" + innerIndexColumnPA.toString());

                //read the obsKeep rows of requested variable[obs]
                for (int v = 0; v < nVars; v++) {       
                    if (ncCFcc != null) ncCFcc.set(71);
                    if (varInLoadOrConVariables[v] &&
                        varNDims[v] == 1 && varUsesDim[v][obsDim]) { //ensure correct dim
                        PrimitiveArray pa = NcHelper.getPrimitiveArray(vars[v]);
                        pa.justKeep(obsKeep); //as each var read in, to save memory
                        pa.trimToSize();
                        addColumn(nColumns(), varNames[v], pa, varAtts[v]);
                        standardizeLastColumn(standardizeWhat);
                    }
                }
               
            //*** read nLevels=2 multidimensional files
            } else if (multidimensional) {
                if (debugMode) String2.log("  Debug: nLevels=2 files, multidimensional");
                readAs = "multidim";
                if (ncCFcc != null) ncCFcc.set(72);

                //create outerIndexPA and innerIndexPA, both [outerDim][innerDim]
                int outerXInnerDimSize = outerDimSize * innerDimSize;
                IntArray outerIndexPA = new IntArray(outerXInnerDimSize, false); 
                BitSet innerKeep = new BitSet(outerXInnerDimSize); //includes outerKeep info
                int tRow = 0;
                for (int outer = 0; outer < outerDimSize; outer++) {
                    outerIndexPA.addN(innerDimSize, outer);
                    if (outerKeep == null || outerKeep.get(outer))
                        innerKeep.set(tRow, tRow + innerDimSize);
                    tRow += innerDimSize;
                }

                //read ALL variable[outerDim][innerDim] into innerTable
                int nLoadOrConVariablesInInnerTable = 0;
                StringArray cdmInnerVars = new StringArray();
                for (int v = 0; v < nVars; v++) {
                    //read ALL innerTable variables, not just varInLoadOrConVariables
                    //because their all-mv rows determine which chunks of obs table to ignore
                    if (ncCFcc != null) ncCFcc.set(73);
                    if (varNDims[v] == 2 && 
                        varUsesDim[v][outerDim] && varUsesDim[v][innerDim]) {
                        //dim order not checked above, so check it here
                        //It's complicated if outerDim is scalarDim.
                        if (ncCFcc != null) ncCFcc.set(74);
                        int dim0 = outerDim == scalarDim? scalarDim :
                                   dimsList.indexOf(vars[v].getDimension(0));
                        int dim1 = dimsList.indexOf(vars[v].getDimension(
                                   outerDim == scalarDim? 0 : 1));
                        if (dim0 == outerDim && dim1 == innerDim) { 
                            if (ncCFcc != null) ncCFcc.set(75);
                            if (varInLoadOrConVariables[v]) {
                                if (ncCFcc != null) ncCFcc.set(76);
                                nLoadOrConVariablesInInnerTable++;
                                cdmInnerVars.add(varNames[v]); //so in file's order; that's consistent; that's good
                            }
                            innerTable.addColumn(innerTable.nColumns(), varNames[v], 
                                NcHelper.getPrimitiveArray(vars[v]), varAtts[v]);
                            innerTable.standardizeLastColumn(standardizeWhat);
                        } else {
                            if (reallyVerbose) 
                                String2.log("  !!! nLevels=2 readAs=" + readAs + 
                                    ": Unexpected dimension order for " + varNames[v]);
                        }                               
                        if (ncCFcc != null) ncCFcc.set(77); //duplicate of 74
                    }
                }
                innerTableNColumns = innerTable.nColumns();  //It has no index columns
                innerTableNRows    = innerTable.nRows();
                globalAttributes.set(cdmInnerName, cdmInnerVars.toString());    //may be "", that's okay
                subsetVars.append(cdmInnerVars);
                globalAttributes.set("subsetVariables", subsetVars.toString()); //may be "", that's okay 

                //trouble?  look for truly orthogonal: just variable[innerDim] 
                if (innerTableNColumns == 0) {
                    if (debugMode) String2.log("  Debug: innerTableNColumns=0");
                    if (ncCFcc != null) ncCFcc.set(78);

                    //read ALL variable[innerDim] into innerTable
                    nLoadOrConVariablesInInnerTable = 0;  //should be already
                    for (int v = 0; v < nVars; v++) {
                        //read ALL innerTable variables, not just varInLoadVariables and varInConstraints
                        //because their all-mv rows determine which chunks of obs table to ignore
                        if (ncCFcc != null) ncCFcc.set(79);
                        if (varNDims[v] == 1 && varUsesDim[v][innerDim]) { //ensure correct dim
                            if (ncCFcc != null) ncCFcc.set(80);
                            if (varInLoadOrConVariables[v])
                                nLoadOrConVariablesInInnerTable++;
                            innerTable.addColumn(innerTable.nColumns(), varNames[v], 
                                NcHelper.getPrimitiveArray(vars[v]), varAtts[v]);
                            innerTable.standardizeLastColumn(standardizeWhat);
                        }
                    }

                    innerTableNColumns = innerTable.nColumns();  //It has no index columns
                    innerTableNRows    = innerTable.nRows();

                    if (innerTableNColumns == 0) {
                        if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                            " (nLevels=2, readAs=" + readAs + 
                            ", no variable[" + outerDimName + "][" + innerDimName + "] " +
                            " or variable[" + innerDimName + "])" + 
                            " fileName=" + fullName + 
                            " time=" + (System.currentTimeMillis() - time) + "ms");
                        removeAllColumns();
                        return;
                    }

                    //make outerDimSize-1 duplicates of the rows of the innerTable
                    //so it becomes innerTable with variable[outerDim][innerDim]
                    for (int col = 0; col < innerTableNColumns; col++) {
                        if (ncCFcc != null) ncCFcc.set(81);
                        PrimitiveArray pa = innerTable.getColumn(col);
                        PrimitiveArray clone = (PrimitiveArray)pa.clone();
                        for (int copy = 1; copy < outerDimSize; copy++) 
                            pa.append(clone); //efficient
                    }
                    innerTableNRows = innerTable.nRows();
                }
                //String2.log("  innerTable=\n" + innerTable.dataToString());

                //rowsWithData   (but don't remove any rows)
                //Note that innerTable MUST exist.
                BitSet keepNonMVs = innerTable.rowsWithData(); 
                //String2.log("  innerTable keepNonMVs=" + keepNonMVs.toString());
                innerKeep.and(keepNonMVs);

                //apply user constraints in innerTable (but don't remove any rows)
                int nInnerGood = innerTable.tryToApplyConstraints(-1, 
                    conNames, conOps, conValues, innerKeep);
                if (nInnerGood == 0) {
                    if (ncCFcc != null) ncCFcc.set(82);
                    if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                        " (nLevels=2, readAs=" + readAs + ", nInnerGood=0)" + 
                        " fileName=" + fullName + 
                        " time=" + (System.currentTimeMillis() - time) + "ms");
                    removeAllColumns();
                    return;
                }
                //order of rows is important, so *don't* justKeep(innerKeep)
                if (debugMode) 
                    String2.log("  Debug: multidim innerTable has nCols=" + innerTableNColumns + 
                        " nRows=" + innerTableNRows + " nKeepRows=" + nInnerGood); 
                //String2.log("outer=\n" + outerTable.dataToString() + "\ninner=\n" + innerTable.dataToString());

                //Are we done? Are those all the variables we need that are in the file?
                if (nLoadOrConVariablesInFile == nLoadOrConVariablesInOuterTable + 
                                                 nLoadOrConVariablesInInnerTable) {

                    //join to add the outerTable columns
                    //rearrange the outerTable columns to the loadVariables order
                    if (ncCFcc != null) ncCFcc.set(83);
                    outerTable.reorderColumns(loadVariableNames, true); //true, remove unrequested columns
                    outerTableNColumns = outerTable.nColumns();
                    outerTableNRows = outerTable.nRows();
                    if (outerTableNColumns > 0) {
                        //join with outerTable 
                        if (ncCFcc != null) ncCFcc.set(84);
                        innerTable.addColumn(0, "outerIndex", outerIndexPA, new Attributes());
                        //insert row number in outerTable (to be the key column)
                        PrimitiveArray keyPA = new IntArray(0, outerTableNRows - 1);
                        outerTable.addColumn(0, "keyColumn", keyPA, new Attributes());                       
                        innerTable.join(1, 0, "", outerTable);  //outerTable is lookUpTable
                        innerTable.removeColumn(0);  //remove the outerIndex
                    } 

                    //justKeep
                    innerTable.justKeep(innerKeep);  //includes outer info, inner info, mv info

                    //globalAttributes already set
                    //copy innerTable to this table
                    int nic = innerTable.nColumns();
                    for (int c = 0; c < nic; c++) 
                        addColumn(c, innerTable.getColumnName(c), 
                            innerTable.getColumn(c), innerTable.columnAttributes(c));

                    //finish up
                    if (ncCFcc != null) ncCFcc.set(85);
                    tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
                    if (nRows() == 0)
                        removeAllColumns();
                    else reorderColumns(loadVariableNames, true); //discard others
                    if (reallyVerbose) String2.log("  readNcCF finished (nLevels=2, readAs=" + readAs + 
                        ", just outerTable+innerTable vars)." +
                        " fileName=" + fullName + 
                        " nRows=" + nRows() + " nCols=" + nColumns() + 
                        " time=" + (System.currentTimeMillis() - time) + "ms");
                    if (debugMode) ensureValid();
                    decodeCharsAndStrings();
                    convertToUnsignedPAs();
                    return;
                }

                //* Make interiorTable with var[obs] and var[scalar][obs]?  some files have them
                if (debugMode) String2.log("  Debug: make interiorTable with variable[obs]?");
                if (ncCFcc != null) ncCFcc.set(86);
                Table interiorTable = new Table();
                int nLoadOrConVariablesInInteriorTable = 0; 
                for (int v = 0; v < nVars; v++) {
                    if (!varInLoadOrConVariables[v])
                        continue;
                    if ((varNDims[v] == 1 && varUsesDim[v][obsDim]) || 
                        (varNDims[v] == 2 && varUsesDim[v][obsDim] && varUsesDim[v][scalarDim])) { //always?
                        nLoadOrConVariablesInInteriorTable++;
                        interiorTable.addColumn(interiorTable.nColumns(), varNames[v], 
                            NcHelper.getPrimitiveArray(vars[v]), varAtts[v]);
                        interiorTable.standardizeLastColumn(standardizeWhat);
                    }
                }
                int interiorTableNColumns = interiorTable.nColumns();  //It has no index columns
                int interiorTableNRows    = interiorTable.nRows();

                //do things if the interiorTable exists
                BitSet interiorKeep = null; //will be null if no interiorTable columns
                if (interiorTableNColumns > 0) {
                    //apply constraints (but keep all the rows)
                    if (ncCFcc != null) ncCFcc.set(87);
                    if (debugMode) String2.log("  Debug: interiorTable exists");
                    interiorKeep = new BitSet();
                    interiorKeep.set(0, interiorTableNRows, true);
                    int interiorNKeep = interiorTable.tryToApplyConstraints(
                        -1, conNames, conOps, conValues, interiorKeep);
                    if (interiorNKeep == 0) {
                        if (ncCFcc != null) ncCFcc.set(88);
                        if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                            " (nLevels=2, readAs=" + readAs + 
                            ", interiorNKeep=0)" + 
                            " fileName=" + fullName + 
                            " time=" + (System.currentTimeMillis() - time) + "ms");
                        removeAllColumns();
                        return;
                    }
                    if (debugMode) String2.log("  Debug: interiorTable=\n" + interiorTable.dataToString(5));

                    //are we done?
                    if (nLoadOrConVariablesInFile == nLoadOrConVariablesInInteriorTable) {

                        //justKeep
                        if (ncCFcc != null) ncCFcc.set(89);
                        interiorTable.justKeep(interiorKeep);  //includes outer info, inner info, mv info

                        //globalAttributes already set
                        //copy interiorTable to this table
                        int nic = interiorTable.nColumns();
                        for (int c = 0; c < nic; c++) 
                            addColumn(c, interiorTable.getColumnName(c), 
                                interiorTable.getColumn(c), interiorTable.columnAttributes(c));

                        //finish up
                        tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
                        if (nRows() == 0)
                            removeAllColumns();
                        else reorderColumns(loadVariableNames, true); //discard others
                        if (reallyVerbose) String2.log("  readNcCF finished (nLevels=2, readAs=" + readAs + 
                            ", just interiorTable vars)." +
                            " fileName=" + fullName + 
                            " nRows=" + nRows() + " nCols=" + nColumns() + 
                            " time=" + (System.currentTimeMillis() - time) + "ms");
                        if (debugMode) ensureValid();
                        decodeCharsAndStrings();
                        convertToUnsignedPAs();
                        return;
                    }
                }

                //read the rowSizesPA 
                //make   outerIndexColumnPA (with row#'s in outerTable)    (but don't add to this table yet)
                //and    innerIndexColumnPA (with row#'s in innerTable)    (but don't add to this table yet)
                //and interiorIndexColumnPA (with row#'s in interiorTable) (but don't add to this table yet)
                //and make obsKeep
                //obsKeep Approach: optimize for situation that takes longest 
                //  (outerKeep and innerKeep all true).  This is also a very simple approach.
                if (debugMode) String2.log("  Debug: read rowSizesPA and make many IndexColumnPAs");
                if (ncCFcc != null) ncCFcc.set(90);
                IntArray outerIndexColumnPA    = new IntArray();
                IntArray innerIndexColumnPA    = new IntArray();  
                IntArray interiorIndexColumnPA = new IntArray();  
                BitSet obsKeep = new BitSet(outerXInnerDimSize * obsDimSize); //all false
                int oiRow  = 0; //outer inner
                int oioRow = 0; //outer inner obs
                for (int outer = 0; outer < outerDimSize; outer++) {
                    for (int inner = 0; inner < innerDimSize; inner++) {
                        if (innerKeep.get(oiRow)) {  //innerKeep always exists and includes outerKeep info
                            for (int obs = 0; obs < obsDimSize; obs++) {
                                boolean tiKeep = interiorKeep == null || interiorKeep.get(obs);
                                if (tiKeep) {  //for all: innerKeep and interiorKeep already applied
                                    outerIndexColumnPA.add(outer);  //row in outerTable
                                    innerIndexColumnPA.add(oiRow);  //row in innerTable
                                    interiorIndexColumnPA.add(obs); //row in interiorTable
                                    obsKeep.set(oioRow);
                                }
                                oioRow++;
                            }
                        } else {
                            oioRow += obsDimSize;
                        }
                        oiRow++;
                    }
                }

                //read the obsKeep rows of requested variable[outerDim][innerDim][obs]
                for (int v = 0; v < nVars; v++) {       
                    if (ncCFcc != null) ncCFcc.set(91);
                    if (varInLoadOrConVariables[v] &&
                        varNDims[v] == 3 && 
                        varUsesDim[v][outerDim] && //dim order checked above when dims detected
                        varUsesDim[v][innerDim] && 
                        varUsesDim[v][obsDim]) {
                        if (ncCFcc != null) ncCFcc.set(92);
                        PrimitiveArray pa = NcHelper.getPrimitiveArray(vars[v]);
                        pa.justKeep(obsKeep); //as each var read in, to save memory
                        pa.trimToSize();
                        addColumn(nColumns(), varNames[v], pa, varAtts[v]);
                        standardizeLastColumn(standardizeWhat);
                    }
                }              

                //remove rows at end with all MV
                int preNRows = nRows();
                obsKeep = rowsWithData();  
                addColumn(0, "outerIndexCol",       outerIndexColumnPA, new Attributes()); 
                addColumn(1, "innerIndexCol",       innerIndexColumnPA, new Attributes());
                addColumn(2, "interiorIndexCol", interiorIndexColumnPA, new Attributes());
                //String2.log("  obs before justKeep(obsKeep):\n" + dataToString());
                justKeep(obsKeep);
                if (debugMode) { 
                    String2.log("  Debug: main table nRows before=" + preNRows + 
                        ", nRows after removeRowsWithJustMVs=" + nRows());
                    ensureValid();  //throws Exception if not
                }
                if (nRows() == 0) {
                    if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA + 
                        " (nLevels=1, readAs=" + readAs + ", after removeMVRows)" + 
                        " fileName=" + fullName + 
                        " time=" + (System.currentTimeMillis() - time) + "ms");
                    removeAllColumns();
                    return;
                }

                //join interiorTable
                if (nLoadOrConVariablesInInteriorTable > 0) {
                    //insert row number in interiorTable (to be the key column)
                    if (ncCFcc != null) ncCFcc.set(93);
                    PrimitiveArray keyPA = new IntArray(0, interiorTableNRows - 1);
                    interiorTable.addColumn(0, "keyColumn", keyPA, new Attributes());                       
                    join(1, 2, "", interiorTable);  
                } 
                removeColumn(2); //interiorIndexCol

                //if nLoadOrConVariablesInOuterTable == 0, no need to join it below
                //rearrange the outerTable columns to the loadVariables order
                outerTable.reorderColumns(loadVariableNames, true); //true, remove unrequested columns
                outerTableNColumns = outerTable.nColumns();
                outerTableNRows = outerTable.nRows();

                //if nLoadOrConVariablesInInnerTable == 0, no need to join it below
                //rearrange the innerTable columns to the loadVariables order
                innerTable.reorderColumns(loadVariableNames, true); //true, remove unrequested columns
                innerTableNColumns = innerTable.nColumns();
                innerTableNRows = innerTable.nRows();

            //unknown nLevels=2 file structure
            } else {
                throw new SimpleException(errorInMethod + 
                    "Invalid file (unknown nLevels=2 file structure: indexVar=" + 
                    indexVar + ", rowSizeVar=" + rowSizeVar + ").");
            }

              
            //*** finish up nLevels=2 files
            //first 2 cols of this table are outerTableIndex and innerTableIndex
            if (debugMode) String2.log("  Debug: finish up nLevels=2 files");
            if (ncCFcc != null) ncCFcc.set(94);

            //apply constraints to obs variables
            //(not outer and inner variables, since they were constrained earlier)
            BitSet keep = new BitSet();
            keep.set(0, nRows());
            int cardinality = nRows();
            for (int con = 0; con < nCon; con++) {
                if (ncCFcc != null) ncCFcc.set(95);
                int v = findColumnNumber(conNames.get(con));
                if (v >= 2) { //an obs variable
                    cardinality = tryToApplyConstraint(-1, 
                        conNames.get(con), conOps.get(con), conValues.get(con), keep);
                    if (cardinality == 0) {
                        if (verbose) String2.log("  readNcCF " + MustBe.THERE_IS_NO_DATA +  
                            " (nLevels=2, readAs=" + readAs + ", after constraints applied)" + 
                            " fileName=" + fullName + 
                            " time=" + (System.currentTimeMillis() - time) + "ms");
                        removeAllColumns();
                        return;
                    }
                }
            }
            if (cardinality < nRows()) {
                if (ncCFcc != null) ncCFcc.set(96);
                justKeep(keep);
            }

            //join to add the innerTable columns
            if (innerTableNColumns > 0) {
                //insert row number in innerTable (to be the key column)
                if (ncCFcc != null) ncCFcc.set(97);
                PrimitiveArray keyPA = new IntArray(0, innerTable.nRows() - 1);
                innerTable.addColumn(0, "keyColumn", keyPA, new Attributes());                       
                join(1, 1, "", innerTable);  //innerTable is lookUpTable                       
            }
            removeColumn(1);  //remove the keyColumn

            //join to add the outerTable columns
            if (outerTableNColumns > 0) {
                //insert row number in outerTable (to be the key column)
                if (ncCFcc != null) ncCFcc.set(98);
                PrimitiveArray keyPA = new IntArray(0, outerTableNRows - 1);
                outerTable.addColumn(0, "keyColumn", keyPA, new Attributes());                       
                join(1, 0, "", outerTable);  //outerTable is lookUpTable
            }
            removeColumn(0);  //remove the keyColumn

            //finish up
            tryToApplyConstraintsAndKeep(-1, conNames, conOps, conValues); //may be 0 rows left
            reorderColumns(loadVariableNames, true); //discard others
            decodeCharsAndStrings();
            convertToUnsignedPAs();
            
            if (ncCFcc != null) ncCFcc.set(99);
            if (reallyVerbose) msg += " finished (nLevels=2, readAs=" + readAs + 
                "). nRows=" + nRows() + " nCols=" + nColumns() + 
                " time=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            //make sure ncFile is explicitly closed
            if (ncFile != null) {
                try {
                    ncFile.close();
                } catch (Throwable t) {
                    msg += "\n" + MustBe.throwableToString(t);
                }
            }
            if (reallyVerbose) String2.log(msg);
        }
    }


    /** This tests reading an ncCF Contiguous Ragged Array file with 7(!) sample_dimension's.
     */
    public static void testReadNcCF7SampleDims() throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCF7SampleDims");
        Table table = new Table();
        String results, expected;
        //From Ajay Krishnan, NCEI/NODC, from
        //https://data.nodc.noaa.gov/thredds/catalog/testdata/wod_ragged/05052016/catalog.html?dataset=testdata/wod_ragged/05052016/ind199105_ctd.nc
        String fileName = String2.unitTestDataDir + 
            "nccf/ncei/ind199105_ctd.nc";
        Attributes gatts;
        String scalarVars = ",crs,WODf,WODfd";

        String2.log("\n\n** Testing " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
        //String2.pressEnterToContinue(NcHelper.ncdump(fileName, "-v crs;WODf;WODfd"));
        //String2.pressEnterToContinue(NcHelper.ncdump(fileName, 
        //    "-v Temperature_row_size;Salinity_row_size;Oxygen_row_size;Pressure_row_size;Chlorophyll_row_size"));

        //test reading just specified legit "z_obs" outer and inner variables
        table.readNcCF(fileName, StringArray.fromCSV(
            "zztop,wod_unique_cast,lat,lon,time,z,z_WODflag" + scalarVars),
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(5);
        expected = 
//with netcdf-java 4.6.5 and before, the last 3 vars had 0's.
//with netcdf-java 4.6.6 and after, they are the default cf missing values
//Unidata says it is not a bug. 4.6.6 is correct. see email from Sean Arms June 15, 2016
//I notified source of files: Ajay Krisnan, but he never replied.
//so I'm going with 4.6.6 and odd values
//was
//"wod_unique_cast,lat,lon,time,z,z_WODflag,crs,WODf,WODfd\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,2.9759612,0,0,0,0\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,3.967939,0,0,0,0\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,5.9518795,0,0,0,0\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,7.9358006,0,0,0,0\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,9.919703,0,0,0,0\n" +
//"...\n";
"wod_unique_cast,lat,lon,time,z,z_WODflag,crs,WODf,WODfd\n" +
"3390296,-43.7802,67.3953,80838.31180554628,2.9759612,0,-2147483647,-32767,-32767\n" +
"3390296,-43.7802,67.3953,80838.31180554628,3.967939,0,-2147483647,-32767,-32767\n" +
"3390296,-43.7802,67.3953,80838.31180554628,5.9518795,0,-2147483647,-32767,-32767\n" +
"3390296,-43.7802,67.3953,80838.31180554628,7.9358006,0,-2147483647,-32767,-32767\n" +
"3390296,-43.7802,67.3953,80838.31180554628,9.919703,0,-2147483647,-32767,-32767\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test reading just specified legit "Temperature_obs" outer and inner variables
        table.readNcCF(fileName, StringArray.fromCSV(
            "zztop,wod_unique_cast,lat,lon,time,Temperature,Temperature_WODflag" + scalarVars), 
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(5);
        expected = 
//was
//"wod_unique_cast,lat,lon,time,Temperature,Temperature_WODflag,crs,WODf,WODfd\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,14.519,0,0,0,0\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,14.526,0,0,0,0\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,14.537,0,0,0,0\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,14.533,0,0,0,0\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,14.532,0,0,0,0\n" +
//"...\n";
"wod_unique_cast,lat,lon,time,Temperature,Temperature_WODflag,crs,WODf,WODfd\n" +
"3390296,-43.7802,67.3953,80838.31180554628,14.519,0,-2147483647,-32767,-32767\n" +
"3390296,-43.7802,67.3953,80838.31180554628,14.526,0,-2147483647,-32767,-32767\n" +
"3390296,-43.7802,67.3953,80838.31180554628,14.537,0,-2147483647,-32767,-32767\n" +
"3390296,-43.7802,67.3953,80838.31180554628,14.533,0,-2147483647,-32767,-32767\n" +
"3390296,-43.7802,67.3953,80838.31180554628,14.532,0,-2147483647,-32767,-32767\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test reading just specified legit outer variables
        table.readNcCF(fileName, StringArray.fromCSV(
            "zztop,wod_unique_cast,lat,lon,time" + scalarVars),
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(5);
        expected = 
//was
//"wod_unique_cast,lat,lon,time,crs,WODf,WODfd\n" +
//"3390296,-43.7802,67.3953,80838.31180554628,0,0,0\n" +
//"3390301,-44.5177,67.9403,80838.68055558205,0,0,0\n" +
//"3390310,-45.2592,68.3755,80839.08888889104,0,0,0\n" +
//"3390318,-46.0113,68.7568,80839.39652776718,0,0,0\n" +
//"3390328,-47.0115,69.431,80839.87291669846,0,0,0\n" +
//"...\n";
"wod_unique_cast,lat,lon,time,crs,WODf,WODfd\n" +
"3390296,-43.7802,67.3953,80838.31180554628,-2147483647,-32767,-32767\n" +
"3390301,-44.5177,67.9403,80838.68055558205,-2147483647,-32767,-32767\n" +
"3390310,-45.2592,68.3755,80839.08888889104,-2147483647,-32767,-32767\n" +
"3390318,-46.0113,68.7568,80839.39652776718,-2147483647,-32767,-32767\n" +
"3390328,-47.0115,69.431,80839.87291669846,-2147483647,-32767,-32767\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test reading just specified legit "Temperature_obs" inner variables
        table.readNcCF(fileName, StringArray.fromCSV(
            "zztop,Temperature,Temperature_WODflag" + scalarVars),
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(5);
        expected = 
//was
//"Temperature,Temperature_WODflag,crs,WODf,WODfd\n" +
//"14.519,0,0,0,0\n" +
//"14.526,0,0,0,0\n" +
//"14.537,0,0,0,0\n" +
//"14.533,0,0,0,0\n" +
//"14.532,0,0,0,0\n" +
//"...\n";
"Temperature,Temperature_WODflag,crs,WODf,WODfd\n" +
"14.519,0,-2147483647,-32767,-32767\n" +
"14.526,0,-2147483647,-32767,-32767\n" +
"14.537,0,-2147483647,-32767,-32767\n" +
"14.533,0,-2147483647,-32767,-32767\n" +
"14.532,0,-2147483647,-32767,-32767\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test reading just specified legit scalar variables
        table.readNcCF(fileName, StringArray.fromCSV(
            "zztop,WODf,crs"), 
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(5);
        expected = 
//was
//"WODf,crs\n" +
//"0,0\n";
"WODf,crs\n" +
"-32767,-2147483647\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test reading WHOLE file (should just catch z_obs dimension)
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(3);
        expected = 
//note it catches z_obs dimension (z, z_WODflag, z_sigfig), not others.
// Temperature_row_size, and Temperature_WODprofileflag are [casts], and don't use Temperature_obs.
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast," +
"lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Cast_Tow_number," +
"Orig_Stat_Num,Bottom_Depth,Cast_Duration,Cast_Direction,High_res_pair,dataset," +
"dbase_orig,origflagset,z,z_WODflag,z_sigfig,Temperature_row_size," +
"Temperature_WODprofileflag,Temperature_Scale,Temperature_Instrument," +
"Salinity_row_size,Salinity_WODprofileflag,Salinity_Scale,Salinity_Instrument," +
"Oxygen_row_size,Oxygen_WODprofileflag,Oxygen_Instrument,Oxygen_Original_units," +
"Pressure_row_size,Chlorophyll_row_size,Chlorophyll_WODprofileflag," +
"Chlorophyll_Instrument,Chlorophyll_uncalibrated,Conductivit_row_size,crs,WODf,WODfp,WODfd\n" +

"FRANCE,FR008787,35MF68SUZIL,3390296,-43.7802,67.3953,80838.31180554628," +
"19910501,7.483333,841,WORLD OCEAN CIRCULATION EXPERIMENT (WOCE)," +
"MARION DUFRESNE (C.s.FNGB;built 1972;decomm-d 1995;renamed Fres;IMO7208388)," +
"NATIONAL MUSEUM OF NATURAL HISTORY (PARIS),1,37.0,4438.0,9.96921E36,,7498735," +
"CTD,WHO/CCHDO,WOCE,2.9759612,0,3,2204,0,,CTD: NEIL BROWN MARK IIIB,2204,0,," +
"CTD: NEIL BROWN MARK IIIB,2204,5,CTD: NEIL BROWN MARK IIIB,umol/kg,2204,0,0,," +
//was "-2147483647,0,0,0,0,0\n" +
"-2147483647,0,-2147483647,-32767,-32767,-32767\n" +

"FRANCE,FR008787,35MF68SUZIL,3390296,-43.7802,67.3953,80838.31180554628," +
"19910501,7.483333,841,WORLD OCEAN CIRCULATION EXPERIMENT (WOCE)," +
"MARION DUFRESNE (C.s.FNGB;built 1972;decomm-d 1995;renamed Fres;IMO7208388)," +
"NATIONAL MUSEUM OF NATURAL HISTORY (PARIS),1,37.0,4438.0,9.96921E36,,7498735," +
"CTD,WHO/CCHDO,WOCE,3.967939,0,3,2204,0,,CTD: NEIL BROWN MARK IIIB,2204,0,," +
"CTD: NEIL BROWN MARK IIIB,2204,5,CTD: NEIL BROWN MARK IIIB,umol/kg,2204,0,0,," +
//was "-2147483647,0,0,0,0,0\n" +
"-2147483647,0,-2147483647,-32767,-32767,-32767\n" +

"FRANCE,FR008787,35MF68SUZIL,3390296,-43.7802,67.3953,80838.31180554628," +
"19910501,7.483333,841,WORLD OCEAN CIRCULATION EXPERIMENT (WOCE)," +
"MARION DUFRESNE (C.s.FNGB;built 1972;decomm-d 1995;renamed Fres;IMO7208388)," +
"NATIONAL MUSEUM OF NATURAL HISTORY (PARIS),1,37.0,4438.0,9.96921E36,,7498735," +
"CTD,WHO/CCHDO,WOCE,5.9518795,0,3,2204,0,,CTD: NEIL BROWN MARK IIIB,2204,0,," +
"CTD: NEIL BROWN MARK IIIB,2204,5,CTD: NEIL BROWN MARK IIIB,umol/kg,2204,0,0,," +
//was "-2147483647,0,0,0,0,0\n" +
"-2147483647,0,-2147483647,-32767,-32767,-32767\n" +

"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        results = table.globalAttributes().getString("cdm_data_type");
        expected = "Profile";
        Test.ensureEqual(results, expected, "results=\n" + results);

        results = table.globalAttributes().getString("subsetVariables");
        expected = 
"country, WOD_cruise_identifier, originators_cruise_identifier, wod_unique_cast, " +
"lat, lon, time, date, GMT_time, Access_no, Project, Platform, Institute, " +
"Cast_Tow_number, Orig_Stat_Num, Bottom_Depth, Cast_Duration, Cast_Direction, " +
"High_res_pair, dataset, dbase_orig, origflagset, Temperature_row_size, " +
"Temperature_WODprofileflag, Temperature_Scale, Temperature_Instrument, " +
"Salinity_row_size, Salinity_WODprofileflag, Salinity_Scale, Salinity_Instrument, " +
"Oxygen_row_size, Oxygen_WODprofileflag, Oxygen_Instrument, Oxygen_Original_units, " +
"Pressure_row_size, " +
"Chlorophyll_row_size, Chlorophyll_WODprofileflag, Chlorophyll_Instrument, " +
"Chlorophyll_uncalibrated, Conductivit_row_size, crs, WODf, WODfp, WODfd";
        Test.ensureEqual(results, expected, "results=\n" + results);

        results = table.globalAttributes().getString("cdm_profile_variables");
        //same expected
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test reading row_size vars -- are they actually read?
        table.readNcCF(fileName, StringArray.fromCSV(
            "zztop,z_row_size,Temperature_row_size,Salinity_row_size,Oxygen_row_size," +
            "Pressure_row_size,Chlorophyll_row_size,Conductivity_row_size"),
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(7);
        expected = //verified with dumpString above
"Temperature_row_size,Salinity_row_size,Oxygen_row_size,Pressure_row_size,Chlorophyll_row_size\n" +
"2204,2204,2204,2204,0\n" +
"1844,1844,1844,1844,0\n" +
"1684,1684,1684,1684,0\n" +
"1587,1587,1587,1587,0\n" +
"357,357,357,357,0\n" +
"34,34,0,34,34\n" +
"34,34,0,34,34\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //test request for vars with 2 different sample_dimensions
        //  second sample_dim throws error
        results = "shouldn't happen";
        try {
            table.readNcCF(fileName, StringArray.fromCSV(
                "zztop,wod_unique_cast,lat,lon,time,z,z_WODflag,Temperature,Temperature_WODflag" + scalarVars),
                0,  //standardizeWhat=0
            null, null, null);
            results = table.dataToString(5);

        } catch (Throwable t2) {
            results = t2.toString();
        }
        expected = "Invalid request: loadVariables includes variables that use two different sample_dimension's (z_obs and Temperature_obs).";
        int po = Math.max(0, results.indexOf(expected));        
        Test.ensureEqual(results.substring(po), expected, "results=\n" + results);

    }


    /** This tests readNcCF reading point files. */
    public static void testReadNcCFPoint(boolean pauseAfterEach) throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCFPoint");
        String pauseMessage = "\nOK?";
        Table table = new Table();
        String results, expected;
        String fileName = String2.unitTestDataDir + "CFPointConventions/point/point-H.1/point-H.1.nc"; 
        Attributes gatts;

/* */
        //***************  point
        String2.log("\n\n** Testing " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));

        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        //String2.log(table.toCSVString());
        results = table.dataToString(5);
        expected = 
"obs,lat,lon,alt,time,temperature,humidity\n" +
"0,41.0,112.0,7.745540487338979,573,26.225288,11.245576\n" +
"1,179.0,68.0,3.0855444414144264,2248,12.695349,67.73824\n" +
"2,10.0,11.0,3.254759157455159,71,21.193731,48.589462\n" +
"3,106.0,22.0,4.549437636401848,1714,35.339344,39.594116\n" +
"4,75.0,16.0,6.061720687265453,1209,22.593496,28.170149\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1a " + pauseMessage); 


        table.readNcCF(fileName, StringArray.fromCSV(
            "row,obs,lat,lon,alt,time,temperature,humidity"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV(""), 
            StringArray.fromCSV(""),
            StringArray.fromCSV(""));
        results = table.dataToString(5);
        //expected is same
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1b " + pauseMessage); 


        results = table.columnAttributes(6).toString();
        expected = 
"    coordinates=time lat lon alt\n" +
"    long_name=Humidity\n" +
"    missing_value=-999.9f\n" +
"    standard_name=specific_humidity\n" +
"    units=Percent\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        results = table.globalAttributes().toString();
        expected = 
"    Conventions=CF-1.6\n" +
"    featureType=point\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        table.readNcCF(fileName, StringArray.fromCSV(
            "obs,lat,time,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("obs"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("2"));
        results = table.dataToString();
        expected = 
"obs,lat,time,temperature\n" +
"2,10.0,71,21.193731\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1c " + pauseMessage); 

        table.readNcCF(fileName, StringArray.fromCSV(
            "obs,lat,time,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("71"));
        results = table.dataToString();
        expected = 
"obs,lat,time,temperature\n" +
"2,10.0,71,21.193731\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1d " + pauseMessage); 

        table.readNcCF(fileName, StringArray.fromCSV(
            "obs,lat,time,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("21.193731"));
        results = table.dataToString();
        expected = 
"obs,lat,time,temperature\n" +
"2,10.0,71,21.193731\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1e " + pauseMessage); 

        //this is important test of just getting dimension values 
        //(when there is no corresponding variable)
        table.readNcCF(fileName, StringArray.fromCSV(
            "obs"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("obs"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("2"));
        results = table.dataToString();
        expected = 
"obs\n" +
"2\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //and test that it gets the global attributes from the file.
        results = table.globalAttributes().toString();
        expected = 
"    Conventions=CF-1.6\n" +
"    featureType=point\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1f " + pauseMessage); 

        table.readNcCF(fileName, StringArray.fromCSV(
            "temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("21.193731"));
        results = table.dataToString();
        expected = 
"temperature\n" +
"21.193731\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1g " + pauseMessage); 

        //
        table.readNcCF(fileName, StringArray.fromCSV(
            "obs,lat,time,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("obs"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");

        table.readNcCF(fileName, StringArray.fromCSV(
            "obs,lat,time,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");

        table.readNcCF(fileName, StringArray.fromCSV(
            "obs,lat,time,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");

        table.readNcCF(fileName, StringArray.fromCSV("obs"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("obs"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");

        table.readNcCF(fileName, StringArray.fromCSV("temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");

        String2.log("\n*** Table.testReadNcCFPoint finished successfully");
    }

    
    
    /** This tests readNcCF nLevels=1. */
    public static void testReadNcCF1(boolean pauseAfterEach) throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCF1");
        String pauseMessage = "\nOK?";
        Table table = new Table();
        String results, expected;
        String profileFileName = String2.unitTestDataDir + "nccf/Profile.nc"; 
        Attributes gatts;

/* */
        //***************   contiguous   profileFileName
        String2.log("\n\n** Testing profile contiguousRagged\n" +
            "  " + profileFileName);
        String2.log(NcHelper.ncdump(profileFileName, "-h"));


        String2.log("\n\n** Test nLevels=1/contiguousRagged  no loadVars, no constraints");
        table.readNcCF(profileFileName, null, 0,  //standardizeWhat=0
            null, null, null);
        //String2.log(table.toCSVString());
        results = table.dataToString(5);
        expected = 
"id,longitude,latitude,time,altitude,chlorophyll,chlorophyll_qc,oxygen,oxygen_qc,pressure,pressure_qc,salinity,salinity_qc,temperature,temperature_qc\n" +
"465958,163.08,39.0,1.107754559E9,-2.0,,,,,,,,,10.1,0.0\n" +
"465958,163.08,39.0,1.107754559E9,-58.0,,,,,,,,,9.9,0.0\n" +
"465958,163.08,39.0,1.107754559E9,-96.0,,,,,,,,,9.2,0.0\n" +
"465958,163.08,39.0,1.107754559E9,-138.0,,,,,,,,,8.8,0.0\n" +
"465958,163.08,39.0,1.107754559E9,-158.0,,,,,,,,,8.1,0.0\n" +
"...\n";
        Test.ensureEqual(results, expected, "");
        Test.ensureEqual(table.nRows(), 118, table.toString());
        results = table.columnAttributes(0).toString();
        expected = 
"    actual_range=465958i,848984i\n" +
"    cf_role=profile_id\n" +
"    colorBarMaximum=1000000.0d\n" +
"    colorBarMinimum=0.0d\n" +
"    ioos_category=Identifier\n" +
"    long_name=Sequence ID\n" +
"    missing_value=2147483647i\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        gatts = table.globalAttributes();
        Test.ensureEqual(gatts.getString("cdm_data_type"), "Profile", gatts.toString());
        Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
            "id, longitude, latitude, time", gatts.toString());
        Test.ensureEqual(gatts.getString("subsetVariables"), 
            "id, longitude, latitude, time", gatts.toString());
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1a " + pauseMessage); 

        //
        String2.log("\n\n** Test 1 non-existent loadVar test:ncCFcc.set(27)");
        table.readNcCF(profileFileName, StringArray.fromCSV("zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV(""), 
            StringArray.fromCSV(""),
            StringArray.fromCSV(""));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1aa " + pauseMessage); 

        //
        String2.log("\n\n** Test nLevels=1/contiguousRagged  " +
            "many loadVars, constraints, NO_DATA");
        table.readNcCF(profileFileName, StringArray.fromCSV(
            "id,longitude,latitude,time,altitude,salinity,salinity_qc,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("id"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("zztop"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1b " + pauseMessage); 

        table.readNcCF(profileFileName, StringArray.fromCSV(
            "id,longitude,latitude,time,altitude,salinity,salinity_qc,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("id"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("zztop"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");

        table.readNcCF(profileFileName, StringArray.fromCSV(
            "id,longitude,latitude,time,altitude,salinity,salinity_qc,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("longitude"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");

        table.readNcCF(profileFileName, StringArray.fromCSV(
            "id,longitude,latitude,time,altitude,salinity,salinity_qc,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");

        table.readNcCF(profileFileName, StringArray.fromCSV(
            "id,longitude,latitude,time,altitude,salinity,salinity_qc,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");


        //
        String2.log("\n\n** Test nLevels=1/contiguousRagged  " +
            "just outerTable loadVars, no constraints");
        table.readNcCF(profileFileName, 
            StringArray.fromCSV("longitude,latitude,time,zztop,id"), 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"longitude,latitude,time,id\n" +
"163.08,39.0,1.107754559E9,465958\n" +
"225.84,16.05,1.1077371E9,580888\n" +
"225.4,15.11,1.107751391E9,580889\n" +
"225.0,14.25,1.107764388E9,580890\n" +
"224.49,13.23,1.10778048E9,580891\n" +
"214.66,54.8,1.107759959E9,848984\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        gatts = table.globalAttributes();
        Test.ensureEqual(gatts.getString("cdm_data_type"), "Profile", gatts.toString());
        Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
            "id, longitude, latitude, time", gatts.toString());
        Test.ensureEqual(gatts.getString("subsetVariables"), 
            "id, longitude, latitude, time", gatts.toString());
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1d " + pauseMessage); 

        table.readNcCF(profileFileName, 
            StringArray.fromCSV("longitude,latitude,time,zztop,id"), 0,  //standardizeWhat=0
            StringArray.fromCSV("id"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");

        table.readNcCF(profileFileName, 
            StringArray.fromCSV("longitude,latitude,time,zztop,id"), 0,  //standardizeWhat=0
            StringArray.fromCSV("latitude"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");

        table.readNcCF(profileFileName, 
            StringArray.fromCSV("longitude,latitude,time,zztop,id"), 0,  //standardizeWhat=0
            StringArray.fromCSV("time"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");


        //
        String2.log("\n\n** Test nLevels=1/contiguousRagged  " +
            "just outerTable loadVars, constraints");
        table.readNcCF(profileFileName, 
            StringArray.fromCSV("longitude,latitude,time,zztop,id"), 0,  //standardizeWhat=0
            
            StringArray.fromCSV("id"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("848984"));
        results = table.dataToString();
        expected = 
"longitude,latitude,time,id\n" +
"214.66,54.8,1.107759959E9,848984\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        gatts = table.globalAttributes();
        Test.ensureEqual(gatts.getString("cdm_data_type"), "Profile", gatts.toString());
        Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
            "id, longitude, latitude, time", gatts.toString());
        Test.ensureEqual(gatts.getString("subsetVariables"), 
            "id, longitude, latitude, time", gatts.toString());
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1e " + pauseMessage); 


        String2.log("\n\n** Test nLevels=1/contiguousRagged  " +
            "just outerTable loadVars, constraints, NO_DATA");
        table.readNcCF(profileFileName, 
            StringArray.fromCSV("longitude,latitude,time,zztop,id"), 0,  //standardizeWhat=0
            StringArray.fromCSV("id"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("zztop"));
        Test.ensureEqual(table.nColumns(), 0, "");
        Test.ensureEqual(table.nRows(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1f " + pauseMessage); 


        String2.log("\n\n** Test nLevels=1/contiguousRagged, specific loadVars, constraints");
        table.readNcCF(profileFileName, StringArray.fromCSV(
            "longitude,latitude,time,altitude,temperature,temperature_qc,zztop,id"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("id,temperature"), 
            StringArray.fromCSV("=,>="),
            StringArray.fromCSV("848984,5"));
        results = table.dataToString();
        expected = 
"longitude,latitude,time,altitude,temperature,temperature_qc,id\n" +
"214.66,54.8,1.107759959E9,-2.0,5.8,0.0,848984\n" +
"214.66,54.8,1.107759959E9,-95.0,5.6,0.0,848984\n" +
"214.66,54.8,1.107759959E9,-101.0,5.4,0.0,848984\n" +
"214.66,54.8,1.107759959E9,-107.0,5.0,0.0,848984\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        gatts = table.globalAttributes();
        Test.ensureEqual(gatts.getString("cdm_data_type"), "Profile", gatts.toString());
        Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
            "id, longitude, latitude, time", gatts.toString());
        Test.ensureEqual(gatts.getString("subsetVariables"), 
            "id, longitude, latitude, time", gatts.toString());
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1g " + pauseMessage); 


        String2.log("\n\n** Test nLevels=1/contiguousRagged  just obs loadVars, no constraints");
        table.readNcCF(profileFileName, 
            StringArray.fromCSV("salinity,temperature,zztop"), 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"salinity,temperature\n" +
",10.1\n" +
",9.9\n" +
",9.2\n" +
",8.8\n" +
",8.1\n" +
",8.1\n" +
",7.4\n" +
",6.7\n" +
",6.0\n";
        Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 118, table.dataToString());
        gatts = table.globalAttributes();
        Test.ensureEqual(gatts.getString("cdm_data_type"), "Profile", gatts.toString());
        Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
            null, gatts.toString());
        Test.ensureEqual(gatts.getString("subsetVariables"), 
            null, gatts.toString());
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1h " + pauseMessage); 

        table.readNcCF(profileFileName, 
            StringArray.fromCSV("salinity"), 0,  //standardizeWhat=0
            StringArray.fromCSV("salinity"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-12345"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");


        //
        String2.log("\n\n** Test nLevels=1/contiguousRagged  just obs loadVars, constraints");
        table.readNcCF(profileFileName, 
            StringArray.fromCSV("temperature,zztop"), 0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"), 
            StringArray.fromCSV(">"),
            StringArray.fromCSV("24.5"));
        results = table.dataToString();
        expected = 
"temperature\n" +
"24.8\n" +
"24.7\n" +
"25.0\n" +
"24.9\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        gatts = table.globalAttributes();
        Test.ensureEqual(gatts.getString("cdm_data_type"), "Profile", gatts.toString());
        Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
            null, gatts.toString());
        Test.ensureEqual(gatts.getString("subsetVariables"), 
            null, gatts.toString());
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1i " + pauseMessage); 


        String2.log("\n\n** Test nLevels=1/contiguousRagged  " +
            "just obs loadVars, constraints, NO_DATA");
        table.readNcCF(profileFileName, 
            StringArray.fromCSV("temperature,zztop"), 0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("-195"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1j " + pauseMessage); 

        //test quick reject 
        //if (constraintVar!=NaN or constraintVar=(finite)) and var not in file,
        String2.log("\n\n** Test #1m quick reject var=(nonNumber) if var not in file: NO_DATA");
        table.readNcCF(profileFileName, 
            StringArray.fromCSV("temperature,zzStation"), 0,  //standardizeWhat=0
            StringArray.fromCSV("zzStation"), 
            StringArray.fromCSV("="),
            StringArray.fromCSV("WXURP"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1m " + pauseMessage); 

        String2.log("\n\n** Test #1n quick reject var!=\"\" if var not in file: NO_DATA");
        table.readNcCF(profileFileName, 
            StringArray.fromCSV("temperature,zzStation"), 0,  //standardizeWhat=0
            StringArray.fromCSV("zzStation"), 
            StringArray.fromCSV("!="),
            new StringArray(new String[]{""}));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1n " + pauseMessage); 

        //but this can't be quickly rejected
        String2.log("\n\n** Test #1o can't quick reject var=99 if var not in file\n" +
            "(since 99 might be defined as missing_value)");
        table.readNcCF(profileFileName, 
            StringArray.fromCSV("temperature,zzStation"), 0,  //standardizeWhat=0
            StringArray.fromCSV("zzStation"), 
            StringArray.fromCSV("="),
            new StringArray(new String[]{"99"}));
        Test.ensureEqual(table.nRows(), 118, "");
        Test.ensureEqual(table.nColumns(), 1, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#1o " + pauseMessage); 


/* */
        //***************  nLevels=1      TimeSeries
        for (int type = 0; type < 2; type++) {
            //ncCF1b and ncCFMA1b have same data, so tests are the same!
            String fileType = type == 0? "contiguous" : "multidimensional";
            //from EDDTableFromNcFiles.testNcCF1b() and testNcCFMA1b();
            String fileName = String2.unitTestDataDir + "nccf/" + (type == 0? "ncCF1b.nc" : "ncCFMA1b.nc");

            String2.log("\n\n** Testing nLevels=1/" + fileType + "\n" +
                "  " + fileName);
            String2.log(NcHelper.ncdump(fileName, "-h"));


            String2.log("\n\n** Test nLevels=1/" + fileType + "  no loadVars, no constraints");
            table.readNcCF(fileName, null, 0,  //standardizeWhat=0
                null, null, null);
String2.log(table.toString());
            results = table.dataToString(5);
            expected = 
"line_station,longitude,latitude,altitude,time,obsScientific,obsValue,obsUnits\n" +
"076.7_100,-124.32333,33.388332,-214.1,1.10064E9,Argyropelecus sladeni,2,number of larvae\n" +
"076.7_100,-124.32333,33.388332,-214.1,1.10064E9,Chauliodus macouni,3,number of larvae\n" +
"076.7_100,-124.32333,33.388332,-214.1,1.10064E9,Danaphos oculatus,4,number of larvae\n" +
"076.7_100,-124.32333,33.388332,-214.1,1.10064E9,Diogenichthys atlanticus,3,number of larvae\n" +
"076.7_100,-124.32333,33.388332,-214.1,1.10064E9,Idiacanthus antrostomus,3,number of larvae\n" +
"...\n";
            Test.ensureEqual(results, expected, "");
            Test.ensureEqual(table.nRows(), 23, table.toString());
            results = table.columnAttributes(0).toString();
            expected = 
"    cf_role=timeseries_id\n" +
"    ioos_category=Identifier\n" +
"    long_name=CalCOFI Line + Station\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TimeSeries", gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_timeseries_variables"), 
                "line_station", gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                "line_station", gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #2a " + pauseMessage); 

            table.readNcCF(fileName, StringArray.fromCSV(""), 0,  //standardizeWhat=0
                StringArray.fromCSV("line_station"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(""), 0,  //standardizeWhat=0
                StringArray.fromCSV("longitude"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(""), 0,  //standardizeWhat=0
                StringArray.fromCSV("time"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(""), 0,  //standardizeWhat=0
                StringArray.fromCSV("obsValue"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


            //
            String2.log("\n\n** Test nLevels=1/" + fileType + "  " +
                "just outerTable loadVars, no constraints");
            table.readNcCF(fileName, StringArray.fromCSV(
                "line_station,zztop"), 0,  //standardizeWhat=0
                null, null, null);
            results = table.dataToString();
            expected = 
"line_station\n" +
"076.7_100\n" +
"080_100\n" +
"083.3_100\n"; //4 row with all mv was removed
            Test.ensureEqual(results, expected, "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TimeSeries", gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_timeseries_variables"), 
                "line_station", gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                "line_station", gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #2b " + pauseMessage); 

            table.readNcCF(fileName, StringArray.fromCSV("line_station"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("line_station"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


            //
            String2.log("\n\n** Test nLevels=1/" + fileType + "  " +
                "just outerTable loadVars, constraints");
            table.readNcCF(fileName, StringArray.fromCSV("line_station,zztop"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("line_station"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("083.3_100"));
            results = table.dataToString();
            expected = 
"line_station\n" +
"083.3_100\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TimeSeries", gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_timeseries_variables"), 
                "line_station", gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                "line_station", gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #2c " + pauseMessage); 


            String2.log("\n\n** Test nLevels=1/" + fileType + "  " +
                "just outerTable loadVars, constraints, NO_DATA");
            table.readNcCF(fileName, 
                StringArray.fromCSV("line_station,zztop"), 0,  //standardizeWhat=0
                StringArray.fromCSV("line_station"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("zztop"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #2d " + pauseMessage); 


            String2.log("\n\n** Test nLevels=1/" + fileType + ", specific loadVars, constraints");
            table.readNcCF(fileName, StringArray.fromCSV(
                "longitude,latitude,altitude,time,line_station,zztop,obsScientific,obsValue,obsUnits"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("line_station,obsValue"), 
                StringArray.fromCSV("=,="),
                StringArray.fromCSV("083.3_100,1"));
            results = table.dataToString();
            expected = 
"longitude,latitude,altitude,time,line_station,obsScientific,obsValue,obsUnits\n" +
"-123.49333,32.245,-211.5,1.10027676E9,083.3_100,Argyropelecus sladeni,1,number of larvae\n" +
"-123.49333,32.245,-211.5,1.10027676E9,083.3_100,Diogenichthys atlanticus,1,number of larvae\n" +
"-123.49333,32.245,-211.5,1.10027676E9,083.3_100,Idiacanthus antrostomus,1,number of larvae\n" +
"-123.49333,32.245,-211.5,1.10027676E9,083.3_100,Tetragonurus cuvieri,1,number of larvae\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TimeSeries", gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_timeseries_variables"), 
                "line_station", gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                "line_station", gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #2e " + pauseMessage); 


            String2.log("\n\n** Test nLevels=1/" + fileType + 
                ", specific loadVars, constraints, NO_DATA");
            table.readNcCF(fileName, StringArray.fromCSV(
                "longitude,latitude,altitude,time,line_station,zztop,obsScientific,obsValue,obsUnits"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("line_station,obsValue"), 
                StringArray.fromCSV("=,="),
                StringArray.fromCSV("083.3_100,-9"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #2f " + pauseMessage); 


            String2.log("\n\n** Test nLevels=1/" + fileType + "  just obs loadVars, no constraints");
            table.readNcCF(fileName, StringArray.fromCSV(
                "obsScientific,obsValue,obsUnits,zztop"), 0,  //standardizeWhat=0
                null, null, null);
            results = table.dataToString();
            expected = 
"obsScientific,obsValue,obsUnits\n" +
"Argyropelecus sladeni,2,number of larvae\n" +
"Chauliodus macouni,3,number of larvae\n" +
"Danaphos oculatus,4,number of larvae\n" +
"Diogenichthys atlanticus,3,number of larvae\n" +
"Idiacanthus antrostomus,3,number of larvae\n" +
"Lestidiops ringens,1,number of larvae\n" +
"Melamphaes lugubris,1,number of larvae\n" +
"Protomyctophum crockeri,4,number of larvae\n" +
"Stenobrachius leucopsarus,1,number of larvae\n" +
"Total Fish Larvae,22,number of larvae\n" +
"Argyropelecus affinis,1,number of larvae\n" +
"Argyropelecus sladeni,2,number of larvae\n" +
"Danaphos oculatus,1,number of larvae\n" +
"Idiacanthus antrostomus,2,number of larvae\n" +
"Melamphaes parvus,1,number of larvae\n" +
"Nannobrachium spp,2,number of larvae\n" +
"Protomyctophum crockeri,1,number of larvae\n" +
"Total Fish Larvae,10,number of larvae\n" +
"Argyropelecus sladeni,1,number of larvae\n" +
"Diogenichthys atlanticus,1,number of larvae\n" +
"Idiacanthus antrostomus,1,number of larvae\n" +
"Tetragonurus cuvieri,1,number of larvae\n" +
"Total Fish Larvae,4,number of larvae\n";
            Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TimeSeries", gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_timeseries_variables"), 
                null, gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                null, gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #2g " + pauseMessage); 

            table.readNcCF(fileName, StringArray.fromCSV("obsScientific"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("obsScientific"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


            //  
            String2.log("\n\n** Test nLevels=1/" + fileType + "  just obs loadVars, constraints");
            table.readNcCF(fileName, 
                StringArray.fromCSV("obsScientific,obsValue,obsUnits,zztop"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("obsValue"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("4"));
            results = table.dataToString();
            expected = 
"obsScientific,obsValue,obsUnits\n" +
"Danaphos oculatus,4,number of larvae\n" +
"Protomyctophum crockeri,4,number of larvae\n" +
"Total Fish Larvae,4,number of larvae\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TimeSeries", gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_timeseries_variables"), 
                null, gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                null, gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #2h " + pauseMessage); 


            String2.log("\n\n** Test nLevels=1/" + fileType + 
                "  just obs loadVars, constraints, NO_DATA");
            table.readNcCF(fileName, 
                StringArray.fromCSV("obsScientific,obsValue,obsUnits,zztop"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("obsValue"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-99"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #2i " + pauseMessage); 

        } //end nLevels=1 type loop

/* */
        //********* expected errors
        String2.log("\n** Expected errors");
        try {
            table.readNcCF(String2.unitTestDataDir + "nccf/badIndexed1To6.nc", null, 
                0,  //standardizeWhat=0
                null, null, null);
            throw new SimpleException("Shouldn't get here.");

        } catch (Exception e) {
            if (e.toString().indexOf(
                "Invalid file: The index values must be 0 - 5, but parentIndex[88]=6.") < 0)
                throw e;
        }


        //******* another test file, from Kevin O'Brien
        try {
            table.readNcCF("c:/data/kevin/interpolated_gld.20120620_045152_meta_2.nc", 
                null, 0,  //standardizeWhat=0
                null, null, null);
            throw new SimpleException("Shouldn't get here.");

        } catch (Exception e) {
            if (e.toString().indexOf(
                "Invalid contiguous ragged file: The sum of the values in the rowSizes " +
                "variable (rowSize sum=1024368) is greater than the size of the " +
                "observationDimension (obs size=1022528).") < 0)
                throw e;
        }

        /* */
        debugMode = oDebug;        
    }

    /** This tests readNcCF nLevels=1. */
    public static void testReadNcCF1Kevin() throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCF1Kevin");
        String pauseMessage = "\nOK?";
        Table table = new Table();
        String results, expected;
        String fileName = "c:/data/kevin/interpolated_gld.20120620_045152_meta_2.nc";  //from Kevin O'Brien
        Attributes gatts;
    
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        String2.log(table.toString());
        debugMode = oDebug;
    }

    /** This tests reading the gocd nccf files. */
    public static void testReadGocdNcCF() throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadGocdNcCF");
        Table table = new Table();
        String results, expected;
        String fileName;
        int po;
        ByteArrayOutputStream os = new ByteArrayOutputStream();

/*
        //*************** non-standard timeSeries file -- TOO WEIRD, don't support it
        //some var var[time=7022][z=1], depth[z=1] 
        //and other station vars (latitude, longitude) with no dimensions
        fileName = "/data/gocd/gocdNcCF/gocd_v3_cmetr.nc"; 
        String2.log("\n\n** Testing " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
//  dimensions:
//    z = 1;
//    time = 7022;
//    float sampling_interval;  // :_FillValue = 9999.9f; // float
//    float seafloor_depth;
//    float latitude;
//    float longitude;
//    int latitude_quality_flag;
//    int longitude_quality_flag;
//    int crs;

//    float depth(z=1);
//    int depth_quality_flag(z=1);

//    double time(time=7022);
//    int time_quality_flag(time=7022);

//    float u(time=7022, z=1);
//    int u_quality_flag(time=7022, z=1);
//    float v(time=7022, z=1);
//    int v_quality_flag(time=7022, z=1);
//    float current_speed(time=7022, z=1);
//    int current_speed_quality_flag(time=7022, z=1);
//    float current_direction(time=7022, z=1);
//    int current_direction_quality_flag(time=7022, z=1);

// global attributes:
//  :gocd_id = "gocd_a0084999_tr1162.nc";
//  :id = "0093183";
//  :featureType = "timeSeries";
//  :cdm_data_type = "Station";
//  :instrument_type = "";
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        //String2.log(table.toCSVString());
        results = table.dataToString(5);
        expected = 
"zztop\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        /* */


        //*************** trajectory profile 
        //This is important test of Table.readNcCF 
        //  if multidimensional file, 2 levels, and outerDim=ScalarDim
        //  this tests if var[scalarDim][obs] was read (e.g., depth[obs]
        //File dims are outerDim=[scalarDim], inner=[time], obs=[obs]
        table = new Table();
        fileName = String2.unitTestDataDir + "gocdNcCF/gocd_v3_sadcp.nc"; 
        String2.log("\n\n** Testing " + fileName);
        results = NcHelper.ncdump(fileName, "-h"); 
        String2.log(results);
//just the structure, rearranged into groups
//  dimensions:
//    time = 501;
//    z = 70;

//    float sampling_interval;
//    int crs;
//
//    float seafloor_depth(time=501);
//    float latitude(time=501);
//    float longitude(time=501);
//    double time(time=501);
//    int latitude_quality_flag(time=501);
//    int longitude_quality_flag(time=501);
//    int time_quality_flag(time=501);
//
//    float depth(z=70);
//    int depth_quality_flag(z=70);
//
//    float u(time=501, z=70);
//    int u_quality_flag(time=501, z=70);
//    float v(time=501, z=70);
//    int v_quality_flag(time=501, z=70);
//    float current_speed(time=501, z=70);
//    int current_speed_quality_flag(time=501, z=70);
//    float current_direction(time=501, z=70);
//    int current_direction_quality_flag(time=501, z=70);

        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        os.reset();
        table.saveAsDAS(os, SEQUENCE_NAME);
        results = os.toString();
        expected = 
"Attributes {\n" +
" s {\n" +
"  sampling_interval {\n" +
"    Float32 _FillValue 9999.9;\n" +
"    String long_name \"Sampling Interval\";\n" +
"    String units \"minutes\";\n" +
"  }\n" +
"  seafloor_depth {\n" +
"    Float32 _FillValue 9999.9;\n" +
"    String long_name \"Seafloor Depth\";\n" +
"    String postive \"down\";\n" +
"    String units \"meters\";\n" +
"  }\n" +
"  latitude {\n" +
"    Float32 _FillValue 9999.9;\n" +
"    String ancillary_variables \"latitude_quality_flag\";\n" +
"    String axis \"Y\";\n" +
"    Float64 data_max 21.0958;\n" +
"    Float64 data_min -14.3883;\n" +
"    String grid_mapping \"crs\";\n" +
"    String long_name \"latitude\";\n" +
"    String standard_name \"latitude\";\n" +
"    String units \"degrees_north\";\n" +
"    Float32 valid_max 90.0;\n" +
"    Float32 valid_min -90.0;\n" +
"  }\n" +
"  longitude {\n" +
"    Float32 _FillValue 9999.9;\n" +
"    String ancillary_variables \"longitude_quality_flag\";\n" +
"    String axis \"X\";\n" +
"    Float64 data_max -158.3554;\n" +
"    Float64 data_min -176.8126;\n" +
"    String grid_mapping \"crs\";\n" +
"    String long_name \"longitude\";\n" +
"    String standard_name \"longitude\";\n" +
"    String units \"degrees_east\";\n" +
"    Float32 valid_max 180.0;\n" +
"    Float32 valid_min -180.0;\n" +
"  }\n" +
"  latitude_quality_flag {\n" +
"    Int32 _FillValue -9;\n" +
"    String flag_meanings \"good_value probably_good probably_bad bad_value modified_value not_used not_used not_used missing_value\";\n" +
"    Int32 flag_values 1, 2, 3, 4, 5, 6, 7, 8, 9;\n" +
"    String long_name \"Latitude Quality Flag\";\n" +
"  }\n" +
"  longitude_quality_flag {\n" +
"    Int32 _FillValue -9;\n" +
"    String flag_meanings \"good_value probably_good probably_bad bad_value modified_value not_used not_used not_used missing_value\";\n" +
"    Int32 flag_values 1, 2, 3, 4, 5, 6, 7, 8, 9;\n" +
"    String long_name \"Longitude Quality Flag\";\n" +
"  }\n" +
"  depth {\n" +
"    String C_format \"%7.2f\";\n" +
"    Float64 data_max 720.0;\n" +
"    Float64 data_min 30.0;\n" +
"    String FORTRAN_format \"F7.2\";\n" +
"    String long_name \"Depth\";\n" +
"    String postive \"down\";\n" +
"    String units \"meters\";\n" +
"    Float32 valid_max 15000.0;\n" +
"    Float32 valid_min 0.0;\n" +
"  }\n" +
"  depth_quality_flag {\n" +
"    Int32 _FillValue -9;\n" +
"    String flag_meanings \"good_value probably_good probably_bad bad_value modified_value not_used not_used not_used missing_value\";\n" +
"    Int32 flag_values 1, 2, 3, 4, 5, 6, 7, 8, 9;\n" +
"    String long_name \"Depth QC Flags\";\n" +
"  }\n" +
"  time {\n" +
"    String ancillary_variables \"time_quality_flag\";\n" +
"    String axis \"T\";\n" +
"    String C_format \"%9.4f\";\n" +
"    Float64 data_max 38751.8319444442;\n" +
"    Float64 data_min 38730.9986111112;\n" +
"    String FORTRAN_format \"F9.4\";\n" +
"    String long_name \"time\";\n" +
"    String standard_name \"time\";\n" +
"    String units \"days since 1900-01-01 00:00:00Z\";\n" +
"  }\n" +
"  time_quality_flag {\n" +
"    Int32 _FillValue -9;\n" +
"    String flag_meanings \"good_value probably_good probably_bad bad_value modified_value not_used not_used not_used missing_value\";\n" +
"    Int32 flag_values 1, 2, 3, 4, 5, 6, 7, 8, 9;\n" +
"    String long_name \"Time Quality Flag\";\n" +
"  }\n" +
"  u {\n" +
"    Float32 _FillValue 9999.9;\n" +
"    String ancillary_variables \"u_quality_flag\";\n" +
"    String C_format \"%7.4f\";\n" +
"    String cell_methods \"time:point z:point\";\n" +
"    String coordinates \"time z\";\n" +
"    Float64 data_max 0.883000030517578;\n" +
"    Float64 data_min -1.25;\n" +
"    String FORTRAN_format \"F7.4\";\n" +
"    String grid_mapping \"crs\";\n" +
"    String long_name \"Eastward Velocity Component\";\n" +
"    String standard_name \"eastward_sea_water_velocity\";\n" +
"    String units \"m s-1\";\n" +
"    Float64 valid_max 5.0;\n" +
"    Float64 valid_min -5.0;\n" +
"  }\n" +
"  u_quality_flag {\n" +
"    Int32 _FillValue -9;\n" +
"    String flag_meanings \"good_value probably_good probably_bad bad_value modified_value not_used not_used not_used missing_value\";\n" +
"    Int32 flag_values 1, 2, 3, 4, 5, 6, 7, 8, 9;\n" +
"    String long_name \"Eastward Velocity component QC Flags\";\n" +
"  }\n" +
"  v {\n" +
"    Float32 _FillValue 9999.9;\n" +
"    String ancillary_variables \"v_quality_flag\";\n" +
"    String C_format \"%7.4f\";\n" +
"    String cell_methods \"time:point z:point\";\n" +
"    String coordinates \"time z\";\n" +
"    Float64 data_max 0.733;\n" +
"    Float64 data_min -0.695;\n" +
"    String FORTRAN_format \"F7.4\";\n" +
"    String grid_mapping \"crs\";\n" +
"    String long_name \"Northward Velocity Component\";\n" +
"    String standard_name \"northward_sea_water_velocity\";\n" +
"    String units \"m s-1\";\n" +
"    Float64 valid_max 5.0;\n" +
"    Float64 valid_min -5.0;\n" +
"  }\n" +
"  v_quality_flag {\n" +
"    Int32 _FillValue -9;\n" +
"    String flag_meanings \"good_value probably_good probably_bad bad_value modified_value not_used not_used not_used missing_value\";\n" +
"    Int32 flag_values 1, 2, 3, 4, 5, 6, 7, 8, 9;\n" +
"    String long_name \"Northward Velocity component QC Flags\";\n" +
"  }\n" +
"  current_speed {\n" +
"    Float32 _FillValue 9999.9;\n" +
"    String ancillary_variables \"current_direction_quality_flag\";\n" +
"    String C_format \"%7.4f\";\n" +
"    String cell_methods \"time:point z:point\";\n" +
"    String coordinates \"time z\";\n" +
"    Float64 data_max 141.42;\n" +
"    Float64 data_min 0.0;\n" +
"    String FORTRAN_format \"F7.4\";\n" +
"    String grid_mapping \"crs\";\n" +
"    String long_name \"Current_Speed\";\n" +
"    String units \"m s-1\";\n" +
"    Float64 valid_max 7.0711;\n" +
"    Float64 valid_min 0.0;\n" +
"  }\n" +
"  current_speed_quality_flag {\n" +
"    String flag_meanings \"good_value probably_good probably_bad bad_value modified_value not_used not_used not_used missing_value\";\n" +
"    Int32 flag_values 1, 2, 3, 4, 5, 6, 7, 8, 9;\n" +
"    String long_name \"Current Speed QC Flags\";\n" +
"  }\n" +
"  current_direction {\n" +
"    Float32 _FillValue 9999.9;\n" +
"    String ancillary_variables \"current_direction_quality_flag\";\n" +
"    String C_format \"%5.1f\";\n" +
"    String cell_methods \"time:point z:point\";\n" +
"    String comment \"True Direction toward which current is flowing\";\n" +
"    String coordinates \"time z\";\n" +
"    Float64 data_max 360.0;\n" +
"    Float64 data_min 0.3;\n" +
"    String FORTRAN_format \"F5.1\";\n" +
"    String grid_mapping \"crs\";\n" +
"    String long_name \"Current Direction\";\n" +
"    String units \"degrees\";\n" +
"    Float64 valid_max 360.0;\n" +
"    Float64 valid_min 0.0;\n" +
"  }\n" +
"  current_direction_quality_flag {\n" +
"    String flag_meanings \"good_value probably_good probably_bad bad_value modified_value not_used not_used not_used missing_value\";\n" +
"    Int32 flag_values 1, 2, 3, 4, 5, 6, 7, 8, 9;\n" +
"    String long_name \"Current Direction QC Flags\";\n" +
"  }\n" +
"  crs {\n" +
"    String epsg_code \"EPSG:4326\";\n" +
"    String grid_mapping_name \"latitude_longitude\";\n" +
"    String inverse_flattening \"298.257223563\";\n" +
"    String long_name \"Coordinate Reference System\";\n" +
"    String longitude_of_prime_meridian \"0.0f\";\n" +
"    String semi_major_axis \"6378137.0\";\n" +
"  }\n" +
" }\n" +
"  NC_GLOBAL {\n" +
"    String acknowledgment \"These data were acquired from the US NOAA National Centers for Environmental Information (NCEI) on [DATE] from http://www.nodc.noaa.gov/gocd/.\";\n" +
"    String cdm_data_type \"TrajectoryProfile\";\n" +
"    String cdm_profile_variables \"seafloor_depth, latitude, longitude, latitude_quality_flag, longitude_quality_flag, time, time_quality_flag\";\n" +
"    String cdm_trajectory_variables \"sampling_interval, crs\";\n" +
"    String contributor \"University of Hawaii and NOAA/NMFS\";\n" +
"    String Conventions \"CF-1.6\";\n" +
"    String creator_email \"Charles.Sun@noaa.gov\";\n" +
"    String creator_name \"Charles Sun\";\n" +
"    String creator_url \"http://www.nodc.noaa.gov\";\n" +
"    String date_created \"2014-12-15T20:20:04Z\";\n" +
"    String date_issued \"2016-01-18T04:39:10Z\";\n" +
"    String date_modified \"2016-01-18T04:39:10Z\";\n" +
"    String featureType \"trajectoryProfile\";\n" +
"    Float32 geospatial_lat_max 21.0958;\n" +
"    Float32 geospatial_lat_min -14.3883;\n" +
"    String geospatial_lat_resolution \"point\";\n" +
"    String geospatial_lat_units \"degrees_north\";\n" +
"    Float32 geospatial_lon_max -158.3554;\n" +
"    Float32 geospatial_lon_min -176.8126;\n" +
"    String geospatial_lon_resolution \"point\";\n" +
"    String geospatial_lon_units \"degrees_east\";\n" +
"    Float32 geospatial_vertical_max 720.0;\n" +
"    Float32 geospatial_vertical_min 30.0;\n" +
"    String geospatial_vertical_positive \"down\";\n" +
"    String geospatial_vertical_resolution \"point\";\n" +
"    String geospatial_vertical_units \"meters\";\n" +
"    String gocd_format_version \"GOCD-3.0\";\n" +
"    String gocd_id \"gocd_a0067774_01192v3.nc\";\n" +
"    String grid_mapping_epsg_code \"EPSG:4326\";\n" +
"    String grid_mapping_inverse_flattening \"298.257223563\";\n" +
"    String grid_mapping_long_name \"Coordinate Reference System\";\n" +
"    String grid_mapping_longitude_of_prime_meridian \"0.0f\";\n" +
"    String grid_mapping_name \"latitude_longitude\";\n" +
"    String grid_mapping_semi_major_axis \"6378137.0\";\n" +
"    String history \"Wed Feb 10 18:31:43 2016: ncrename -d depth,z test.nc\n" +
"2016-01-18T04:39:10Z csun updateOCD.R Version 2.0\n" +
"Thu Jan  7 15:59:35 2016: ncatted -a valid_max,seafloor_depth,d,, ../V3/a0067774/gocd_a0067774_01192v3.nc\n" +
"Thu Jan  7 15:59:35 2016: ncatted -a valid_min,seafloor_depth,d,, ../V3/a0067774/gocd_a0067774_01192v3.nc\n" +
"Thu Jan  7 15:59:35 2016: ncatted -a missing_value,seafloor_depth,d,, ../V3/a0067774/gocd_a0067774_01192v3.nc\n" +
"Thu Jan  7 15:59:35 2016: ncatted -a missing_value,sampling_interval,d,, ../V3/a0067774/gocd_a0067774_01192v3.nc\n" +
"2016-01-07T14:01:54Z csun updateGOCD.R Version 1.0\n" +
"2014-12-15T20:20:04Z csun convJASADCP.f90 Version 1.0\";\n" +
"    String id \"0093183\";\n" +
"    String institution \"NOAA National Centers for Environmental Information\";\n" +
"    String instrument_type \"Ocean Surveyor OS75\";\n" +
"    String keywords \"EARTH SCIENCE,OCEANS,OCEAN CIRCULATION,OCEAN CURRENTS\";\n" +
"    String keywords_vocabulary \"GCMD Science Keywords\";\n" +
"    String license \"These data are openly available to the public Please acknowledge the use of these data with the text given in the acknowledgment attribute.\";\n" +
"    String Metadata_Conventions \"Unidata Dataset Discovery v1.0\";\n" +
"    String naming_authority \"gov.noaa.nodc\";\n" +
"    String principal_invesigator \"E.Firing,J.Hummon,R.Brainard\";\n" +
"    String project_name \"Coral Reef Ecosystem Investigations\";\n" +
"    String publisher_email \"NODC.Services@noaa.gov\";\n" +
"    String publisher_name \"US DOC; NESDIS; NATIONAL CENTERS FOR ENVIRONMENTAL INFORMATION - IN295\";\n" +
"    String publisher_url \"http://www.nodc.noaa.gov/\";\n" +
"    String QC_indicator \"Contact Principle Investigaror(s)\";\n" +   //sic
"    String QC_Manual \"Contact Principle Investigaror(s)\";\n" +
"    String QC_Software \"Contact Principle Investigaror(s)\";\n" +
"    String QC_test_codes \"Contact Principle Investigaror(s)\";\n" +
"    String QC_test_names \"Contact Principle Investigaror(s)\";\n" +
"    String QC_test_results \"Contact Principle Investigaror(s)\";\n" +
"    String references \"http://www.nodc.noaa.gov/\";\n" +
"    String source \"global ocean currents in the NCEI archive holdings\";\n" +
"    String standard_name_vocabulary \"CF-1.6\";\n" +
"    String subsetVariables \"sampling_interval, crs, seafloor_depth, latitude, longitude, latitude_quality_flag, longitude_quality_flag, time, time_quality_flag\";\n" +
"    String summary \"global ocean currents in the NCEI archive holdings\";\n" +
"    String time_coverage_duration \"P0Y020DT20H00M00S\";\n" +
"    String time_coverage_end \"2006-02-05T19:58:00Z\";\n" +
"    String time_coverage_resolution \"R000501/2006-01-15T23:58:00Z/P0Y020DT20H00M00\";\n" +
"    String time_coverage_start \"2006-01-15T23:58:00Z\";\n" +
"    String title \"Global Ocean Currents Database  - gocd_a0067774_01192v3.nc\";\n" +
"    String uuid \"26f4a163-4c81-437b-9ad7-796822d1ce49\";\n" +
"  }\n" +
"}\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        os.reset();
        table.saveAsDDS(os, SEQUENCE_NAME);
        results = os.toString();
        expected = 
"Dataset {\n" +
"  Sequence {\n" +
"    Float32 sampling_interval;\n" +
"    Float32 seafloor_depth;\n" +
"    Float32 latitude;\n" +
"    Float32 longitude;\n" +
"    Int32 latitude_quality_flag;\n" +
"    Int32 longitude_quality_flag;\n" +
"    Float32 depth;\n" +
"    Int32 depth_quality_flag;\n" +
"    Float64 time;\n" +
"    Int32 time_quality_flag;\n" +
"    Float32 u;\n" +
"    Int32 u_quality_flag;\n" +
"    Float32 v;\n" +
"    Int32 v_quality_flag;\n" +
"    Float32 current_speed;\n" +
"    Int32 current_speed_quality_flag;\n" +
"    Float32 current_direction;\n" +
"    Int32 current_direction_quality_flag;\n" +
"    Int32 crs;\n" +
"  } s;\n" +
"} s;\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //String2.log(table.toCSVString());
        results = table.dataToString(5);
        expected = 
"sampling_interval,seafloor_depth,latitude,longitude,latitude_quality_flag,longitude_quality_flag," +
  "depth,depth_quality_flag,time,time_quality_flag,u,u_quality_flag,v,v_quality_flag," +
  "current_speed,current_speed_quality_flag,current_direction," +
  "current_direction_quality_flag,crs\n" +
// sapmInt,sfDpth lat      lon          depth  time         u        v       cspeed  cdir  crs
"9999.9,9999.9,21.0958,-158.3554,1,1,30.0,1,38730.9986,1,-0.004,1,0.174,1,0.174,1,358.7,1,0\n" +
"9999.9,9999.9,21.0958,-158.3554,1,1,40.0,1,38730.9986,1,-0.008,1,0.169,1,0.1692,1,357.3,1,0\n" +
"9999.9,9999.9,21.0958,-158.3554,1,1,50.0,1,38730.9986,1,-0.01,1,0.165,1,0.1653,1,356.5,1,0\n" +
"9999.9,9999.9,21.0958,-158.3554,1,1,60.0,1,38730.9986,1,-0.009,1,0.163,1,0.1632,1,356.8,1,0\n" +
"9999.9,9999.9,21.0958,-158.3554,1,1,70.0,1,38730.9986,1,-0.012,1,0.173,1,0.1734,1,356.0,1,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        results = table.dataToString(); //no row numbers
        expected =     //why are cspeed and cdir known, but u,v not?
//sampInt sfDpth lat      lon          depth   time         u         v         cspeed   cdir   crs
"9999.9,9999.9,-14.2758,-170.6805,1,1,680.0,1,38751.8319,1,9999.9,-9,9999.9,-9,141.42,1,45.0,1,0\n" +
"9999.9,9999.9,-14.2758,-170.6805,1,1,690.0,1,38751.8319,1,9999.9,-9,9999.9,-9,141.42,1,45.0,1,0\n" +
"9999.9,9999.9,-14.2758,-170.6805,1,1,700.0,1,38751.8319,1,9999.9,-9,9999.9,-9,141.42,1,45.0,1,0\n" +
"9999.9,9999.9,-14.2758,-170.6805,1,1,710.0,1,38751.8319,1,9999.9,-9,9999.9,-9,141.42,1,45.0,1,0\n" +
"9999.9,9999.9,-14.2758,-170.6805,1,1,720.0,1,38751.8319,1,9999.9,-9,9999.9,-9,141.42,1,45.0,1,0\n";
        po = results.indexOf(expected.substring(0, 40));
        Test.ensureEqual(results.substring(po), expected, 
            "results=\n" + results.substring(po));
        /* */


        //***************  a similar test
        //  2 levels, and outerDim=ScalarDim
        //  this tests if var[scalarDim][obs] was read (e.g., depth[obs]
        //File dims are outerDim=[scalarDim], inner=[time], obs=[obs]
        table = new Table();
        fileName = "/data/gocd/gocd_v3_madcp.nc"; 
        String2.log("\n\n** Testing " + fileName);
        results = NcHelper.ncdump(fileName, "-h");
        String2.log(results);
//just the structure, rearranged into groups
//   z = 14;
//   time = 3188;
//   int crs;
//   float sampling_interval;
//   float seafloor_depth;
//   float latitude;
//   float longitude;
//   int latitude_quality_flag;
//   int longitude_quality_flag;

//   float depth(z=14);
//   int depth_quality_flag(z=14);

//   double time(time=3188);
//   int time_quality_flag(time=3188);

//   float u(time=3188, z=14);
//   int u_quality_flag(time=3188, z=14);
//   float v(time=3188, z=14);
//   int v_quality_flag(time=3188, z=14);
//   float current_speed(time=3188, z=14);
//   int current_speed_quality_flag(time=3188, z=14);
//   float current_direction(time=3188, z=14);
//   int current_direction_quality_flag(time=3188, z=14);

        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        os.reset();
        table.saveAsDDS(os, SEQUENCE_NAME);
        results = os.toString();
        expected = 
"Dataset {\n" +
"  Sequence {\n" +
"    Float32 sampling_interval;\n" +
"    Float32 seafloor_depth;\n" +
"    Float32 latitude;\n" +
"    Float32 longitude;\n" +
"    Int32 latitude_quality_flag;\n" +
"    Int32 longitude_quality_flag;\n" +
"    Float32 depth;\n" +
"    Int32 depth_quality_flag;\n" +
"    Float64 time;\n" +
"    Int32 time_quality_flag;\n" +
"    Float32 u;\n" +
"    Int32 u_quality_flag;\n" +
"    Float32 v;\n" +
"    Int32 v_quality_flag;\n" +
"    Float32 current_speed;\n" +
"    Int32 current_speed_quality_flag;\n" +
"    Float32 current_direction;\n" +
"    Int32 current_direction_quality_flag;\n" +
"    Int32 crs;\n" +
"  } s;\n" +
"} s;\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //String2.log(table.toCSVString());
        results = table.dataToString(5);
        expected = 
"sampling_interval,seafloor_depth,latitude,longitude," +
"latitude_quality_flag,longitude_quality_flag,depth,depth_quality_flag,time,time_quality_flag,u,u_quality_flag,v,v_quality_flag," +
"current_speed,current_speed_quality_flag,current_direction," +
"current_direction_quality_flag,crs\n" +
// si   sDepth  lat      lon       q q depth q time       q u      q v      q cspeed q cDir q crs
"60.0,32.6386,42.37859,-70.78094,1,1,26.34,1,38621.7448,1,0.0066,1,0.0072,1,0.0111,1,42.8,1,0\n" +
"60.0,32.6386,42.37859,-70.78094,1,1,24.34,1,38621.7448,1,0.0279,1,-0.008,1,0.0292,1,106.0,1,0\n" +
"60.0,32.6386,42.37859,-70.78094,1,1,22.34,1,38621.7448,1,0.0325,1,2.0E-4,1,0.033,1,89.7,1,0\n" +
"60.0,32.6386,42.37859,-70.78094,1,1,20.34,1,38621.7448,1,-0.0094,1,0.0011,1,0.0121,1,277.0,1,0\n" +
"60.0,32.6386,42.37859,-70.78094,1,1,18.34,1,38621.7448,1,-0.0383,1,-0.0367,1,0.0532,1,226.2,1,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        results = table.dataToString(); //no row numbers
        //String2.log(results);
        expected =     //why are cspeed and cdir known, but u,v not?
//si   sDepth  lat      lon       q q depth q time     q u       q v       q cspeed q cDir  q crs
"60.0,32.6386,42.37859,-70.78094,1,1,8.34,1,38754.5365,1,-0.0177,1,-0.0152,1,0.0257,1,229.2,1,0\n" +
"60.0,32.6386,42.37859,-70.78094,1,1,6.34,1,38754.5365,1,-0.0186,1,-0.0145,1,0.0251,1,232.0,1,0\n" +
"60.0,32.6386,42.37859,-70.78094,1,1,4.34,1,38754.5365,1,-0.0149,1,-0.0181,1,0.03,1,219.4,1,0\n" +
"60.0,32.6386,42.37859,-70.78094,1,1,2.34,1,38754.5365,1,-0.0026,2,-0.0202,2,0.0293,1,187.4,2,0\n" +
"60.0,32.6386,42.37859,-70.78094,1,1,0.34,1,38754.5365,1,9999.9,9,9999.9,9,9999.9,9,45.0,9,0\n";
        po = results.indexOf(expected.substring(0, 80));
        Test.ensureEqual(results.substring(po), expected, 
            "results=\n" + results.substring(po));
        /* */


        // ************* v4 file #1 timeSeries has
        // featureType=timeSeriesProfile   cdm_data_type=profile
        // outerdim=scalar   var[time=6952][z=1]  time[time=6952] depth[z=1]
        table = new Table();
        fileName = "/data/gocd/gocd_a0000841_rcm00566_v4.nc"; 
        String2.log("\n\n** Testing " + fileName);
        results = NcHelper.ncdump(fileName, "-h");
        String2.log(results);
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        String2.log(table.dataToString());
        results = table.dataToString(5);
        expected = 
"sampling_interval,seafloor_depth,latitude,longitude,latitude_quality_flag," +
"longitude_quality_flag,depth,depth_quality_flag,time,time_quality_flag," +
"u,u_quality_flag,v,v_quality_flag,current_speed,current_speed_quality_flag," +
"current_direction,current_direction_quality_flag,crs\n" +
//si   sd     lat       lon        q q depth  q time               q u     q v      q cSpeed p dir q crs
"60.0,2640.0,62.894997,-35.857998,1,1,1980.0,1,31662.424999999814,1,0.015,1,0.0865,1,0.0878,1,9.8,1,0\n" +
"60.0,2640.0,62.894997,-35.857998,1,1,1980.0,1,31662.46666666679,1,-0.0045,1,0.0933,1,0.0934,1,357.2,1,0\n" +
"60.0,2640.0,62.894997,-35.857998,1,1,1980.0,1,31662.508333333302,1,-0.0072,1,0.0856,1,0.0859,1,355.2,1,0\n" +
"60.0,2640.0,62.894997,-35.857998,1,1,1980.0,1,31662.549999999814,1,-0.0065999995,1,0.1025,1,0.1027,1,356.3,1,0\n" +
"60.0,2640.0,62.894997,-35.857998,1,1,1980.0,1,31662.59166666679,1,-0.0036,1,0.11200001,1,0.1121,1,358.2,1,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        /* */

        //********************* v4 file #2 has
/*        // featureType=timeSeriesProfile   cdm_data_type=profile
        // latitude=scalar   var[time=126][z=12]  time[time=126] depth[z=12]
        table = new Table();
        fileName = "/data/gocd/gocd_a0060062_4381adc-a_v4.nc"; 
        String2.log("\n\n** Testing " + fileName);
        results = NcHelper.ncdump(fileName, "-h");
        String2.log(results);
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        String2.log(table.dataToString());
        results = table.dataToString(5);
        expected = 
"zz\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        /* */

        String2.log("\n*** Table.testReadGocdNcCF finished successfully");
        debugMode = oDebug;

    }

    /** This tests readNcCF nLevels=2. */
    public static void testReadNcCF2(boolean pauseAfterEach) throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCF2");
        String pauseMessage = "\nOK?";
        Table table = new Table();
        String results, expected;
        Attributes gatts;

 
        //***************  nLevels=2  multidimensional
        for (int type = 0; type < 2; type++) {
            //ncCF2b and ncCFMA2b have same data, so tests are the same!
            String fileType = type == 0? "ragged" : "multidimensional";
            //from EDDTableFromNcFiles.testNcCF2b() and testNcCFMA2b();
            String fileName = String2.unitTestDataDir + "nccf/" + 
                (type == 0? "ncCF2b.nc" : "ncCFMA2b.nc");
            String msg = "ERROR when type=" + type + ": ";

            String2.log("\n\n** Testing type=" + type + " nLevels=2/" + fileType + "\n" +
                "  " + fileName);
            String2.log(NcHelper.ncdump(fileName, "-h"));
/* */
            String2.log("\n\n** Test nLevels=2/" + fileType + "  no loadVars, no constraints");
            table.readNcCF(fileName, null, 0,  //standardizeWhat=0
                null, null, null);
String2.log(table.toString());
            results = table.dataToString(5);
            expected = 
"platform,cruise,org,type,station_id,longitude,latitude,time,depth,temperature,salinity\n" +
"33P2,Q990046312,ME,TE,13968849,176.64,-75.45,1.3351446E9,4.0,-1.84,35.64\n" +
"33P2,Q990046312,ME,TE,13968849,176.64,-75.45,1.3351446E9,10.0,-1.84,35.64\n" +
"33P2,Q990046312,ME,TE,13968849,176.64,-75.45,1.3351446E9,20.0,-1.83,35.64\n" +
"33P2,Q990046312,ME,TE,13968849,176.64,-75.45,1.3351446E9,30.0,-1.83,35.64\n" +
"33P2,Q990046312,ME,TE,13968849,176.64,-75.45,1.3351446E9,49.0,-1.83,35.64\n" +
"...\n";
            Test.ensureEqual(results, expected, msg);
            Test.ensureEqual(table.nRows(), 53, msg + table.toString());
            results = table.columnAttributes(0).toString();
            expected = 
"    comment=See the list of platform codes (sorted in various ways) at http://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html\n" +
"    ioos_category=Identifier\n" +
"    long_name=GTSPP Platform Code\n" +
"    references=http://www.nodc.noaa.gov/gtspp/document/codetbls/callist.html\n";
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), "platform, cruise", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
                "org, type, station_id, longitude, latitude, time", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                "platform, cruise, org, type, station_id, longitude, latitude, time", 
                msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue("type=" + type + ": " + fileType + " #3a " + pauseMessage); 

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("cruise,latitude,depth,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("cruise"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, msg);
                Test.ensureEqual(table.nColumns(), 0, msg);

                table.readNcCF(fileName, 
                    StringArray.fromCSV("cruise,latitude,depth,temperature"), 
                    0,  //standardizeWhat=0            
                    StringArray.fromCSV("latitude"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, msg);
                Test.ensureEqual(table.nColumns(), 0, msg);

                table.readNcCF(fileName, 
                    StringArray.fromCSV("cruise,latitude,depth,temperature"), 
                    0,  //standardizeWhat=0            
                    StringArray.fromCSV("depth"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, msg);
                Test.ensureEqual(table.nColumns(), 0, msg);

                table.readNcCF(fileName, 
                    StringArray.fromCSV("cruise,latitude,depth,temperature"), 
                    0,  //standardizeWhat=0            
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, msg);
                Test.ensureEqual(table.nColumns(), 0, msg);

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("latitude,depth,temperature"), 
                    0,  //standardizeWhat=0            
                    StringArray.fromCSV("latitude"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, msg);
                Test.ensureEqual(table.nColumns(), 0, msg);

                table.readNcCF(fileName, 
                    StringArray.fromCSV("latitude,depth,temperature"), 
                    0,  //standardizeWhat=0            
                    StringArray.fromCSV("depth"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, msg);
                Test.ensureEqual(table.nColumns(), 0, msg);

                table.readNcCF(fileName, 
                    StringArray.fromCSV("latitude,depth,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, msg);
                Test.ensureEqual(table.nColumns(), 0, msg);

                //
                table.readNcCF(fileName, StringArray.fromCSV("depth,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("depth"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, msg);
                Test.ensureEqual(table.nColumns(), 0, msg);

                table.readNcCF(fileName, StringArray.fromCSV("depth,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, StringArray.fromCSV("latitude,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("latitude"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("latitude,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, StringArray.fromCSV("latitude,cruise"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("latitude"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("latitude,cruise"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("cruise"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, StringArray.fromCSV("depth,cruise"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("depth"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("depth,cruise"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("cruise"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, StringArray.fromCSV("temperature,cruise"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("temperature,cruise"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("cruise"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, StringArray.fromCSV("cruise"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("cruise"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("latitude"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("latitude"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("depth"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("depth"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");


            //
            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just outerTable loadVars, constraints");
            table.readNcCF(fileName, StringArray.fromCSV("platform,cruise,zztop"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("platform"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("33P2"));
            results = table.dataToString();
            expected = 
"platform,cruise\n" +
"33P2,Q990046312\n";
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile",
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), "platform, cruise", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), null, 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), "platform, cruise", 
                msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue("type=" + type + ": " + fileType + " #3b " + pauseMessage); 

            //
            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just outerTable loadVars, constraints, NO_DATA");
            table.readNcCF(fileName, StringArray.fromCSV("platform,cruise,zztop"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("platform"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("zztop"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3c " + pauseMessage); 


            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just innerTable loadVars, no constraints");
            String2.log("ncdump of " + fileName + "\n" +  NcHelper.ncdump(fileName, "-v station_id;type"));
            table.readNcCF(fileName, 
                StringArray.fromCSV("station_id,zztop,type"), 
                0,  //standardizeWhat=0
                null, null, null);
            results = table.dataToString();
            expected = 
//before: 4th row with mv's is removed
//2020-08-03 now it isn't removed for type=1 because station_id is int with no defined _FillValue or missing_value and [3]=2147483647!
//  In other words: this is a flaw in the data file.
//  note type0=ragged, type1=multidimensional
"station_id,type\n" +
"13968849,TE\n" +
"13968850,TE\n" +
"13933177,BA\n" +
(type == 0? "" : "2147483647,\n"); 
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), null, 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), "type, station_id", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), "type, station_id", 
                msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3d " + pauseMessage); 


            //
            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just innerTable loadVars, constraints");
            table.readNcCF(fileName, StringArray.fromCSV("station_id,zztop,type"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_id"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("13933177"));
            results = table.dataToString();
            expected = 
"station_id,type\n" +
"13933177,BA\n";
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), null, 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), "type, station_id", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), "type, station_id", 
                msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3e " + pauseMessage); 


            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just innerTable loadVars, constraints, NO_DATA");
            table.readNcCF(fileName, StringArray.fromCSV("station_id,zztop,type"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_id"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("zztop"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3f " + pauseMessage); 


            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just outerTable and innerTable loadVars, no constraints");
            table.readNcCF(fileName, StringArray.fromCSV(
                "cruise,org,type,station_id,longitude,latitude,time,zztop,platform"), 
                0,  //standardizeWhat=0
                null, null, null);
            results = table.dataToString();
            expected = 
"cruise,org,type,station_id,longitude,latitude,time,platform\n" +
"Q990046312,ME,TE,13968849,176.64,-75.45,1.3351446E9,33P2\n" +
"Q990046312,ME,TE,13968850,176.64,-75.43,1.335216E9,33P2\n" +
"SHIP    12,ME,BA,13933177,173.54,-34.58,1.33514142E9,9999\n" +
(type == 0? "" : "SHIP    12,,,2147483647,,,,9999\n"); //2020-08-03 this also appeared. See 2020-08-03 comments above
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), "platform, cruise", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
                "org, type, station_id, longitude, latitude, time", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                "platform, cruise, org, type, station_id, longitude, latitude, time", 
                msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3g " + pauseMessage); 


            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just outerTable and innerTable loadVars, constraints");
            table.readNcCF(fileName, StringArray.fromCSV(
                "row,cruise,org,type,station_id,longitude,latitude,time,zztop,platform"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("platform,station_id"), 
                StringArray.fromCSV("=,="),
                StringArray.fromCSV("33P2,13968850"));
            results = table.dataToString();
            expected = 
"cruise,org,type,station_id,longitude,latitude,time,platform\n" +
"Q990046312,ME,TE,13968850,176.64,-75.43,1.335216E9,33P2\n";
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), "platform, cruise", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
                "org, type, station_id, longitude, latitude, time", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                "platform, cruise, org, type, station_id, longitude, latitude, time", 
                msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3h " + pauseMessage); 

            //
            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just outerTable and innerTable loadVars, constraints, NO_DATA");
            table.readNcCF(fileName, StringArray.fromCSV(
                "row,cruise,org,type,station_id,longitude,latitude,time,zztop,platform"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("platform,station_id"), 
                StringArray.fromCSV("=,="),
                StringArray.fromCSV("33P2,zztop"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3i " + pauseMessage); 


            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just outerTable and obs loadVars, constraints");
            table.readNcCF(fileName, 
                StringArray.fromCSV("salinity,platform,zztop,cruise"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("platform,salinity"), 
                StringArray.fromCSV("=,>="),
                StringArray.fromCSV("33P2,35.98"));
            results = table.dataToString();
            expected = 
"salinity,platform,cruise\n" +
"35.99,33P2,Q990046312\n" +
"36.0,33P2,Q990046312\n" +
"35.98,33P2,Q990046312\n";
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), "platform, cruise", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), null, 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), "platform, cruise", 
                msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3j " + pauseMessage); 


            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just outerTable and obs loadVars, constraints, NO_DATA");
            table.readNcCF(fileName, 
                StringArray.fromCSV("salinity,platform,zztop,cruise"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("platform,salinity"), 
                StringArray.fromCSV("=,="),
                StringArray.fromCSV("33P2,-100"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3k " + pauseMessage); 


            String2.log("\n\n** Test nLevels=2/" + fileType + "  " + 
                "just innerTable and obs loadVars, no constraints");
            table.readNcCF(fileName, StringArray.fromCSV(
                "latitude,longitude,time,zztop,salinity"), 0,  //standardizeWhat=0
                null, null, null);
            results = table.dataToString();
            expected = 
"latitude,longitude,time,salinity\n" +
"-75.45,176.64,1.3351446E9,35.64\n" +
"-75.45,176.64,1.3351446E9,35.64\n" +
"-75.45,176.64,1.3351446E9,35.64\n" +
"-75.45,176.64,1.3351446E9,35.64\n" +
"-75.45,176.64,1.3351446E9,35.64\n" +
"-75.45,176.64,1.3351446E9,35.63\n" +
"-75.45,176.64,1.3351446E9,35.59\n" +
"-75.45,176.64,1.3351446E9,35.52\n" +
"-75.45,176.64,1.3351446E9,35.56\n" +
"-75.45,176.64,1.3351446E9,35.77\n" +
"-75.45,176.64,1.3351446E9,35.81\n" +
"-75.45,176.64,1.3351446E9,35.82\n" +
"-75.45,176.64,1.3351446E9,35.88\n" +
"-75.45,176.64,1.3351446E9,35.94\n" +
"-75.45,176.64,1.3351446E9,35.99\n" +
"-75.45,176.64,1.3351446E9,36.0\n" +
"-75.43,176.64,1.335216E9,35.64\n" +
"-75.43,176.64,1.335216E9,35.64\n" +
"-75.43,176.64,1.335216E9,35.64\n" +
"-75.43,176.64,1.335216E9,35.64\n" +
"-75.43,176.64,1.335216E9,35.63\n" +
"-75.43,176.64,1.335216E9,35.63\n" +
"-75.43,176.64,1.335216E9,35.61\n" +
"-75.43,176.64,1.335216E9,35.58\n" +
"-75.43,176.64,1.335216E9,35.5\n" +
"-75.43,176.64,1.335216E9,35.77\n" +
"-75.43,176.64,1.335216E9,35.81\n" +
"-75.43,176.64,1.335216E9,35.86\n" +
"-75.43,176.64,1.335216E9,35.9\n" +
"-75.43,176.64,1.335216E9,35.93\n" +
"-75.43,176.64,1.335216E9,35.96\n" +
"-75.43,176.64,1.335216E9,35.98\n";

//multidimensional deletes these rows because all read obs columns have mv's
//This is not ideal, but I don't want to read all obs columns in file to determine which rows to delete.
if (fileType.equals("ragged"))
    expected +=
"-34.58,173.54,1.33514142E9,\n" + 
"-34.58,173.54,1.33514142E9,\n" + 
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n" +
"-34.58,173.54,1.33514142E9,\n";
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), null, 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
                "longitude, latitude, time", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                "longitude, latitude, time", 
                msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3l " + pauseMessage); 


            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just innerTable and obs loadVars, constraints");
            table.readNcCF(fileName, 
                StringArray.fromCSV("latitude,longitude,time,zztop,salinity"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("time,salinity"), 
                StringArray.fromCSV("=,="),
                StringArray.fromCSV("1.335216E9,35.77"));
            results = table.dataToString();
            expected = 
"latitude,longitude,time,salinity\n" +
"-75.43,176.64,1.335216E9,35.77\n";
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), null, 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), 
                "longitude, latitude, time", msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), 
                "longitude, latitude, time", msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3m " + pauseMessage); 


            //
            String2.log("\n\n** Test nLevels=2/" + fileType + "  " +
                "just innerTable and obs loadVars, constraints, NO_DATA");
            table.readNcCF(fileName, 
                StringArray.fromCSV("latitude,longitude,time,zztop,salinity"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("time,salinity"), 
                StringArray.fromCSV("=,="),
                StringArray.fromCSV("1.335216E9,-1000"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3n " + pauseMessage); 


            String2.log("\n\n** Test nLevels=2/" + fileType + "  just obs loadVars, constraints");
            table.readNcCF(fileName, StringArray.fromCSV("temperature,salinity,zztop"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("salinity"),  
                StringArray.fromCSV("="),
                StringArray.fromCSV("35.77"));
            results = table.dataToString();
            expected = 
"temperature,salinity\n" +
"-1.1,35.77\n" +
"-1.12,35.77\n";
            Test.ensureEqual(results, expected, msg + "results=\n" + results);
            gatts = table.globalAttributes();
            Test.ensureEqual(gatts.getString("cdm_data_type"), "TrajectoryProfile", 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_trajectory_variables"), null, 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("cdm_profile_variables"), null, 
                msg + gatts.toString());
            Test.ensureEqual(gatts.getString("subsetVariables"), null, 
                msg + gatts.toString());
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3o " + pauseMessage); 


            // 
            String2.log("\n\n** Test nLevels=2/" + fileType + 
                "  just obs loadVars, constraints, NO_DATA");
            table.readNcCF(fileName, StringArray.fromCSV("temperature,salinity,zztop"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("salinity"),  
                StringArray.fromCSV("="),
                StringArray.fromCSV("-1000"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");
            if (pauseAfterEach) 
                String2.pressEnterToContinue(fileType + " #3p " + pauseMessage); 

        } //end nLevels=2 type loop

        debugMode = oDebug;        
    }


    /** This tests readNcCF profile files from ASA
     * via https://github.com/asascience-open/CFPointConventions
     * stored in unitTestDataDir/CFPointConventions.
     */
    public static void testReadNcCFASAProfile(boolean pauseAfterEach) throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCFASAProfile");
        String pauseMessage = "\nOK?";
        Table table = new Table();
        String results, expected, fileName;

/* */
        //***************  profile contiguous
        fileName = String2.unitTestDataDir + "CFPointConventions/profile/" +
            "profile-Contiguous-Ragged-MultipleProfiles-H.3.4/" +
            "profile-Contiguous-Ragged-MultipleProfiles-H.3.4.nc";
        String2.log("\n\n** Testing contiguous file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, ""));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(18);
        expected = 
/* pre 2012-10-02 was
"lat,lon,profile,time,z,temperature,humidity\n" +
"137.0,30.0,0,0,8.055641,32.962334,14.262256\n" +
"137.0,30.0,0,0,8.9350815,25.433783,41.722572\n" +
"137.0,30.0,0,0,5.1047354,4.0391192,44.34395\n" +
"137.0,30.0,0,0,4.2890472,6.0850625,13.220096\n" +
"137.0,30.0,0,0,1.9311341,32.794086,32.313293\n"; */
//z seems to be made up numbers. not in order (for a given profile) as one would expect.
"lat,lon,profile,time,z,temperature,humidity\n" +
"34.0,115.0,0,0,9.913809,30.592709,32.71529\n" +
"34.0,115.0,0,0,5.699307,17.442251,76.26051\n" +
"34.0,115.0,0,0,0.617254,14.230382,13.789284\n" +
"34.0,115.0,0,0,2.6114788,38.859676,21.792738\n" +
"34.0,115.0,0,0,6.519849,28.003593,33.264217\n" +
"34.0,115.0,0,0,8.975919,10.699942,61.52172\n" +
"34.0,115.0,0,0,9.912431,32.747574,85.96188\n" +
"34.0,115.0,0,0,7.5545244,18.109398,41.733406\n" +
"34.0,115.0,0,0,7.568512,10.165248,84.50128\n" +
"34.0,115.0,0,0,3.376015,0.48572874,5.2108083\n" +
"11.0,95.0,1,3600,0.16332848,1.193263,87.431725\n" +
"11.0,95.0,1,3600,4.9485574,31.53037,65.04175\n" +
"11.0,95.0,1,3600,6.424919,11.956788,54.758873\n" +
"11.0,95.0,1,3600,4.7111635,36.69692,50.6536\n" +
"11.0,95.0,1,3600,6.854408,21.065716,83.941765\n" +
"11.0,95.0,1,3600,9.321201,31.395382,17.139112\n" +
"176.0,17.0,2,7200,7.2918577,17.65049,66.33111\n" +
"176.0,17.0,2,7200,3.270435,35.854877,17.296724\n" +
"...\n";


        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 58, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#4a " + pauseMessage); 

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, StringArray.fromCSV("lat,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("lat,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, StringArray.fromCSV("lat,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("lat,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");


                //
                table.readNcCF(fileName, StringArray.fromCSV("z,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("z,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, StringArray.fromCSV("temperature,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("temperature,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, StringArray.fromCSV("profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("lat"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, StringArray.fromCSV("z"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");


        //test get outer+obs variables with outer constraint
        table.readNcCF(fileName, StringArray.fromCSV("profile,lat,lon,temperature"),
            0,  //standardizeWhat=0
            StringArray.fromCSV("lat"), StringArray.fromCSV("="), StringArray.fromCSV("11"));
        results = table.dataToString();
        expected = 
"profile,lat,lon,temperature\n" +
"1,11.0,95.0,1.193263\n" +
"1,11.0,95.0,31.53037\n" +
"1,11.0,95.0,11.956788\n" +
"1,11.0,95.0,36.69692\n" +
"1,11.0,95.0,21.065716\n" +
"1,11.0,95.0,31.395382\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test get outer+obs variables with obs constraint
        table.readNcCF(fileName, StringArray.fromCSV("profile,lat,lon,temperature"),
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"), StringArray.fromCSV("="), StringArray.fromCSV("11.956788"));
        results = table.dataToString();
        expected = 
"profile,lat,lon,temperature\n" +
"1,11.0,95.0,11.956788\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test get obs variables with outer constraint
        table.readNcCF(fileName, StringArray.fromCSV("lat,temperature"),
            0,  //standardizeWhat=0
            StringArray.fromCSV("lat"), StringArray.fromCSV("="), StringArray.fromCSV("11"));
        results = table.dataToString();
        expected = 
"lat,temperature\n" +
"11.0,1.193263\n" +
"11.0,31.53037\n" +
"11.0,11.956788\n" +
"11.0,36.69692\n" +
"11.0,21.065716\n" +
"11.0,31.395382\n";
        Test.ensureEqual(results, expected, "results=\n" + results);




        //***************  profile incomplete multidimensional --- 
        fileName = String2.unitTestDataDir + "CFPointConventions/profile/" +
            "profile-Incomplete-MultiDimensional-MultipleProfiles-H.3.2/" +
            "profile-Incomplete-MultiDimensional-MultipleProfiles-H.3.2.nc";
        String2.log("\n\n** Testing incomplete\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(45);
        expected = 
"lat,lon,profile,time,alt,temperature,humidity,wind_speed\n" +
"171.0,119.0,0,0,3.6755686,17.65279,-999.9,51.078896\n" +
"171.0,119.0,0,0,0.26343155,6.2052555,-999.9,64.199974\n" +
"171.0,119.0,0,0,3.175112,12.011641,-999.9,6.9850345\n" +
"171.0,119.0,0,0,4.208357,21.89748,-999.9,58.273148\n" +
"171.0,119.0,0,0,2.6554945,21.416033,-999.9,71.660774\n" +
"171.0,119.0,0,0,4.9972143,1.4952343,-999.9,31.470207\n" +
"171.0,119.0,0,0,1.9827757,21.466,-999.9,11.440447\n" +
"171.0,119.0,0,0,4.1058283,14.191161,-999.9,21.072964\n" +
"171.0,119.0,0,0,5.648934,7.727216,-999.9,20.63561\n" +
"171.0,119.0,0,0,1.2512851,21.434706,-999.9,60.469204\n" +
"171.0,119.0,0,0,9.600934,2.1928697,-999.9,71.77351\n" +
"171.0,119.0,0,0,1.9799258,16.0188,-999.9,55.211063\n" +
"171.0,119.0,0,0,1.2364764,3.242274,-999.9,11.2599\n" +
"171.0,119.0,0,0,2.834809,39.97538,-999.9,84.81159\n" +
"171.0,119.0,0,0,3.950956,19.135057,-999.9,29.651375\n" +
"171.0,119.0,0,0,8.663035,36.685486,-999.9,16.686064\n" +
"171.0,119.0,0,0,1.8081368,31.313751,-999.9,55.862072\n" +
"171.0,119.0,0,0,7.7147174,22.89713,-999.9,55.927597\n" +
"171.0,119.0,0,0,9.629576,18.616583,-999.9,68.66041\n" +
"171.0,119.0,0,0,6.9754705,7.9321976,-999.9,60.648094\n" +
"171.0,119.0,0,0,2.7991323,11.907311,-999.9,67.411575\n" +
"171.0,119.0,0,0,1.5943866,29.448673,-999.9,79.15605\n" +
"171.0,119.0,0,0,0.9762172,3.3020692,-999.9,85.00339\n" +
"171.0,119.0,0,0,5.5088353,12.813819,-999.9,77.104706\n" +
"171.0,119.0,0,0,7.2601357,38.730194,-999.9,18.446539\n" +
"171.0,119.0,0,0,8.384121,19.790619,-999.9,74.80566\n" +
"171.0,119.0,0,0,6.4686337,23.498947,-999.9,76.68345\n" +
"171.0,119.0,0,0,2.0993211,21.344112,-999.9,28.282118\n" +
"171.0,119.0,0,0,0.8403456,17.045395,-999.9,88.80201\n" +
"171.0,119.0,0,0,9.251101,15.639243,-999.9,70.71877\n" +
"171.0,119.0,0,0,1.3482393,9.54115,-999.9,59.91356\n" +
"171.0,119.0,0,0,3.6940877,30.967232,-999.9,35.620453\n" +
"171.0,119.0,0,0,6.3351345,6.0343504,-999.9,44.98056\n" +
"171.0,119.0,0,0,6.3332343,20.940767,-999.9,76.89658\n" +
"171.0,119.0,0,0,0.053762503,20.765089,-999.9,12.856414\n" +
"171.0,119.0,0,0,1.0131614,12.508157,-999.9,69.99224\n" +
"171.0,119.0,0,0,4.424666,37.28969,-999.9,24.69326\n" +
"171.0,119.0,0,0,1.5825375,17.199543,-999.9,63.037647\n" +
"171.0,119.0,0,0,3.072151,13.194056,-999.9,33.561863\n" +
"171.0,119.0,0,0,5.897976,6.350154,-999.9,9.787908\n" +
"171.0,119.0,0,0,1.6135278,22.95996,-999.9,85.10665\n" +
"171.0,119.0,0,0,6.9384937,7.619196,-999.9,33.569344\n" +
"155.0,158.0,1,3600,2.1733663,4.981018,-999.9,41.24567\n" +
"155.0,158.0,1,3600,2.189715,16.313164,-999.9,8.15441\n" +
"155.0,158.0,1,3600,9.445334,18.173727,-999.9,52.259445\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        //  42 * 142 = 5964 obs spaces, so it is incomplete 
        Test.ensureEqual(table.nRows(), 5754, ""); 
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#4b " + pauseMessage); 

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,alt,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,alt,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,alt,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("alt"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,alt,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,alt,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,alt,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("alt"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,alt,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("alt,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("alt"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("alt,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");


                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("alt,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("alt"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("alt,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("temperature,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("temperature,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("alt"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("alt"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");



        //***************  profile indexed        IMPORTANT - I didn't have sample of indexed
    try {
        fileName = String2.unitTestDataDir + "CFPointConventions/profile/" +
            "profile-Indexed-Ragged-MultipleProfiles-H.3.5/" +
            "profile-Indexed-Ragged-MultipleProfiles-H.3.5.nc";
        String2.log("\n\n** Testing indexed file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, ""));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
String2.log(table.dataToString());
        results = table.dataToString(20);
        expected = 
"lat,lon,profile,time,z,temperature,humidity\n" +
"93.0,71.0,0,0,0.38200212,23.69535,52.60904\n" +
"93.0,71.0,0,0,1.200709,29.121883,12.060117\n" +
"93.0,71.0,0,0,2.6969194,23.355228,9.943134\n" +
"93.0,71.0,0,0,3.4035592,21.57062,75.10006\n" +
"93.0,71.0,0,0,5.829337,2.9969826,17.760695\n" +
"93.0,71.0,0,0,5.8626857,37.635395,86.32262\n" +
"93.0,71.0,0,0,6.5773344,2.3481517,85.33706\n" +
"93.0,71.0,0,0,7.7204447,5.337912,54.993973\n" +
"93.0,71.0,0,0,8.301987,32.431896,88.71708\n" +
"93.0,71.0,0,0,9.088309,30.518106,44.74581\n" +
"45.0,151.0,1,3600,0.47979552,28.567852,65.933014\n" +
"45.0,151.0,1,3600,0.594338,7.940218,79.38502\n" +
"45.0,151.0,1,3600,4.0314445,20.808128,13.365513\n" +
"45.0,151.0,1,3600,6.101271,4.62561,8.945877\n" +
"45.0,151.0,1,3600,6.1228404,13.251722,50.431633\n" +
"45.0,151.0,1,3600,8.454789,17.803867,4.852586\n" +
"169.0,145.0,2,7200,1.9213479,7.1473145,11.227387\n" +
"169.0,145.0,2,7200,3.328237,27.21546,29.352453\n" +
"112.0,9.0,3,10800,0.009190708,6.3910594,56.909916\n" +
"112.0,9.0,3,10800,0.013856917,13.634793,63.741573\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 100, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#4c " + pauseMessage); 

//"19,112.0,9.0,3,10800,0.013856917,13.634793,63.741573\n";
        table.readNcCF(fileName, 
                StringArray.fromCSV("profile,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("profile,temperature"), 
                StringArray.fromCSV("=,="),
                StringArray.fromCSV("3,13.634793"));
        results = table.dataToString();
        expected = 
"profile,temperature\n" +
"3,13.634793\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,profile"), 
                    0,  //standardizeWhat=0
                StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");


                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("z,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("z,profile"), 
                    0,  //standardizeWhat=0
                StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("temperature,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("temperature,profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("profile"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("profile"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("z"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");



        //"19,112.0,9.0,3,10800,0.013856917,13.634793,63.741573\n";
        table.readNcCF(fileName, 
                StringArray.fromCSV("profile,z"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("profile,z"), 
                StringArray.fromCSV("=,="),
                StringArray.fromCSV("3,0.013856917"));
        results = table.dataToString();
        expected = 
"profile,z\n" +
"3,0.013856917\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        String2.log("\n\n** Testing indexed file NO_DATA - inner");
        table.readNcCF(fileName, 
            StringArray.fromCSV("lat,lon,profile,time,z,temperature,humidity"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("z"), 
            StringArray.fromCSV("="), 
            StringArray.fromCSV("-10000"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#4d " + pauseMessage); 


        String2.log("\n\n** Testing indexed file NO_DATA - odd combo"); 
        table.readNcCF(fileName, 
            StringArray.fromCSV("lat,lon,profile,time,z,temperature,humidity"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("lat,z"), 
            StringArray.fromCSV("=,="), 
            StringArray.fromCSV("93,0.594338")); //actual values, but never in this combination
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#4e " + pauseMessage); 


        String2.log("\n\n** Testing indexed file NO_DATA - outer");
        table.readNcCF(fileName, 
            StringArray.fromCSV("lat,lon,profile,time,z,temperature,humidity"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("humidity"), 
            StringArray.fromCSV("="), 
            StringArray.fromCSV("-10000"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#4f " + pauseMessage); 

    } catch (Exception e) {
        String2.pressEnterToContinue(MustBe.throwableToString(e)); 
    }


        //***************  profile orthogonal        
        fileName = String2.unitTestDataDir + "CFPointConventions/profile/" +
            "profile-Orthogonal-MultiDimensional-MultipleProfiles-H.3.1/" +
            "profile-Orthogonal-MultiDimensional-MultipleProfiles-H.3.1.nc";
        String2.log("\n\n** Testing orthogonal file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, ""));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(55);
        expected =   //z[obs] is in the innerTable
"lat,lon,profile,time,z,temperature,humidity\n" +
"19.0,116.0,0,0,1.6315197,15.477672,45.439682\n" +
"19.0,116.0,0,0,7.0598154,31.758614,35.987625\n" +
"19.0,116.0,0,0,0.36953768,2.4893014,65.79051\n" +
"19.0,116.0,0,0,7.5342026,26.857018,48.042828\n" +
"19.0,116.0,0,0,7.404938,19.151163,35.629215\n" +
"19.0,116.0,0,0,1.4442251,24.565704,37.29833\n" +
"19.0,116.0,0,0,9.80883,15.455084,23.763685\n" +
"19.0,116.0,0,0,8.060886,26.090511,14.579169\n" +
"19.0,116.0,0,0,1.965906,8.010671,69.79476\n" +
"19.0,116.0,0,0,9.60608,26.692741,78.83376\n" +
"19.0,116.0,0,0,9.839138,39.378746,37.22304\n" +
"19.0,116.0,0,0,6.2004266,14.685706,39.81143\n" +
"19.0,116.0,0,0,6.9113455,7.344667,18.64804\n" +
"19.0,116.0,0,0,8.798231,7.1495833,25.831097\n" +
"19.0,116.0,0,0,2.3565977,0.25708458,32.442547\n" +
"19.0,116.0,0,0,8.742956,34.86492,49.41099\n" +
"19.0,116.0,0,0,8.557564,35.413876,66.573906\n" +
"19.0,116.0,0,0,9.6161375,37.28068,4.6605506\n" +
"19.0,116.0,0,0,6.610992,5.4654717,60.635574\n" +
"19.0,116.0,0,0,1.936887,33.513893,82.823166\n" +
"19.0,116.0,0,0,3.0184858,31.41321,75.51568\n" +
"19.0,116.0,0,0,2.5581324,15.092895,79.2067\n" +
"19.0,116.0,0,0,7.1288857,20.573462,27.601343\n" +
"19.0,116.0,0,0,1.5220404,0.5649648,3.6447735\n" +
"19.0,116.0,0,0,3.276416,27.345316,62.10269\n" +
"19.0,116.0,0,0,0.40930283,27.671362,79.762955\n" +
"19.0,116.0,0,0,2.4845016,31.252121,61.57929\n" +
"19.0,116.0,0,0,9.366717,9.342631,78.63049\n" +
"19.0,116.0,0,0,0.3365049,20.81806,29.236477\n" +
"19.0,116.0,0,0,7.646478,3.1961684,7.8138685\n" +
"19.0,116.0,0,0,5.075439,36.427265,20.879707\n" +
"19.0,116.0,0,0,5.1594234,18.314194,6.4109855\n" +
"19.0,116.0,0,0,2.1663764,10.056105,5.798549\n" +
"19.0,116.0,0,0,9.028424,5.7192965,56.243206\n" +
"19.0,116.0,0,0,9.031402,13.884695,36.763905\n" +
"19.0,116.0,0,0,5.26929,3.5693107,84.04594\n" +
"19.0,116.0,0,0,2.6247969,8.933488,28.76576\n" +
"19.0,116.0,0,0,9.745737,24.357897,76.431816\n" +
"19.0,116.0,0,0,3.722143,17.96677,18.759092\n" +
"19.0,116.0,0,0,1.9264901,28.71267,52.148735\n" +
"19.0,116.0,0,0,3.9815784,35.91171,33.082714\n" +
"19.0,116.0,0,0,4.657818,31.10753,65.25383\n" +
"109.0,178.0,1,3600,1.6315197,26.582031,10.312429\n" +
"109.0,178.0,1,3600,7.0598154,4.909754,50.415916\n" +
"109.0,178.0,1,3600,0.36953768,30.069138,36.845417\n" +
"109.0,178.0,1,3600,7.5342026,3.341837,52.53064\n" +
"109.0,178.0,1,3600,7.404938,36.832874,81.62572\n" +
"109.0,178.0,1,3600,1.4442251,21.88992,78.833565\n" +
"109.0,178.0,1,3600,9.80883,25.902088,50.43351\n" +
"109.0,178.0,1,3600,8.060886,30.653927,81.53324\n" +
"109.0,178.0,1,3600,1.965906,0.8834069,86.67266\n" +
"109.0,178.0,1,3600,9.60608,27.2307,74.25348\n" +
"109.0,178.0,1,3600,9.839138,15.706074,86.22133\n" +
"109.0,178.0,1,3600,6.2004266,34.751484,79.71265\n" +
"109.0,178.0,1,3600,6.9113455,16.43026,30.387852\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 5964, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#4g " + pauseMessage); 

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("profile,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("profile"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("profile,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("profile,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //  
            table.readNcCF(fileName, 
                StringArray.fromCSV("z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("profile,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("profile"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("profile,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("z"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


        /* */
        debugMode = oDebug;        
    }
       
    /** This tests readNcCF timeseries files from ASA
     * via https://github.com/asascience-open/CFPointConventions
     * stored in unitTestDataDir/CFPointConventions.
     */
    public static void testReadNcCFASATimeSeries(boolean pauseAfterEach) throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCFASATimeseries");
        String pauseMessage = "\nOK?";
        Table table = new Table();
        String results, expected, fileName;

 
        //***************  timeseries orthogonal 
        fileName = String2.unitTestDataDir + "CFPointConventions/timeseries/" +
            "timeSeries-Orthogonal-Multidimenstional-MultipleStations-H.2.1/" +
            "timeSeries-Orthogonal-Multidimenstional-MultipleStations-H.2.1.nc";
        String2.log("\n\n** Testing orthogonal file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, ""));
//!!! obs vars are temperature[time=100][station=10]
//so outer=time and inner is station!
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(12);
        expected = 
"lat,lon,station_name,alt,time,temperature,humidity\n" +
"8.0,146.0,Station-0,0.8488673,0,18.618036,27.177536\n" +
"4.0,53.0,Station-1,1.8478156,0,13.216496,83.71079\n" +
"90.0,159.0,Station-2,3.4614673,0,39.300182,44.69293\n" +
"55.0,25.0,Station-3,4.8902116,0,17.008652,2.3659434\n" +
"115.0,30.0,Station-4,9.45969,0,24.951536,7.1026664\n" +
"165.0,125.0,Station-5,0.17808062,0,35.995247,41.411594\n" +
"143.0,175.0,Station-6,8.85507,0,24.334364,39.776123\n" +
"157.0,175.0,Station-7,0.47320434,0,33.077255,1.1665242\n" +
"101.0,80.0,Station-8,7.470208,0,6.9397545,72.75068\n" +
"167.0,57.0,Station-9,0.6709764,0,28.991974,71.65753\n" +
"8.0,146.0,Station-0,0.8488673,3600,3.0675685,53.43748\n" +
"4.0,53.0,Station-1,1.8478156,3600,37.31892,46.79294\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 1000, "");
        results = table.columnAttributes(5).toString(); //temperature
        expected = 
"    coordinates=lat lon alt\n" +   //this is what source has.  But it should include time.
"    long_name=Air Temperature\n" +
"    missing_value=-999.9f\n" +
"    standard_name=air_temperature\n" +
"    units=Celsius\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#5a " + pauseMessage); 

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,time,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,time,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,time,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("time"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,time,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,time"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,time"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,time"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("time"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,time,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,time,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("time"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,time,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,time"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,time"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("time"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("time,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("time"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("time,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("alt,time"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("alt,time"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("time"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("time"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("time"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


        //read just inner [station] vars
        table.readNcCF(fileName, StringArray.fromCSV("station_name,lat,lon"), 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"station_name,lat,lon\n" +
"Station-0,8.0,146.0\n" +
"Station-1,4.0,53.0\n" +
"Station-2,90.0,159.0\n" +
"Station-3,55.0,25.0\n" +
"Station-4,115.0,30.0\n" +
"Station-5,165.0,125.0\n" +
"Station-6,143.0,175.0\n" +
"Station-7,157.0,175.0\n" +
"Station-8,101.0,80.0\n" +
"Station-9,167.0,57.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read just inner [station] vars, with constraint
        table.readNcCF(fileName, StringArray.fromCSV("station_name,lat,lon"), 
            0,  //standardizeWhat=0                
            StringArray.fromCSV("lat"), StringArray.fromCSV(">"), StringArray.fromCSV("150"));
        results = table.dataToString();
        expected = 
"station_name,lat,lon\n" +
"Station-5,165.0,125.0\n" +
"Station-7,157.0,175.0\n" +
"Station-9,167.0,57.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read just outer [time] vars
        table.readNcCF(fileName, StringArray.fromCSV("time"), 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(5);
        expected = 
"time\n" +
"0\n" +
"3600\n" +
"7200\n" +
"10800\n" +
"14400\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 100, "");

        //read just outer [time] vars, with constraint
        table.readNcCF(fileName, StringArray.fromCSV("time"), 
            0,  //standardizeWhat=0                
            StringArray.fromCSV("time,time"), StringArray.fromCSV(">,<"), StringArray.fromCSV("7000,11000"));
        results = table.dataToString();
        expected = 
"time\n" +
"7200\n" +
"10800\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read just outer+inner [time][station] vars
        table.readNcCF(fileName, StringArray.fromCSV("station_name,lat,lon,time"), 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"station_name,lat,lon,time\n" +
"Station-0,8.0,146.0,0\n" +
"Station-1,4.0,53.0,0\n" +
"Station-2,90.0,159.0,0\n" +
"Station-3,55.0,25.0,0\n" +
"Station-4,115.0,30.0,0\n" +
"Station-5,165.0,125.0,0\n" +
"Station-6,143.0,175.0,0\n" +
"Station-7,157.0,175.0,0\n" +
"Station-8,101.0,80.0,0\n" +
"Station-9,167.0,57.0,0\n" +
"Station-0,8.0,146.0,3600\n";
        Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 10*100, "");

        expected = 
"Station-0,8.0,146.0,345600\n" +
"Station-1,4.0,53.0,345600\n" +
"Station-2,90.0,159.0,345600\n" +
"Station-3,55.0,25.0,345600\n" +
"Station-4,115.0,30.0,345600\n" +
"Station-5,165.0,125.0,345600\n" +
"Station-6,143.0,175.0,345600\n" +
"Station-7,157.0,175.0,345600\n" +
"Station-8,101.0,80.0,345600\n" +
"Station-9,167.0,57.0,345600\n";
        int po = results.indexOf(expected);
        Test.ensureTrue(po > 0, "po=" + po);
        Test.ensureEqual(results.substring(po, po + expected.length()), expected, "results=\n" + results);

        //read just outer+inner [time][station] vars, with outer [time] constraint
        table.readNcCF(fileName, StringArray.fromCSV("station_name,lat,lon,time"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time"), StringArray.fromCSV("="), StringArray.fromCSV("345600"));
        results = table.dataToString();
        expected = 
"station_name,lat,lon,time\n" +
"Station-0,8.0,146.0,345600\n" +
"Station-1,4.0,53.0,345600\n" +
"Station-2,90.0,159.0,345600\n" +
"Station-3,55.0,25.0,345600\n" +
"Station-4,115.0,30.0,345600\n" +
"Station-5,165.0,125.0,345600\n" +
"Station-6,143.0,175.0,345600\n" +
"Station-7,157.0,175.0,345600\n" +
"Station-8,101.0,80.0,345600\n" +
"Station-9,167.0,57.0,345600\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read just outer+inner [time][station] vars, with inner [station] constraint
        table.readNcCF(fileName, StringArray.fromCSV("station_name,lat,lon,time"), 
            0,  //standardizeWhat=0                
            StringArray.fromCSV("lat"), StringArray.fromCSV("="), StringArray.fromCSV("165"));
        results = table.dataToString();
        expected = 
"station_name,lat,lon,time\n" +
"Station-5,165.0,125.0,0\n" +
"Station-5,165.0,125.0,3600\n" +
"Station-5,165.0,125.0,7200\n" +
"Station-5,165.0,125.0,10800\n" +
"Station-5,165.0,125.0,14400\n" +
"Station-5,165.0,125.0,18000\n" +
"Station-5,165.0,125.0,21600\n";
        Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 100, "");

        //read just outer+inner [time][station] vars, with outer and inner constraint
        table.readNcCF(fileName, StringArray.fromCSV("station_name,lat,lon,time"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time,lat"), StringArray.fromCSV("=,="), StringArray.fromCSV("345600,165"));
        results = table.dataToString();
        expected = 
"station_name,lat,lon,time\n" +
"Station-5,165.0,125.0,345600\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read just outer+inner+obs vars, with outer and inner constraint
        table.readNcCF(fileName, StringArray.fromCSV(""), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time,lat"), StringArray.fromCSV("=,="), StringArray.fromCSV("345600,165"));
        results = table.dataToString();
        expected = 
"lat,lon,station_name,alt,time,temperature,humidity\n" +
"165.0,125.0,Station-5,0.17808062,345600,38.457962,28.075706\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read just outer+obs vars, with outer and inner constraint
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, StringArray.fromCSV("lat,time,temperature,humidity"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time,lat"), StringArray.fromCSV("=,="), StringArray.fromCSV("345600,165"));
        results = table.dataToString();
        expected = 
"lat,time,temperature,humidity\n" +
"165.0,345600,38.457962,28.075706\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read just inner+obs vars, with outer and inner constraint
        table.readNcCF(fileName, StringArray.fromCSV("lat,lon,station_name,time,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time,lat"), StringArray.fromCSV("=,="), StringArray.fromCSV("345600,165"));
        results = table.dataToString();
        expected = 
"lat,lon,station_name,time,temperature\n" +
"165.0,125.0,Station-5,345600,38.457962\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
     
        //read just obs vars, with outer and inner constraint
        table.readNcCF(fileName, StringArray.fromCSV("time,lat,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time,lat"), StringArray.fromCSV("=,="), StringArray.fromCSV("345600,165"));
        results = table.dataToString();
        expected = 
"time,lat,temperature\n" +
"345600,165.0,38.457962\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
     

        //***************  timeseries incomplete multidimensional --- 
        fileName = String2.unitTestDataDir + "CFPointConventions/timeseries/" +
            "timeSeries-Incomplete-MultiDimensional-MultipleStations-H.2.2/" +
            "timeSeries-Incomplete-MultiDimensional-MultipleStations-H.2.2.nc";
        String2.log("\n\n** Testing incomplete file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(24);
        expected = 
"lat,lon,station_elevation,station_info,station_name,alt,time,temperature,humidity\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,0,17.0,56.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,3600,7.0,49.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,7200,19.0,86.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,10800,5.0,81.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,14400,0.0,55.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,18000,10.0,9.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,21600,32.0,57.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,25200,39.0,39.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,28800,39.0,68.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,32400,29.0,6.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,36000,26.0,12.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,39600,24.0,72.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,43200,14.0,80.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,46800,38.0,52.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,50400,35.0,46.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,54000,33.0,48.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,57600,34.0,85.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,61200,27.0,3.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,64800,37.0,61.0\n" +
"121.0,81.0,4.859895,0,Station-0,1.9358816,68400,0.0,0.0\n" +
"150.0,73.0,2.6002314,1,Station-1,4.052759,0,25.0,73.0\n" +
"150.0,73.0,2.6002314,1,Station-1,4.052759,3600,29.0,74.0\n" +
"150.0,73.0,2.6002314,1,Station-1,4.052759,7200,33.0,88.0\n" +
"150.0,73.0,2.6002314,1,Station-1,4.052759,10800,25.0,3.0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 200, "");
        results = table.columnAttributes(7).toString();  //temperature
        expected = 
"    coordinates=time lat lon alt\n" +
"    long_name=Air Temperature\n" +
"    missing_value=-999.9f\n" +
"    standard_name=air_temperature\n" +
"    units=Celsius\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#5b " + pauseMessage); 

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


        //read just outer [station] vars
        table.readNcCF(fileName, StringArray.fromCSV("station_name,lat,lon"), 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"station_name,lat,lon\n" +
"Station-0,121.0,81.0\n" +
"Station-1,150.0,73.0\n" +
"Station-2,107.0,152.0\n" +
"Station-3,117.0,143.0\n" +
"Station-4,107.0,11.0\n" +
"Station-5,161.0,100.0\n" +
"Station-6,150.0,169.0\n" +
"Station-7,176.0,85.0\n" +
"Station-8,83.0,126.0\n" +
"Station-9,84.0,170.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read just outer [station] vars, with constraint
        table.readNcCF(fileName, StringArray.fromCSV("station_name,lat,lon"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("lat"), StringArray.fromCSV(">"), StringArray.fromCSV("155"));
        results = table.dataToString();
        expected = 
"station_name,lat,lon\n" +
"Station-5,161.0,100.0\n" +
"Station-7,176.0,85.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //There are no just inner[obs] variables

        //read just outer+obs vars, with outer constraint
        table.readNcCF(fileName, StringArray.fromCSV("lat,time,temperature,humidity"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("lat"), StringArray.fromCSV("="), StringArray.fromCSV("150"));
        results = table.dataToString();
        expected = 
//metadata mv=-999.9 for temp and humidity, so 9e36 below are "valid" values
"lat,time,temperature,humidity\n" +
"150.0,0,25.0,73.0\n" +
"150.0,3600,29.0,74.0\n" +
"150.0,7200,33.0,88.0\n" +
"150.0,10800,25.0,3.0\n" +
"150.0,14400,2.0,70.0\n" +
"150.0,18000,9.0,37.0\n" +
"150.0,21600,10.0,45.0\n" +
"150.0,25200,33.0,24.0\n" +
"150.0,28800,1.0,43.0\n" +
"150.0,32400,26.0,0.0\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,-2147483647,9.96921E36,9.96921E36\n" +
"150.0,0,18.0,4.0\n" +
"150.0,3600,18.0,83.0\n" +
"150.0,7200,27.0,10.0\n" +
"150.0,10800,33.0,43.0\n" +
"150.0,14400,34.0,31.0\n" +
"150.0,18000,0.0,69.0\n" +
"150.0,21600,27.0,34.0\n" +
"150.0,25200,3.0,41.0\n" +
"150.0,28800,38.0,14.0\n" +
"150.0,32400,20.0,5.0\n" +
"150.0,36000,26.0,48.0\n" +
"150.0,39600,11.0,29.0\n" +
"150.0,43200,22.0,60.0\n" +
"150.0,46800,39.0,63.0\n" +
"150.0,50400,27.0,18.0\n" +
"150.0,54000,26.0,84.0\n" +
"150.0,57600,26.0,71.0\n" +
"150.0,61200,33.0,25.0\n" +
"150.0,64800,27.0,17.0\n" +
"150.0,68400,17.0,79.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
    
        //read just outer+obs vars, with outer + obs constraint
        table.readNcCF(fileName, StringArray.fromCSV("lat,time,temperature,humidity"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("lat,humidity"), StringArray.fromCSV("=,="), StringArray.fromCSV("150,43"));
        results = table.dataToString();
        expected = 
"lat,time,temperature,humidity\n" +
"150.0,28800,1.0,43.0\n" +
"150.0,10800,33.0,43.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
    
        //read just outer+obs vars, 
        table.readNcCF(fileName, StringArray.fromCSV("time,temperature,humidity"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time,temperature"), StringArray.fromCSV("=,="), StringArray.fromCSV("7200,33"));
        results = table.dataToString();
        expected = 
//"22,150.0,73.0,2.6002314,1,Station-1,4.052759,7200,33.0,88.0\n" + from above
"time,temperature,humidity\n" +
"7200,33.0,88.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

            //read just obs vars, with outer and obs constraint
        table.readNcCF(fileName, StringArray.fromCSV("time,lon,alt,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time,lon"), StringArray.fromCSV("=,="), StringArray.fromCSV("7200,73"));
        results = table.dataToString();
        expected = 
"time,lon,alt,temperature\n" +
"7200,73.0,4.052759,33.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        /* */
        //read just obs vars, with outer and obs constraint
        table.readNcCF(fileName, StringArray.fromCSV("time,lon,alt,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("lon,temperature"), StringArray.fromCSV("=,="), StringArray.fromCSV("73,33"));
        results = table.dataToString();
        expected = 
"time,lon,alt,temperature\n" +
"7200,73.0,4.052759,33.0\n" +
"25200,73.0,4.052759,33.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //read just obs vars, with outer and obs constraint
        table.readNcCF(fileName, StringArray.fromCSV("time,lon,alt,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time,temperature"), StringArray.fromCSV("=,="), StringArray.fromCSV("7200,33"));
        results = table.dataToString();
        expected = 
"time,lon,alt,temperature\n" +
"7200,73.0,4.052759,33.0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        debugMode = oDebug;        
    }
       
    /** This tests readNcCF trajectory files from ASA
     * via https://github.com/asascience-open/CFPointConventions
     * stored in unitTestDataDir/CFPointConventions.
     */
    public static void testReadNcCFASATrajectory(boolean pauseAfterEach) throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCFASATrajectory");
        String pauseMessage = "\nOK?";
        Table table = new Table();
        String results, expected, fileName;

/* */
        //***************  trajectory contiguous 
        fileName = String2.unitTestDataDir + "CFPointConventions/trajectory/" +
            "trajectory-Contiguous-Ragged-MultipleTrajectories-H.4.3/" +
            "trajectory-Contiguous-Ragged-MultipleTrajectories-H.4.3.nc";
        String2.log("\n\n** Testing contiguous file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(20);
        expected = 
"lat,lon,trajectory_info,trajectory_name,time,z,temperature,humidity\n" +
"16.937433,-35.901237,0,Trajectory0,0,0.0,18.559397,46.487503\n" +
"32.011345,-8.81588,0,Trajectory0,3600,1.0,34.649773,16.22458\n" +
"3.137092,-64.15942,0,Trajectory0,7200,2.0,35.318504,77.41457\n" +
"10.783036,-11.503419,0,Trajectory0,10800,3.0,19.39111,56.601\n" +
"4.6016994,-6.416601,0,Trajectory0,14400,4.0,5.4162874,62.606712\n" +
"25.337688,-69.37197,0,Trajectory0,18000,5.0,2.604784,16.390015\n" +
"30.219189,-71.78619,0,Trajectory0,21600,6.0,22.968603,62.276855\n" +
"5.3421707,-29.245968,0,Trajectory0,25200,7.0,8.609019,14.976101\n" +
"25.687958,-57.089973,0,Trajectory0,28800,8.0,9.202528,79.17113\n" +
"31.82367,-58.56237,0,Trajectory0,32400,9.0,1.5670301,26.49425\n" +
"23.310976,-3.997997,0,Trajectory0,36000,10.0,23.187065,64.34719\n" +
"43.486816,-62.39688,0,Trajectory0,39600,11.0,37.44155,29.570276\n" +
"44.56024,-54.139122,0,Trajectory0,43200,12.0,11.75348,72.36402\n" +
"42.48622,-42.518707,1,Trajectory1,0,0.0,20.665886,67.27393\n" +
"32.187572,-73.20317,1,Trajectory1,3600,1.0,26.498121,79.754486\n" +
"6.4802227,-72.74957,1,Trajectory1,7200,2.0,17.64227,70.126625\n" +
"38.596996,-67.64374,1,Trajectory1,10800,3.0,23.615097,59.626125\n" +
"24.085066,-63.833694,1,Trajectory1,14400,4.0,30.743101,35.862038\n" +
"24.221394,-57.373817,1,Trajectory1,18000,5.0,39.391495,28.661589\n" +
"22.637892,-47.858807,1,Trajectory1,21600,6.0,1.2310536,55.708595\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 163, ""); 
        results = table.columnAttributes(5).toString(); //temperature
        expected = 
"    axis=Z\n" +
"    long_name=height above mean sea level\n" +
"    missing_value=-999.0f\n" +
"    positive=up\n" +
"    standard_name=altitude\n" +
"    units=m\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#8a " + pauseMessage); 

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("z,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");




        //***************  trajectory single multidimensional --- 
        fileName = String2.unitTestDataDir + "CFPointConventions/trajectory/" +
            "trajectory-Incomplete-Multidimensional-SingleTrajectory-H.4.2/" +
            "trajectory-Incomplete-Multidimensional-SingleTrajectory-H.4.2.nc";
        String2.log("\n\n** Testing single multidimensional file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, ""));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
                null, null, null);
        results = table.dataToString(5);
        expected = 
"lat,lon,trajectory_info,trajectory_name,time,z,temperature,humidity\n" +
"42.003387,-7.9335957,0,Trajectory1,0,0.0,12.522581,35.668747\n" +
"8.972063,-46.335754,0,Trajectory1,3600,1.0,25.658121,1.0647067\n" +
"25.841967,-49.1959,0,Trajectory1,7200,2.0,35.43442,13.059927\n" +
"35.699753,-40.790943,0,Trajectory1,10800,3.0,35.752117,48.576355\n" +
"11.132234,-25.553247,0,Trajectory1,14400,4.0,6.082586,64.91749\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 100, "");
        results = table.columnAttributes(table.findColumnNumber("temperature")).toString();  
        expected = 
"    coordinates=time lat lon z\n" +
"    long_name=Air Temperature\n" +
"    missing_value=-999.9f\n" +
"    standard_name=air_temperature\n" +
"    units=Celsius\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#8c " + pauseMessage); 

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("z,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

        //***************  trajectory indexed --- 
        fileName = String2.unitTestDataDir + "CFPointConventions/trajectory/" +
            "trajectory-Indexed-Ragged-MultipleTrajectories-H.4.4/" +
            "trajectory-Indexed-Ragged-MultipleTrajectories-H.4.4.nc";
        String2.log("\n\n** Testing indexed file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, ""));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(5);
        expected = 
"lat,lon,trajectory_info,trajectory_name,time,z,temperature,humidity\n" +
"11.256147,-5.989336,8,Trajectory8,72000,12.518082,14.902713,37.237553\n" +
"26.104128,-2.6626983,3,Trajectory3,111600,7.372036,24.243849,12.862466\n" +
"22.414213,-23.53803,4,Trajectory4,68400,5.7999315,1.4940661,20.668322\n" +
"22.181162,-34.355854,4,Trajectory4,122400,20.127024,6.8310843,55.93755\n" +
"2.177301,-58.388607,5,Trajectory5,162000,1.764841,27.893003,28.2276\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 213, "");
        results = table.columnAttributes(6).toString();  //temperature
        expected = 
"    coordinates=time lat lon z\n" +
"    long_name=Air Temperature\n" +
"    missing_value=-999.9f\n" +
"    standard_name=air_temperature\n" +
"    units=Celsius\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#8d " + pauseMessage); 

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("z,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature,trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, 
                StringArray.fromCSV("trajectory_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, 
                StringArray.fromCSV("z"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


        /* */
        debugMode = oDebug;        
    }


    public static void testInteractiveNcCFMA(boolean pauseAfterEach) throws Exception {
        //***************  trajectory multiple multidimensional --- 
       try {

            Table table = new Table();
            String results, expected;
            String pauseMessage = "\nOK?";
            String fileName = String2.unitTestDataDir + "CFPointConventions/trajectory/" +
                "trajectory-Incomplete-Multidimensional-MultipleTrajectories-H.4.1/" +
                "trajectory-Incomplete-Multidimensional-MultipleTrajectories-H.4.1.nc";
            String2.log("\n\n** Testing multiple multidimensional file\n" +
                "  " + fileName);
            String2.log(NcHelper.ncdump(fileName, "-h"));

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("trajectory_name"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("trajectory_name,lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("z,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,trajectory_name"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat,trajectory_name"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("trajectory_name"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("z,trajectory_name"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("z,trajectory_name"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("trajectory_name"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("temperature,trajectory_name"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("temperature,trajectory_name"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("trajectory_name"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                //
                table.readNcCF(fileName, 
                    StringArray.fromCSV("trajectory_name"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("trajectory_name"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("lat"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("lat"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("temperature"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("temperature"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");

                table.readNcCF(fileName, 
                    StringArray.fromCSV("z"), 
                    0,  //standardizeWhat=0
                    StringArray.fromCSV("z"), 
                    StringArray.fromCSV("="),
                    StringArray.fromCSV("-12345"));
                Test.ensureEqual(table.nRows(), 0, "");
                Test.ensureEqual(table.nColumns(), 0, "");


            table.readNcCF(fileName, null, 0,  //standardizeWhat=0
                    null, null, null);
            results = table.dataToString(55);
            expected = 
    //rows that a human thinks should be rejected are kept
    //probably because trajectory_info and trajectory_name aren't missing values 
    //  AND because lat,lon have missing values but there is no missing_value attribute.
    "lat,lon,trajectory_info,trajectory_name,time,z,temperature,humidity\n" +
    "2.152863,-35.078842,0,Trajectory0,0,0.0,13.466983,65.38418\n" +
    "33.60481,-44.12696,0,Trajectory0,3600,1.0,23.050304,7.0401154\n" +
    "22.562508,-18.115444,0,Trajectory0,7200,2.0,15.112072,45.15019\n" +
    "13.432817,-21.772585,0,Trajectory0,10800,3.0,22.97767,12.618799\n" +
    "43.011986,-28.655304,0,Trajectory0,14400,4.0,21.318092,4.788235\n" +
    "18.84832,-25.418892,0,Trajectory0,18000,5.0,27.496708,66.337166\n" +
    "18.040411,-30.469133,0,Trajectory0,21600,6.0,30.678926,31.57974\n" +
    "32.34516,-75.79432,0,Trajectory0,25200,7.0,12.096431,11.228316\n" +
    "8.652234,-69.01581,0,Trajectory0,28800,8.0,12.523737,47.003998\n" +
    "18.905367,-18.362652,0,Trajectory0,32400,9.0,22.805552,8.789174\n" +
    "12.184539,-42.194824,0,Trajectory0,36000,10.0,17.411797,40.25377\n" +
    "16.498188,-74.44906,0,Trajectory0,39600,11.0,27.783548,20.712833\n" +
    "1.5479256,-53.522717,0,Trajectory0,43200,12.0,11.809888,5.6157913\n" +
    "22.033587,-28.557417,0,Trajectory0,46800,13.0,13.730549,2.8293543\n" +
    "5.997217,-35.043163,0,Trajectory0,50400,14.0,6.549969,30.482803\n" +
    "8.580469,-45.364418,0,Trajectory0,54000,15.0,11.789269,2.303839\n" +
    "6.253441,-9.302229,0,Trajectory0,57600,16.0,24.03656,56.802467\n" +
    "12.948677,-20.07699,0,Trajectory0,61200,17.0,17.980707,66.24162\n" +
    "41.49208,-19.628315,0,Trajectory0,64800,18.0,0.44739303,25.76894\n" +
    "25.784758,-65.65333,0,Trajectory0,68400,19.0,13.147206,1.4286463\n" +
    "25.884523,-64.92309,0,Trajectory0,72000,20.0,21.278152,72.43937\n" +
    "7.5993505,-33.58001,0,Trajectory0,75600,21.0,14.465093,74.04942\n" +
    "23.801714,-8.210893,0,Trajectory0,79200,22.0,17.250273,43.468597\n" +
    "24.086273,-16.376455,0,Trajectory0,82800,23.0,36.73325,56.15435\n" +
    "8.838917,-65.32871,0,Trajectory0,86400,24.0,21.714993,32.324383\n" +
    "3.049409,-50.187355,0,Trajectory0,90000,25.0,17.755543,7.7604437\n" +
    "32.699135,-13.603052,0,Trajectory0,93600,26.0,21.764454,68.36558\n" +
    "28.82149,-4.238066,0,Trajectory0,97200,27.0,4.18221,75.262665\n" +
    "4.573595,-15.691054,0,Trajectory0,100800,28.0,36.230297,74.156654\n" +
    "30.231867,-29.110548,0,Trajectory0,104400,29.0,10.372004,8.0368805\n" +
    "26.295082,-24.224209,0,Trajectory0,108000,30.0,7.0729938,31.468176\n" +
    "26.146648,-35.461746,0,Trajectory0,111600,31.0,12.3075285,71.35397\n" +
    "18.875525,-11.409157,0,Trajectory0,115200,32.0,30.241188,45.14291\n" +
    "44.57873,-29.37942,0,Trajectory0,118800,33.0,21.847982,61.776512\n" +
    "40.911667,-31.65526,0,Trajectory0,122400,34.0,30.369759,29.810774\n" +
    "9.5415745,-57.1067,0,Trajectory0,126000,35.0,15.864324,33.90924\n" +
    //these aren't rejected because
    //* trajectory_info has the attribute missing_value=-999,
    //  but the data above has trajectory_info=0, which isn't a missing value.
    //* trajectory_name is a string, so my reader doesn't expect a
    //  missing_value attribute, but my reader does treat a data
    //  value of "" (nothing) as a missing value.  Unfortunately, this
    //  file has other values (e.g., "Trajectory0"), so my reader
    //  treats those as not missing values.
    //* lat and lon have data values of -999.9 which is probably
    //  intended to be a missing value marker, but those variables
    //  have no missing_value attributes, so my program treats them as
    //  valid values.
    //I reported to Kyle 2012-10-03 and hope he'll make changes

    //"36,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" + 
    //"37,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"38,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"39,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"40,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"41,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"42,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"43,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"44,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"45,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"46,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"47,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"48,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    //"49,-999.9,-999.9,0,Trajectory0,-999,-999.9,-999.9,-999.9\n" +
    "36,13.633951,-61.779095,1,Trajectory1,0,0.0,31.081379,7.8967414\n" +
    "37,41.583824,-52.047775,1,Trajectory1,3600,1.0,23.026224,25.034555\n" +
    "38,14.176689,-15.26571,1,Trajectory1,7200,2.0,21.750353,61.35738\n" +
    "39,23.482225,-69.246284,1,Trajectory1,10800,3.0,25.214777,70.63098\n" +
    "40,8.910114,-12.47847,1,Trajectory1,14400,4.0,29.234118,53.387733\n" +
    "...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
            Test.ensureEqual(table.nRows(), 200, "");
            results = table.columnAttributes(5).toString();  //temperature
            expected = 
    "    axis=Z\n" +
    "    long_name=height above mean sea level\n" +
    "    missing_value=-999.9f\n" +
    "    positive=up\n" +
    "    standard_name=altitude\n" +
    "    units=m\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
            if (pauseAfterEach) 
                String2.pressEnterToContinue("#8b " + pauseMessage); 


        
        } catch (Exception e) {
            //String2.pressEnterToContinue(
            Test.knownProblem(
                "KYLE WILCOX'S DSG TEST FILE.",
                MustBe.throwableToString(e) + 
                "\nI reported this problem to Kyle 2012-10-03" +
                "\n2013-10-30 Since Kyle changed jobs, it is unlikely he will ever fix this.");
        }
    }

    /** This tests readNcCF timeSeriesProfile files from ASA
     * via https://github.com/asascience-open/CFPointConventions
     * stored in unitTestDataDir/CFPointConventions.
     */
    public static void testReadNcCFASATimeSeriesProfile(boolean pauseAfterEach) throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCFASATimeSeriesProfile");
        String pauseMessage = "\nOK?";
        Table table = new Table();
        String results, expected, fileName;
        String orthoMultiDimH51FileName = String2.unitTestDataDir + 
            "CFPointConventions/timeSeriesProfile/" +
            "timeSeriesProfile-Orthogonal-Multidimensional-MultipeStations-H.5.1/" +
            "timeSeriesProfile-Orthogonal-Multidimensional-MultipeStations-H.5.1.nc";
        String raggedSingleStationFileName = String2.unitTestDataDir + 
            "CFPointConventions/timeSeriesProfile/" +
            "timeSeriesProfile-Ragged-SingleStation-H.5.3/" +
            "timeSeriesProfile-Ragged-SingleStation-H.5.3.nc";

  
        //***************  timeSeriesProfile multidimensional --- 
        fileName = String2.unitTestDataDir + "CFPointConventions/timeSeriesProfile/" +
            "timeSeriesProfile-Multidimensional-MultipeStations-H.5.1/" +
            "timeSeriesProfile-Multidimensional-MultipeStations-H.5.1.nc";
        String2.log("\n\n** Testing incomplete file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
                null, null, null);
        results = table.dataToString(5);
        expected = 
"lat,lon,station_info,station_name,alt,time,temperature\n" +
"37.5,-76.5,0,Station1,0.0,0,0.0\n" +
"37.5,-76.5,0,Station1,2.5,0,0.1\n" +
"37.5,-76.5,0,Station1,5.0,0,0.2\n" +
"37.5,-76.5,0,Station1,7.5,0,0.3\n" +
"37.5,-76.5,0,Station1,10.0,0,0.4\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 240, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6a " + pauseMessage); 


            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

        //***************  timeSeriesProfile multidimensional single station
        fileName = String2.unitTestDataDir + "CFPointConventions/timeSeriesProfile/" +
            "timeSeriesProfile-Multidimensional-SingleStation-H.5.2/" +
            "timeSeriesProfile-Multidimensional-SingleStation-H.5.2.nc";
        String2.log("\n\n** Testing contiguous file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);  
        results = table.dataToString();
        expected = 
"lat,lon,station_info,station_name,alt,time,temperature\n" +
"37.5,-76.5,0,Station1,0.0,0,0.0\n" +
"37.5,-76.5,0,Station1,2.5,0,0.1\n" +
"37.5,-76.5,0,Station1,5.0,0,0.2\n" +
"37.5,-76.5,0,Station1,7.5,0,0.3\n" +
"37.5,-76.5,0,Station1,10.0,0,0.4\n";
        Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);
        expected = 
"37.5,-76.5,0,Station1,287.5,10800,11.5\n" +
"37.5,-76.5,0,Station1,290.0,10800,11.6\n" +
"37.5,-76.5,0,Station1,292.5,10800,11.7\n" +
"37.5,-76.5,0,Station1,295.0,10800,11.8\n" +
"37.5,-76.5,0,Station1,297.5,10800,11.9\n";
        Test.ensureEqual(results.substring(results.length() - expected.length()), 
            expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 120, "");
        results = table.columnAttributes(table.findColumnNumber("alt")).toString();
        expected = 
"    axis=Z\n" +
"    positive=up\n" +
"    units=m\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        results = table.columnAttributes(table.findColumnNumber("temperature")).toString();
        expected = 
"    coordinates=time lat lon alt\n" +
"    long_name=Water Temperature\n" +
"    missing_value=-999.9f\n" +
"    units=Celsius\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6b " + pauseMessage); 


            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

        //***************  timeSeriesProfile orthogonal multidimensional --- 
        //!!! IMPORTANT/ONLY test of file with variable[innerDim] for innerTable
        // and variable[time][z][station]  which is allowed, ordering
        fileName = orthoMultiDimH51FileName;
        String2.log("\n\n** Testing incomplete file\n" + "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
                null, null, null);
        results = table.dataToString(12);
        expected = 
"lat,lon,alt,station_info,station_name,time,temperature,humidity\n" +
"37.5,-76.5,0.0,0,Station1,0,15.698009,89.70879\n" +
"32.5,-78.3,0.0,1,Station2,0,8.11997,33.637585\n" +
"37.5,-76.5,10.0,0,Station1,0,10.9166565,55.78947\n" +
"32.5,-78.3,10.0,1,Station2,0,39.356647,65.43795\n" +
"37.5,-76.5,20.0,0,Station1,0,15.666663,50.176994\n" +
"32.5,-78.3,20.0,1,Station2,0,33.733116,58.14976\n" +
"37.5,-76.5,30.0,0,Station1,0,1.1587523,36.855045\n" +
"32.5,-78.3,30.0,1,Station2,0,4.65479,63.862186\n" +
"37.5,-76.5,0.0,0,Station1,3600,31.059647,65.01694\n" +
"32.5,-78.3,0.0,1,Station2,3600,33.374344,22.771135\n" +
"37.5,-76.5,10.0,0,Station1,3600,5.680936,35.675472\n" +
"32.5,-78.3,10.0,1,Station2,3600,17.763374,38.54674\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 800, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6c " + pauseMessage); 

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

        fileName = orthoMultiDimH51FileName;
        String2.log("\n\n** Testing incomplete file with constraints\n" +
            "  " + fileName);
        //String2.log(NcHelper.ncdump(orthoMultiDimH51FileName, "-h"));
        table.readNcCF(fileName, null, 
            0,  //standardizeWhat=0
            StringArray.fromCSV("station_name"), 
            StringArray.fromCSV("="), 
            StringArray.fromCSV("Station1"));
        results = table.dataToString(12);
        expected = 
"lat,lon,alt,station_info,station_name,time,temperature,humidity\n" +
"37.5,-76.5,0.0,0,Station1,0,15.698009,89.70879\n" +
"37.5,-76.5,10.0,0,Station1,0,10.9166565,55.78947\n" +
"37.5,-76.5,20.0,0,Station1,0,15.666663,50.176994\n" +
"37.5,-76.5,30.0,0,Station1,0,1.1587523,36.855045\n" +
"37.5,-76.5,0.0,0,Station1,3600,31.059647,65.01694\n" +
"37.5,-76.5,10.0,0,Station1,3600,5.680936,35.675472\n" +
"37.5,-76.5,20.0,0,Station1,3600,24.156359,45.77856\n" +
"37.5,-76.5,30.0,0,Station1,3600,25.934822,35.178967\n" +
"37.5,-76.5,0.0,0,Station1,7200,6.518481,12.735875\n" +
"37.5,-76.5,10.0,0,Station1,7200,4.463567,47.44697\n" +
"37.5,-76.5,20.0,0,Station1,7200,29.448772,20.438272\n" +
"37.5,-76.5,30.0,0,Station1,7200,37.245636,62.655357\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 400, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6d " + pauseMessage); 

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

        //test just variable[obs]  (interiorTable) 
        String2.log("\n\n** Testing incomplete file\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, StringArray.fromCSV("lat,lon,station_name,zztop"),
            0,  //standardizeWhat=0
            StringArray.fromCSV("station_name"), 
            StringArray.fromCSV("="), 
            StringArray.fromCSV("Station1"));
        results = table.dataToString();
        expected = 
"lat,lon,station_name\n" +
"37.5,-76.5,Station1\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 1, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6e " + pauseMessage); 


        //**********  NO_DATA
        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, outer/inner/obsVar
        String2.log("\n\n** Testing orthoMultiDimH51FileName just outer/inner/obsVar, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("time,zztop,alt,temperature"), 
            0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDa " + pauseMessage); 


        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, just outerVar
        String2.log("\n\n** Testing orthoMultiDimH51FileName just outerVar, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("zztop,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDb " + pauseMessage); 

        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, just innerVar
        String2.log("\n\n** Testing orthoMultiDimH51FileName just innerVar, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("alt,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("alt"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("10000"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDc " + pauseMessage); 

        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, just obsVar
        String2.log("\n\n** Testing orthoMultiDimH51File just obsVar, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("zztop,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDd " + pauseMessage); 


        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, just outerVar* and innerVar
        String2.log("\n\n** Testing orthoMultiDimH51File just outer*/innerVar, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("zztop,time,alt"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDe1 " + pauseMessage); 


        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, just outerVar and innerVar*
        String2.log("\n\n** Testing orthoMultiDimH51File just outer/innerVar*, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("zztop,time,alt"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("alt"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("10000"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDe2 " + pauseMessage); 


        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, just outerVar* and obsVar
        String2.log("\n\n** Testing orthoMultiDimH51File just outer*/obsVar, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("time,temperature,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDf1 " + pauseMessage); 

        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, just outerVar and obsVar*
        String2.log("\n\n** Testing orthoMultiDimH51File just outer/obsVar*, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("time,temperature,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDf2 " + pauseMessage); 

        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, just innerVar* and obsVar
        String2.log("\n\n** Testing orthoMultiDimH51File just inner*/obsVar, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("alt,temperature,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("alt"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("10000"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDg1 " + pauseMessage); 
      
        //**********  timeSeriesProfile orthoMultiDimH51FileName --- NO_DATA, just innerVar and obsVar*
        String2.log("\n\n** Testing orthoMultiDimH51File just inner/obsVar*, NO_DATA\n" +
            "  " + orthoMultiDimH51FileName);
        table.readNcCF(orthoMultiDimH51FileName, 
            StringArray.fromCSV("alt,temperature,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6NDg2 " + pauseMessage); 


        //*******
        //***************  timeSeriesProfile ragged --- 
        fileName = String2.unitTestDataDir + "CFPointConventions/timeSeriesProfile/" +
            "timeSeriesProfile-Ragged-MultipeStations-H.5.3/" +
            "timeSeriesProfile-Ragged-MultipeStations-H.5.3.nc";
        String2.log("\n\n** Testing timeSeriesProfile ragged file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
//file has:
//lat, lon, station_info, station_name, profile, time, station_index, row_size, height, temperature
"lat,lon,station_info,station_name,profile,time,height,temperature\n" +
"37.5,-76.5,0,Station1,0,0,0.5,6.7\n" +
"37.5,-76.5,0,Station1,0,0,1.5,6.9\n" +
"32.5,-78.3,1,Station2,1,3600,0.8,7.6\n" +
"32.5,-78.3,1,Station2,1,3600,1.8,7.7\n" +
"32.5,-78.3,1,Station2,1,3600,2.8,7.9\n" +
"32.5,-78.3,1,Station2,1,3600,3.8,8.0\n" +
"37.5,-76.5,0,Station1,2,7200,0.5,6.7\n" +
"37.5,-76.5,0,Station1,2,7200,1.5,7.0\n" +
"32.5,-78.3,1,Station2,3,10800,0.8,8.2\n" +
"32.5,-78.3,1,Station2,3,10800,1.8,7.7\n" +
"32.5,-78.3,1,Station2,3,10800,2.8,7.8\n" +
"32.5,-78.3,1,Station2,3,10800,3.8,9.1\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 12, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6j " + pauseMessage); 

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "height,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "height,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "height,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "height,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "height"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

        //***************  timeSeriesProfile ragged single station --- 
        //This is ONLY TEST FILE of nLevels=2 single station (outerTable are scalar vars)!!!!!!!!
        //Note also the lack of a stationIndex var with instance_dimension="someDimension" 
        //  since there is no instance_dimension
        fileName = raggedSingleStationFileName;
        String2.log("\n\n** Testing raggedSingleStationFile\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, ""));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
                null, null, null);
        results = table.dataToString();
        expected = 
"lat,lon,station_info,station_name,profile,time,height,temperature\n" +
"37.5,-76.5,0,Station1,0,0,0.5,6.7\n" +
"37.5,-76.5,0,Station1,0,0,1.5,6.9\n" +
"37.5,-76.5,0,Station1,1,3600,0.5,6.8\n" +
"37.5,-76.5,0,Station1,1,3600,1.5,7.9\n" +
"37.5,-76.5,0,Station1,2,7200,0.5,6.8\n" +
"37.5,-76.5,0,Station1,2,7200,1.5,7.9\n" +
"37.5,-76.5,0,Station1,2,7200,2.5,8.4\n" +
"37.5,-76.5,0,Station1,3,10800,0.5,5.7\n" +
"37.5,-76.5,0,Station1,3,10800,1.5,9.2\n" +
"37.5,-76.5,0,Station1,3,10800,2.5,8.3\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 10, "");
        results = table.columnAttributes(table.findColumnNumber("profile")).toString();
        expected = 
"    cf_role=profile_id\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6m " + pauseMessage); 

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name,lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "height,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "height,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "height,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "height,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "height,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "station_name"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station_name"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "height"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("height"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


        //***************  timeSeriesProfile ragged single station ---  just outerVar
        String2.log("\n\n** Testing raggedSingleStationFile just outerVar\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("zztop,lat,lon,station_info,station_name"), 
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"lat,lon,station_info,station_name\n" +
"37.5,-76.5,0,Station1\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 1, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station latitude\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6n " + pauseMessage); 

        //***************  timeSeriesProfile ragged single station ---  just innerVar
        String2.log("\n\n** Testing raggedSingleStationFile just innerVar\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("time,zztop,profile"), 
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"time,profile\n" +
"0,0\n" +
"3600,1\n" +
"7200,2\n" +
"10800,3\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 4, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=time\n" +
"    missing_value=-999i\n" +
"    standard_name=time\n" +
"    units=seconds since 1990-01-01 00:00:00\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6o " + pauseMessage); 

        //***************  timeSeriesProfile ragged single station ---  just outerVar and innerVar
        String2.log("\n\n** Testing raggedSingleStationFile just outerVar and innerVar\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("station_info,station_name,lon,lat,time,profile,"), 
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"station_info,station_name,lon,lat,time,profile\n" +
"0,Station1,-76.5,37.5,0,0\n" +
"0,Station1,-76.5,37.5,3600,1\n" +
"0,Station1,-76.5,37.5,7200,2\n" +
"0,Station1,-76.5,37.5,10800,3\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 4, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station info\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6p " + pauseMessage); 

        //***************  timeSeriesProfile ragged single station ---  just outerVar and obsVar
        String2.log("\n\n** Testing raggedSingleStationFile just outerVar and obsVar\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("station_info,temperature,zztop,station_name,"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("8"));
        results = table.dataToString();
        expected = 
"station_info,temperature,station_name\n" +
"0,8.4,Station1\n" +
"0,9.2,Station1\n" +
"0,8.3,Station1\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 3, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station info\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6q " + pauseMessage); 

        //***************  timeSeriesProfile ragged single station ---  just innerVar and obsVar
        String2.log("\n\n** Testing raggedSingleStationFile just innerVar and obsVar\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("temperature,zztop,time"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("8"));
        results = table.dataToString();
        expected = 
"temperature,time\n" +
"8.4,7200\n" +
"9.2,10800\n" +
"8.3,10800\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 3, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    coordinates=time lat lon height\n" +
"    long_name=Water Temperature\n" +
"    missing_value=-999.9f\n" +
"    standard_name=sea_water_temperature\n" +
"    units=Celsius\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#6r " + pauseMessage); 


        //**********  NO_DATA
        //**********  timeSeriesProfile ragged single station --- NO_DATA, outer/inner/obsVar
        String2.log("\n\n** Testing raggedSingleStationFile just outer/inner/obsVar, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("station_info,zztop,profile,temperature"), 
            0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7a " + pauseMessage); 


        //**********  timeSeriesProfile ragged single station --- NO_DATA, just outerVar
        String2.log("\n\n** Testing raggedSingleStationFile just outerVar, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("zztop,station_info"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("station_info"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("10"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7b " + pauseMessage); 

        //**********  timeSeriesProfile ragged single station --- NO_DATA, just innerVar
        String2.log("\n\n** Testing raggedSingleStationFile just innerVar, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("profile,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("profile"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7c " + pauseMessage); 

        //**********  timeSeriesProfile ragged single station --- NO_DATA, just obsVar
        String2.log("\n\n** Testing raggedSingleStationFile just obsVar, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("zztop,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7d " + pauseMessage); 


        //**********  timeSeriesProfile ragged single station --- NO_DATA, just outerVar* and innerVar
        String2.log("\n\n** Testing raggedSingleStationFile just outer*/innerVar, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("zztop,station_info,profile"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("station_info"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("10"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7e1 " + pauseMessage); 


        //**********  timeSeriesProfile ragged single station --- NO_DATA, just outerVar and innerVar*
        String2.log("\n\n** Testing raggedSingleStationFile just outer/innerVar*, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("zztop,station_info,profile"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("profile"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7e2 " + pauseMessage); 


        //**********  timeSeriesProfile ragged single station --- NO_DATA, just outerVar* and obsVar
        String2.log("\n\n** Testing raggedSingleStationFile just outer*/obsVar, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("temperature,station_info,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("station_info"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("10"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7f1 " + pauseMessage); 

        //**********  timeSeriesProfile ragged single station --- NO_DATA, just outerVar and obsVar*
        String2.log("\n\n** Testing raggedSingleStationFile just outer/obsVar*, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("temperature,station_info,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7f2 " + pauseMessage); 

        //**********  timeSeriesProfile ragged single station --- NO_DATA, just innerVar* and obsVar
        String2.log("\n\n** Testing raggedSingleStationFile just inner*/obsVar, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("temperature,profile,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("profile"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-1"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7g1 " + pauseMessage); 
      
        //**********  timeSeriesProfile ragged single station --- NO_DATA, just innerVar and obsVar*
        String2.log("\n\n** Testing raggedSingleStationFile just inner/obsVar*, NO_DATA\n" +
            "  " + raggedSingleStationFileName);
        table.readNcCF(raggedSingleStationFileName, 
            StringArray.fromCSV("temperature,profile,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#7g2 " + pauseMessage); 
      

        /* */
        debugMode = oDebug;        
    }

    /** This tests readNcCF trajectoryProfile files from ASA
     * via https://github.com/asascience-open/CFPointConventions
     * stored in unitTestDataDir/CFPointConventions.
     */
    public static void testReadNcCFASATrajectoryProfile(boolean pauseAfterEach) throws Exception {
        verbose = true;
        reallyVerbose = true;
        boolean oDebug = debugMode;
        debugMode = true;
        String2.log("\n*** Table.testReadNcCFASATrajectoryProfile");
        String pauseMessage = "\nOK?";
        Table table = new Table();
        String results, expected, fileName;
        String orthoMultiDimH61FileName = String2.unitTestDataDir + 
            "CFPointConventions/trajectoryProfile/" +
            "trajectoryProfile-Multidimensional-MultipleTrajectories-H.6.1/" +
            "trajectoryProfile-Multidimensional-MultipleTrajectories-H.6.1.nc";
        String raggedMultipleStationFileName = String2.unitTestDataDir + 
            "CFPointConventions/trajectoryProfile/" +
            "trajectoryProfile-Ragged-MultipleTrajectories-H.6.3/" +
            "trajectoryProfile-Ragged-MultipleTrajectories-H.6.3.nc";

/* */  
        //***************  trajectoryProfile multidimensional single station
        try {
        fileName = String2.unitTestDataDir + 
            "CFPointConventions/trajectoryProfile/" +
            "trajectoryProfile-Multidimensional-SingleTrajectory-H.6.2/" +
            "trajectoryProfile-Multidimensional-SingleTrajectory-H.6.2.nc";
        String2.log("\n\n** Testing contiguous file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, "-h"));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);  
        results = table.dataToString();
        expected = 
"lat,lon,trajectory,alt,time,temperature,salinity\n" +
"4.9986253,-35.718536,0,0.0,0,3.2502668,79.006065\n" +
"4.9986253,-35.718536,0,1.0,0,30.566391,37.089394\n" +
"4.9986253,-35.718536,0,2.0,0,0.8428718,20.478456\n" +
"1.4658529,-25.19569,0,0.0,3600,27.982288,17.57356\n" +
"1.4658529,-25.19569,0,1.0,3600,15.750698,11.152985\n" +
"1.4658529,-25.19569,0,2.0,3600,39.36954,31.84863\n" +
"1.4658529,-25.19569,0,3.0,3600,8.506618,77.88138\n" +
"1.4658529,-25.19569,0,4.0,3600,39.580475,77.575645\n" +
"38.299484,-55.72639,0,0.0,7200,36.646107,77.1104\n";
        Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 20, "");
        results = table.columnAttributes(table.findColumnNumber("lat")).toString();
        expected = 
"    long_name=Latitude\n" +
"    missing_value=-999.9f\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        results = table.columnAttributes(table.findColumnNumber("alt")).toString();
        expected = 
"    axis=Z\n" +
"    long_name=height below mean sea level\n" +
"    missing_value=-999.9f\n" +
"    positive=down\n" +
"    standard_name=altitude\n" +
"    units=m\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10a " + pauseMessage); 

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

        } catch (Exception e) {
            String2.pressEnterToContinue(MustBe.throwableToString(e)); 
        }



        //***************  trajectoryProfile orthogonal multidimensional --- 
        try {
        fileName = orthoMultiDimH61FileName;
        String2.log("\n\n** Testing orthogonal multidim file\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, ""));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(14);
        expected = 
"lat,lon,trajectory,alt,time,temperature,salinity\n" +
"18.736742,-28.520071,0,0.0,0,8.067447,62.835354\n" +
"18.736742,-28.520071,0,1.0,0,15.871663,27.454027\n" +
"18.736742,-28.520071,0,2.0,0,32.306496,61.80094\n" +
"18.736742,-28.520071,0,3.0,0,27.631369,74.84051\n" +
"18.736742,-28.520071,0,4.0,0,22.757963,73.378914\n" +
"39.43245,-57.711514,1,0.0,0,36.39878,77.23479\n" +
"39.43245,-57.711514,1,1.0,0,14.957566,7.621207\n" +
"39.43245,-57.711514,1,2.0,0,5.405648,56.557266\n" +
"39.43245,-57.711514,1,3.0,0,4.9267964,75.427795\n" +
"39.43245,-57.711514,1,4.0,0,7.806849,42.65483\n" +
"39.43245,-57.711514,1,5.0,0,28.784224,13.940006\n" +
"39.43245,-57.711514,1,6.0,0,19.139135,53.46242\n" +
"25.034857,-62.39183,1,0.0,3600,24.302265,62.551056\n" +
"25.034857,-62.39183,1,1.0,3600,11.195762,4.3670874\n" +
"...\n";  
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 65, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=Latitude\n" +
"    missing_value=-999.9f\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10c " + pauseMessage); 

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "alt"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("alt"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");


        String2.log("\n\n** Testing incomplete file with constraints\n" +
            "  " + orthoMultiDimH61FileName);
        //String2.log(NcHelper.ncdump(orthoMultiDimH61FileName, "-h"));
        table.readNcCF(orthoMultiDimH61FileName, null, 
            0,  //standardizeWhat=0
            StringArray.fromCSV("trajectory"), 
            StringArray.fromCSV("="), 
            StringArray.fromCSV("1"));
        results = table.dataToString();
        expected = 
"lat,lon,trajectory,alt,time,temperature,salinity\n" +
"39.43245,-57.711514,1,0.0,0,36.39878,77.23479\n" +
"39.43245,-57.711514,1,1.0,0,14.957566,7.621207\n" +
"39.43245,-57.711514,1,2.0,0,5.405648,56.557266\n" +
"39.43245,-57.711514,1,3.0,0,4.9267964,75.427795\n" +
"39.43245,-57.711514,1,4.0,0,7.806849,42.65483\n" +
"39.43245,-57.711514,1,5.0,0,28.784224,13.940006\n" +
"39.43245,-57.711514,1,6.0,0,19.139135,53.46242\n" +
"25.034857,-62.39183,1,0.0,3600,24.302265,62.551056\n" +
"25.034857,-62.39183,1,1.0,3600,11.195762,4.3670874\n" +
"25.034857,-62.39183,1,2.0,3600,20.055767,62.966892\n" +
"25.034857,-62.39183,1,3.0,3600,38.838474,49.101334\n" +
"25.034857,-62.39183,1,4.0,3600,16.995031,19.580278\n" +
"25.034857,-62.39183,1,5.0,3600,5.6433516,62.23398\n" +
"25.034857,-62.39183,1,6.0,3600,3.8319156,3.1172054\n" +
"27.619982,-46.87254,1,0.0,7200,26.57189,22.247057\n" +
"27.619982,-46.87254,1,1.0,7200,6.7928324,61.507736\n" +
"27.619982,-46.87254,1,2.0,7200,37.85058,49.765\n" +
"27.619982,-46.87254,1,3.0,7200,31.926285,65.68376\n" +
"27.619982,-46.87254,1,4.0,7200,36.00912,39.43354\n" +
"27.619982,-46.87254,1,5.0,7200,1.9108725,22.057114\n" +
"27.619982,-46.87254,1,6.0,7200,23.234598,62.765938\n" +
"16.401363,-38.747154,1,0.0,10800,39.38336,41.227074\n" +
"16.401363,-38.747154,1,1.0,10800,22.487091,60.7646\n" +
"16.401363,-38.747154,1,2.0,10800,16.574474,5.8886514\n" +
"16.401363,-38.747154,1,3.0,10800,3.2033331,48.783085\n" +
"16.401363,-38.747154,1,4.0,10800,32.13747,12.481885\n" +
"16.401363,-38.747154,1,5.0,10800,5.927774,46.63955\n" +
"16.401363,-38.747154,1,6.0,10800,9.936579,44.746056\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 28, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=Latitude\n" +
"    missing_value=-999.9f\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10d " + pauseMessage); 

        //test just variable[obs]  (interiorTable) 
        String2.log("\n\n** Testing incomplete file\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, StringArray.fromCSV("lat,lon,trajectory,time,zztop"),
            0,  //standardizeWhat=0
            StringArray.fromCSV("trajectory"), 
            StringArray.fromCSV("="), 
            StringArray.fromCSV("2"));
        results = table.dataToString();
        expected = 
"lat,lon,trajectory,time\n" +
"22.20038,-74.5625,2,0\n" +
"39.905518,-15.35749,2,3600\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=Latitude\n" +
"    missing_value=-999.9f\n" +
"    standard_name=latitude\n" +
"    units=degrees_north\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10e " + pauseMessage); 
        } catch (Exception e) {
            String2.pressEnterToContinue(MustBe.throwableToString(e)); 
        }


        //**********  NO_DATA
        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, outer/inner/obsVar
        String2.log("\n\n** Testing orthoMultiDimH61FileName just outer/inner/obsVar, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("trajectory,lat,zztop,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDa " + pauseMessage); 


        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, just outerVar
        String2.log("\n\n** Testing orthoMultiDimH61FileName just outerVar, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("zztop,trajectory"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("trajectory"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDb " + pauseMessage); 

        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, just innerVar
        String2.log("\n\n** Testing orthoMultiDimH61FileName just innerVar, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("lat,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("lat"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDc " + pauseMessage); 

        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, just obsVar
        String2.log("\n\n** Testing orthoMultiDimH51File just obsVar, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("zztop,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDd " + pauseMessage); 


        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, just outerVar* and innerVar
        String2.log("\n\n** Testing orthoMultiDimH51File just outer* /innerVar, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("zztop,trajectory,lat"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("trajectory"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDe1 " + pauseMessage); 


        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, just outerVar and innerVar*
        String2.log("\n\n** Testing orthoMultiDimH51File just outer/innerVar*, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("zztop,trajectory,lat"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("lat"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDe2 " + pauseMessage); 


        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, just outerVar* and obsVar
        String2.log("\n\n** Testing orthoMultiDimH51File just outer* /obsVar, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("trajectory,temperature,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("trajectory"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDf1 " + pauseMessage); 

        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, just outerVar and obsVar*
        String2.log("\n\n** Testing orthoMultiDimH51File just outer/obsVar*, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("trajectory,temperature,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDf2 " + pauseMessage); 

        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, just innerVar* and obsVar
        String2.log("\n\n** Testing orthoMultiDimH51File just inner* /obsVar, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("lat,temperature,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("lat"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDg1 " + pauseMessage); 
      
        //**********  trajectoryProfile orthoMultiDimH61FileName --- NO_DATA, just innerVar and obsVar*
        String2.log("\n\n** Testing orthoMultiDimH51File just inner/obsVar*, NO_DATA\n" +
            "  " + orthoMultiDimH61FileName);
        table.readNcCF(orthoMultiDimH61FileName, 
            StringArray.fromCSV("lat,temperature,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10NDg2 " + pauseMessage); 


        //*******
        //***************  trajectoryProfile ragged multiple station --- 
        try {
        fileName = raggedMultipleStationFileName;
        String2.log("\n\n** Testing raggedMultipleStationFile\n" +
            "  " + fileName);
        String2.log(NcHelper.ncdump(fileName, ""));
        table.readNcCF(fileName, null, 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"trajectory,lat,lon,time,z,temperature,humidity\n" +
"0,49.0,-60.0,176400,0.0,39.174652,78.30777\n" +
"0,49.0,-60.0,176400,1.0,30.924078,58.185684\n" +
"0,49.0,-60.0,176400,2.0,19.258087,47.014008\n" +
"0,49.0,-60.0,176400,3.0,33.512325,77.832664\n" +
"0,49.0,-60.0,176400,4.0,35.435345,55.649605\n" +
"0,49.0,-60.0,176400,5.0,17.33441,60.725643\n" +
"0,49.0,-60.0,176400,6.0,6.3611813,40.747665\n" +
"0,49.0,-60.0,176400,7.0,37.18272,32.312344\n" +
"0,49.0,-60.0,176400,8.0,31.59126,30.934\n" +
"0,49.0,-60.0,176400,9.0,36.08196,48.639427\n" +
"0,49.0,-60.0,176400,10.0,22.3596,16.427603\n" +
"0,49.0,-60.0,176400,11.0,6.2299767,16.590557\n" +
"0,53.0,-60.0,104400,0.0,13.244916,28.135975\n" +
"0,53.0,-60.0,104400,1.0,17.160164,41.951385\n";
        Test.ensureEqual(results.substring(0, expected.length()), expected, 
            "results=\n" + results);
        expected = 
"4,47.0,-44.0,136800,33.0,8.7725,74.930565\n" +
"4,47.0,-44.0,136800,34.0,29.10568,31.136621\n" +
"4,47.0,-44.0,136800,35.0,4.7999196,18.904522\n" +
"4,47.0,-44.0,136800,36.0,1.4633778,47.546745\n" +
"4,47.0,-44.0,136800,37.0,24.846626,77.9313\n" +
"4,47.0,-44.0,136800,38.0,16.368006,8.343946\n";
        Test.ensureEqual(
            results.substring(results.length() - expected.length(), results.length()),
            expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 594, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    cf_role=trajectory_id\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10m " + pauseMessage); 

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory,lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "z,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "z,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "z,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "z,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "z,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature,trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            //
            table.readNcCF(fileName, StringArray.fromCSV(
                "trajectory"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("trajectory"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "lat"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("lat"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "temperature"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("temperature"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

            table.readNcCF(fileName, StringArray.fromCSV(
                "z"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("z"), 
                StringArray.fromCSV("="),
                StringArray.fromCSV("-12345"));
            Test.ensureEqual(table.nRows(), 0, "");
            Test.ensureEqual(table.nColumns(), 0, "");

        //***************  trajectoryProfile ragged multiple station ---  just outerVar
        String2.log("\n\n** Testing raggedMultipleStationFile just outerVar\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("zztop,trajectory"), 
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(20);
        expected = 
"trajectory\n" +
"0\n" +
"1\n" +
"2\n" +
"3\n" +
"4\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 5, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    cf_role=trajectory_id\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10n " + pauseMessage); 

        //***************  trajectoryProfile ragged multiple station ---  just innerVar
        String2.log("\n\n** Testing raggedMultipleStationFile just innerVar\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("time,zztop,trajectory"), 
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"time,trajectory\n" +
"176400,0\n" +
"104400,0\n" +
"140400,0\n" +
"151200,0\n" +
"111600,1\n" +
"36000,1\n" +
"64800,1\n" +
"46800,1\n" +
"0,2\n" +
"162000,2\n" +
"180000,2\n" +
"129600,2\n" +
"154800,3\n" +
"3600,3\n" +
"122400,3\n" +
"32400,3\n" +
"136800,4\n" +
"140400,4\n" +
"140400,4\n" +
"136800,4\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 20, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=time of measurement\n" +
"    missing_value=-999i\n" +
"    standard_name=time\n" +
"    units=seconds since 1990-01-01 00:00:00\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10o " + pauseMessage); 

        //***************  trajectoryProfile ragged multiple station ---  just outerVar and innerVar
        String2.log("\n\n** Testing raggedMultipleStationFile just outerVar and innerVar\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("lon,lat,time,trajectory,"), 
            0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString();
        expected = 
"lon,lat,time,trajectory\n" +
"-60.0,49.0,176400,0\n" +
"-60.0,53.0,104400,0\n" +
"-63.0,45.0,140400,0\n" +
"-62.0,45.0,151200,0\n" +
"-56.0,54.0,111600,1\n" +
"-68.0,53.0,36000,1\n" +
"-66.0,43.0,64800,1\n" +
"-47.0,58.0,46800,1\n" +
"-52.0,47.0,0,2\n" +
"-50.0,48.0,162000,2\n" +
"-60.0,59.0,180000,2\n" +
"-71.0,42.0,129600,2\n" +
"-66.0,53.0,154800,3\n" +
"-53.0,50.0,3600,3\n" +
"-67.0,56.0,122400,3\n" +
"-73.0,48.0,32400,3\n" +
"-67.0,47.0,136800,4\n" +
"-45.0,43.0,140400,4\n" +
"-40.0,54.0,140400,4\n" +
"-44.0,47.0,136800,4\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 20, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    long_name=station longitude\n" +
"    standard_name=longitude\n" +
"    units=degrees_east\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10p " + pauseMessage); 

        //***************  trajectoryProfile ragged multiple station ---  just outerVar and obsVar
        String2.log("\n\n** Testing raggedMultipleStationFile just outerVar and obsVar\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("trajectory,temperature,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("39"));
        results = table.dataToString();
        expected = 
"trajectory,temperature\n" +
"0,39.174652\n" +
"0,39.157566\n" +
"0,39.915646\n" +
"0,39.041203\n" +
"1,39.104313\n" +
"1,39.74818\n" +
"1,39.077923\n" +
"1,39.406986\n" +
"2,39.85588\n" +
"2,39.213017\n" +
"2,39.89851\n" +
"2,39.404697\n" +
"2,39.012913\n" +
"3,39.276768\n" +
"3,39.832867\n" +
"3,39.119217\n" +
"3,39.335064\n" +
"3,39.261826\n" +
"3,39.501484\n" +
"4,39.015987\n" +
"4,39.5769\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 21, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    cf_role=trajectory_id\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10q " + pauseMessage); 

        //***************  trajectoryProfile ragged multiple station ---  just innerVar and obsVar
        String2.log("\n\n** Testing raggedMultipleStationFile just innerVar and obsVar\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("temperature,zztop,time"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("39"));
        results = table.dataToString();
        expected = 
"temperature,time\n" +
"39.174652,176400\n" +
"39.157566,104400\n" +
"39.915646,104400\n" +
"39.041203,104400\n" +
"39.104313,111600\n" +
"39.74818,36000\n" +
"39.077923,64800\n" +
"39.406986,64800\n" +
"39.85588,0\n" +
"39.213017,180000\n" +
"39.89851,180000\n" +
"39.404697,180000\n" +
"39.012913,180000\n" +
"39.276768,154800\n" +
"39.832867,3600\n" +
"39.119217,122400\n" +
"39.335064,122400\n" +
"39.261826,122400\n" +
"39.501484,122400\n" +
"39.015987,140400\n" +
"39.5769,136800\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 21, "");
        results = table.columnAttributes(0).toString();
        expected = 
"    coordinates=time lat lon z\n" +
"    long_name=Air Temperature\n" +
"    missing_value=-999.9f\n" +
"    standard_name=air_temperature\n" +
"    units=Celsius\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#10r " + pauseMessage); 


        //**********  NO_DATA
        //**********  trajectoryProfile ragged multiple station --- NO_DATA, outer/inner/obsVar
        String2.log("\n\n** Testing raggedMultipleStationFile just outer/inner/obsVar, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("trajectory,zztop,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11a " + pauseMessage); 


        //**********  trajectoryProfile ragged multiple station --- NO_DATA, just outerVar
        String2.log("\n\n** Testing raggedMultipleStationFile just outerVar, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("zztop,trajectory"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("trajectory"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("10"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11b " + pauseMessage); 

        //**********  trajectoryProfile ragged multiple station --- NO_DATA, just innerVar
        String2.log("\n\n** Testing raggedMultipleStationFile just innerVar, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("time,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("time"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11c " + pauseMessage); 

        //**********  trajectoryProfile ragged multiple station --- NO_DATA, just obsVar
        String2.log("\n\n** Testing raggedMultipleStationFile just obsVar, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("zztop,temperature"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11d " + pauseMessage); 


        //**********  trajectoryProfile ragged multiple station --- NO_DATA, just outerVar* and innerVar
        String2.log("\n\n** Testing raggedMultipleStationFile just outer*/innerVar, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("zztop,z,trajectory"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("z"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11e1 " + pauseMessage); 


        //**********  trajectoryProfile ragged multiple station --- NO_DATA, just outerVar and innerVar*
        String2.log("\n\n** Testing raggedMultipleStationFile just outer/innerVar*, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("zztop,z,trajectory"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("trajectory"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-5"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11e2 " + pauseMessage); 


        //**********  trajectoryProfile ragged multiple station --- NO_DATA, just outerVar* and obsVar
        String2.log("\n\n** Testing raggedMultipleStationFile just outer*/obsVar, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("temperature,trajectory,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("trajectory"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-10"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11f1 " + pauseMessage); 

        //**********  trajectoryProfile ragged multiple station --- NO_DATA, just outerVar and obsVar*
        String2.log("\n\n** Testing raggedMultipleStationFile just outer/obsVar*, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("temperature,trajectory,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11f2 " + pauseMessage); 

        //**********  trajectoryProfile ragged multiple station --- NO_DATA, just innerVar* and obsVar
        String2.log("\n\n** Testing raggedMultipleStationFile just inner*/obsVar, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("temperature,z,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("z"),
            StringArray.fromCSV("="),
            StringArray.fromCSV("-1"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11g1 " + pauseMessage); 
      
        //**********  trajectoryProfile ragged multiple station --- NO_DATA, just innerVar and obsVar*
        String2.log("\n\n** Testing raggedMultipleStationFile just inner/obsVar*, NO_DATA\n" +
            "  " + raggedMultipleStationFileName);
        table.readNcCF(raggedMultipleStationFileName, 
            StringArray.fromCSV("temperature,z,zztop"), 
            0,  //standardizeWhat=0
            StringArray.fromCSV("temperature"),
            StringArray.fromCSV(">="),
            StringArray.fromCSV("100"));
        Test.ensureEqual(table.nRows(), 0, "");
        Test.ensureEqual(table.nColumns(), 0, "");
        if (pauseAfterEach) 
            String2.pressEnterToContinue("#11g2 " + pauseMessage); 
      
        } catch (Exception e) {
            String2.pressEnterToContinue(MustBe.throwableToString(e)); 
        }
        /* */
        debugMode = oDebug;        
    }

    /** 
     * This reads an NCEI-style invalid CF DSG Contiguous Ragged Array .nc file.
     * Suitable sample files are from https://data.nodc.noaa.gov/thredds/catalog/ncei/wod/
     * See local copies in /erddapTestBig/nccf/wod/
     *
     * @param colNames If empty, this reads all columns.
     *     If conNames... specified and this is specified, this includes all of the conNames.
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat
     * @param conNames may be null or size=0;
     * @throws Exception if trouble.
     *    No matching data is not an error and returns an empty table (0 rows and 0 columns).
     */
    public void readInvalidCRA(String fullName, StringArray colNames,
        int standardizeWhat,
        StringArray conNames, StringArray conOps, StringArray conVals) throws Exception {

        String msg = "  Table.readInvalidCRA " + fullName; 
        long time = System.currentTimeMillis();
        clear();
        if (colNames == null) 
            colNames = new StringArray(1, false);
        //String2.log(NcHelper.ncdump(fullName, "-h"));  
        NetcdfFile ncFile = NcHelper.openFile(fullName); 
        Attributes gridMappingAtts = null;
        try {

            NcHelper.getGlobalAttributes(ncFile, globalAttributes());
            Attributes gatts = globalAttributes();

            //ensure featureType=Profile (other single level types could be supported -- need examples)
            String featureType = gatts.getString("featureType");
            featureType = featureType == null? "" : String2.toTitleCase(featureType);
            Test.ensureEqual(featureType, "Profile", "Unexpected featureType.");

            //find vars with sample_dimension, find outerDimName, largestInnerDim
            String profileIDVarName = null;
            int    profileIDVarNumber = -1;
            String outerDimName = null; //e.g., cast
            Dimension outerDim = null;
            String largestInnerDimName = null; //e.g., z_obs
            int largestInnerDimSize = -1;
            List<Variable> varList = ncFile.getVariables();
            int nVars = varList.size();
            String vNames[]           = new String[nVars];
            Attributes vatts[]        = new Attributes[nVars];
            PAType varPATypes[]       = new PAType[nVars];
            boolean isCharArray[]     = new boolean[nVars];
            int nDims[]               = new int[nVars];
            int realNDims[]           = new int[nVars];
            String varMissingValues[] = new String[nVars];
            boolean varHasSampleDimensionAtt[] = new boolean[nVars];
            HashMap<String,PrimitiveArray> rowSizesHM = new HashMap(); //e.g., sample_dimension="z_obs" -> z_row_size PA
            for (int v = 0; v < nVars; v++) {
                Variable var = varList.get(v);
                vNames[v] = var.getFullName();
                vatts[v] = new Attributes();
                NcHelper.getVariableAttributes(var, vatts[v]);

                //does this var point to the pseudo-data var with CF grid_mapping (projection) information?
                if (gridMappingAtts == null) {
                    gridMappingAtts = NcHelper.getGridMappingAtts(ncFile, 
                        vatts[v].getString("grid_mapping"));
                    if (gridMappingAtts != null)
                        globalAttributes.add(gridMappingAtts);
                }

                varPATypes[v] = NcHelper.getElementPAType(var); //exception if trouble
                nDims[v] = var.getRank();
                isCharArray[v] = nDims[v] > 0 &&  varPATypes[v] == PAType.CHAR; 
                if (varPATypes[v] == PAType.CHAR)
                    varPATypes[v] = PAType.STRING; //assume all char -> string
                realNDims[v] = nDims[v] - (isCharArray[v]? 1 : 0);
                varMissingValues[v] = vatts[v].getString("_FillValue");
                if (varMissingValues[v] == null)
                    varMissingValues[v] = vatts[v].getString("missing_value");
                if (varMissingValues[v] == null)
                    varMissingValues[v] = "";

                //profile_id?
                String cfRole = vatts[v].getString("cf_role");
                if (cfRole != null)
                    cfRole = cfRole.toLowerCase();
                if ("profile_id".equals(cfRole)) {
                    if (debugMode) msg +=
                        "\n>> found cf_role=profile_id for var=" + vNames[v];
                    if (profileIDVarName != null)
                        throw new RuntimeException( 
                            "Two variables have the attribute cf_role=profile_id: " +
                            profileIDVarName + " and " + vNames[v] + ".");
                    profileIDVarName = vNames[v];
                    profileIDVarNumber = v;

                    Test.ensureEqual(realNDims[v], 1, 
                        "Unexpected number of dimensions for var=" + vNames[v]);
                    Dimension tOuterDim = var.getDimension(0);
                    String tOuterDimName = tOuterDim.getFullName();
                    Test.ensureNotNull(tOuterDimName,  
                        "Unexpected dimensionName=null for var=" + vNames[v]);
                    if (outerDimName == null) {
                        outerDimName = tOuterDimName;
                        outerDim     = tOuterDim;
                    } else {
                        Test.ensureEqual(tOuterDimName, outerDimName, 
                            "Unexpected dimension for var=" + vNames[v]);
                    }
                }

                //gather sample_dimension atts and row_size PAs
                //INVALID FILES: Primary_Investigator_rowsize doesn't have sample_dimension: so fix it
                //  See "numberofpis" below for additional, related fixes.
                String sampleDimension = vNames[v].equals("Primary_Investigator_rowsize")?
                    "numberofpis" :  
                    vatts[v].getString("sample_dimension");
                if (sampleDimension != null) {
                    if (debugMode) msg += 
                        "\n>> found sample_dimension=" + sampleDimension + " for var=" + vNames[v];
                    varHasSampleDimensionAtt[v] = true;

                    //get/verify outerDimName, e.g., casts
                    Test.ensureEqual(realNDims[v], 1, 
                        "Unexpected number of dimensions for var=" + vNames[v]);
                    Dimension tOuterDim = var.getDimension(0);
                    String tOuterDimName = tOuterDim.getFullName();
                    Test.ensureNotNull(tOuterDimName, 
                        "Unexpected dimensionName=null for var=" + vNames[v]);
                    if (outerDimName == null) {
                        outerDimName = tOuterDimName;
                        outerDim     = tOuterDim;
                    } else {
                        Test.ensureEqual(tOuterDimName, outerDimName, 
                            "Unexpected dimension for var=" + vNames[v]);
                    }

                    //get rowSizes
                    rowSizesHM.put(sampleDimension, NcHelper.getPrimitiveArray(var));
                    //no need to unpack rowSizes

                    //is it the largest sample_dimension (e.g., z_obs)?
                    Dimension dim = ncFile.findDimension(sampleDimension);                    
                    int tSize = dim.getLength();
                    if (tSize > largestInnerDimSize) {
                        largestInnerDimSize = tSize;
                        largestInnerDimName = sampleDimension;
                    }                        
                }
            }
            Test.ensureNotNull(profileIDVarName, 
                "No variable was found with a cf_role=profile_id attribute.");
            Test.ensureTrue(outerDimName != null, 
                "No outer dimension (e.g., casts) found!");
            Test.ensureTrue(largestInnerDimSize > 0, 
                "No row_size variables with a sample_dimension attribute (e.g., z_obs) were found!");
            int outerDimSize = outerDim.getLength();

            //read the outerDim vars (including scalars and primary_investigator)  
            if (debugMode) msg += "\n>> read the outerDim";
            Table outerTable = new Table();
            StringArray cdm_profile_variables = new StringArray();
            for (int v = 0; v < nVars; v++) {
                Variable var = varList.get(v);
                Attributes vatt = vatts[v];

                //if varName isn't in colNames, skip it
                if (colNames.size() > 0 && colNames.indexOf(vNames[v]) < 0)
                    continue;  

                //scalar?   e.g., crs
                if (realNDims[v] == 0) {
                    if (debugMode) msg += "\n>> found scalar var=" + vNames[v];

                    if ("crs".equals(vNames[v])) {
                        //if crs, ignore value and promote to vatts to gatt
                        String[] vattNames = vatt.getNames(); 
                        int vattSize = vattNames.length;
                        for (int va = 0; va < vattSize; va++)
                            gatts.add(vNames[v] + "_" + vattNames[va], vatt.get(vattNames[va]));
                    } else {
                        //add to outerTable
                        outerTable.addColumn(outerTable.nColumns(), vNames[v], 
                            NcHelper.getPrimitiveArray(var), vatt);                        
                        outerTable.standardizeLastColumn(standardizeWhat);
                    }
                    continue;

                } else if (realNDims[v] == 1) {
                    Dimension dim = var.getDimension(0);
                    String dimName = dim.getFullName();

                    //FIX flaws related to Primary_Investigator / numberofpis.
                    //Treat numberofpis differently than other dimNames:
                    //  convert PI's for each cast into /-separated string since some have internal ';'.
                    if (dimName.equals("numberofpis")) { 
                        PrimitiveArray rowSizesPA = rowSizesHM.get(dimName);
                        Test.ensureNotNull(rowSizesPA, 
                            "No row_size info for dim=" + dimName + " for var=" + vNames[v]);
                        PrimitiveArray varPA = NcHelper.getPrimitiveArray(var);
                        StringArray newPA = new StringArray(outerDimSize, false);
                        PrimitiveArray tSubset = null;
                        int thisPo = 0;
                        for (int outer = 0; outer < outerDimSize; outer++) {
                            int thisChunkSize = rowSizesPA.getInt(outer);
                            tSubset = varPA.subset(tSubset, thisPo, 1, thisPo + thisChunkSize - 1);
                            //usually just 0 or 1 pi's, gld has more
                            String tts = String2.toSVString(tSubset.toStringArray(), "/", false); 
                            newPA.add(tts);                             
                            thisPo += thisChunkSize;
                        }
                        //add to outerTable
                        outerTable.addColumn(outerTable.nColumns(), vNames[v], 
                            newPA, vatt);  
                        outerTable.standardizeLastColumn(standardizeWhat);
                        continue;
                    }

                    if (!outerDimName.equals(dimName))
                        continue;
                    if (varHasSampleDimensionAtt[v])    
                        //it's a row_size var with a sample_dimension att
                        continue;

                    //add to outerTable
                    outerTable.addColumn(outerTable.nColumns(), vNames[v], 
                        NcHelper.getPrimitiveArray(var), vatt);  //char -> String
                    outerTable.standardizeLastColumn(standardizeWhat);
                }
            }

            //expand scalars to same number of rows as outerDim
            ensureColumnsAreSameSize_LastValue();

            //set cdm_profile_variables
            String cpv = outerTable.getColumnNamesCSSVString();
            cpv = String2.replaceAll(cpv, ", lat,", ", latitude,");
            cpv = String2.replaceAll(cpv, ", lon,", ", longitude,");
            cpv = String2.replaceAll(cpv, ", z,", ", depth,");
            //the numeric time variable is called time
            if (cpv.length() > 0)
                gatts.set("cdm_profile_variables", cpv);

            //apply constraints, but keep all rows
            if (debugMode) String2.log(">> apply constraints");
            BitSet keepOuter = new BitSet();
            keepOuter.set(0, outerDimSize);
            if (outerTable.nRows() > 0 && 
                outerTable.tryToApplyConstraints(profileIDVarNumber,
                    conNames, conOps, conVals, keepOuter) == 0) {
                //No matching data is not an error and returns an empty table (0 rows and 0 columns).
                if (reallyVerbose) msg += " finished. " + 
                    MustBe.THERE_IS_NO_DATA + 
                    " Just outer table. time" + (System.currentTimeMillis() - time) + "ms";
                return;
            }
            boolean keepAllOuter = keepOuter.nextClearBit(0) == -1;

            //are we done?
            if (debugMode) msg += "\n>> are we done because just outer columns?";
            if (colNames.size() > 0) {
                //are all colNames in outerTable?
                boolean done = true;
                for (int col = 0; col < colNames.size(); col++) {
                    if (outerTable.findColumnNumber(colNames.get(col)) < 0) {
                        done = false;
                        break;
                    }
                }

                if (done) {
                    ncFile.close();
                    ncFile = null;
                    outerTable.justKeep(keepOuter);
                    outerTable.reorderColumns(colNames, true);
                    outerTable.decodeCharsAndStrings();
                    outerTable.convertToUnsignedPAs();

                    //copy outerTable to this table
                    for (int col = 0; col < outerTable.nColumns(); col++)
                        addColumn(col, outerTable.getColumnName(col), 
                            outerTable.getColumn(col), outerTable.columnAttributes(col));

                    if (reallyVerbose) msg +=
                        " finished. Just outer table. nRows=" + 
                        nRows() + " nCols=" + nColumns() + 
                        " time=" + (System.currentTimeMillis() - time) + "ms";
                    return;
                }
            }

            //find nActiveInnerRows and largestLargestChunkSize
            PrimitiveArray largestRowSizes = rowSizesHM.get(largestInnerDimName);
            int checkNTotalInnerRows = 0;
            int nActiveInnerRows = 0;
            int largestLargestChunkSize = 0;
            for (int outer = 0; outer < outerDimSize; outer++) {
                int tChunkSize = largestRowSizes.getInt(outer);
                checkNTotalInnerRows += tChunkSize;
                if (!keepOuter.get(outer)) //skip this outer
                    continue;
                nActiveInnerRows += tChunkSize;
                largestLargestChunkSize = Math.max(largestLargestChunkSize, tChunkSize);
            }
            if (checkNTotalInnerRows != largestInnerDimSize)
                throw new RuntimeException("Invalid file: The sum of the row sizes for " +
                    largestInnerDimName + " (" + checkNTotalInnerRows + ") doesn't equal the size of dimension=" +
                    largestInnerDimName + " (" + largestInnerDimSize + ").");

            //expand the kept outerTable rows in this table
            for (int col = 0; col < outerTable.nColumns(); col++) {
                String tName = outerTable.getColumnName(col);

                //if varName isn't in colNames, skip it
                if (colNames.size() > 0 && colNames.indexOf(tName) < 0)
                    continue;  
                if (debugMode) msg += "\n>> expand outerTable into this table, var=" + tName;

                PrimitiveArray otpa = outerTable.getColumn(col);
                PrimitiveArray newPA = PrimitiveArray.factory(otpa.elementType(), 
                    nActiveInnerRows, false);
                addColumn(nColumns(), tName, newPA, outerTable.columnAttributes(col));

                for (int outer = 0; outer < outerDimSize; outer++) {

                    if (!keepOuter.get(outer)) {
                        //skip this outer, e.g., this cast
                        continue;
                    }

                    //addN of that value
                    newPA.addNStrings(largestRowSizes.getInt(outer), otpa.getString(outer));  
                }
            }
            outerTable = null; //encourage gc

            //make the innerTable in this table
            for (int v = 0; v < nVars; v++) {
                Variable var = varList.get(v);
                Attributes vatt = vatts[v];

                //if varName isn't in colNames, skip it
                if (colNames.size() > 0 && colNames.indexOf(vNames[v]) < 0)
                    continue;  

                //find 1D vars where dim isn't outerDimName, e.g., Temperature
                if (realNDims[v] != 1) 
                    continue;
                Dimension dim = var.getDimension(0);
                String dimName = dim.getFullName();
                if (outerDimName.equals(dimName) || //already in outer table? 
                    dimName.equals("numberofpis")) 
                    continue;

                //Let's do this!
                if (debugMode) msg +=
                    "\n>> make the innerTable in this table, v[" + v + "]=" + vNames[v];
                
                //get the row_size info
                PrimitiveArray rowSizesPA = rowSizesHM.get(dimName);
                Test.ensureNotNull(rowSizesPA, 
                    "No row_size info for dim=" + dimName + " for var=" + vNames[v]);

                //get the var's data
                PrimitiveArray varPA = NcHelper.getPrimitiveArray(var);
                varPA = vatts[v].standardizeVariable(standardizeWhat, vNames[v], varPA);

                //can we use varPA as is?
                if (keepAllOuter && varPA.size() == largestInnerDimSize) {
                    addColumn(nColumns(), vNames[v], varPA, vatts[v]);
                    continue;
                }

                //build newPA, with correct size for each cast, and just keep the keepOuter chunks
                PrimitiveArray newPA = PrimitiveArray.factory(varPATypes[v], 
                    nActiveInnerRows, false);

                int thisPo = 0;
                PrimitiveArray tSubset = null;
                for (int outer = 0; outer < outerDimSize; outer++) {
                    int largestChunkSize = largestRowSizes.getInt(outer);
                    int thisChunkSize    = rowSizesPA.getInt(outer);

                    if (!keepOuter.get(outer)) {
                        //skip this outer
                        thisPo    += thisChunkSize;
                        continue;
                    }

                    if (thisChunkSize == 0) {
                        //This deals with the main invalid part of these files.
                        //add missing values to newPA
                        newPA.addNStrings(largestChunkSize, varMissingValues[v]);  

                    } else if (thisChunkSize == largestChunkSize) {
                        //copy values into newPA
                        tSubset = varPA.subset(tSubset, thisPo, 1, thisPo + thisChunkSize - 1);
                        newPA.append(tSubset); 

                        //only need to do once, but not extant till here
                        tSubset.clear(); //speeds up ensureCapacity
                        tSubset.ensureCapacity(largestLargestChunkSize); 

                    } else {
                        throw new RuntimeException("For " + outerDimName + "[" + outer + 
                            "], the number of " + dimName + " values (" + thisChunkSize + 
                            ") doesn't equal the number of " + largestInnerDimName + 
                            " values (" + largestChunkSize + ").");
                    }                                 
                    thisPo += thisChunkSize;
                }
                if (thisPo != varPA.size())
                    throw new RuntimeException("Invalid file: The sum of the row sizes for " +
                        dimName + " (" + thisPo + ") doesn't equal the size of dimension=" +
                        dimName + " (" + varPA.size() + ").");

                addColumn(nColumns(), vNames[v], newPA, vatts[v]);
            }             

            //finish up 
            ncFile.close();
            ncFile = null;

            //apply all constraints
            tryToApplyConstraintsAndKeep(findColumnNumber(profileIDVarName),  //may be -1
                conNames, conOps, conVals); //may be 0 rows left

            //put in colNames order
            if (colNames.size() > 0) 
                reorderColumns(colNames, true);

            //we're done
            if (reallyVerbose) msg += 
                " finished. nRows=" + nRows() + " nCols=" + nColumns() + 
                " time=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Exception e) {
            if (!reallyVerbose) String2.log(msg); 
            throw new Exception(String2.ERROR + " in readInvalidCRA(" + fullName + "): " + 
                e.toString(), e);

        } finally {
            //make sure ncFile is explicitly closed
            if (ncFile != null) {
                try { ncFile.close();
                } catch (Throwable t2) {}
            }
            if (reallyVerbose) String2.log(msg);
        }
    }


    public static void testReadInvalidCRA() throws Exception {
        String2.log("\n*** Table.testReadInvalidCRA()");
        StringArray colNames, conNames, conOps, conVals;
        Table table = new Table();
        table.debugMode = true;
        String dir = String2.unitTestBigDataDir + "nccf/wod/";
        String fullName, results, expected;
        //String doAllString = String2.getStringFromSystemIn(
        //    "Do all the tests, including ones that are slow and take lots of memory (y/n)?");
        boolean doAll = true; //doAllString.startsWith("y");
/* */
        //read all
        fullName = dir + "wod_apb_2005.nc";
        if (doAll) {
            table.readInvalidCRA(fullName, null, 0,  //standardizeWhat=0
                null, null, null);
            results = table.toString(5);
            expected = 
"{\n" +
"dimensions:\n" +
"\trow = 19223385 ;\n" +
"\tcountry_strlen = 13 ;\n" +
"\tWOD_cruise_identifier_strlen = 8 ;\n" +
"\toriginators_cruise_identifier_strlen = 15 ;\n" +
"\tProject_strlen = 60 ;\n" +
"\tPlatform_strlen = 19 ;\n" +
"\tdataset_strlen = 14 ;\n" +
"\tOcean_Vehicle_strlen = 13 ;\n" +
"\tTemperature_Instrument_strlen = 73 ;\n" +
"\tSalinity_Instrument_strlen = 73 ;\n" +
"\tPrimary_Investigator_strlen = 20 ;\n" +
"\tPrimary_Investigator_VAR_strlen = 13 ;\n" +
"variables:\n" +
"\tchar country(row, country_strlen) ;\n" +
"\tchar WOD_cruise_identifier(row, WOD_cruise_identifier_strlen) ;\n" +
"\t\tWOD_cruise_identifier:comment = \"two byte country code + WOD cruise number (unique to country code)\" ;\n" +
"\t\tWOD_cruise_identifier:long_name = \"WOD_cruise_identifier\" ;\n" +
"\tchar originators_cruise_identifier(row, originators_cruise_identifier_strlen) ;\n" +
"\tint wod_unique_cast(row) ;\n" +
"\t\twod_unique_cast:cf_role = \"profile_id\" ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:standard_name = \"latitude\" ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:standard_name = \"longitude\" ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:units = \"days since 1770-01-01 00:00:00 UTC\" ;\n" +
"\tint date(row) ;\n" +
"\t\tdate:comment = \"YYYYMMDD\" ;\n" +
"\t\tdate:long_name = \"date\" ;\n" +
"\tfloat GMT_time(row) ;\n" +
"\t\tGMT_time:long_name = \"GMT_time\" ;\n" +
"\t\tGMT_time:units = \"hours\" ;\n" +
"\tint Access_no(row) ;\n" +
"\t\tAccess_no:_FillValue = -99999 ;\n" +
"\t\tAccess_no:comment = \"used to find original data at NODC\" ;\n" +
"\t\tAccess_no:long_name = \"NODC_accession_number\" ;\n" +
"\t\tAccess_no:units_wod = \"NODC_code\" ;\n" +
"\tchar Project(row, Project_strlen) ;\n" +
"\t\tProject:comment = \"name or acronym of project under which data were measured\" ;\n" +
"\t\tProject:long_name = \"Project_name\" ;\n" +
"\tchar Platform(row, Platform_strlen) ;\n" +
"\t\tPlatform:comment = \"name of platform from which measurements were taken\" ;\n" +
"\t\tPlatform:long_name = \"Platform_name\" ;\n" +
"\tint Orig_Stat_Num(row) ;\n" +
"\t\tOrig_Stat_Num:_FillValue = -99999 ;\n" +
"\t\tOrig_Stat_Num:comment = \"number assigned to a given station by data originator\" ;\n" +
"\t\tOrig_Stat_Num:long_name = \"Originators_Station_Number\" ;\n" +
"\tchar dataset(row, dataset_strlen) ;\n" +
"\t\tdataset:long_name = \"WOD_dataset\" ;\n" +
"\tchar Ocean_Vehicle(row, Ocean_Vehicle_strlen) ;\n" +
"\t\tOcean_Vehicle:comment = \"Ocean_vehicle\" ;\n" +
"\tbyte Temperature_WODprofileflag(row) ;\n" +
"\t\tTemperature_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tTemperature_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Temperature_Instrument(row, Temperature_Instrument_strlen) ;\n" +
"\t\tTemperature_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tTemperature_Instrument:long_name = \"Instrument\" ;\n" +
"\tint Temperature_uncalibrated(row) ;\n" +
"\t\tTemperature_uncalibrated:_FillValue = -99999 ;\n" +
"\t\tTemperature_uncalibrated:comment = \"set if measurements have not been calibrated\" ;\n" +
"\tbyte Salinity_WODprofileflag(row) ;\n" +
"\t\tSalinity_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tSalinity_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Salinity_Instrument(row, Salinity_Instrument_strlen) ;\n" +
"\t\tSalinity_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tSalinity_Instrument:long_name = \"Instrument\" ;\n" +
"\tchar Primary_Investigator(row, Primary_Investigator_strlen) ;\n" +
"\tchar Primary_Investigator_VAR(row, Primary_Investigator_VAR_strlen) ;\n" +
"\tfloat z(row) ;\n" +
"\t\tz:ancillary_variables = \"z_sigfigs z_WODflag\" ;\n" +
"\t\tz:long_name = \"depth_below_sea_surface\" ;\n" +
"\t\tz:positive = \"down\" ;\n" +
"\t\tz:standard_name = \"depth\" ;\n" +
"\t\tz:units = \"m\" ;\n" +
"\tbyte z_WODflag(row) ;\n" +
"\t\tz_WODflag:flag_meanings = \"accepted duplicate_or_inversion density_inversion\" ;\n" +
"\t\tz_WODflag:flag_values = 0, 1, 2 ;\n" +
"\t\tz_WODflag:long_name = \"WOD_depth_level_flag\" ;\n" +
"\t\tz_WODflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_sigfigs(row) ;\n" +
"\t\tz_sigfigs:long_name = \"depth significant figures   \" ;\n" +
"\tfloat Temperature(row) ;\n" +
"\t\tTemperature:_FillValue = -1.0E10f ;\n" +
"\t\tTemperature:ancillary_variables = \"Temperature_sigfigs Temperature_WODflag Temperature_WODprofileflag\" ;\n" +
"\t\tTemperature:coordinates = \"time lat lon z\" ;\n" +
"\t\tTemperature:grid_mapping = \"crs\" ;\n" +
"\t\tTemperature:long_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:units = \"degree_C\" ;\n" +
"\tbyte Temperature_sigfigs(row) ;\n" +
"\t\tTemperature_sigfigs:long_name = \"sea_water_temperature significant_figures\" ;\n" +
"\tbyte Temperature_WODflag(row) ;\n" +
"\t\tTemperature_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tTemperature_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tTemperature_WODflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tfloat Pressure(row) ;\n" +
"\t\tPressure:_FillValue = -1.0E10f ;\n" +
"\t\tPressure:ancillary_variables = \"Pressure_sigfigs Pressure_WODflag Pressure_WODprofileflag\" ;\n" +
"\t\tPressure:coordinates = \"time lat lon z\" ;\n" +
"\t\tPressure:grid_mapping = \"crs\" ;\n" +
"\t\tPressure:long_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:standard_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:units = \"dbar\" ;\n" +
"\tbyte Pressure_sigfigs(row) ;\n" +
"\t\tPressure_sigfigs:long_name = \"sea_water_pressure significant_figures\" ;\n" +
"\tfloat Salinity(row) ;\n" +
"\t\tSalinity:_FillValue = -1.0E10f ;\n" +
"\t\tSalinity:ancillary_variables = \"Salinity_sigfigs Salinity_WODflag Salinity_WODprofileflag\" ;\n" +
"\t\tSalinity:coordinates = \"time lat lon z\" ;\n" +
"\t\tSalinity:grid_mapping = \"crs\" ;\n" +
"\t\tSalinity:long_name = \"sea_water_salinity\" ;\n" +
"\t\tSalinity:standard_name = \"sea_water_salinity\" ;\n" +
"\tbyte Salinity_sigfigs(row) ;\n" +
"\t\tSalinity_sigfigs:long_name = \"sea_water_salinity significant_figures\" ;\n" +
"\tbyte Salinity_WODflag(row) ;\n" +
"\t\tSalinity_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tSalinity_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tSalinity_WODflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"country, WOD_cruise_identifier, originators_cruise_identifier, wod_unique_cast, latitude, longitude, time, date, GMT_time, Access_no, Project, Platform, Orig_Stat_Num, dataset, Ocean_Vehicle, Temperature_WODprofileflag, Temperature_Instrument, Temperature_uncalibrated, Salinity_WODprofileflag, Salinity_Instrument, Primary_Investigator, Primary_Investigator_VAR\" ;\n" +
"\t\t:Conventions = \"CF-1.6\" ;\n" +
"\t\t:creator_email = \"OCLhelp@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Ocean Climate Lab/NCEI\" ;\n" +
"\t\t:creator_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:crs_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:crs_grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:crs_inverse_flattening = 298.25723f ;\n" +
"\t\t:crs_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:crs_semi_major_axis = 6378137.0f ;\n" +
"\t\t:date_created = \"2018-03-24\" ;\n" +
"\t\t:date_modified = \"2018-03-24\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 66.6276f ;\n" +
"\t\t:geospatial_lat_min = -71.2137f ;\n" +
"\t\t:geospatial_lat_resolution = \"point\" ;\n" +
"\t\t:geospatial_lon_max = 8.102386f ;\n" +
"\t\t:geospatial_lon_min = 55.2659f ;\n" +
"\t\t:geospatial_lon_resolution = \"point\" ;\n" +
"\t\t:geospatial_vertical_max = 1975.4133f ;\n" +
"\t\t:geospatial_vertical_min = 0.0f ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"meters\" ;\n" +
"\t\t:grid_mapping_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:grid_mapping_inverse_flattening = 298.25723f ;\n" +
"\t\t:grid_mapping_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:grid_mapping_semi_major_axis = 6378137.0f ;\n" +
"\t\t:id = \"/nodc/data/oc5.clim.0/wod_update_nc/2005/wod_apb_2005.nc\" ;\n" +
"\t\t:institution = \"National Centers for Environmental Information (NCEI), NOAA\" ;\n" +
"\t\t:naming_authority = \"gov.noaa.nodc\" ;\n" +
"\t\t:project = \"World Ocean Database\" ;\n" +
"\t\t:publisher_email = \"NODC.Services@noaa.gov\" ;\n" +
"\t\t:publisher_name = \"US DOC; NESDIS; NATIONAL CENTERS FOR ENVIRONMENTAL INFORMATION\" ;\n" +
"\t\t:publisher_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:references = \"World Ocean Database 2013. URL:http://data.nodc.noaa.gov/woa/WOD/DOC/wod_intro.pdf\" ;\n" +
"\t\t:source = \"World Ocean Database\" ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v41\" ;\n" +
"\t\t:summary = \"Data for multiple casts from the World Ocean Database\" ;\n" +
"\t\t:time_coverage_end = \"2005-12-31\" ;\n" +
"\t\t:time_coverage_start = \"2005-01-01\" ;\n" +
"\t\t:title = \"World Ocean Database - Multi-cast file\" ;\n" +
"}\n" +
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Orig_Stat_Num,dataset,Ocean_Vehicle,Temperature_WODprofileflag,Temperature_Instrument,Temperature_uncalibrated,Salinity_WODprofileflag,Salinity_Instrument,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Pressure,Pressure_sigfigs,Salinity,Salinity_sigfigs,Salinity_WODflag\n" +
"UNITED STATES,US033376,2004017,14009590,42.875145,-139.0886,85832.01060199086,20050101,0.2544478,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,12888,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,0.0,0,1,12.3,3,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033376,2004017,14009590,42.875145,-139.0886,85832.01060199086,20050101,0.2544478,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,12888,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,1.0,0,2,12.35,4,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033376,2004017,14009590,42.875145,-139.0886,85832.01060199086,20050101,0.2544478,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,12888,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,8.5,0,2,12.35,4,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033376,2004017,14009590,42.875145,-139.0886,85832.01060199086,20050101,0.2544478,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,12888,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,22.5,0,3,12.35,4,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033376,2004017,14009590,42.875145,-139.0886,85832.01060199086,20050101,0.2544478,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,12888,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,36.5,0,3,12.35,4,0,-1.0E10,,-1.0E10,,\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            table.removeRows(0, 10000000);
            results = table.dataToString(5);
            expected = 
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Orig_Stat_Num,dataset,Ocean_Vehicle,Temperature_WODprofileflag,Temperature_Instrument,Temperature_uncalibrated,Salinity_WODprofileflag,Salinity_Instrument,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Pressure,Pressure_sigfigs,Salinity,Salinity_sigfigs,Salinity_WODflag\n" +
"UNITED STATES,US033495,2005057,14148754,48.738785,-133.2403,86025.06550899148,20050713,1.5722158,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,2738,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,55.0,0,3,8.2,2,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033495,2005057,14148754,48.738785,-133.2403,86025.06550899148,20050713,1.5722158,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,2738,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,66.0,0,3,8.1,2,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033495,2005057,14148754,48.738785,-133.2403,86025.06550899148,20050713,1.5722158,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,2738,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,77.5,0,3,7.75,3,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033495,2005057,14148754,48.738785,-133.2403,86025.06550899148,20050713,1.5722158,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,2738,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,89.5,0,3,7.6,2,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033495,2005057,14148754,48.738785,-133.2403,86025.06550899148,20050713,1.5722158,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,2738,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,101.0,0,4,7.35,3,0,-1.0E10,,-1.0E10,,\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            table.removeRows(0, 9223380);
            results = table.dataToString();
            expected = 
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Orig_Stat_Num,dataset,Ocean_Vehicle,Temperature_WODprofileflag,Temperature_Instrument,Temperature_uncalibrated,Salinity_WODprofileflag,Salinity_Instrument,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Pressure,Pressure_sigfigs,Salinity,Salinity_sigfigs,Salinity_WODflag\n" +
"UNITED STATES,US033460,2005059,14331034,31.686825,-120.0401,86196.99254602194,20051231,23.821104,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,13046,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,550.0,0,4,5.95,3,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033460,2005059,14331034,31.686825,-120.0401,86196.99254602194,20051231,23.821104,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,13046,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,557.5,0,4,5.85,3,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033460,2005059,14331034,31.686825,-120.0401,86196.99254602194,20051231,23.821104,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,13046,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,564.0,0,4,5.85,3,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033460,2005059,14331034,31.686825,-120.0401,86196.99254602194,20051231,23.821104,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,13046,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,570.5,0,4,5.8,2,0,-1.0E10,,-1.0E10,,\n" +
"UNITED STATES,US033460,2005059,14331034,31.686825,-120.0401,86196.99254602194,20051231,23.821104,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,13046,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,579.0,0,4,5.8,2,0,-1.0E10,,-1.0E10,,\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
        }

        //*** just read outer col
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast","time"}), 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(5);
        expected = 
"wod_unique_cast,time\n" +
"14009590,85832.01060199086\n" +
"14009591,85832.03254599497\n" +
"14009592,85832.01828699\n" +
"14009593,85832.0382870026\n" +
"14009594,85832.01134299766\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 346231, "");

        table.removeRows(0, 346226);
        results = table.dataToString();
        expected = 
"wod_unique_cast,time\n" +
"14331030,86196.96106499434\n" +
"14331031,86196.97773098946\n" +
"14331032,86196.99402803183\n" +
"14331033,86196.97189801931\n" +
"14331034,86196.99254602194\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //just read outer col  with constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast","time"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast"}), 
            new StringArray(new String[]{"="}), 
            new StringArray(new String[]{"14148754"}));
        results = table.dataToString(5);
//from above
//"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Orig_Stat_Num,dataset,Ocean_Vehicle,Temperature_WODprofileflag,Temperature_Instrument,Temperature_uncalibrated,Salinity_WODprofileflag,Salinity_Instrument,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Pressure,Pressure_sigfigs,Salinity,Salinity_sigfigs,Salinity_WODflag\n" +
//"UNITED STATES,US033495,2005057,14148754,48.738785,-133.2403,86025.06550899148,20050713,1.5722158,77805,TAGGING OF PACIFIC PREDATORS (TOPP),,2738,animal mounted,Elephant Seal,0,ANIMAL MOUNTED: TDR (Time-Depth Recorder) Tag (Wildlife Computers),1,0,,COSTA; DR. DANIEL P.,all_variables,55.0,0,3,8.2,2,0,-1.0E10,,-1.0E10,,\n" +
        expected = 
"wod_unique_cast,time\n" +
"14148754,86025.06550899148\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //*** just read inner col
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"z", "Temperature","Temperature_sigfigs"}), 0,  //standardizeWhat=0
            null, null, null);
        results = table.dataToString(5);
//from above
//...z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Pressure,Pressure_sigfigs,Salinity,Salinity_sigfigs,Salinity_WODflag\n" +
//...0.0,0,1,12.3,3,0,-1.0E10,,-1.0E10,,\n" +
//...1.0,0,2,12.35,4,0,-1.0E10,,-1.0E10,,\n" +
//...8.5,0,2,12.35,4,0,-1.0E10,,-1.0E10,,\n" +
//...22.5,0,3,12.35,4,0,-1.0E10,,-1.0E10,,\n" +
//...36.5,0,3,12.35,4,0,-1.0E10,,-1.0E10,,\n" +
        expected = 
"z,Temperature,Temperature_sigfigs\n" +
"0.0,12.3,3\n" +
"1.0,12.35,4\n" +
"8.5,12.35,4\n" +
"22.5,12.35,4\n" +
"36.5,12.35,4\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 19223385, "");

        table.removeRows(0, 19223380);
        results = table.dataToString();
//from above
//...z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Pressure,Pressure_sigfigs,Salinity,Salinity_sigfigs,Salinity_WODflag\n" +
//...550.0,0,4,5.95,3,0,-1.0E10,,-1.0E10,,\n" +
//...557.5,0,4,5.85,3,0,-1.0E10,,-1.0E10,,\n" +
//...564.0,0,4,5.85,3,0,-1.0E10,,-1.0E10,,\n" +
//...570.5,0,4,5.8,2,0,-1.0E10,,-1.0E10,,\n" +
//...579.0,0,4,5.8,2,0,-1.0E10,,-1.0E10,,\n";
        expected = 
"z,Temperature,Temperature_sigfigs\n" +
"550.0,5.95,3\n" +
"557.5,5.85,3\n" +
"564.0,5.85,3\n" +
"570.5,5.8,2\n" +
"579.0,5.8,2\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //just read inner col  with constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"z", "Temperature"}), 
            new StringArray(new String[]{"=", "="}), 
            new StringArray(new String[]{"570.5", "5.8"}));
        results = table.dataToString(5);
        expected = 
"z,Temperature,Temperature_WODflag\n" +
"570.5,5.8,0\n" +
"570.5,5.8,0\n" +
"570.5,5.8,0\n" +
"570.5,5.8,0\n" +
"570.5,5.8,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 22, "");


        //read outer and inner col with outer constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast"}), 
            new StringArray(new String[]{"="}), 
            new StringArray(new String[]{"14148754"}));
        results = table.dataToString(10);
//from above
//...wod_unique_cast,...z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Pressure,Pressure_sigfigs,Salinity,Salinity_sigfigs,Salinity_WODflag\n" +
//...14148754,...       55.0,0,3,8.2,2,0,-1.0E10,,-1.0E10,,\n" +
//...14148754,...       66.0,0,3,8.1,2,0,-1.0E10,,-1.0E10,,\n" +
//...14148754,...       77.5,0,3,7.75,3,0,-1.0E10,,-1.0E10,,\n" +
//...14148754,...       89.5,0,3,7.6,2,0,-1.0E10,,-1.0E10,,\n" +
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"14148754,86025.06550899148,0.0,13.85,0\n" +
"14148754,86025.06550899148,0.5,13.85,0\n" +
"14148754,86025.06550899148,3.0,13.85,0\n" +
"14148754,86025.06550899148,15.0,13.55,0\n" +
"14148754,86025.06550899148,30.0,10.05,0\n" +
"14148754,86025.06550899148,43.5,8.4,0\n" +
"14148754,86025.06550899148,55.0,8.2,0\n" +
"14148754,86025.06550899148,66.0,8.1,0\n" +
"14148754,86025.06550899148,77.5,7.75,0\n" +
"14148754,86025.06550899148,89.5,7.6,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 90, "");

        //read outer and inner col with outer and inner constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast", "Temperature"}), 
            new StringArray(new String[]{"=", "="}), 
            new StringArray(new String[]{"14148754", "13.55"}));
        results = table.dataToString(5);
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"14148754,86025.06550899148,15.0,13.55,0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //*** list the non-"" PI's
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"Primary_Investigator"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"Primary_Investigator"}), 
            new StringArray(new String[]{"!="}), 
            new StringArray(new String[]{""}));
        results = table.dataToString(5);
        expected = 
"Primary_Investigator\n" +
"COSTA; DR. DANIEL P.\n" +
"COSTA; DR. DANIEL P.\n" +
"COSTA; DR. DANIEL P.\n" +
"COSTA; DR. DANIEL P.\n" +
"COSTA; DR. DANIEL P.\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), 323499, "");


        //*** read all ctd   !!! This fails with -Xmx6000m of memory. Succeeds with -Xmx8000m
        fullName = dir + "wod_ctd_2005.nc";
        if (doAll) {
            table.readInvalidCRA(fullName, null, 0,  //standardizeWhat=0
                null, null, null);
            results = table.toString(5);
            expected = 
"{\n" +
"dimensions:\n" +
"\trow = 14843110 ;\n" +
"\tcountry_strlen = 18 ;\n" +
"\tWOD_cruise_identifier_strlen = 8 ;\n" +
"\toriginators_cruise_identifier_strlen = 15 ;\n" +
"\toriginators_station_identifier_strlen = 9 ;\n" +
"\tProject_strlen = 71 ;\n" +
"\tPlatform_strlen = 80 ;\n" +
"\tInstitute_strlen = 80 ;\n" +
"\tCast_Direction_strlen = 4 ;\n" +
"\tWater_Color_strlen = 54 ;\n" +
"\tWave_Direction_strlen = 25 ;\n" +
"\tWave_Height_strlen = 9 ;\n" +
"\tSea_State_strlen = 42 ;\n" +
"\tWave_Period_strlen = 17 ;\n" +
"\tWind_Direction_strlen = 25 ;\n" +
"\tWeather_Condition_strlen = 169 ;\n" +
"\tCloud_Type_strlen = 18 ;\n" +
"\tCloud_Cover_strlen = 65 ;\n" +
"\tdataset_strlen = 4 ;\n" +
"\tRecorder_strlen = 47 ;\n" +
"\tdepth_eq_strlen = 8 ;\n" +
"\tVisibility_strlen = 24 ;\n" +
"\tneeds_z_fix_strlen = 16 ;\n" +
"\treal_time_strlen = 14 ;\n" +
"\tdbase_orig_strlen = 59 ;\n" +
"\torigflagset_strlen = 5 ;\n" +
"\tTemperature_Scale_strlen = 19 ;\n" +
"\tTemperature_Instrument_strlen = 74 ;\n" +
"\tSalinity_Scale_strlen = 15 ;\n" +
"\tSalinity_Instrument_strlen = 74 ;\n" +
"\tOxygen_Instrument_strlen = 103 ;\n" +
"\tOxygen_Method_strlen = 0 ;\n" +
"\tOxygen_Original_units_strlen = 60 ;\n" +
"\tPressure_Instrument_strlen = 65 ;\n" +
"\tChlorophyll_Instrument_strlen = 59 ;\n" +
"\tChlorophyll_Original_units_strlen = 32 ;\n" +
"\tPrimary_Investigator_strlen = 26 ;\n" +
"\tPrimary_Investigator_VAR_strlen = 13 ;\n" +
"variables:\n" +
"\tchar country(row, country_strlen) ;\n" +
"\tchar WOD_cruise_identifier(row, WOD_cruise_identifier_strlen) ;\n" +
"\t\tWOD_cruise_identifier:comment = \"two byte country code + WOD cruise number (unique to country code)\" ;\n" +
"\t\tWOD_cruise_identifier:long_name = \"WOD_cruise_identifier\" ;\n" +
"\tchar originators_cruise_identifier(row, originators_cruise_identifier_strlen) ;\n" +
"\tint wod_unique_cast(row) ;\n" +
"\t\twod_unique_cast:cf_role = \"profile_id\" ;\n" +
"\tchar originators_station_identifier(row, originators_station_identifier_strlen) ;\n" +
"\t\toriginators_station_identifier:long_name = \"originators_station_identifier\" ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:standard_name = \"latitude\" ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:standard_name = \"longitude\" ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:units = \"days since 1770-01-01 00:00:00 UTC\" ;\n" +
"\tint date(row) ;\n" +
"\t\tdate:comment = \"YYYYMMDD\" ;\n" +
"\t\tdate:long_name = \"date\" ;\n" +
"\tfloat GMT_time(row) ;\n" +
"\t\tGMT_time:long_name = \"GMT_time\" ;\n" +
"\t\tGMT_time:units = \"hours\" ;\n" +
"\tint Access_no(row) ;\n" +
"\t\tAccess_no:_FillValue = -99999 ;\n" +
"\t\tAccess_no:comment = \"used to find original data at NODC\" ;\n" +
"\t\tAccess_no:long_name = \"NODC_accession_number\" ;\n" +
"\t\tAccess_no:units_wod = \"NODC_code\" ;\n" +
"\tchar Project(row, Project_strlen) ;\n" +
"\t\tProject:comment = \"name or acronym of project under which data were measured\" ;\n" +
"\t\tProject:long_name = \"Project_name\" ;\n" +
"\tchar Platform(row, Platform_strlen) ;\n" +
"\t\tPlatform:comment = \"name of platform from which measurements were taken\" ;\n" +
"\t\tPlatform:long_name = \"Platform_name\" ;\n" +
"\tchar Institute(row, Institute_strlen) ;\n" +
"\t\tInstitute:comment = \"name of institute which collected data\" ;\n" +
"\t\tInstitute:long_name = \"Responsible_institute\" ;\n" +
"\tint Cast_Tow_number(row) ;\n" +
"\t\tCast_Tow_number:_FillValue = -99999 ;\n" +
"\t\tCast_Tow_number:comment = \"originator assigned sequential cast or tow_no\" ;\n" +
"\t\tCast_Tow_number:long_name = \"Cast_or_Tow_number\" ;\n" +
"\tint Orig_Stat_Num(row) ;\n" +
"\t\tOrig_Stat_Num:_FillValue = -99999 ;\n" +
"\t\tOrig_Stat_Num:comment = \"number assigned to a given station by data originator\" ;\n" +
"\t\tOrig_Stat_Num:long_name = \"Originators_Station_Number\" ;\n" +
"\tfloat Bottom_Depth(row) ;\n" +
"\t\tBottom_Depth:_FillValue = -1.0E10f ;\n" +
"\t\tBottom_Depth:standard_name = \"sea_floor_depth_below_sea_surface\" ;\n" +
"\t\tBottom_Depth:units = \"meters\" ;\n" +
"\tfloat Cast_Duration(row) ;\n" +
"\t\tCast_Duration:_FillValue = -1.0E10f ;\n" +
"\t\tCast_Duration:long_name = \"Cast_Duration\" ;\n" +
"\t\tCast_Duration:units = \"hours\" ;\n" +
"\tchar Cast_Direction(row, Cast_Direction_strlen) ;\n" +
"\t\tCast_Direction:long_name = \"Cast_Direction\" ;\n" +
"\tint High_res_pair(row) ;\n" +
"\t\tHigh_res_pair:_FillValue = -99999 ;\n" +
"\t\tHigh_res_pair:comment = \"WOD unique cast number for bottle/CTD from same rosette\" ;\n" +
"\t\tHigh_res_pair:long_name = \"WOD_high_resolution_pair_number\" ;\n" +
"\tchar Water_Color(row, Water_Color_strlen) ;\n" +
"\t\tWater_Color:long_name = \"Water_Color\" ;\n" +
"\t\tWater_Color:units_wod = \"Forel-Ule scale (00 to 21)\" ;\n" +
"\tfloat Water_Transpar(row) ;\n" +
"\t\tWater_Transpar:_FillValue = -1.0E10f ;\n" +
"\t\tWater_Transpar:comment = \"Secchi disk depth\" ;\n" +
"\t\tWater_Transpar:long_name = \"Water_Transparency\" ;\n" +
"\t\tWater_Transpar:units = \"meters\" ;\n" +
"\tchar Wave_Direction(row, Wave_Direction_strlen) ;\n" +
"\t\tWave_Direction:long_name = \"Wave_Direction\" ;\n" +
"\t\tWave_Direction:units_wod = \"WMO 0877 or NODC 0110\" ;\n" +
"\tchar Wave_Height(row, Wave_Height_strlen) ;\n" +
"\t\tWave_Height:long_name = \"Wave_Height\" ;\n" +
"\t\tWave_Height:units_wod = \"WMO 1555 or NODC 0104\" ;\n" +
"\tchar Sea_State(row, Sea_State_strlen) ;\n" +
"\t\tSea_State:long_name = \"Sea_State\" ;\n" +
"\t\tSea_State:units_wod = \"WMO 3700 or NODC 0109\" ;\n" +
"\tchar Wave_Period(row, Wave_Period_strlen) ;\n" +
"\t\tWave_Period:long_name = \"Wave_Period\" ;\n" +
"\t\tWave_Period:units_wod = \"WMO 3155 or NODC 0378\" ;\n" +
"\tchar Wind_Direction(row, Wind_Direction_strlen) ;\n" +
"\t\tWind_Direction:long_name = \"Wind_Direction\" ;\n" +
"\t\tWind_Direction:units_wod = \"WMO 0877 or NODC 0110\" ;\n" +
"\tfloat Wind_Speed(row) ;\n" +
"\t\tWind_Speed:_FillValue = -1.0E10f ;\n" +
"\t\tWind_Speed:standard_name = \"wind_speed\" ;\n" +
"\t\tWind_Speed:units = \"knots\" ;\n" +
"\tfloat Barometric_Pres(row) ;\n" +
"\t\tBarometric_Pres:_FillValue = -1.0E10f ;\n" +
"\t\tBarometric_Pres:long_name = \"Barometric_Pressure\" ;\n" +
"\t\tBarometric_Pres:units = \"millibars\" ;\n" +
"\tfloat Dry_Bulb_Temp(row) ;\n" +
"\t\tDry_Bulb_Temp:_FillValue = -1.0E10f ;\n" +
"\t\tDry_Bulb_Temp:long_name = \"Dry_Bulb_Air_Temperature\" ;\n" +
"\t\tDry_Bulb_Temp:units = \"degree_C\" ;\n" +
"\tfloat Wet_Bulb_Temp(row) ;\n" +
"\t\tWet_Bulb_Temp:_FillValue = -1.0E10f ;\n" +
"\t\tWet_Bulb_Temp:long_name = \"Wet_Bulb_Air_Temperature\" ;\n" +
"\t\tWet_Bulb_Temp:units = \"degree_C\" ;\n" +
"\tchar Weather_Condition(row, Weather_Condition_strlen) ;\n" +
"\t\tWeather_Condition:comment = \"Weather conditions at time of measurements\" ;\n" +
"\t\tWeather_Condition:long_name = \"Weather_Condition\" ;\n" +
"\tchar Cloud_Type(row, Cloud_Type_strlen) ;\n" +
"\t\tCloud_Type:long_name = \"Cloud_Type\" ;\n" +
"\t\tCloud_Type:units_wod = \"WMO 0500 or NODC 0053\" ;\n" +
"\tchar Cloud_Cover(row, Cloud_Cover_strlen) ;\n" +
"\t\tCloud_Cover:long_name = \"Cloud_Cover\" ;\n" +
"\t\tCloud_Cover:units_wod = \"WMO 2700 or NODC 0105\" ;\n" +
"\tchar dataset(row, dataset_strlen) ;\n" +
"\t\tdataset:long_name = \"WOD_dataset\" ;\n" +
"\tchar Recorder(row, Recorder_strlen) ;\n" +
"\t\tRecorder:comment = \"Device which recorded measurements\" ;\n" +
"\t\tRecorder:long_name = \"Recorder\" ;\n" +
"\t\tRecorder:units_wod = \"WMO code 4770\" ;\n" +
"\tchar depth_eq(row, depth_eq_strlen) ;\n" +
"\t\tdepth_eq:comment = \"which drop rate equation was used\" ;\n" +
"\t\tdepth_eq:long_name = \"depth_equation_used\" ;\n" +
"\tbyte Bottom_Hit(row) ;\n" +
"\t\tBottom_Hit:_FillValue = -9 ;\n" +
"\t\tBottom_Hit:comment = \"set to one if instrument hit bottom\" ;\n" +
"\t\tBottom_Hit:long_name = \"Bottom_Hit\" ;\n" +
"\tchar Visibility(row, Visibility_strlen) ;\n" +
"\t\tVisibility:long_name = \"Horizontal_visibility\" ;\n" +
"\t\tVisibility:units_wod = \"WMO Code 4300\" ;\n" +
"\tfloat Ref_Surf_Temp(row) ;\n" +
"\t\tRef_Surf_Temp:_FillValue = -1.0E10f ;\n" +
"\t\tRef_Surf_Temp:comment = \"Reference_or_Sea_Surface_Temperature\" ;\n" +
"\t\tRef_Surf_Temp:units = \"degree_C\" ;\n" +
"\tchar needs_z_fix(row, needs_z_fix_strlen) ;\n" +
"\t\tneeds_z_fix:comment = \"instruction for fixing depths\" ;\n" +
"\t\tneeds_z_fix:long_name = \"z_fix_instructions\" ;\n" +
"\t\tneeds_z_fix:units_wod = \"WOD_code\" ;\n" +
"\tchar real_time(row, real_time_strlen) ;\n" +
"\t\treal_time:comment = \"timeliness and quality status\" ;\n" +
"\t\treal_time:long_name = \"real_time_data\" ;\n" +
"\tchar dbase_orig(row, dbase_orig_strlen) ;\n" +
"\t\tdbase_orig:comment = \"Database from which data were extracted\" ;\n" +
"\t\tdbase_orig:long_name = \"database_origin\" ;\n" +
"\tchar origflagset(row, origflagset_strlen) ;\n" +
"\t\torigflagset:comment = \"set of originators flag codes to use\" ;\n" +
"\tbyte Temperature_WODprofileflag(row) ;\n" +
"\t\tTemperature_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tTemperature_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Temperature_Scale(row, Temperature_Scale_strlen) ;\n" +
"\t\tTemperature_Scale:long_name = \"Scale upon which values were measured\" ;\n" +
"\tchar Temperature_Instrument(row, Temperature_Instrument_strlen) ;\n" +
"\t\tTemperature_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tTemperature_Instrument:long_name = \"Instrument\" ;\n" +
"\tint Temperature_uncalibrated(row) ;\n" +
"\t\tTemperature_uncalibrated:_FillValue = -99999 ;\n" +
"\t\tTemperature_uncalibrated:comment = \"set if measurements have not been calibrated\" ;\n" +
"\tbyte Salinity_WODprofileflag(row) ;\n" +
"\t\tSalinity_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tSalinity_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Salinity_Scale(row, Salinity_Scale_strlen) ;\n" +
"\t\tSalinity_Scale:long_name = \"Scale upon which values were measured\" ;\n" +
"\tchar Salinity_Instrument(row, Salinity_Instrument_strlen) ;\n" +
"\t\tSalinity_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tSalinity_Instrument:long_name = \"Instrument\" ;\n" +
"\tint Salinity_uncalibrated(row) ;\n" +
"\t\tSalinity_uncalibrated:_FillValue = -99999 ;\n" +
"\t\tSalinity_uncalibrated:comment = \"set if measurements have not been calibrated\" ;\n" +
"\tbyte Oxygen_WODprofileflag(row) ;\n" +
"\t\tOxygen_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tOxygen_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tOxygen_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Oxygen_Instrument(row, Oxygen_Instrument_strlen) ;\n" +
"\t\tOxygen_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tOxygen_Instrument:long_name = \"Instrument\" ;\n" +
"\tchar Oxygen_Method(row, Oxygen_Method_strlen) ;\n" +
"\t\tOxygen_Method:comment = \"Method\" ;\n" +
"\tchar Oxygen_Original_units(row, Oxygen_Original_units_strlen) ;\n" +
"\t\tOxygen_Original_units:comment = \"Units originally used: coverted to standard units\" ;\n" +
"\tint Oxygen_uncalibrated(row) ;\n" +
"\t\tOxygen_uncalibrated:_FillValue = -99999 ;\n" +
"\t\tOxygen_uncalibrated:comment = \"set if measurements have not been calibrated\" ;\n" +
"\tchar Pressure_Instrument(row, Pressure_Instrument_strlen) ;\n" +
"\t\tPressure_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tPressure_Instrument:long_name = \"Instrument\" ;\n" +
"\tbyte Chlorophyll_WODprofileflag(row) ;\n" +
"\t\tChlorophyll_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tChlorophyll_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tChlorophyll_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Chlorophyll_Instrument(row, Chlorophyll_Instrument_strlen) ;\n" +
"\t\tChlorophyll_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tChlorophyll_Instrument:long_name = \"Instrument\" ;\n" +
"\tchar Chlorophyll_Original_units(row, Chlorophyll_Original_units_strlen) ;\n" +
"\t\tChlorophyll_Original_units:comment = \"Units originally used: coverted to standard units\" ;\n" +
"\tint Chlorophyll_uncalibrated(row) ;\n" +
"\t\tChlorophyll_uncalibrated:_FillValue = -99999 ;\n" +
"\t\tChlorophyll_uncalibrated:comment = \"set if measurements have not been calibrated\" ;\n" +
"\tchar Primary_Investigator(row, Primary_Investigator_strlen) ;\n" +
"\tchar Primary_Investigator_VAR(row, Primary_Investigator_VAR_strlen) ;\n" +
"\tfloat z(row) ;\n" +
"\t\tz:ancillary_variables = \"z_sigfigs z_WODflag z_origflag\" ;\n" +
"\t\tz:long_name = \"depth_below_sea_surface\" ;\n" +
"\t\tz:positive = \"down\" ;\n" +
"\t\tz:standard_name = \"depth\" ;\n" +
"\t\tz:units = \"m\" ;\n" +
"\tbyte z_WODflag(row) ;\n" +
"\t\tz_WODflag:flag_meanings = \"accepted duplicate_or_inversion density_inversion\" ;\n" +
"\t\tz_WODflag:flag_values = 0, 1, 2 ;\n" +
"\t\tz_WODflag:long_name = \"WOD_depth_level_flag\" ;\n" +
"\t\tz_WODflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_origflag(row) ;\n" +
"\t\tz_origflag:_FillValue = -9 ;\n" +
"\t\tz_origflag:comment = \"Originator flags are dependent on origflagset\" ;\n" +
"\t\tz_origflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_sigfigs(row) ;\n" +
"\t\tz_sigfigs:long_name = \"depth significant figures   \" ;\n" +
"\tfloat Temperature(row) ;\n" +
"\t\tTemperature:_FillValue = -1.0E10f ;\n" +
"\t\tTemperature:ancillary_variables = \"Temperature_sigfigs Temperature_WODflag Temperature_WODprofileflag Temperature_origflag\" ;\n" +
"\t\tTemperature:coordinates = \"time lat lon z\" ;\n" +
"\t\tTemperature:grid_mapping = \"crs\" ;\n" +
"\t\tTemperature:long_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:units = \"degree_C\" ;\n" +
"\tbyte Temperature_sigfigs(row) ;\n" +
"\t\tTemperature_sigfigs:long_name = \"sea_water_temperature significant_figures\" ;\n" +
"\tbyte Temperature_WODflag(row) ;\n" +
"\t\tTemperature_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tTemperature_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tTemperature_WODflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tbyte Temperature_origflag(row) ;\n" +
"\t\tTemperature_origflag:_FillValue = -9 ;\n" +
"\t\tTemperature_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tTemperature_origflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tfloat Salinity(row) ;\n" +
"\t\tSalinity:_FillValue = -1.0E10f ;\n" +
"\t\tSalinity:ancillary_variables = \"Salinity_sigfigs Salinity_WODflag Salinity_WODprofileflag Salinity_origflag\" ;\n" +
"\t\tSalinity:coordinates = \"time lat lon z\" ;\n" +
"\t\tSalinity:grid_mapping = \"crs\" ;\n" +
"\t\tSalinity:long_name = \"sea_water_salinity\" ;\n" +
"\t\tSalinity:standard_name = \"sea_water_salinity\" ;\n" +
"\tbyte Salinity_sigfigs(row) ;\n" +
"\t\tSalinity_sigfigs:long_name = \"sea_water_salinity significant_figures\" ;\n" +
"\tbyte Salinity_WODflag(row) ;\n" +
"\t\tSalinity_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tSalinity_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tSalinity_WODflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\tbyte Salinity_origflag(row) ;\n" +
"\t\tSalinity_origflag:_FillValue = -9 ;\n" +
"\t\tSalinity_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tSalinity_origflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\tfloat Oxygen(row) ;\n" +
"\t\tOxygen:_FillValue = -1.0E10f ;\n" +
"\t\tOxygen:ancillary_variables = \"Oxygen_sigfigs Oxygen_WODflag Oxygen_WODprofileflag Oxygen_origflag\" ;\n" +
"\t\tOxygen:coordinates = \"time lat lon z\" ;\n" +
"\t\tOxygen:grid_mapping = \"crs\" ;\n" +
"\t\tOxygen:long_name = \"volume_fraction_of_oxygen_in_sea_water\" ;\n" +
"\t\tOxygen:standard_name = \"volume_fraction_of_oxygen_in_sea_water\" ;\n" +
"\t\tOxygen:units = \"ml/l\" ;\n" +
"\tbyte Oxygen_sigfigs(row) ;\n" +
"\t\tOxygen_sigfigs:long_name = \"volume_fraction_of_oxygen_in_sea_water significant_figures\" ;\n" +
"\tbyte Oxygen_WODflag(row) ;\n" +
"\t\tOxygen_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tOxygen_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tOxygen_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tOxygen_WODflag:standard_name = \"volume_fraction_of_oxygen_in_sea_water status_flag\" ;\n" +
"\tbyte Oxygen_origflag(row) ;\n" +
"\t\tOxygen_origflag:_FillValue = -9 ;\n" +
"\t\tOxygen_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tOxygen_origflag:standard_name = \"volume_fraction_of_oxygen_in_sea_water status_flag\" ;\n" +
"\tfloat Pressure(row) ;\n" +
"\t\tPressure:_FillValue = -1.0E10f ;\n" +
"\t\tPressure:ancillary_variables = \"Pressure_sigfigs Pressure_WODflag Pressure_WODprofileflag Pressure_origflag\" ;\n" +
"\t\tPressure:coordinates = \"time lat lon z\" ;\n" +
"\t\tPressure:grid_mapping = \"crs\" ;\n" +
"\t\tPressure:long_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:standard_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:units = \"dbar\" ;\n" +
"\tbyte Pressure_sigfigs(row) ;\n" +
"\t\tPressure_sigfigs:long_name = \"sea_water_pressure significant_figures\" ;\n" +
"\tbyte Pressure_origflag(row) ;\n" +
"\t\tPressure_origflag:_FillValue = -9 ;\n" +
"\t\tPressure_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tPressure_origflag:standard_name = \"sea_water_pressure status_flag\" ;\n" +
"\tfloat Chlorophyll(row) ;\n" +
"\t\tChlorophyll:_FillValue = -1.0E10f ;\n" +
"\t\tChlorophyll:ancillary_variables = \"Chlorophyll_sigfigs Chlorophyll_WODflag Chlorophyll_WODprofileflag Chlorophyll_origflag\" ;\n" +
"\t\tChlorophyll:coordinates = \"time lat lon z\" ;\n" +
"\t\tChlorophyll:grid_mapping = \"crs\" ;\n" +
"\t\tChlorophyll:long_name = \"mass_concentration_of_chlorophyll_in_sea_water\" ;\n" +
"\t\tChlorophyll:standard_name = \"mass_concentration_of_chlorophyll_in_sea_water\" ;\n" +
"\t\tChlorophyll:units = \"ugram/l\" ;\n" +
"\tbyte Chlorophyll_sigfigs(row) ;\n" +
"\t\tChlorophyll_sigfigs:long_name = \"mass_concentration_of_chlorophyll_in_sea_water significant_figures\" ;\n" +
"\tbyte Chlorophyll_WODflag(row) ;\n" +
"\t\tChlorophyll_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tChlorophyll_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tChlorophyll_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tChlorophyll_WODflag:standard_name = \"mass_concentration_of_chlorophyll_in_sea_water status_flag\" ;\n" +
"\tbyte Chlorophyll_origflag(row) ;\n" +
"\t\tChlorophyll_origflag:_FillValue = -9 ;\n" +
"\t\tChlorophyll_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tChlorophyll_origflag:standard_name = \"mass_concentration_of_chlorophyll_in_sea_water status_flag\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"country, WOD_cruise_identifier, originators_cruise_identifier, wod_unique_cast, originators_station_identifier, latitude, longitude, time, date, GMT_time, Access_no, Project, Platform, Institute, Cast_Tow_number, Orig_Stat_Num, Bottom_Depth, Cast_Duration, Cast_Direction, High_res_pair, Water_Color, Water_Transpar, Wave_Direction, Wave_Height, Sea_State, Wave_Period, Wind_Direction, Wind_Speed, Barometric_Pres, Dry_Bulb_Temp, Wet_Bulb_Temp, Weather_Condition, Cloud_Type, Cloud_Cover, dataset, Recorder, depth_eq, Bottom_Hit, Visibility, Ref_Surf_Temp, needs_z_fix, real_time, dbase_orig, origflagset, Temperature_WODprofileflag, Temperature_Scale, Temperature_Instrument, Temperature_uncalibrated, Salinity_WODprofileflag, Salinity_Scale, Salinity_Instrument, Salinity_uncalibrated, Oxygen_WODprofileflag, Oxygen_Instrument, Oxygen_Method, Oxygen_Original_units, Oxygen_uncalibrated, Pressure_Instrument, Chlorophyll_WODprofileflag, Chlorophyll_Instrument, Chlorophyll_Original_units, Chlorophyll_uncalibrated, Primary_Investigator, Primary_Investigator_VAR\" ;\n" +
"\t\t:Conventions = \"CF-1.6\" ;\n" +
"\t\t:creator_email = \"OCLhelp@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Ocean Climate Lab/NCEI\" ;\n" +
"\t\t:creator_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:crs_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:crs_grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:crs_inverse_flattening = 298.25723f ;\n" +
"\t\t:crs_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:crs_semi_major_axis = 6378137.0f ;\n" +
"\t\t:date_created = \"2018-03-24\" ;\n" +
"\t\t:date_modified = \"2018-03-24\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 89.986336f ;\n" +
"\t\t:geospatial_lat_min = -78.579f ;\n" +
"\t\t:geospatial_lat_resolution = \"point\" ;\n" +
"\t\t:geospatial_lon_max = 180.0f ;\n" +
"\t\t:geospatial_lon_min = -180.0f ;\n" +
"\t\t:geospatial_lon_resolution = \"point\" ;\n" +
"\t\t:geospatial_vertical_max = 6473.251f ;\n" +
"\t\t:geospatial_vertical_min = 0.0f ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"meters\" ;\n" +
"\t\t:grid_mapping_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:grid_mapping_inverse_flattening = 298.25723f ;\n" +
"\t\t:grid_mapping_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:grid_mapping_semi_major_axis = 6378137.0f ;\n" +
"\t\t:id = \"/nodc/data/oc5.clim.0/wod_update_nc/2005/wod_ctd_2005.nc\" ;\n" +
"\t\t:institution = \"National Centers for Environmental Information (NCEI), NOAA\" ;\n" +
"\t\t:naming_authority = \"gov.noaa.nodc\" ;\n" +
"\t\t:project = \"World Ocean Database\" ;\n" +
"\t\t:publisher_email = \"NODC.Services@noaa.gov\" ;\n" +
"\t\t:publisher_name = \"US DOC; NESDIS; NATIONAL CENTERS FOR ENVIRONMENTAL INFORMATION\" ;\n" +
"\t\t:publisher_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:references = \"World Ocean Database 2013. URL:http://data.nodc.noaa.gov/woa/WOD/DOC/wod_intro.pdf\" ;\n" +
"\t\t:source = \"World Ocean Database\" ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v41\" ;\n" +
"\t\t:summary = \"Data for multiple casts from the World Ocean Database\" ;\n" +
"\t\t:time_coverage_end = \"2005-12-31\" ;\n" +
"\t\t:time_coverage_start = \"2005-01-01\" ;\n" +
"\t\t:title = \"World Ocean Database - Multi-cast file\" ;\n" +
"}\n" +
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,originators_station_identifier,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Cast_Tow_number,Orig_Stat_Num,Bottom_Depth,Cast_Duration,Cast_Direction,High_res_pair,Water_Color,Water_Transpar,Wave_Direction,Wave_Height,Sea_State,Wave_Period,Wind_Direction,Wind_Speed,Barometric_Pres,Dry_Bulb_Temp,Wet_Bulb_Temp,Weather_Condition,Cloud_Type,Cloud_Cover,dataset,Recorder,depth_eq,Bottom_Hit,Visibility,Ref_Surf_Temp,needs_z_fix,real_time,dbase_orig,origflagset,Temperature_WODprofileflag,Temperature_Scale,Temperature_Instrument,Temperature_uncalibrated,Salinity_WODprofileflag,Salinity_Scale,Salinity_Instrument,Salinity_uncalibrated,Oxygen_WODprofileflag,Oxygen_Instrument,Oxygen_Method,Oxygen_Original_units,Oxygen_uncalibrated,Pressure_Instrument,Chlorophyll_WODprofileflag,Chlorophyll_Instrument,Chlorophyll_Original_units,Chlorophyll_uncalibrated,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Salinity_origflag,Oxygen,Oxygen_sigfigs,Oxygen_WODflag,Oxygen_origflag,Pressure,Pressure_sigfigs,Pressure_origflag,Chlorophyll,Chlorophyll_sigfigs,Chlorophyll_WODflag,Chlorophyll_origflag\n" +
"NEW ZEALAND,NZ001156,tan0501,15076949,,-43.427,177.9535,85832.04166666791,20050101,1.0,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,24,332.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,0.0,0,-9,1,12.792,5,0,-9,34.702,5,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
"NEW ZEALAND,NZ001156,tan0501,15076949,,-43.427,177.9535,85832.04166666791,20050101,1.0,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,24,332.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,1.0,0,-9,1,13.085,5,0,-9,34.573,5,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
"NEW ZEALAND,NZ001156,tan0501,15076949,,-43.427,177.9535,85832.04166666791,20050101,1.0,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,24,332.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,2.0,0,-9,1,12.729,5,0,-9,34.562,5,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
"NEW ZEALAND,NZ001156,tan0501,15076949,,-43.427,177.9535,85832.04166666791,20050101,1.0,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,24,332.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,3.0,0,-9,1,12.778,5,0,-9,34.585,5,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
"NEW ZEALAND,NZ001156,tan0501,15076949,,-43.427,177.9535,85832.04166666791,20050101,1.0,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,24,332.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,7.0,0,-9,1,12.538,5,0,-9,34.629,5,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            table.removeRows(0, 14843110 - 5);
            results = table.dataToString();
            expected = 
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,originators_station_identifier,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Cast_Tow_number,Orig_Stat_Num,Bottom_Depth,Cast_Duration,Cast_Direction,High_res_pair,Water_Color,Water_Transpar,Wave_Direction,Wave_Height,Sea_State,Wave_Period,Wind_Direction,Wind_Speed,Barometric_Pres,Dry_Bulb_Temp,Wet_Bulb_Temp,Weather_Condition,Cloud_Type,Cloud_Cover,dataset,Recorder,depth_eq,Bottom_Hit,Visibility,Ref_Surf_Temp,needs_z_fix,real_time,dbase_orig,origflagset,Temperature_WODprofileflag,Temperature_Scale,Temperature_Instrument,Temperature_uncalibrated,Salinity_WODprofileflag,Salinity_Scale,Salinity_Instrument,Salinity_uncalibrated,Oxygen_WODprofileflag,Oxygen_Instrument,Oxygen_Method,Oxygen_Original_units,Oxygen_uncalibrated,Pressure_Instrument,Chlorophyll_WODprofileflag,Chlorophyll_Instrument,Chlorophyll_Original_units,Chlorophyll_uncalibrated,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Salinity_origflag,Oxygen,Oxygen_sigfigs,Oxygen_WODflag,Oxygen_origflag,Pressure,Pressure_sigfigs,Pressure_origflag,Chlorophyll,Chlorophyll_sigfigs,Chlorophyll_WODflag,Chlorophyll_origflag\n" +
"NEW ZEALAND,NZ001163,tan0601,15077333,,-43.9471,-179.09016,86196.95902776718,20051231,23.016666,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,25,382.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,374.0,0,-9,3,8.695,4,0,-9,34.571,5,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
"NEW ZEALAND,NZ001163,tan0601,15077333,,-43.9471,-179.09016,86196.95902776718,20051231,23.016666,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,25,382.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,375.0,0,-9,3,8.692,4,0,-9,34.571,5,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
"NEW ZEALAND,NZ001163,tan0601,15077333,,-43.9471,-179.09016,86196.95902776718,20051231,23.016666,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,25,382.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,376.0,0,-9,3,8.686,4,0,-9,34.571,5,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
"NEW ZEALAND,NZ001163,tan0601,15077333,,-43.9471,-179.09016,86196.95902776718,20051231,23.016666,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,25,382.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,377.0,0,-9,3,8.682,4,0,-9,34.57,4,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
"NEW ZEALAND,NZ001163,tan0601,15077333,,-43.9471,-179.09016,86196.95902776718,20051231,23.016666,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,25,382.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,378.0,0,-9,3,8.675,4,0,-9,34.57,4,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
        }

        //read outer and inner col with outer constraint
//from above
//"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,originators_station_identifier,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Cast_Tow_number,Orig_Stat_Num,Bottom_Depth,Cast_Duration,Cast_Direction,High_res_pair,Water_Color,Water_Transpar,Wave_Direction,Wave_Height,Sea_State,Wave_Period,Wind_Direction,Wind_Speed,Barometric_Pres,Dry_Bulb_Temp,Wet_Bulb_Temp,Weather_Condition,Cloud_Type,Cloud_Cover,dataset,Recorder,depth_eq,Bottom_Hit,Visibility,Ref_Surf_Temp,needs_z_fix,real_time,dbase_orig,origflagset,Temperature_WODprofileflag,Temperature_Scale,Temperature_Instrument,Temperature_uncalibrated,Salinity_WODprofileflag,Salinity_Scale,Salinity_Instrument,Salinity_uncalibrated,Oxygen_WODprofileflag,Oxygen_Instrument,Oxygen_Method,Oxygen_Original_units,Oxygen_uncalibrated,Pressure_Instrument,Chlorophyll_WODprofileflag,Chlorophyll_Instrument,Chlorophyll_Original_units,Chlorophyll_uncalibrated,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Salinity_origflag,Oxygen,Oxygen_sigfigs,Oxygen_WODflag,Oxygen_origflag,Pressure,Pressure_sigfigs,Pressure_origflag,Chlorophyll,Chlorophyll_sigfigs,Chlorophyll_WODflag,Chlorophyll_origflag\n" +
//"NEW ZEALAND,NZ001163,tan0601,15077333,,-43.9471,-179.09016,86196.95902776718,20051231,23.016666,74288,,TANGAROA (R/V; call sign ZMFR; built 1991; IMO9011571),NATIONAL INSTITUTE OF WATER & ATMOSPHERIC RESEARCH LTD (NIWA); AUCKLAND,-99999,25,382.0,-1.0E10,,-99999,,-1.0E10,,,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,CTD,,,-9,,-1.0E10,,,GODAR Project,,0,,,-99999,0,,,-99999,0,,,,-99999,,0,,,-99999,,,374.0,0,-9,3,8.695,4,0,-9,34.571,5,0,-9,-1.0E10,,,-9,-1.0E10,,-9,-1.0E10,,,-9\n" +
        fullName = dir + "wod_ctd_2005.nc";
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast"}), 
            new StringArray(new String[]{"="}), 
            new StringArray(new String[]{"15077333"}));
        results = table.dataToString(5);
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"15077333,86196.95902776718,0.0,15.537,0\n" +
"15077333,86196.95902776718,1.0,15.544,0\n" +
"15077333,86196.95902776718,2.0,15.533,0\n" +
"15077333,86196.95902776718,3.0,15.516,0\n" +
"15077333,86196.95902776718,5.0,15.501,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //outer and inner constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast", "Temperature"}), 
            new StringArray(new String[]{"=", "="}), 
            new StringArray(new String[]{"15077333", "15.533"}));
        results = table.dataToString();
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"15077333,86196.95902776718,2.0,15.533,0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //*** read all drb
        fullName = dir + "wod_drb_2005.nc";
        if (doAll) {
            table.readInvalidCRA(fullName, null, 0,  //standardizeWhat=0
                null, null, null);
            results = table.toString(5);
            expected = 
"{\n" +
"dimensions:\n" +
"\trow = 846878 ;\n" +
"\tcountry_strlen = 13 ;\n" +
"\tWOD_cruise_identifier_strlen = 8 ;\n" +
"\toriginators_cruise_identifier_strlen = 5 ;\n" +
"\tPlatform_strlen = 17 ;\n" +
"\tInstitute_strlen = 62 ;\n" +
"\tdataset_strlen = 13 ;\n" +
"\tOcean_Vehicle_strlen = 38 ;\n" +
"\tTemperature_Instrument_strlen = 50 ;\n" +
"\tSalinity_Instrument_strlen = 50 ;\n" +
"\tPrimary_Investigator_strlen = 14 ;\n" +
"\tPrimary_Investigator_VAR_strlen = 13 ;\n" +
"variables:\n" +
"\tchar country(row, country_strlen) ;\n" +
"\tchar WOD_cruise_identifier(row, WOD_cruise_identifier_strlen) ;\n" +
"\t\tWOD_cruise_identifier:comment = \"two byte country code + WOD cruise number (unique to country code)\" ;\n" +
"\t\tWOD_cruise_identifier:long_name = \"WOD_cruise_identifier\" ;\n" +
"\tchar originators_cruise_identifier(row, originators_cruise_identifier_strlen) ;\n" +
"\tint wod_unique_cast(row) ;\n" +
"\t\twod_unique_cast:cf_role = \"profile_id\" ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:standard_name = \"latitude\" ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:standard_name = \"longitude\" ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:units = \"days since 1770-01-01 00:00:00 UTC\" ;\n" +
"\tint date(row) ;\n" +
"\t\tdate:comment = \"YYYYMMDD\" ;\n" +
"\t\tdate:long_name = \"date\" ;\n" +
"\tfloat GMT_time(row) ;\n" +
"\t\tGMT_time:long_name = \"GMT_time\" ;\n" +
"\t\tGMT_time:units = \"hours\" ;\n" +
"\tint Access_no(row) ;\n" +
"\t\tAccess_no:_FillValue = -99999 ;\n" +
"\t\tAccess_no:comment = \"used to find original data at NODC\" ;\n" +
"\t\tAccess_no:long_name = \"NODC_accession_number\" ;\n" +
"\t\tAccess_no:units_wod = \"NODC_code\" ;\n" +
"\tchar Platform(row, Platform_strlen) ;\n" +
"\t\tPlatform:comment = \"name of platform from which measurements were taken\" ;\n" +
"\t\tPlatform:long_name = \"Platform_name\" ;\n" +
"\tchar Institute(row, Institute_strlen) ;\n" +
"\t\tInstitute:comment = \"name of institute which collected data\" ;\n" +
"\t\tInstitute:long_name = \"Responsible_institute\" ;\n" +
"\tint Orig_Stat_Num(row) ;\n" +
"\t\tOrig_Stat_Num:_FillValue = -99999 ;\n" +
"\t\tOrig_Stat_Num:comment = \"number assigned to a given station by data originator\" ;\n" +
"\t\tOrig_Stat_Num:long_name = \"Originators_Station_Number\" ;\n" +
"\tchar dataset(row, dataset_strlen) ;\n" +
"\t\tdataset:long_name = \"WOD_dataset\" ;\n" +
"\tchar Ocean_Vehicle(row, Ocean_Vehicle_strlen) ;\n" +
"\t\tOcean_Vehicle:comment = \"Ocean_vehicle\" ;\n" +
"\tbyte Temperature_WODprofileflag(row) ;\n" +
"\t\tTemperature_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tTemperature_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Temperature_Instrument(row, Temperature_Instrument_strlen) ;\n" +
"\t\tTemperature_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tTemperature_Instrument:long_name = \"Instrument\" ;\n" +
"\tbyte Salinity_WODprofileflag(row) ;\n" +
"\t\tSalinity_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tSalinity_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Salinity_Instrument(row, Salinity_Instrument_strlen) ;\n" +
"\t\tSalinity_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tSalinity_Instrument:long_name = \"Instrument\" ;\n" +
"\tchar Primary_Investigator(row, Primary_Investigator_strlen) ;\n" +
"\tchar Primary_Investigator_VAR(row, Primary_Investigator_VAR_strlen) ;\n" +
"\tfloat z(row) ;\n" +
"\t\tz:ancillary_variables = \"z_sigfigs z_WODflag\" ;\n" +
"\t\tz:long_name = \"depth_below_sea_surface\" ;\n" +
"\t\tz:positive = \"down\" ;\n" +
"\t\tz:standard_name = \"depth\" ;\n" +
"\t\tz:units = \"m\" ;\n" +
"\tbyte z_WODflag(row) ;\n" +
"\t\tz_WODflag:flag_meanings = \"accepted duplicate_or_inversion density_inversion\" ;\n" +
"\t\tz_WODflag:flag_values = 0, 1, 2 ;\n" +
"\t\tz_WODflag:long_name = \"WOD_depth_level_flag\" ;\n" +
"\t\tz_WODflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_sigfigs(row) ;\n" +
"\t\tz_sigfigs:long_name = \"depth significant figures   \" ;\n" +
"\tfloat Temperature(row) ;\n" +
"\t\tTemperature:_FillValue = -1.0E10f ;\n" +
"\t\tTemperature:ancillary_variables = \"Temperature_sigfigs Temperature_WODflag Temperature_WODprofileflag\" ;\n" +
"\t\tTemperature:coordinates = \"time lat lon z\" ;\n" +
"\t\tTemperature:grid_mapping = \"crs\" ;\n" +
"\t\tTemperature:long_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:units = \"degree_C\" ;\n" +
"\tbyte Temperature_sigfigs(row) ;\n" +
"\t\tTemperature_sigfigs:long_name = \"sea_water_temperature significant_figures\" ;\n" +
"\tbyte Temperature_WODflag(row) ;\n" +
"\t\tTemperature_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tTemperature_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tTemperature_WODflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tfloat Salinity(row) ;\n" +
"\t\tSalinity:_FillValue = -1.0E10f ;\n" +
"\t\tSalinity:ancillary_variables = \"Salinity_sigfigs Salinity_WODflag Salinity_WODprofileflag\" ;\n" +
"\t\tSalinity:coordinates = \"time lat lon z\" ;\n" +
"\t\tSalinity:grid_mapping = \"crs\" ;\n" +
"\t\tSalinity:long_name = \"sea_water_salinity\" ;\n" +
"\t\tSalinity:standard_name = \"sea_water_salinity\" ;\n" +
"\tbyte Salinity_sigfigs(row) ;\n" +
"\t\tSalinity_sigfigs:long_name = \"sea_water_salinity significant_figures\" ;\n" +
"\tbyte Salinity_WODflag(row) ;\n" +
"\t\tSalinity_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tSalinity_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tSalinity_WODflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\tfloat Pressure(row) ;\n" +
"\t\tPressure:_FillValue = -1.0E10f ;\n" +
"\t\tPressure:ancillary_variables = \"Pressure_sigfigs Pressure_WODflag Pressure_WODprofileflag\" ;\n" +
"\t\tPressure:coordinates = \"time lat lon z\" ;\n" +
"\t\tPressure:grid_mapping = \"crs\" ;\n" +
"\t\tPressure:long_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:standard_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:units = \"dbar\" ;\n" +
"\tbyte Pressure_sigfigs(row) ;\n" +
"\t\tPressure_sigfigs:long_name = \"sea_water_pressure significant_figures\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"country, WOD_cruise_identifier, originators_cruise_identifier, wod_unique_cast, latitude, longitude, time, date, GMT_time, Access_no, Platform, Institute, Orig_Stat_Num, dataset, Ocean_Vehicle, Temperature_WODprofileflag, Temperature_Instrument, Salinity_WODprofileflag, Salinity_Instrument, Primary_Investigator, Primary_Investigator_VAR\" ;\n" +
"\t\t:Conventions = \"CF-1.6\" ;\n" +
"\t\t:creator_email = \"OCLhelp@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Ocean Climate Lab/NCEI\" ;\n" +
"\t\t:creator_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:crs_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:crs_grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:crs_inverse_flattening = 298.25723f ;\n" +
"\t\t:crs_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:crs_semi_major_axis = 6378137.0f ;\n" +
"\t\t:date_created = \"2018-03-25\" ;\n" +
"\t\t:date_modified = \"2018-03-25\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 89.625f ;\n" +
"\t\t:geospatial_lat_min = 76.025f ;\n" +
"\t\t:geospatial_lat_resolution = \"point\" ;\n" +
"\t\t:geospatial_lon_max = 180.0f ;\n" +
"\t\t:geospatial_lon_min = -180.0f ;\n" +
"\t\t:geospatial_lon_resolution = \"point\" ;\n" +
"\t\t:geospatial_vertical_max = 780.2189f ;\n" +
"\t\t:geospatial_vertical_min = 8.113341f ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"meters\" ;\n" +
"\t\t:grid_mapping_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:grid_mapping_inverse_flattening = 298.25723f ;\n" +
"\t\t:grid_mapping_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:grid_mapping_semi_major_axis = 6378137.0f ;\n" +
"\t\t:id = \"/nodc/data/oc5.clim.0/wod_update_nc/2005/wod_drb_2005.nc\" ;\n" +
"\t\t:institution = \"National Centers for Environmental Information (NCEI), NOAA\" ;\n" +
"\t\t:naming_authority = \"gov.noaa.nodc\" ;\n" +
"\t\t:project = \"World Ocean Database\" ;\n" +
"\t\t:publisher_email = \"NODC.Services@noaa.gov\" ;\n" +
"\t\t:publisher_name = \"US DOC; NESDIS; NATIONAL CENTERS FOR ENVIRONMENTAL INFORMATION\" ;\n" +
"\t\t:publisher_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:references = \"World Ocean Database 2013. URL:http://data.nodc.noaa.gov/woa/WOD/DOC/wod_intro.pdf\" ;\n" +
"\t\t:source = \"World Ocean Database\" ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v41\" ;\n" +
"\t\t:summary = \"Data for multiple casts from the World Ocean Database\" ;\n" +
"\t\t:time_coverage_end = \"2005-12-31\" ;\n" +
"\t\t:time_coverage_start = \"2005-01-01\" ;\n" +
"\t\t:title = \"World Ocean Database - Multi-cast file\" ;\n" +
"}\n" +
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Platform,Institute,Orig_Stat_Num,dataset,Ocean_Vehicle,Temperature_WODprofileflag,Temperature_Instrument,Salinity_WODprofileflag,Salinity_Instrument,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Pressure,Pressure_sigfigs\n" +
"JAPAN,JP033439,,10899854,88.1995,-15.9725,85832.0,20050101,0.0,14672,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),3006,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,25.348,0,6,-1.738,5,0,31.7095,6,0,-1.0E10,\n" +
"JAPAN,JP033439,,10899854,88.1995,-15.9725,85832.0,20050101,0.0,14672,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),3006,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,50.694,0,6,-1.738,5,0,31.7078,6,0,-1.0E10,\n" +
"JAPAN,JP033439,,10899854,88.1995,-15.9725,85832.0,20050101,0.0,14672,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),3006,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,81.104,0,6,-1.68,5,0,33.4528,6,0,-1.0E10,\n" +
"JAPAN,JP033439,,10899854,88.1995,-15.9725,85832.0,20050101,0.0,14672,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),3006,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,121.808,0,7,-1.286,5,0,34.1678,6,0,-1.0E10,\n" +
"JAPAN,JP033439,,10899854,88.1995,-15.9725,85832.0,20050101,0.0,14672,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),3006,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,203.193,0,7,0.432,4,0,34.7061,6,0,-1.0E10,\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            table.removeRows(0, 846878 - 5);
            results = table.dataToString();
            expected = 
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Platform,Institute,Orig_Stat_Num,dataset,Ocean_Vehicle,Temperature_WODprofileflag,Temperature_Instrument,Salinity_WODprofileflag,Salinity_Instrument,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Pressure,Pressure_sigfigs\n" +
"JAPAN,JP033440,,10909132,76.025,-11.6514,86196.95833331347,20051231,23.0,-504834352,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),-504843054,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,106.845,0,7,-1.474,5,0,33.5642,6,0,-1.0E10,\n" +
"JAPAN,JP033440,,10909132,76.025,-11.6514,86196.95833331347,20051231,23.0,-504834352,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),-504843054,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,148.032,0,7,-0.74,4,0,34.2258,6,0,-1.0E10,\n" +
"JAPAN,JP033440,,10909132,76.025,-11.6514,86196.95833331347,20051231,23.0,-504834352,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),-504843054,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,194.357,0,7,-0.436,4,0,31.0866,6,0,-1.0E10,\n" +
"JAPAN,JP033441,,10909133,87.4024,-112.5225,86196.95833331347,20051231,23.0,-504834352,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),-504846154,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,50.447,0,6,-1.6169,5,0,30.988,6,0,-1.0E10,\n" +
"JAPAN,JP033441,,10909133,87.4024,-112.5225,86196.95833331347,20051231,23.0,-504834352,,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),-504846154,drifting buoy,J-CAD (JAMSTEC Compact Arctic Drifter),0,,0,,,,121.051,0,7,-1.5004,5,0,34.0442,6,0,-1.0E10,\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
        }


        //read outer and inner col with outer constraint
        fullName = dir + "wod_drb_2005.nc";
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast"}), 
            new StringArray(new String[]{"="}), 
            new StringArray(new String[]{"10909132"}));
        results = table.dataToString(5);
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"10909132,86196.95833331347,22.264,-1.818,0\n" +
"10909132,86196.95833331347,44.526,-1.816,0\n" +
"10909132,86196.95833331347,71.236,-1.798,0\n" +
"10909132,86196.95833331347,106.845,-1.474,0\n" +
"10909132,86196.95833331347,148.032,-0.74,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //outer and inner constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast", "Temperature"}), 
            new StringArray(new String[]{"=", "="}), 
            new StringArray(new String[]{"10909132", "-1.798"}));
        results = table.dataToString();
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"10909132,86196.95833331347,71.236,-1.798,0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);



        //*** read all gld
        fullName = dir + "wod_gld_2005.nc";
        if (doAll) {
            table.readInvalidCRA(fullName, null, 0,  //standardizeWhat=0
                null, null, null);
            results = table.toString(5);
            expected = 
"{\n" +
"dimensions:\n" +
"\trow = 3398337 ;\n" +
"\tcountry_strlen = 13 ;\n" +
"\tWOD_cruise_identifier_strlen = 8 ;\n" +
"\toriginators_cruise_identifier_strlen = 15 ;\n" +
"\tPlatform_strlen = 80 ;\n" +
"\tInstitute_strlen = 79 ;\n" +
"\tCast_Direction_strlen = 2 ;\n" +
"\tdataset_strlen = 6 ;\n" +
"\tOcean_Vehicle_strlen = 9 ;\n" +
"\torigflagset_strlen = 5 ;\n" +
"\tTemperature_Instrument_strlen = 70 ;\n" +
"\tSalinity_Instrument_strlen = 70 ;\n" +
"\tPrimary_Investigator_strlen = 33 ;\n" +
"\tPrimary_Investigator_VAR_strlen = 27 ;\n" +
"variables:\n" +
"\tchar country(row, country_strlen) ;\n" +
"\tchar WOD_cruise_identifier(row, WOD_cruise_identifier_strlen) ;\n" +
"\t\tWOD_cruise_identifier:comment = \"two byte country code + WOD cruise number (unique to country code)\" ;\n" +
"\t\tWOD_cruise_identifier:long_name = \"WOD_cruise_identifier\" ;\n" +
"\tchar originators_cruise_identifier(row, originators_cruise_identifier_strlen) ;\n" +
"\tint wod_unique_cast(row) ;\n" +
"\t\twod_unique_cast:cf_role = \"profile_id\" ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:standard_name = \"latitude\" ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:standard_name = \"longitude\" ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:units = \"days since 1770-01-01 00:00:00 UTC\" ;\n" +
"\tint date(row) ;\n" +
"\t\tdate:comment = \"YYYYMMDD\" ;\n" +
"\t\tdate:long_name = \"date\" ;\n" +
"\tfloat GMT_time(row) ;\n" +
"\t\tGMT_time:long_name = \"GMT_time\" ;\n" +
"\t\tGMT_time:units = \"hours\" ;\n" +
"\tint Access_no(row) ;\n" +
"\t\tAccess_no:_FillValue = -99999 ;\n" +
"\t\tAccess_no:comment = \"used to find original data at NODC\" ;\n" +
"\t\tAccess_no:long_name = \"NODC_accession_number\" ;\n" +
"\t\tAccess_no:units_wod = \"NODC_code\" ;\n" +
"\tchar Platform(row, Platform_strlen) ;\n" +
"\t\tPlatform:comment = \"name of platform from which measurements were taken\" ;\n" +
"\t\tPlatform:long_name = \"Platform_name\" ;\n" +
"\tchar Institute(row, Institute_strlen) ;\n" +
"\t\tInstitute:comment = \"name of institute which collected data\" ;\n" +
"\t\tInstitute:long_name = \"Responsible_institute\" ;\n" +
"\tint Orig_Stat_Num(row) ;\n" +
"\t\tOrig_Stat_Num:_FillValue = -99999 ;\n" +
"\t\tOrig_Stat_Num:comment = \"number assigned to a given station by data originator\" ;\n" +
"\t\tOrig_Stat_Num:long_name = \"Originators_Station_Number\" ;\n" +
"\tchar Cast_Direction(row, Cast_Direction_strlen) ;\n" +
"\t\tCast_Direction:long_name = \"Cast_Direction\" ;\n" +
"\tchar dataset(row, dataset_strlen) ;\n" +
"\t\tdataset:long_name = \"WOD_dataset\" ;\n" +
"\tchar Ocean_Vehicle(row, Ocean_Vehicle_strlen) ;\n" +
"\t\tOcean_Vehicle:comment = \"Ocean_vehicle\" ;\n" +
"\tint WMO_ID(row) ;\n" +
"\t\tWMO_ID:_FillValue = -99999 ;\n" +
"\t\tWMO_ID:long_name = \"WMO_identification_code\" ;\n" +
"\tchar origflagset(row, origflagset_strlen) ;\n" +
"\t\torigflagset:comment = \"set of originators flag codes to use\" ;\n" +
"\tbyte Temperature_WODprofileflag(row) ;\n" +
"\t\tTemperature_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tTemperature_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Temperature_Instrument(row, Temperature_Instrument_strlen) ;\n" +
"\t\tTemperature_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tTemperature_Instrument:long_name = \"Instrument\" ;\n" +
"\tbyte Salinity_WODprofileflag(row) ;\n" +
"\t\tSalinity_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tSalinity_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Salinity_Instrument(row, Salinity_Instrument_strlen) ;\n" +
"\t\tSalinity_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tSalinity_Instrument:long_name = \"Instrument\" ;\n" +
"\tbyte Chlorophyll_WODprofileflag(row) ;\n" +
"\t\tChlorophyll_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tChlorophyll_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tChlorophyll_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Primary_Investigator(row, Primary_Investigator_strlen) ;\n" +
"\tchar Primary_Investigator_VAR(row, Primary_Investigator_VAR_strlen) ;\n" +
"\tfloat z(row) ;\n" +
"\t\tz:ancillary_variables = \"z_sigfigs z_WODflag z_origflag\" ;\n" +
"\t\tz:long_name = \"depth_below_sea_surface\" ;\n" +
"\t\tz:positive = \"down\" ;\n" +
"\t\tz:standard_name = \"depth\" ;\n" +
"\t\tz:units = \"m\" ;\n" +
"\tbyte z_WODflag(row) ;\n" +
"\t\tz_WODflag:flag_meanings = \"accepted duplicate_or_inversion density_inversion\" ;\n" +
"\t\tz_WODflag:flag_values = 0, 1, 2 ;\n" +
"\t\tz_WODflag:long_name = \"WOD_depth_level_flag\" ;\n" +
"\t\tz_WODflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_origflag(row) ;\n" +
"\t\tz_origflag:_FillValue = -9 ;\n" +
"\t\tz_origflag:comment = \"Originator flags are dependent on origflagset\" ;\n" +
"\t\tz_origflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_sigfigs(row) ;\n" +
"\t\tz_sigfigs:long_name = \"depth significant figures   \" ;\n" +
"\tfloat Temperature(row) ;\n" +
"\t\tTemperature:_FillValue = -1.0E10f ;\n" +
"\t\tTemperature:ancillary_variables = \"Temperature_sigfigs Temperature_WODflag Temperature_WODprofileflag Temperature_origflag\" ;\n" +
"\t\tTemperature:coordinates = \"time lat lon z\" ;\n" +
"\t\tTemperature:grid_mapping = \"crs\" ;\n" +
"\t\tTemperature:long_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:units = \"degree_C\" ;\n" +
"\tbyte Temperature_sigfigs(row) ;\n" +
"\t\tTemperature_sigfigs:long_name = \"sea_water_temperature significant_figures\" ;\n" +
"\tbyte Temperature_WODflag(row) ;\n" +
"\t\tTemperature_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tTemperature_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tTemperature_WODflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tbyte Temperature_origflag(row) ;\n" +
"\t\tTemperature_origflag:_FillValue = -9 ;\n" +
"\t\tTemperature_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tTemperature_origflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tfloat Salinity(row) ;\n" +
"\t\tSalinity:_FillValue = -1.0E10f ;\n" +
"\t\tSalinity:ancillary_variables = \"Salinity_sigfigs Salinity_WODflag Salinity_WODprofileflag Salinity_origflag\" ;\n" +
"\t\tSalinity:coordinates = \"time lat lon z\" ;\n" +
"\t\tSalinity:grid_mapping = \"crs\" ;\n" +
"\t\tSalinity:long_name = \"sea_water_salinity\" ;\n" +
"\t\tSalinity:standard_name = \"sea_water_salinity\" ;\n" +
"\tbyte Salinity_sigfigs(row) ;\n" +
"\t\tSalinity_sigfigs:long_name = \"sea_water_salinity significant_figures\" ;\n" +
"\tbyte Salinity_WODflag(row) ;\n" +
"\t\tSalinity_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tSalinity_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tSalinity_WODflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\tbyte Salinity_origflag(row) ;\n" +
"\t\tSalinity_origflag:_FillValue = -9 ;\n" +
"\t\tSalinity_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tSalinity_origflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\tfloat Pressure(row) ;\n" +
"\t\tPressure:_FillValue = -1.0E10f ;\n" +
"\t\tPressure:ancillary_variables = \"Pressure_sigfigs Pressure_WODflag Pressure_WODprofileflag Pressure_origflag\" ;\n" +
"\t\tPressure:coordinates = \"time lat lon z\" ;\n" +
"\t\tPressure:grid_mapping = \"crs\" ;\n" +
"\t\tPressure:long_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:standard_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:units = \"dbar\" ;\n" +
"\tbyte Pressure_sigfigs(row) ;\n" +
"\t\tPressure_sigfigs:long_name = \"sea_water_pressure significant_figures\" ;\n" +
"\tbyte Pressure_origflag(row) ;\n" +
"\t\tPressure_origflag:_FillValue = -9 ;\n" +
"\t\tPressure_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tPressure_origflag:standard_name = \"sea_water_pressure status_flag\" ;\n" +
"\tfloat Latitude(row) ;\n" +
"\t\tLatitude:_FillValue = -1.0E10f ;\n" +
"\t\tLatitude:ancillary_variables = \"Latitude_sigfigs Latitude_WODflag Latitude_WODprofileflag Latitude_origflag\" ;\n" +
"\t\tLatitude:coordinates = \"time lat lon z\" ;\n" +
"\t\tLatitude:grid_mapping = \"crs\" ;\n" +
"\t\tLatitude:long_name = \"latitude\" ;\n" +
"\t\tLatitude:standard_name = \"latitude\" ;\n" +
"\t\tLatitude:units = \"degrees_north\" ;\n" +
"\tbyte Latitude_sigfigs(row) ;\n" +
"\t\tLatitude_sigfigs:long_name = \"latitude significant_figures\" ;\n" +
"\tbyte Latitude_WODflag(row) ;\n" +
"\t\tLatitude_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tLatitude_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tLatitude_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tLatitude_WODflag:standard_name = \"latitude status_flag\" ;\n" +
"\tbyte Latitude_origflag(row) ;\n" +
"\t\tLatitude_origflag:_FillValue = -9 ;\n" +
"\t\tLatitude_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tLatitude_origflag:standard_name = \"latitude status_flag\" ;\n" +
"\tfloat Longitude(row) ;\n" +
"\t\tLongitude:_FillValue = -1.0E10f ;\n" +
"\t\tLongitude:ancillary_variables = \"Longitude_sigfigs Longitude_WODflag Longitude_WODprofileflag Longitude_origflag\" ;\n" +
"\t\tLongitude:coordinates = \"time lat lon z\" ;\n" +
"\t\tLongitude:grid_mapping = \"crs\" ;\n" +
"\t\tLongitude:long_name = \"longitude\" ;\n" +
"\t\tLongitude:standard_name = \"longitude\" ;\n" +
"\t\tLongitude:units = \"degrees_east\" ;\n" +
"\tbyte Longitude_sigfigs(row) ;\n" +
"\t\tLongitude_sigfigs:long_name = \"longitude significant_figures\" ;\n" +
"\tbyte Longitude_WODflag(row) ;\n" +
"\t\tLongitude_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tLongitude_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tLongitude_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tLongitude_WODflag:standard_name = \"longitude status_flag\" ;\n" +
"\tbyte Longitude_origflag(row) ;\n" +
"\t\tLongitude_origflag:_FillValue = -9 ;\n" +
"\t\tLongitude_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tLongitude_origflag:standard_name = \"longitude status_flag\" ;\n" +
"\tfloat JulianDay(row) ;\n" +
"\t\tJulianDay:_FillValue = -1.0E10f ;\n" +
"\t\tJulianDay:ancillary_variables = \"JulianDay_sigfigs JulianDay_WODflag JulianDay_WODprofileflag JulianDay_origflag\" ;\n" +
"\t\tJulianDay:coordinates = \"time lat lon z\" ;\n" +
"\t\tJulianDay:grid_mapping = \"crs\" ;\n" +
"\t\tJulianDay:long_name = \"JulianDay\" ;\n" +
"\tbyte JulianDay_sigfigs(row) ;\n" +
"\t\tJulianDay_sigfigs:long_name = \"JulianDay significant_figures\" ;\n" +
"\tbyte JulianDay_WODflag(row) ;\n" +
"\t\tJulianDay_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tJulianDay_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tJulianDay_WODflag:long_name = \"JulianDay st\" ;\n" +
"\tbyte JulianDay_origflag(row) ;\n" +
"\t\tJulianDay_origflag:_FillValue = -9 ;\n" +
"\t\tJulianDay_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tJulianDay_origflag:long_name = \"JulianDay st\" ;\n" +
"\tfloat Chlorophyll(row) ;\n" +
"\t\tChlorophyll:_FillValue = -1.0E10f ;\n" +
"\t\tChlorophyll:ancillary_variables = \"Chlorophyll_sigfigs Chlorophyll_WODflag Chlorophyll_WODprofileflag Chlorophyll_origflag\" ;\n" +
"\t\tChlorophyll:coordinates = \"time lat lon z\" ;\n" +
"\t\tChlorophyll:grid_mapping = \"crs\" ;\n" +
"\t\tChlorophyll:long_name = \"mass_concentration_of_chlorophyll_in_sea_water\" ;\n" +
"\t\tChlorophyll:standard_name = \"mass_concentration_of_chlorophyll_in_sea_water\" ;\n" +
"\t\tChlorophyll:units = \"ugram/l\" ;\n" +
"\tbyte Chlorophyll_sigfigs(row) ;\n" +
"\t\tChlorophyll_sigfigs:long_name = \"mass_concentration_of_chlorophyll_in_sea_water significant_figures\" ;\n" +
"\tbyte Chlorophyll_WODflag(row) ;\n" +
"\t\tChlorophyll_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tChlorophyll_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tChlorophyll_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tChlorophyll_WODflag:standard_name = \"mass_concentration_of_chlorophyll_in_sea_water status_flag\" ;\n" +
"\tbyte Chlorophyll_origflag(row) ;\n" +
"\t\tChlorophyll_origflag:_FillValue = -9 ;\n" +
"\t\tChlorophyll_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tChlorophyll_origflag:standard_name = \"mass_concentration_of_chlorophyll_in_sea_water status_flag\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"country, WOD_cruise_identifier, originators_cruise_identifier, wod_unique_cast, latitude, longitude, time, date, GMT_time, Access_no, Platform, Institute, Orig_Stat_Num, Cast_Direction, dataset, Ocean_Vehicle, WMO_ID, origflagset, Temperature_WODprofileflag, Temperature_Instrument, Salinity_WODprofileflag, Salinity_Instrument, Chlorophyll_WODprofileflag, Primary_Investigator, Primary_Investigator_VAR\" ;\n" +
"\t\t:Conventions = \"CF-1.6\" ;\n" +
"\t\t:creator_email = \"OCLhelp@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Ocean Climate Lab/NCEI\" ;\n" +
"\t\t:creator_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:crs_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:crs_grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:crs_inverse_flattening = 298.25723f ;\n" +
"\t\t:crs_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:crs_semi_major_axis = 6378137.0f ;\n" +
"\t\t:date_created = \"2018-03-25\" ;\n" +
"\t\t:date_modified = \"2018-03-25\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 63.9972f ;\n" +
"\t\t:geospatial_lat_min = 22.481083f ;\n" +
"\t\t:geospatial_lat_resolution = \"point\" ;\n" +
"\t\t:geospatial_lon_max = 16.887665f ;\n" +
"\t\t:geospatial_lon_min = -158.30486f ;\n" +
"\t\t:geospatial_lon_resolution = \"point\" ;\n" +
"\t\t:geospatial_vertical_max = 1026.7106f ;\n" +
"\t\t:geospatial_vertical_min = -0.29778513f ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"meters\" ;\n" +
"\t\t:grid_mapping_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:grid_mapping_inverse_flattening = 298.25723f ;\n" +
"\t\t:grid_mapping_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:grid_mapping_semi_major_axis = 6378137.0f ;\n" +
"\t\t:id = \"/nodc/data/oc5.clim.0/wod_update_nc/2005/wod_gld_2005.nc\" ;\n" +
"\t\t:institution = \"National Centers for Environmental Information (NCEI), NOAA\" ;\n" +
"\t\t:naming_authority = \"gov.noaa.nodc\" ;\n" +
"\t\t:project = \"World Ocean Database\" ;\n" +
"\t\t:publisher_email = \"NODC.Services@noaa.gov\" ;\n" +
"\t\t:publisher_name = \"US DOC; NESDIS; NATIONAL CENTERS FOR ENVIRONMENTAL INFORMATION\" ;\n" +
"\t\t:publisher_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:references = \"World Ocean Database 2013. URL:http://data.nodc.noaa.gov/woa/WOD/DOC/wod_intro.pdf\" ;\n" +
"\t\t:source = \"World Ocean Database\" ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v41\" ;\n" +
"\t\t:summary = \"Data for multiple casts from the World Ocean Database\" ;\n" +
"\t\t:time_coverage_end = \"2005-12-31\" ;\n" +
"\t\t:time_coverage_start = \"2005-01-01\" ;\n" +
"\t\t:title = \"World Ocean Database - Multi-cast file\" ;\n" +
"}\n" +
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Platform,Institute,Orig_Stat_Num,Cast_Direction,dataset,Ocean_Vehicle,WMO_ID,origflagset,Temperature_WODprofileflag,Temperature_Instrument,Salinity_WODprofileflag,Salinity_Instrument,Chlorophyll_WODprofileflag,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Salinity_origflag,Pressure,Pressure_sigfigs,Pressure_origflag,Latitude,Latitude_sigfigs,Latitude_WODflag,Latitude_origflag,Longitude,Longitude_sigfigs,Longitude_WODflag,Longitude_origflag,JulianDay,JulianDay_sigfigs,JulianDay_WODflag,JulianDay_origflag,Chlorophyll,Chlorophyll_sigfigs,Chlorophyll_WODflag,Chlorophyll_origflag\n" +
"UNITED STATES,US035083,p015,15727905,56.54242,-55.34162,85832.0146483751,20050101,0.351561,111844,SG015 (AUV;Seaglider #015;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),377,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,0.89629334,0,1,2,3.2594981,4,0,1,-1.0E10,-127,-127,-9,0.9058805,3,1,56.54242,7,0,1,-55.34162,7,0,1,0.19433588,5,0,1,-1.0E10,,,-9\n" +
"UNITED STATES,US035083,p015,15727905,56.54242,-55.34162,85832.0146483751,20050101,0.351561,111844,SG015 (AUV;Seaglider #015;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),377,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,0.8763757,0,1,2,3.5394983,4,0,1,-1.0E10,-127,-127,-9,0.8857498,3,1,56.542416,7,0,1,-55.34162,7,0,1,0.19433588,5,0,1,-1.0E10,,,-9\n" +
"UNITED STATES,US035083,p015,15727905,56.54242,-55.34162,85832.0146483751,20050101,0.351561,111844,SG015 (AUV;Seaglider #015;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),377,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,1.1153866,0,1,3,3.6717756,4,0,1,-1.0E10,-127,-127,-9,1.1273179,4,1,56.542416,7,0,1,-55.34162,7,0,1,0.19433588,5,0,1,-1.0E10,,,-9\n" +
"UNITED STATES,US035083,p015,15727905,56.54242,-55.34162,85832.0146483751,20050101,0.351561,111844,SG015 (AUV;Seaglider #015;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),377,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,1.4639436,0,1,3,3.678846,4,0,1,34.7831,5,0,1,1.4796048,4,1,56.542416,7,0,1,-55.34162,7,0,1,0.19433588,5,0,1,-1.0E10,,,-9\n" +
"UNITED STATES,US035083,p015,15727905,56.54242,-55.34162,85832.0146483751,20050101,0.351561,111844,SG015 (AUV;Seaglider #015;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),377,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,1.7925826,0,1,3,3.6769755,4,0,1,34.789787,5,0,1,1.811761,4,1,56.542416,7,0,1,-55.341618,7,0,1,0.19433588,5,0,1,-1.0E10,,,-9\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            table.removeRows(0, 3398337 - 5);
            results = table.dataToString();
            expected = 
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Platform,Institute,Orig_Stat_Num,Cast_Direction,dataset,Ocean_Vehicle,WMO_ID,origflagset,Temperature_WODprofileflag,Temperature_Instrument,Salinity_WODprofileflag,Salinity_Instrument,Chlorophyll_WODprofileflag,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Salinity_origflag,Pressure,Pressure_sigfigs,Pressure_origflag,Latitude,Latitude_sigfigs,Latitude_WODflag,Latitude_origflag,Longitude,Longitude_sigfigs,Longitude_WODflag,Longitude_origflag,JulianDay,JulianDay_sigfigs,JulianDay_WODflag,JulianDay_origflag,Chlorophyll,Chlorophyll_sigfigs,Chlorophyll_WODflag,Chlorophyll_origflag\n" +
"UNITED STATES,US037856,0156003p012,17842328,47.00655,-127.19153,86196.91210919619,20051231,21.890621,156003,SG012 (AUV;Seaglider #012;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),3,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,976.9241,0,1,5,3.5159547,4,0,1,34.39147,5,0,1,989.7248,6,1,47.007023,7,0,1,-127.15596,8,0,1,365.91602,8,0,1,-1.0E10,,,-9\n" +
"UNITED STATES,US037856,0156003p012,17842328,47.00655,-127.19153,86196.91210919619,20051231,21.890621,156003,SG012 (AUV;Seaglider #012;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),3,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,980.71027,0,1,5,3.512552,4,0,1,34.39222,5,0,1,993.56976,6,1,47.007023,7,0,1,-127.15583,8,0,1,365.91406,8,0,1,-1.0E10,,,-9\n" +
"UNITED STATES,US037856,0156003p012,17842328,47.00655,-127.19153,86196.91210919619,20051231,21.890621,156003,SG012 (AUV;Seaglider #012;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),3,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,984.67487,0,1,5,3.5072713,4,0,1,-1.0E10,-127,-127,-9,997.5959,6,1,47.00701,7,0,1,-127.15576,8,0,1,365.91406,8,0,1,-1.0E10,,,-9\n" +
"UNITED STATES,US037856,0156003p012,17842328,47.00655,-127.19153,86196.91210919619,20051231,21.890621,156003,SG012 (AUV;Seaglider #012;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),3,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,987.4005,0,1,5,3.5013642,4,0,1,-1.0E10,-127,-127,-9,1000.36383,7,1,47.006985,7,0,1,-127.15577,8,0,1,365.9121,8,0,1,-1.0E10,,,-9\n" +
"UNITED STATES,US037856,0156003p012,17842328,47.00655,-127.19153,86196.91210919619,20051231,21.890621,156003,SG012 (AUV;Seaglider #012;owned by Applied Phys.Lab.Univ.of Washington),UNIVERSITY OF WASHINGTON; APPLIED PHYSICS LABORATORY (APL),3,UP,glider,Seaglider,-99999,GTSPP,0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,CTD: SBE 41/41CP (Sea-Bird CTD Module for Autonomous Profiling Floats),0,RHINES; PETER B./ERIKSEN; CHARLES,all_variables/all_variables,987.97534,0,1,5,3.5010133,4,0,1,-1.0E10,-127,-127,-9,1000.94763,7,1,47.00696,7,0,1,-127.15578,8,0,1,365.9121,8,0,1,-1.0E10,,,-9\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
        }



        //read outer and inner col with outer constraint
        fullName = dir + "wod_gld_2005.nc";
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast"}), 
            new StringArray(new String[]{"="}), 
            new StringArray(new String[]{"17842328"}));
        results = table.dataToString(5);
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"17842328,86196.91210919619,0.8763757,10.643924,0\n" +
"17842328,86196.91210919619,1.1950568,10.658873,0\n" +
"17842328,86196.91210919619,2.0614686,10.660649,0\n" +
"17842328,86196.91210919619,2.8780832,10.663277,0\n" +
"17842328,86196.91210919619,3.6449013,10.660924,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //outer and inner constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast", "Temperature"}), 
            new StringArray(new String[]{"=", "="}), 
            new StringArray(new String[]{"17842328", "10.660649"}));
        results = table.dataToString();
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"17842328,86196.91210919619,2.0614686,10.660649,0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);



        //*** read all mrb
        fullName = dir + "wod_mrb_2005.nc";
        if (doAll) {
           table.readInvalidCRA(fullName, null, 0,  //standardizeWhat=0
                null, null, null);
            results = table.toString(5);
            expected = 
"{\n" +
"dimensions:\n" +
"\trow = 1184438 ;\n" +
"\tcountry_strlen = 13 ;\n" +
"\tWOD_cruise_identifier_strlen = 8 ;\n" +
"\toriginators_cruise_identifier_strlen = 5 ;\n" +
"\tProject_strlen = 80 ;\n" +
"\tPlatform_strlen = 14 ;\n" +
"\tInstitute_strlen = 62 ;\n" +
"\tWind_Direction_strlen = 25 ;\n" +
"\tdataset_strlen = 11 ;\n" +
"\treal_time_strlen = 14 ;\n" +
"\tdbase_orig_strlen = 24 ;\n" +
"\torigflagset_strlen = 24 ;\n" +
"\tTemperature_Instrument_strlen = 52 ;\n" +
"\tSalinity_Instrument_strlen = 52 ;\n" +
"variables:\n" +
"\tchar country(row, country_strlen) ;\n" +
"\tchar WOD_cruise_identifier(row, WOD_cruise_identifier_strlen) ;\n" +
"\t\tWOD_cruise_identifier:comment = \"two byte country code + WOD cruise number (unique to country code)\" ;\n" +
"\t\tWOD_cruise_identifier:long_name = \"WOD_cruise_identifier\" ;\n" +
"\tchar originators_cruise_identifier(row, originators_cruise_identifier_strlen) ;\n" +
"\tint wod_unique_cast(row) ;\n" +
"\t\twod_unique_cast:cf_role = \"profile_id\" ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:standard_name = \"latitude\" ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:standard_name = \"longitude\" ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:units = \"days since 1770-01-01 00:00:00 UTC\" ;\n" +
"\tint date(row) ;\n" +
"\t\tdate:comment = \"YYYYMMDD\" ;\n" +
"\t\tdate:long_name = \"date\" ;\n" +
"\tfloat GMT_time(row) ;\n" +
"\t\tGMT_time:long_name = \"GMT_time\" ;\n" +
"\t\tGMT_time:units = \"hours\" ;\n" +
"\tint Access_no(row) ;\n" +
"\t\tAccess_no:_FillValue = -99999 ;\n" +
"\t\tAccess_no:comment = \"used to find original data at NODC\" ;\n" +
"\t\tAccess_no:long_name = \"NODC_accession_number\" ;\n" +
"\t\tAccess_no:units_wod = \"NODC_code\" ;\n" +
"\tchar Project(row, Project_strlen) ;\n" +
"\t\tProject:comment = \"name or acronym of project under which data were measured\" ;\n" +
"\t\tProject:long_name = \"Project_name\" ;\n" +
"\tchar Platform(row, Platform_strlen) ;\n" +
"\t\tPlatform:comment = \"name of platform from which measurements were taken\" ;\n" +
"\t\tPlatform:long_name = \"Platform_name\" ;\n" +
"\tchar Institute(row, Institute_strlen) ;\n" +
"\t\tInstitute:comment = \"name of institute which collected data\" ;\n" +
"\t\tInstitute:long_name = \"Responsible_institute\" ;\n" +
"\tint Orig_Stat_Num(row) ;\n" +
"\t\tOrig_Stat_Num:_FillValue = -99999 ;\n" +
"\t\tOrig_Stat_Num:comment = \"number assigned to a given station by data originator\" ;\n" +
"\t\tOrig_Stat_Num:long_name = \"Originators_Station_Number\" ;\n" +
"\tchar Wind_Direction(row, Wind_Direction_strlen) ;\n" +
"\t\tWind_Direction:long_name = \"Wind_Direction\" ;\n" +
"\t\tWind_Direction:units_wod = \"WMO 0877 or NODC 0110\" ;\n" +
"\tfloat Wind_Speed(row) ;\n" +
"\t\tWind_Speed:_FillValue = -1.0E10f ;\n" +
"\t\tWind_Speed:standard_name = \"wind_speed\" ;\n" +
"\t\tWind_Speed:units = \"knots\" ;\n" +
"\tfloat Dry_Bulb_Temp(row) ;\n" +
"\t\tDry_Bulb_Temp:_FillValue = -1.0E10f ;\n" +
"\t\tDry_Bulb_Temp:long_name = \"Dry_Bulb_Air_Temperature\" ;\n" +
"\t\tDry_Bulb_Temp:units = \"degree_C\" ;\n" +
"\tchar dataset(row, dataset_strlen) ;\n" +
"\t\tdataset:long_name = \"WOD_dataset\" ;\n" +
"\tchar real_time(row, real_time_strlen) ;\n" +
"\t\treal_time:comment = \"timeliness and quality status\" ;\n" +
"\t\treal_time:long_name = \"real_time_data\" ;\n" +
"\tchar dbase_orig(row, dbase_orig_strlen) ;\n" +
"\t\tdbase_orig:comment = \"Database from which data were extracted\" ;\n" +
"\t\tdbase_orig:long_name = \"database_origin\" ;\n" +
"\tint WMO_ID(row) ;\n" +
"\t\tWMO_ID:_FillValue = -99999 ;\n" +
"\t\tWMO_ID:long_name = \"WMO_identification_code\" ;\n" +
"\tchar origflagset(row, origflagset_strlen) ;\n" +
"\t\torigflagset:comment = \"set of originators flag codes to use\" ;\n" +
"\tbyte Temperature_WODprofileflag(row) ;\n" +
"\t\tTemperature_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tTemperature_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Temperature_Instrument(row, Temperature_Instrument_strlen) ;\n" +
"\t\tTemperature_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tTemperature_Instrument:long_name = \"Instrument\" ;\n" +
"\tbyte Salinity_WODprofileflag(row) ;\n" +
"\t\tSalinity_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tSalinity_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Salinity_Instrument(row, Salinity_Instrument_strlen) ;\n" +
"\t\tSalinity_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tSalinity_Instrument:long_name = \"Instrument\" ;\n" +
"\tfloat z(row) ;\n" +
"\t\tz:ancillary_variables = \"z_sigfigs z_WODflag z_origflag\" ;\n" +
"\t\tz:long_name = \"depth_below_sea_surface\" ;\n" +
"\t\tz:positive = \"down\" ;\n" +
"\t\tz:standard_name = \"depth\" ;\n" +
"\t\tz:units = \"m\" ;\n" +
"\tbyte z_WODflag(row) ;\n" +
"\t\tz_WODflag:flag_meanings = \"accepted duplicate_or_inversion density_inversion\" ;\n" +
"\t\tz_WODflag:flag_values = 0, 1, 2 ;\n" +
"\t\tz_WODflag:long_name = \"WOD_depth_level_flag\" ;\n" +
"\t\tz_WODflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_origflag(row) ;\n" +
"\t\tz_origflag:_FillValue = -9 ;\n" +
"\t\tz_origflag:comment = \"Originator flags are dependent on origflagset\" ;\n" +
"\t\tz_origflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_sigfigs(row) ;\n" +
"\t\tz_sigfigs:long_name = \"depth significant figures   \" ;\n" +
"\tfloat Temperature(row) ;\n" +
"\t\tTemperature:_FillValue = -1.0E10f ;\n" +
"\t\tTemperature:ancillary_variables = \"Temperature_sigfigs Temperature_WODflag Temperature_WODprofileflag Temperature_origflag\" ;\n" +
"\t\tTemperature:coordinates = \"time lat lon z\" ;\n" +
"\t\tTemperature:grid_mapping = \"crs\" ;\n" +
"\t\tTemperature:long_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:units = \"degree_C\" ;\n" +
"\tbyte Temperature_sigfigs(row) ;\n" +
"\t\tTemperature_sigfigs:long_name = \"sea_water_temperature significant_figures\" ;\n" +
"\tbyte Temperature_WODflag(row) ;\n" +
"\t\tTemperature_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tTemperature_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tTemperature_WODflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tbyte Temperature_origflag(row) ;\n" +
"\t\tTemperature_origflag:_FillValue = -9 ;\n" +
"\t\tTemperature_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tTemperature_origflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tfloat Salinity(row) ;\n" +
"\t\tSalinity:_FillValue = -1.0E10f ;\n" +
"\t\tSalinity:ancillary_variables = \"Salinity_sigfigs Salinity_WODflag Salinity_WODprofileflag Salinity_origflag\" ;\n" +
"\t\tSalinity:coordinates = \"time lat lon z\" ;\n" +
"\t\tSalinity:grid_mapping = \"crs\" ;\n" +
"\t\tSalinity:long_name = \"sea_water_salinity\" ;\n" +
"\t\tSalinity:standard_name = \"sea_water_salinity\" ;\n" +
"\tbyte Salinity_sigfigs(row) ;\n" +
"\t\tSalinity_sigfigs:long_name = \"sea_water_salinity significant_figures\" ;\n" +
"\tbyte Salinity_WODflag(row) ;\n" +
"\t\tSalinity_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tSalinity_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tSalinity_WODflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\tbyte Salinity_origflag(row) ;\n" +
"\t\tSalinity_origflag:_FillValue = -9 ;\n" +
"\t\tSalinity_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tSalinity_origflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"country, WOD_cruise_identifier, originators_cruise_identifier, wod_unique_cast, latitude, longitude, time, date, GMT_time, Access_no, Project, Platform, Institute, Orig_Stat_Num, Wind_Direction, Wind_Speed, Dry_Bulb_Temp, dataset, real_time, dbase_orig, WMO_ID, origflagset, Temperature_WODprofileflag, Temperature_Instrument, Salinity_WODprofileflag, Salinity_Instrument\" ;\n" +
"\t\t:Conventions = \"CF-1.6\" ;\n" +
"\t\t:creator_email = \"OCLhelp@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Ocean Climate Lab/NCEI\" ;\n" +
"\t\t:creator_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:crs_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:crs_grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:crs_inverse_flattening = 298.25723f ;\n" +
"\t\t:crs_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:crs_semi_major_axis = 6378137.0f ;\n" +
"\t\t:date_created = \"2018-03-24\" ;\n" +
"\t\t:date_modified = \"2018-03-24\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 80.5578f ;\n" +
"\t\t:geospatial_lat_min = -18.89f ;\n" +
"\t\t:geospatial_lat_resolution = \"point\" ;\n" +
"\t\t:geospatial_lon_max = -0.02999878f ;\n" +
"\t\t:geospatial_lon_min = 80.48f ;\n" +
"\t\t:geospatial_lon_resolution = \"point\" ;\n" +
"\t\t:geospatial_vertical_max = 4309.0f ;\n" +
"\t\t:geospatial_vertical_min = 1.0f ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"meters\" ;\n" +
"\t\t:grid_mapping_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:grid_mapping_inverse_flattening = 298.25723f ;\n" +
"\t\t:grid_mapping_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:grid_mapping_semi_major_axis = 6378137.0f ;\n" +
"\t\t:id = \"/nodc/data/oc5.clim.0/wod_update_nc/2005/wod_mrb_2005.nc\" ;\n" +
"\t\t:institution = \"National Centers for Environmental Information (NCEI), NOAA\" ;\n" +
"\t\t:naming_authority = \"gov.noaa.nodc\" ;\n" +
"\t\t:project = \"World Ocean Database\" ;\n" +
"\t\t:publisher_email = \"NODC.Services@noaa.gov\" ;\n" +
"\t\t:publisher_name = \"US DOC; NESDIS; NATIONAL CENTERS FOR ENVIRONMENTAL INFORMATION\" ;\n" +
"\t\t:publisher_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:references = \"World Ocean Database 2013. URL:http://data.nodc.noaa.gov/woa/WOD/DOC/wod_intro.pdf\" ;\n" +
"\t\t:source = \"World Ocean Database\" ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v41\" ;\n" +
"\t\t:summary = \"Data for multiple casts from the World Ocean Database\" ;\n" +
"\t\t:time_coverage_end = \"2005-12-31\" ;\n" +
"\t\t:time_coverage_start = \"2005-01-01\" ;\n" +
"\t\t:title = \"World Ocean Database - Multi-cast file\" ;\n" +
"}\n" +
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Orig_Stat_Num,Wind_Direction,Wind_Speed,Dry_Bulb_Temp,dataset,real_time,dbase_orig,WMO_ID,origflagset,Temperature_WODprofileflag,Temperature_Instrument,Salinity_WODprofileflag,Salinity_Instrument,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Salinity_origflag\n" +
"UNITED STATES,US029953,,12631835,80.5578,-68.9076,85832.0,20050101,0.0,63240,ARCTIC/SUBARCTIC OCEAN FLUXES (ASOF),,UNIVERSITY OF DELAWARE;SCHOOL OF MARINE SCIENCE AND POLICY,-99999,,-1.0E10,-1.0E10,moored buoy,,,-99999,,0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",28.294939,0,-9,5,-1.782,4,0,-9,32.662,5,0,-9\n" +
"UNITED STATES,US029953,,12631835,80.5578,-68.9076,85832.0,20050101,0.0,63240,ARCTIC/SUBARCTIC OCEAN FLUXES (ASOF),,UNIVERSITY OF DELAWARE;SCHOOL OF MARINE SCIENCE AND POLICY,-99999,,-1.0E10,-1.0E10,moored buoy,,,-99999,,0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",77.65329,0,-9,5,-1.755,4,0,-9,32.706,5,0,-9\n" +
"UNITED STATES,US029953,,12631835,80.5578,-68.9076,85832.0,20050101,0.0,63240,ARCTIC/SUBARCTIC OCEAN FLUXES (ASOF),,UNIVERSITY OF DELAWARE;SCHOOL OF MARINE SCIENCE AND POLICY,-99999,,-1.0E10,-1.0E10,moored buoy,,,-99999,,0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",126.99971,0,-9,6,-1.235,4,0,-9,33.404,5,0,-9\n" +
"UNITED STATES,US029953,,12631835,80.5578,-68.9076,85832.0,20050101,0.0,63240,ARCTIC/SUBARCTIC OCEAN FLUXES (ASOF),,UNIVERSITY OF DELAWARE;SCHOOL OF MARINE SCIENCE AND POLICY,-99999,,-1.0E10,-1.0E10,moored buoy,,,-99999,,0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",196.10425,0,-9,6,-0.396,3,0,-9,34.347,5,0,-9\n" +
"UNITED STATES,US029953,,12631836,80.5578,-68.9076,85832.01000976562,20050101,0.24023438,63240,ARCTIC/SUBARCTIC OCEAN FLUXES (ASOF),,UNIVERSITY OF DELAWARE;SCHOOL OF MARINE SCIENCE AND POLICY,-99999,,-1.0E10,-1.0E10,moored buoy,,,-99999,,0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",0,\"CTD: SBE 37-IM MicroCAT (Sea-Bird Electronics, Inc.)\",27.602451,0,-9,5,-1.782,4,0,-9,32.66,5,0,-9\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            table.removeRows(0, 1184438 - 5);
            results = table.dataToString();
            expected = 
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Orig_Stat_Num,Wind_Direction,Wind_Speed,Dry_Bulb_Temp,dataset,real_time,dbase_orig,WMO_ID,origflagset,Temperature_WODprofileflag,Temperature_Instrument,Salinity_WODprofileflag,Salinity_Instrument,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Salinity_origflag\n" +
"BRAZIL,BR001182,,10688847,4.09,-37.98,86196.0,20051231,9.96921E36,78936,PIRATA BUOY ARRAY,FIXED PLATFORM,,-99999,85 DEGREES - 94 DEGREES,8.3592005,27.0,moored buoy,,PMEL TAO/PIRATA database,31002,PMEL TAO/PIRATA database,0,,0,,100.0,0,2,3,26.48,5,0,1,-1.0E10,-127,-127,-9\n" +
"BRAZIL,BR001182,,10688847,4.09,-37.98,86196.0,20051231,9.96921E36,78936,PIRATA BUOY ARRAY,FIXED PLATFORM,,-99999,85 DEGREES - 94 DEGREES,8.3592005,27.0,moored buoy,,PMEL TAO/PIRATA database,31002,PMEL TAO/PIRATA database,0,,0,,140.0,0,2,3,15.74,5,0,2,-1.0E10,-127,-127,-9\n" +
"BRAZIL,BR001182,,10688847,4.09,-37.98,86196.0,20051231,9.96921E36,78936,PIRATA BUOY ARRAY,FIXED PLATFORM,,-99999,85 DEGREES - 94 DEGREES,8.3592005,27.0,moored buoy,,PMEL TAO/PIRATA database,31002,PMEL TAO/PIRATA database,0,,0,,180.0,0,2,3,13.85,5,0,1,-1.0E10,-127,-127,-9\n" +
"BRAZIL,BR001182,,10688847,4.09,-37.98,86196.0,20051231,9.96921E36,78936,PIRATA BUOY ARRAY,FIXED PLATFORM,,-99999,85 DEGREES - 94 DEGREES,8.3592005,27.0,moored buoy,,PMEL TAO/PIRATA database,31002,PMEL TAO/PIRATA database,0,,0,,300.0,0,2,3,11.67,5,0,1,-1.0E10,-127,-127,-9\n" +
"BRAZIL,BR001182,,10688847,4.09,-37.98,86196.0,20051231,9.96921E36,78936,PIRATA BUOY ARRAY,FIXED PLATFORM,,-99999,85 DEGREES - 94 DEGREES,8.3592005,27.0,moored buoy,,PMEL TAO/PIRATA database,31002,PMEL TAO/PIRATA database,0,,0,,500.0,0,2,3,8.16,4,0,1,-1.0E10,-127,-127,-9\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
        }


        //read outer and inner col with outer constraint
        fullName = dir + "wod_mrb_2005.nc";
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast"}), 
            new StringArray(new String[]{"="}), 
            new StringArray(new String[]{"10688847"}));
        results = table.dataToString(5);
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"10688847,86196.0,1.0,27.98,0\n" +
"10688847,86196.0,20.0,27.98,0\n" +
"10688847,86196.0,40.0,27.99,0\n" +
"10688847,86196.0,60.0,28.0,0\n" +
"10688847,86196.0,80.0,27.97,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //outer and inner constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast", "Temperature"}), 
            new StringArray(new String[]{"=", "="}), 
            new StringArray(new String[]{"10688847", "27.99"}));
        results = table.dataToString();
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"10688847,86196.0,40.0,27.99,0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);



        //*** read all osd -- THIS FILE FAILS BECAUSE IT HAS DataType=Structure!
        //fullName = dir + "wod_osd_2005.nc";
        //table.readInvalidCRA(fullName, null, null, null, null);
        //results = table.toString(5);
        //expected = "zztop\n";
        //Test.ensureEqual(results, expected, "results=\n" + results);

        //table.removeRows(0, 146042 - 5);
        //results = table.dataToString();
        //expected = "zztop\n";
        //Test.ensureEqual(results, expected, "results=\n" + results);


        //*** read all
        fullName = dir + "wod_pfl_2005.nc";
        if (doAll) {
            table.readInvalidCRA(fullName, null, 0,  //standardizeWhat=0
                null, null, null);
            results = table.toString(5);
            expected = 
"{\n" +
"dimensions:\n" +
"\trow = 4420114 ;\n" +
"\tcountry_strlen = 18 ;\n" +
"\tWOD_cruise_identifier_strlen = 8 ;\n" +
"\toriginators_cruise_identifier_strlen = 8 ;\n" +
"\tProject_strlen = 74 ;\n" +
"\tPlatform_strlen = 15 ;\n" +
"\tInstitute_strlen = 79 ;\n" +
"\tCast_Direction_strlen = 22 ;\n" +
"\tdataset_strlen = 15 ;\n" +
"\tRecorder_strlen = 44 ;\n" +
"\treal_time_strlen = 36 ;\n" +
"\tOcean_Vehicle_strlen = 68 ;\n" +
"\tdbase_orig_strlen = 22 ;\n" +
"\torigflagset_strlen = 21 ;\n" +
"\tTemperature_Instrument_strlen = 40 ;\n" +
"\tSalinity_Instrument_strlen = 40 ;\n" +
"\tSalinity_Method_strlen = 0 ;\n" +
"\tOxygen_Original_units_strlen = 7 ;\n" +
"\tPrimary_Investigator_strlen = 120 ;\n" +
"\tPrimary_Investigator_VAR_strlen = 97 ;\n" +
"variables:\n" +
"\tchar country(row, country_strlen) ;\n" +
"\tchar WOD_cruise_identifier(row, WOD_cruise_identifier_strlen) ;\n" +
"\t\tWOD_cruise_identifier:comment = \"two byte country code + WOD cruise number (unique to country code)\" ;\n" +
"\t\tWOD_cruise_identifier:long_name = \"WOD_cruise_identifier\" ;\n" +
"\tchar originators_cruise_identifier(row, originators_cruise_identifier_strlen) ;\n" +
"\tint wod_unique_cast(row) ;\n" +
"\t\twod_unique_cast:cf_role = \"profile_id\" ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:standard_name = \"latitude\" ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:standard_name = \"longitude\" ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:units = \"days since 1770-01-01 00:00:00 UTC\" ;\n" +
"\tint date(row) ;\n" +
"\t\tdate:comment = \"YYYYMMDD\" ;\n" +
"\t\tdate:long_name = \"date\" ;\n" +
"\tfloat GMT_time(row) ;\n" +
"\t\tGMT_time:long_name = \"GMT_time\" ;\n" +
"\t\tGMT_time:units = \"hours\" ;\n" +
"\tint Access_no(row) ;\n" +
"\t\tAccess_no:_FillValue = -99999 ;\n" +
"\t\tAccess_no:comment = \"used to find original data at NODC\" ;\n" +
"\t\tAccess_no:long_name = \"NODC_accession_number\" ;\n" +
"\t\tAccess_no:units_wod = \"NODC_code\" ;\n" +
"\tchar Project(row, Project_strlen) ;\n" +
"\t\tProject:comment = \"name or acronym of project under which data were measured\" ;\n" +
"\t\tProject:long_name = \"Project_name\" ;\n" +
"\tchar Platform(row, Platform_strlen) ;\n" +
"\t\tPlatform:comment = \"name of platform from which measurements were taken\" ;\n" +
"\t\tPlatform:long_name = \"Platform_name\" ;\n" +
"\tchar Institute(row, Institute_strlen) ;\n" +
"\t\tInstitute:comment = \"name of institute which collected data\" ;\n" +
"\t\tInstitute:long_name = \"Responsible_institute\" ;\n" +
"\tint Orig_Stat_Num(row) ;\n" +
"\t\tOrig_Stat_Num:_FillValue = -99999 ;\n" +
"\t\tOrig_Stat_Num:comment = \"number assigned to a given station by data originator\" ;\n" +
"\t\tOrig_Stat_Num:long_name = \"Originators_Station_Number\" ;\n" +
"\tchar Cast_Direction(row, Cast_Direction_strlen) ;\n" +
"\t\tCast_Direction:long_name = \"Cast_Direction\" ;\n" +
"\tchar dataset(row, dataset_strlen) ;\n" +
"\t\tdataset:long_name = \"WOD_dataset\" ;\n" +
"\tchar Recorder(row, Recorder_strlen) ;\n" +
"\t\tRecorder:comment = \"Device which recorded measurements\" ;\n" +
"\t\tRecorder:long_name = \"Recorder\" ;\n" +
"\t\tRecorder:units_wod = \"WMO code 4770\" ;\n" +
"\tchar real_time(row, real_time_strlen) ;\n" +
"\t\treal_time:comment = \"timeliness and quality status\" ;\n" +
"\t\treal_time:long_name = \"real_time_data\" ;\n" +
"\tchar Ocean_Vehicle(row, Ocean_Vehicle_strlen) ;\n" +
"\t\tOcean_Vehicle:comment = \"Ocean_vehicle\" ;\n" +
"\tchar dbase_orig(row, dbase_orig_strlen) ;\n" +
"\t\tdbase_orig:comment = \"Database from which data were extracted\" ;\n" +
"\t\tdbase_orig:long_name = \"database_origin\" ;\n" +
"\tint WMO_ID(row) ;\n" +
"\t\tWMO_ID:_FillValue = -99999 ;\n" +
"\t\tWMO_ID:long_name = \"WMO_identification_code\" ;\n" +
"\tchar origflagset(row, origflagset_strlen) ;\n" +
"\t\torigflagset:comment = \"set of originators flag codes to use\" ;\n" +
"\tbyte Temperature_WODprofileflag(row) ;\n" +
"\t\tTemperature_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tTemperature_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Temperature_Instrument(row, Temperature_Instrument_strlen) ;\n" +
"\t\tTemperature_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tTemperature_Instrument:long_name = \"Instrument\" ;\n" +
"\tfloat Temperature_Adjustment(row) ;\n" +
"\t\tTemperature_Adjustment:_FillValue = -1.0E10f ;\n" +
"\t\tTemperature_Adjustment:comment = \"Adjustment made to original measurement values and measurement units\" ;\n" +
"\tbyte Salinity_WODprofileflag(row) ;\n" +
"\t\tSalinity_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tSalinity_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Salinity_Instrument(row, Salinity_Instrument_strlen) ;\n" +
"\t\tSalinity_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tSalinity_Instrument:long_name = \"Instrument\" ;\n" +
"\tchar Salinity_Method(row, Salinity_Method_strlen) ;\n" +
"\t\tSalinity_Method:comment = \"Method\" ;\n" +
"\tfloat Salinity_Adjustment(row) ;\n" +
"\t\tSalinity_Adjustment:_FillValue = -1.0E10f ;\n" +
"\t\tSalinity_Adjustment:comment = \"Adjustment made to original measurement values and measurement units\" ;\n" +
"\tint Salinity_(row) ;\n" +
"\t\tSalinity_:_FillValue = -99999 ;\n" +
"\tfloat Pressure_Adjustment(row) ;\n" +
"\t\tPressure_Adjustment:_FillValue = -1.0E10f ;\n" +
"\t\tPressure_Adjustment:comment = \"Adjustment made to original measurement values and measurement units\" ;\n" +
"\tbyte Oxygen_WODprofileflag(row) ;\n" +
"\t\tOxygen_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tOxygen_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tOxygen_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Oxygen_Original_units(row, Oxygen_Original_units_strlen) ;\n" +
"\t\tOxygen_Original_units:comment = \"Units originally used: coverted to standard units\" ;\n" +
"\tfloat Oxygen_Adjustment(row) ;\n" +
"\t\tOxygen_Adjustment:_FillValue = -1.0E10f ;\n" +
"\t\tOxygen_Adjustment:comment = \"Adjustment made to original measurement values and measurement units\" ;\n" +
"\tchar Primary_Investigator(row, Primary_Investigator_strlen) ;\n" +
"\tchar Primary_Investigator_VAR(row, Primary_Investigator_VAR_strlen) ;\n" +
"\tfloat z(row) ;\n" +
"\t\tz:ancillary_variables = \"z_sigfigs z_WODflag z_origflag\" ;\n" +
"\t\tz:long_name = \"depth_below_sea_surface\" ;\n" +
"\t\tz:positive = \"down\" ;\n" +
"\t\tz:standard_name = \"depth\" ;\n" +
"\t\tz:units = \"m\" ;\n" +
"\tbyte z_WODflag(row) ;\n" +
"\t\tz_WODflag:flag_meanings = \"accepted duplicate_or_inversion density_inversion\" ;\n" +
"\t\tz_WODflag:flag_values = 0, 1, 2 ;\n" +
"\t\tz_WODflag:long_name = \"WOD_depth_level_flag\" ;\n" +
"\t\tz_WODflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_origflag(row) ;\n" +
"\t\tz_origflag:_FillValue = -9 ;\n" +
"\t\tz_origflag:comment = \"Originator flags are dependent on origflagset\" ;\n" +
"\t\tz_origflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_sigfigs(row) ;\n" +
"\t\tz_sigfigs:long_name = \"depth significant figures   \" ;\n" +
"\tfloat Temperature(row) ;\n" +
"\t\tTemperature:_FillValue = -1.0E10f ;\n" +
"\t\tTemperature:ancillary_variables = \"Temperature_sigfigs Temperature_WODflag Temperature_WODprofileflag Temperature_origflag\" ;\n" +
"\t\tTemperature:coordinates = \"time lat lon z\" ;\n" +
"\t\tTemperature:grid_mapping = \"crs\" ;\n" +
"\t\tTemperature:long_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:units = \"degree_C\" ;\n" +
"\tbyte Temperature_sigfigs(row) ;\n" +
"\t\tTemperature_sigfigs:long_name = \"sea_water_temperature significant_figures\" ;\n" +
"\tbyte Temperature_WODflag(row) ;\n" +
"\t\tTemperature_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tTemperature_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tTemperature_WODflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tbyte Temperature_origflag(row) ;\n" +
"\t\tTemperature_origflag:_FillValue = -9 ;\n" +
"\t\tTemperature_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tTemperature_origflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tfloat Salinity(row) ;\n" +
"\t\tSalinity:_FillValue = -1.0E10f ;\n" +
"\t\tSalinity:ancillary_variables = \"Salinity_sigfigs Salinity_WODflag Salinity_WODprofileflag Salinity_origflag\" ;\n" +
"\t\tSalinity:coordinates = \"time lat lon z\" ;\n" +
"\t\tSalinity:grid_mapping = \"crs\" ;\n" +
"\t\tSalinity:long_name = \"sea_water_salinity\" ;\n" +
"\t\tSalinity:standard_name = \"sea_water_salinity\" ;\n" +
"\tbyte Salinity_sigfigs(row) ;\n" +
"\t\tSalinity_sigfigs:long_name = \"sea_water_salinity significant_figures\" ;\n" +
"\tbyte Salinity_WODflag(row) ;\n" +
"\t\tSalinity_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tSalinity_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tSalinity_WODflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\tbyte Salinity_origflag(row) ;\n" +
"\t\tSalinity_origflag:_FillValue = -9 ;\n" +
"\t\tSalinity_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tSalinity_origflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\tfloat Pressure(row) ;\n" +
"\t\tPressure:_FillValue = -1.0E10f ;\n" +
"\t\tPressure:ancillary_variables = \"Pressure_sigfigs Pressure_WODflag Pressure_WODprofileflag Pressure_origflag\" ;\n" +
"\t\tPressure:coordinates = \"time lat lon z\" ;\n" +
"\t\tPressure:grid_mapping = \"crs\" ;\n" +
"\t\tPressure:long_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:standard_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:units = \"dbar\" ;\n" +
"\tbyte Pressure_sigfigs(row) ;\n" +
"\t\tPressure_sigfigs:long_name = \"sea_water_pressure significant_figures\" ;\n" +
"\tbyte Pressure_origflag(row) ;\n" +
"\t\tPressure_origflag:_FillValue = -9 ;\n" +
"\t\tPressure_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tPressure_origflag:standard_name = \"sea_water_pressure status_flag\" ;\n" +
"\tfloat Oxygen(row) ;\n" +
"\t\tOxygen:_FillValue = -1.0E10f ;\n" +
"\t\tOxygen:ancillary_variables = \"Oxygen_sigfigs Oxygen_WODflag Oxygen_WODprofileflag Oxygen_origflag\" ;\n" +
"\t\tOxygen:coordinates = \"time lat lon z\" ;\n" +
"\t\tOxygen:grid_mapping = \"crs\" ;\n" +
"\t\tOxygen:long_name = \"volume_fraction_of_oxygen_in_sea_water\" ;\n" +
"\t\tOxygen:standard_name = \"volume_fraction_of_oxygen_in_sea_water\" ;\n" +
"\t\tOxygen:units = \"ml/l\" ;\n" +
"\tbyte Oxygen_sigfigs(row) ;\n" +
"\t\tOxygen_sigfigs:long_name = \"volume_fraction_of_oxygen_in_sea_water significant_figures\" ;\n" +
"\tbyte Oxygen_WODflag(row) ;\n" +
"\t\tOxygen_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tOxygen_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tOxygen_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tOxygen_WODflag:standard_name = \"volume_fraction_of_oxygen_in_sea_water status_flag\" ;\n" +
"\tbyte Oxygen_origflag(row) ;\n" +
"\t\tOxygen_origflag:_FillValue = -9 ;\n" +
"\t\tOxygen_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tOxygen_origflag:standard_name = \"volume_fraction_of_oxygen_in_sea_water status_flag\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"country, WOD_cruise_identifier, originators_cruise_identifier, wod_unique_cast, latitude, longitude, time, date, GMT_time, Access_no, Project, Platform, Institute, Orig_Stat_Num, Cast_Direction, dataset, Recorder, real_time, Ocean_Vehicle, dbase_orig, WMO_ID, origflagset, Temperature_WODprofileflag, Temperature_Instrument, Temperature_Adjustment, Salinity_WODprofileflag, Salinity_Instrument, Salinity_Method, Salinity_Adjustment, Salinity_, Pressure_Adjustment, Oxygen_WODprofileflag, Oxygen_Original_units, Oxygen_Adjustment, Primary_Investigator, Primary_Investigator_VAR\" ;\n" +
"\t\t:Conventions = \"CF-1.6\" ;\n" +
"\t\t:creator_email = \"OCLhelp@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Ocean Climate Lab/NCEI\" ;\n" +
"\t\t:creator_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:crs_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:crs_grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:crs_inverse_flattening = 298.25723f ;\n" +
"\t\t:crs_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:crs_semi_major_axis = 6378137.0f ;\n" +
"\t\t:date_created = \"2018-03-24\" ;\n" +
"\t\t:date_modified = \"2018-03-24\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 77.427f ;\n" +
"\t\t:geospatial_lat_min = -72.811f ;\n" +
"\t\t:geospatial_lat_resolution = \"point\" ;\n" +
"\t\t:geospatial_lon_max = 180.0f ;\n" +
"\t\t:geospatial_lon_min = -180.0f ;\n" +
"\t\t:geospatial_lon_resolution = \"point\" ;\n" +
"\t\t:geospatial_vertical_max = 6420.1216f ;\n" +
"\t\t:geospatial_vertical_min = -1.0f ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"meters\" ;\n" +
"\t\t:grid_mapping_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:grid_mapping_inverse_flattening = 298.25723f ;\n" +
"\t\t:grid_mapping_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:grid_mapping_semi_major_axis = 6378137.0f ;\n" +
"\t\t:id = \"/nodc/data/oc5.clim.0/wod_update_nc/2005/wod_pfl_2005.nc\" ;\n" +
"\t\t:institution = \"National Centers for Environmental Information (NCEI), NOAA\" ;\n" +
"\t\t:naming_authority = \"gov.noaa.nodc\" ;\n" +
"\t\t:project = \"World Ocean Database\" ;\n" +
"\t\t:publisher_email = \"NODC.Services@noaa.gov\" ;\n" +
"\t\t:publisher_name = \"US DOC; NESDIS; NATIONAL CENTERS FOR ENVIRONMENTAL INFORMATION\" ;\n" +
"\t\t:publisher_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:references = \"World Ocean Database 2013. URL:http://data.nodc.noaa.gov/woa/WOD/DOC/wod_intro.pdf\" ;\n" +
"\t\t:source = \"World Ocean Database\" ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v41\" ;\n" +
"\t\t:summary = \"Data for multiple casts from the World Ocean Database\" ;\n" +
"\t\t:time_coverage_end = \"2005-12-31\" ;\n" +
"\t\t:time_coverage_start = \"2005-01-01\" ;\n" +
"\t\t:title = \"World Ocean Database - Multi-cast file\" ;\n" +
"}\n" +
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Orig_Stat_Num,Cast_Direction,dataset,Recorder,real_time,Ocean_Vehicle,dbase_orig,WMO_ID,origflagset,Temperature_WODprofileflag,Temperature_Instrument,Temperature_Adjustment,Salinity_WODprofileflag,Salinity_Instrument,Salinity_Method,Salinity_Adjustment,Salinity_,Pressure_Adjustment,Oxygen_WODprofileflag,Oxygen_Original_units,Oxygen_Adjustment,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Salinity_origflag,Pressure,Pressure_sigfigs,Pressure_origflag,Oxygen,Oxygen_sigfigs,Oxygen_WODflag,Oxygen_origflag\n" +
"JAPAN,JP031068,Q1900475,10405561,-13.641,69.829,85832.02929583378,20050101,0.7031,2352,J-ARGO (JAPAN ARGO),,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),2,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),1900475,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,CTD: TYPE UNKNOWN,,0.0,-99999,0.0,0,,-1.0E10,TAKEUCHI; KENSUKE,all_variables,4.4739165,0,1,3,27.817,5,0,1,34.939,5,0,1,4.5,2,1,-1.0E10,,,-9\n" +
"JAPAN,JP031068,Q1900475,10405561,-13.641,69.829,85832.02929583378,20050101,0.7031,2352,J-ARGO (JAPAN ARGO),,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),2,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),1900475,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,CTD: TYPE UNKNOWN,,0.0,-99999,0.0,0,,-1.0E10,TAKEUCHI; KENSUKE,all_variables,9.44482,0,1,3,27.745,5,0,1,34.942,5,0,1,9.5,2,1,-1.0E10,,,-9\n" +
"JAPAN,JP031068,Q1900475,10405561,-13.641,69.829,85832.02929583378,20050101,0.7031,2352,J-ARGO (JAPAN ARGO),,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),2,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),1900475,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,CTD: TYPE UNKNOWN,,0.0,-99999,0.0,0,,-1.0E10,TAKEUCHI; KENSUKE,all_variables,13.91853,0,1,4,27.408,5,0,1,34.98,5,0,1,14.0,3,1,-1.0E10,,,-9\n" +
"JAPAN,JP031068,Q1900475,10405561,-13.641,69.829,85832.02929583378,20050101,0.7031,2352,J-ARGO (JAPAN ARGO),,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),2,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),1900475,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,CTD: TYPE UNKNOWN,,0.0,-99999,0.0,0,,-1.0E10,TAKEUCHI; KENSUKE,all_variables,18.889206,0,1,4,27.286,5,0,1,34.997,5,0,1,19.0,3,1,-1.0E10,,,-9\n" +
"JAPAN,JP031068,Q1900475,10405561,-13.641,69.829,85832.02929583378,20050101,0.7031,2352,J-ARGO (JAPAN ARGO),,JAPAN AGENCY FOR MARINE-EARTH SCIENCE AND TECHNOLOGY (JAMSTEC),2,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),1900475,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,CTD: TYPE UNKNOWN,,0.0,-99999,0.0,0,,-1.0E10,TAKEUCHI; KENSUKE,all_variables,24.257399,0,1,4,27.233,5,0,1,35.001,5,0,1,24.4,3,1,-1.0E10,,,-9\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            table.removeRows(0, 4420114 - 5);
            results = table.dataToString();
            expected = 
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Orig_Stat_Num,Cast_Direction,dataset,Recorder,real_time,Ocean_Vehicle,dbase_orig,WMO_ID,origflagset,Temperature_WODprofileflag,Temperature_Instrument,Temperature_Adjustment,Salinity_WODprofileflag,Salinity_Instrument,Salinity_Method,Salinity_Adjustment,Salinity_,Pressure_Adjustment,Oxygen_WODprofileflag,Oxygen_Original_units,Oxygen_Adjustment,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Salinity_origflag,Pressure,Pressure_sigfigs,Pressure_origflag,Oxygen,Oxygen_sigfigs,Oxygen_WODflag,Oxygen_origflag\n" +
"UNKNOWN,99005892,2900451,11898775,39.42,132.58,86196.9589958787,20051231,23.015902,42682,,,,45,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),2900451,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,\"CTD: Sea-Bird Electronics, MODEL UNKNOWN\",,0.0,-99999,0.0,0,,-1.0E10,SUK; MOON-SIK,all_variables,613.0759,0,1,5,0.474,3,0,1,34.071,5,0,2,618.7,6,1,-1.0E10,,,-9\n" +
"UNKNOWN,99005892,2900451,11898775,39.42,132.58,86196.9589958787,20051231,23.015902,42682,,,,45,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),2900451,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,\"CTD: Sea-Bird Electronics, MODEL UNKNOWN\",,0.0,-99999,0.0,0,,-1.0E10,SUK; MOON-SIK,all_variables,632.8637,0,1,5,0.463,3,0,1,34.071,5,0,2,638.7,6,1,-1.0E10,,,-9\n" +
"UNKNOWN,99005892,2900451,11898775,39.42,132.58,86196.9589958787,20051231,23.015902,42682,,,,45,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),2900451,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,\"CTD: Sea-Bird Electronics, MODEL UNKNOWN\",,0.0,-99999,0.0,0,,-1.0E10,SUK; MOON-SIK,all_variables,652.84753,0,1,5,0.448,3,0,1,34.07,5,0,2,658.9,6,1,-1.0E10,,,-9\n" +
"UNKNOWN,99005892,2900451,11898775,39.42,132.58,86196.9589958787,20051231,23.015902,42682,,,,45,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),2900451,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,\"CTD: Sea-Bird Electronics, MODEL UNKNOWN\",,0.0,-99999,0.0,0,,-1.0E10,SUK; MOON-SIK,all_variables,672.5326,0,1,5,0.438,3,0,1,34.07,5,0,2,678.8,6,1,-1.0E10,,,-9\n" +
"UNKNOWN,99005892,2900451,11898775,39.42,132.58,86196.9589958787,20051231,23.015902,42682,,,,45,UP,profiling float,,delayed_mode quality controlled data,\"APEX (Autonomous Profiling Explorer, Webb Research Corporation)\",US GODAE server (Argo),2900451,ARGO profiling floats,0,CTD: TYPE UNKNOWN,0.0,0,\"CTD: Sea-Bird Electronics, MODEL UNKNOWN\",,0.0,-99999,0.0,0,,-1.0E10,SUK; MOON-SIK,all_variables,693.007,0,1,5,0.428,3,0,1,34.07,5,0,2,699.5,6,1,-1.0E10,,,-9\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
        }

        //read outer and inner col with outer constraint
        fullName = dir + "wod_pfl_2005.nc";
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast"}), 
            new StringArray(new String[]{"="}), 
            new StringArray(new String[]{"11898775"}));
        results = table.dataToString(5);
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"11898775,86196.9589958787,4.5649443,7.71,0\n" +
"11898775,86196.9589958787,13.892994,7.696,0\n" +
"11898775,86196.9589958787,24.014437,7.491,0\n" +
"11898775,86196.9589958787,33.83771,7.302,0\n" +
"11898775,86196.9589958787,43.958168,7.241,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //outer and inner constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast", "Temperature"}), 
            new StringArray(new String[]{"=", "="}), 
            new StringArray(new String[]{"11898775", "7.491"}));
        results = table.dataToString();
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"11898775,86196.9589958787,24.014437,7.491,0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);



        //*** read all uor
        fullName = dir + "wod_uor_2005.nc";
        if (doAll) {
            table.readInvalidCRA(fullName, null, 0,  //standardizeWhat=0
                null, null, null);
            results = table.toString(5);
            expected = 
"{\n" +
"dimensions:\n" +
"\trow = 1169159 ;\n" +
"\tcountry_strlen = 6 ;\n" +
"\tWOD_cruise_identifier_strlen = 8 ;\n" +
"\toriginators_cruise_identifier_strlen = 9 ;\n" +
"\tPlatform_strlen = 73 ;\n" +
"\tWave_Height_strlen = 10 ;\n" +
"\tWave_Period_strlen = 17 ;\n" +
"\tWind_Direction_strlen = 25 ;\n" +
"\tWeather_Condition_strlen = 169 ;\n" +
"\tCloud_Cover_strlen = 65 ;\n" +
"\tdataset_strlen = 9 ;\n" +
"variables:\n" +
"\tchar country(row, country_strlen) ;\n" +
"\tchar WOD_cruise_identifier(row, WOD_cruise_identifier_strlen) ;\n" +
"\t\tWOD_cruise_identifier:comment = \"two byte country code + WOD cruise number (unique to country code)\" ;\n" +
"\t\tWOD_cruise_identifier:long_name = \"WOD_cruise_identifier\" ;\n" +
"\tchar originators_cruise_identifier(row, originators_cruise_identifier_strlen) ;\n" +
"\tint wod_unique_cast(row) ;\n" +
"\t\twod_unique_cast:cf_role = \"profile_id\" ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:standard_name = \"latitude\" ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:standard_name = \"longitude\" ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:units = \"days since 1770-01-01 00:00:00 UTC\" ;\n" +
"\tint date(row) ;\n" +
"\t\tdate:comment = \"YYYYMMDD\" ;\n" +
"\t\tdate:long_name = \"date\" ;\n" +
"\tfloat GMT_time(row) ;\n" +
"\t\tGMT_time:long_name = \"GMT_time\" ;\n" +
"\t\tGMT_time:units = \"hours\" ;\n" +
"\tint Access_no(row) ;\n" +
"\t\tAccess_no:_FillValue = -99999 ;\n" +
"\t\tAccess_no:comment = \"used to find original data at NODC\" ;\n" +
"\t\tAccess_no:long_name = \"NODC_accession_number\" ;\n" +
"\t\tAccess_no:units_wod = \"NODC_code\" ;\n" +
"\tchar Platform(row, Platform_strlen) ;\n" +
"\t\tPlatform:comment = \"name of platform from which measurements were taken\" ;\n" +
"\t\tPlatform:long_name = \"Platform_name\" ;\n" +
"\tfloat Bottom_Depth(row) ;\n" +
"\t\tBottom_Depth:_FillValue = -1.0E10f ;\n" +
"\t\tBottom_Depth:standard_name = \"sea_floor_depth_below_sea_surface\" ;\n" +
"\t\tBottom_Depth:units = \"meters\" ;\n" +
"\tchar Wave_Height(row, Wave_Height_strlen) ;\n" +
"\t\tWave_Height:long_name = \"Wave_Height\" ;\n" +
"\t\tWave_Height:units_wod = \"WMO 1555 or NODC 0104\" ;\n" +
"\tchar Wave_Period(row, Wave_Period_strlen) ;\n" +
"\t\tWave_Period:long_name = \"Wave_Period\" ;\n" +
"\t\tWave_Period:units_wod = \"WMO 3155 or NODC 0378\" ;\n" +
"\tchar Wind_Direction(row, Wind_Direction_strlen) ;\n" +
"\t\tWind_Direction:long_name = \"Wind_Direction\" ;\n" +
"\t\tWind_Direction:units_wod = \"WMO 0877 or NODC 0110\" ;\n" +
"\tfloat Wind_Speed(row) ;\n" +
"\t\tWind_Speed:_FillValue = -1.0E10f ;\n" +
"\t\tWind_Speed:standard_name = \"wind_speed\" ;\n" +
"\t\tWind_Speed:units = \"knots\" ;\n" +
"\tfloat Barometric_Pres(row) ;\n" +
"\t\tBarometric_Pres:_FillValue = -1.0E10f ;\n" +
"\t\tBarometric_Pres:long_name = \"Barometric_Pressure\" ;\n" +
"\t\tBarometric_Pres:units = \"millibars\" ;\n" +
"\tfloat Dry_Bulb_Temp(row) ;\n" +
"\t\tDry_Bulb_Temp:_FillValue = -1.0E10f ;\n" +
"\t\tDry_Bulb_Temp:long_name = \"Dry_Bulb_Air_Temperature\" ;\n" +
"\t\tDry_Bulb_Temp:units = \"degree_C\" ;\n" +
"\tfloat Wet_Bulb_Temp(row) ;\n" +
"\t\tWet_Bulb_Temp:_FillValue = -1.0E10f ;\n" +
"\t\tWet_Bulb_Temp:long_name = \"Wet_Bulb_Air_Temperature\" ;\n" +
"\t\tWet_Bulb_Temp:units = \"degree_C\" ;\n" +
"\tchar Weather_Condition(row, Weather_Condition_strlen) ;\n" +
"\t\tWeather_Condition:comment = \"Weather conditions at time of measurements\" ;\n" +
"\t\tWeather_Condition:long_name = \"Weather_Condition\" ;\n" +
"\tchar Cloud_Cover(row, Cloud_Cover_strlen) ;\n" +
"\t\tCloud_Cover:long_name = \"Cloud_Cover\" ;\n" +
"\t\tCloud_Cover:units_wod = \"WMO 2700 or NODC 0105\" ;\n" +
"\tchar dataset(row, dataset_strlen) ;\n" +
"\t\tdataset:long_name = \"WOD_dataset\" ;\n" +
"\tbyte Temperature_WODprofileflag(row) ;\n" +
"\t\tTemperature_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tTemperature_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tbyte Salinity_WODprofileflag(row) ;\n" +
"\t\tSalinity_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tSalinity_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tfloat z(row) ;\n" +
"\t\tz:ancillary_variables = \"z_sigfigs z_WODflag\" ;\n" +
"\t\tz:long_name = \"depth_below_sea_surface\" ;\n" +
"\t\tz:positive = \"down\" ;\n" +
"\t\tz:standard_name = \"depth\" ;\n" +
"\t\tz:units = \"m\" ;\n" +
"\tbyte z_WODflag(row) ;\n" +
"\t\tz_WODflag:flag_meanings = \"accepted duplicate_or_inversion density_inversion\" ;\n" +
"\t\tz_WODflag:flag_values = 0, 1, 2 ;\n" +
"\t\tz_WODflag:long_name = \"WOD_depth_level_flag\" ;\n" +
"\t\tz_WODflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_sigfigs(row) ;\n" +
"\t\tz_sigfigs:long_name = \"depth significant figures   \" ;\n" +
"\tfloat Temperature(row) ;\n" +
"\t\tTemperature:_FillValue = -1.0E10f ;\n" +
"\t\tTemperature:ancillary_variables = \"Temperature_sigfigs Temperature_WODflag Temperature_WODprofileflag\" ;\n" +
"\t\tTemperature:coordinates = \"time lat lon z\" ;\n" +
"\t\tTemperature:grid_mapping = \"crs\" ;\n" +
"\t\tTemperature:long_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:units = \"degree_C\" ;\n" +
"\tbyte Temperature_sigfigs(row) ;\n" +
"\t\tTemperature_sigfigs:long_name = \"sea_water_temperature significant_figures\" ;\n" +
"\tbyte Temperature_WODflag(row) ;\n" +
"\t\tTemperature_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tTemperature_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tTemperature_WODflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tfloat Salinity(row) ;\n" +
"\t\tSalinity:_FillValue = -1.0E10f ;\n" +
"\t\tSalinity:ancillary_variables = \"Salinity_sigfigs Salinity_WODflag Salinity_WODprofileflag\" ;\n" +
"\t\tSalinity:coordinates = \"time lat lon z\" ;\n" +
"\t\tSalinity:grid_mapping = \"crs\" ;\n" +
"\t\tSalinity:long_name = \"sea_water_salinity\" ;\n" +
"\t\tSalinity:standard_name = \"sea_water_salinity\" ;\n" +
"\tbyte Salinity_sigfigs(row) ;\n" +
"\t\tSalinity_sigfigs:long_name = \"sea_water_salinity significant_figures\" ;\n" +
"\tbyte Salinity_WODflag(row) ;\n" +
"\t\tSalinity_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tSalinity_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tSalinity_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tSalinity_WODflag:standard_name = \"sea_water_salinity status_flag\" ;\n" +
"\tfloat Pressure(row) ;\n" +
"\t\tPressure:_FillValue = -1.0E10f ;\n" +
"\t\tPressure:ancillary_variables = \"Pressure_sigfigs Pressure_WODflag Pressure_WODprofileflag\" ;\n" +
"\t\tPressure:coordinates = \"time lat lon z\" ;\n" +
"\t\tPressure:grid_mapping = \"crs\" ;\n" +
"\t\tPressure:long_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:standard_name = \"sea_water_pressure\" ;\n" +
"\t\tPressure:units = \"dbar\" ;\n" +
"\tbyte Pressure_sigfigs(row) ;\n" +
"\t\tPressure_sigfigs:long_name = \"sea_water_pressure significant_figures\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"country, WOD_cruise_identifier, originators_cruise_identifier, wod_unique_cast, latitude, longitude, time, date, GMT_time, Access_no, Platform, Bottom_Depth, Wave_Height, Wave_Period, Wind_Direction, Wind_Speed, Barometric_Pres, Dry_Bulb_Temp, Wet_Bulb_Temp, Weather_Condition, Cloud_Cover, dataset, Temperature_WODprofileflag, Salinity_WODprofileflag\" ;\n" +
"\t\t:Conventions = \"CF-1.6\" ;\n" +
"\t\t:creator_email = \"OCLhelp@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Ocean Climate Lab/NCEI\" ;\n" +
"\t\t:creator_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:crs_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:crs_grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:crs_inverse_flattening = 298.25723f ;\n" +
"\t\t:crs_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:crs_semi_major_axis = 6378137.0f ;\n" +
"\t\t:date_created = \"2018-03-25\" ;\n" +
"\t\t:date_modified = \"2018-03-25\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 62.485f ;\n" +
"\t\t:geospatial_lat_min = 42.67f ;\n" +
"\t\t:geospatial_lat_resolution = \"point\" ;\n" +
"\t\t:geospatial_lon_max = -46.9317f ;\n" +
"\t\t:geospatial_lon_min = -65.84f ;\n" +
"\t\t:geospatial_lon_resolution = \"point\" ;\n" +
"\t\t:geospatial_vertical_max = 1443.402f ;\n" +
"\t\t:geospatial_vertical_min = 0.0f ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"meters\" ;\n" +
"\t\t:grid_mapping_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:grid_mapping_inverse_flattening = 298.25723f ;\n" +
"\t\t:grid_mapping_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:grid_mapping_semi_major_axis = 6378137.0f ;\n" +
"\t\t:id = \"/nodc/data/oc5.clim.0/wod_update_nc/2005/wod_uor_2005.nc\" ;\n" +
"\t\t:institution = \"National Centers for Environmental Information (NCEI), NOAA\" ;\n" +
"\t\t:naming_authority = \"gov.noaa.nodc\" ;\n" +
"\t\t:project = \"World Ocean Database\" ;\n" +
"\t\t:publisher_email = \"NODC.Services@noaa.gov\" ;\n" +
"\t\t:publisher_name = \"US DOC; NESDIS; NATIONAL CENTERS FOR ENVIRONMENTAL INFORMATION\" ;\n" +
"\t\t:publisher_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:references = \"World Ocean Database 2013. URL:http://data.nodc.noaa.gov/woa/WOD/DOC/wod_intro.pdf\" ;\n" +
"\t\t:source = \"World Ocean Database\" ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v41\" ;\n" +
"\t\t:summary = \"Data for multiple casts from the World Ocean Database\" ;\n" +
"\t\t:time_coverage_end = \"2005-12-17\" ;\n" +
"\t\t:time_coverage_start = \"2005-01-08\" ;\n" +
"\t\t:title = \"World Ocean Database - Multi-cast file\" ;\n" +
"}\n" +
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Platform,Bottom_Depth,Wave_Height,Wave_Period,Wind_Direction,Wind_Speed,Barometric_Pres,Dry_Bulb_Temp,Wet_Bulb_Temp,Weather_Condition,Cloud_Cover,dataset,Temperature_WODprofileflag,Salinity_WODprofileflag,z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Pressure,Pressure_sigfigs\n" +
"CANADA,CA155645,18TL05542,10742153,49.435,-50.725,85839.57291668653,20050108,13.75,98794,TELEOST (CGGS;R/V;c.s.CGCB;b.1988;ex.Atlantic Champion 1995;IMO8714346),326.0,2.5 METER,6 OR 7 SECONDS,285 DEGREES - 294 DEGREES,24.8832,1023.0,0.0,-0.1,CLOUDS GENERALLY DISSOLVING OF BECOMING LESS DEVELOPED-CHAR.  CHANGE OF STATE OF SKY DURING PAST HR.,6 OKTAS     7/10-8/10,towed CTD,0,0,0.0,0,1,1.321,4,0,33.597,5,0,0.0,1\n" +
"CANADA,CA155645,18TL05542,10742153,49.435,-50.725,85839.57291668653,20050108,13.75,98794,TELEOST (CGGS;R/V;c.s.CGCB;b.1988;ex.Atlantic Champion 1995;IMO8714346),326.0,2.5 METER,6 OR 7 SECONDS,285 DEGREES - 294 DEGREES,24.8832,1023.0,0.0,-0.1,CLOUDS GENERALLY DISSOLVING OF BECOMING LESS DEVELOPED-CHAR.  CHANGE OF STATE OF SKY DURING PAST HR.,6 OKTAS     7/10-8/10,towed CTD,0,0,0.099147804,0,1,1.321,4,0,33.598,5,0,0.1,1\n" +
"CANADA,CA155645,18TL05542,10742153,49.435,-50.725,85839.57291668653,20050108,13.75,98794,TELEOST (CGGS;R/V;c.s.CGCB;b.1988;ex.Atlantic Champion 1995;IMO8714346),326.0,2.5 METER,6 OR 7 SECONDS,285 DEGREES - 294 DEGREES,24.8832,1023.0,0.0,-0.1,CLOUDS GENERALLY DISSOLVING OF BECOMING LESS DEVELOPED-CHAR.  CHANGE OF STATE OF SKY DURING PAST HR.,6 OKTAS     7/10-8/10,towed CTD,0,0,0.19829556,0,1,1.321,4,0,33.601,5,0,0.2,1\n" +
"CANADA,CA155645,18TL05542,10742153,49.435,-50.725,85839.57291668653,20050108,13.75,98794,TELEOST (CGGS;R/V;c.s.CGCB;b.1988;ex.Atlantic Champion 1995;IMO8714346),326.0,2.5 METER,6 OR 7 SECONDS,285 DEGREES - 294 DEGREES,24.8832,1023.0,0.0,-0.1,CLOUDS GENERALLY DISSOLVING OF BECOMING LESS DEVELOPED-CHAR.  CHANGE OF STATE OF SKY DURING PAST HR.,6 OKTAS     7/10-8/10,towed CTD,0,0,0.79318106,0,1,1.321,4,0,33.603,5,0,0.8,1\n" +
"CANADA,CA155645,18TL05542,10742153,49.435,-50.725,85839.57291668653,20050108,13.75,98794,TELEOST (CGGS;R/V;c.s.CGCB;b.1988;ex.Atlantic Champion 1995;IMO8714346),326.0,2.5 METER,6 OR 7 SECONDS,285 DEGREES - 294 DEGREES,24.8832,1023.0,0.0,-0.1,CLOUDS GENERALLY DISSOLVING OF BECOMING LESS DEVELOPED-CHAR.  CHANGE OF STATE OF SKY DURING PAST HR.,6 OKTAS     7/10-8/10,towed CTD,0,0,1.487212,0,2,1.321,4,0,33.604,5,0,1.5,2\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            table.removeRows(0, 1169159 - 5);
            results = table.dataToString();
            expected = 
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,lat,lon,time,date,GMT_time,Access_no,Platform,Bottom_Depth,Wave_Height,Wave_Period,Wind_Direction,Wind_Speed,Barometric_Pres,Dry_Bulb_Temp,Wet_Bulb_Temp,Weather_Condition,Cloud_Cover,dataset,Temperature_WODprofileflag,Salinity_WODprofileflag,z,z_WODflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Salinity,Salinity_sigfigs,Salinity_WODflag,Pressure,Pressure_sigfigs\n" +
"CANADA,CA019465,181C05632,10749307,51.2133,-53.85,86182.78125,20051217,18.75,2026318698,WILFRED TEMPLEMAN (CCGS;F/R/V;call sign CGDV; built 1981;IMO7907099),206.0,1.5 METER,5 SECONDS OR LESS,95 DEGREES - 104 DEGREES,19.8288,1032.0,-1.0E10,-1.0E10,CONTINUOUS FALL OF SNOW FLAKES-MODERATE AT TIME OF OBSERVATION,6 OKTAS     7/10-8/10,towed CTD,0,0,197.47443,0,4,2.176,4,0,34.101,5,0,199.3,4\n" +
"CANADA,CA019465,181C05632,10749307,51.2133,-53.85,86182.78125,20051217,18.75,2026318698,WILFRED TEMPLEMAN (CCGS;F/R/V;call sign CGDV; built 1981;IMO7907099),206.0,1.5 METER,5 SECONDS OR LESS,95 DEGREES - 104 DEGREES,19.8288,1032.0,-1.0E10,-1.0E10,CONTINUOUS FALL OF SNOW FLAKES-MODERATE AT TIME OF OBSERVATION,6 OKTAS     7/10-8/10,towed CTD,0,0,197.57347,0,4,2.176,4,0,34.101,5,0,199.4,4\n" +
"CANADA,CA019465,181C05632,10749307,51.2133,-53.85,86182.78125,20051217,18.75,2026318698,WILFRED TEMPLEMAN (CCGS;F/R/V;call sign CGDV; built 1981;IMO7907099),206.0,1.5 METER,5 SECONDS OR LESS,95 DEGREES - 104 DEGREES,19.8288,1032.0,-1.0E10,-1.0E10,CONTINUOUS FALL OF SNOW FLAKES-MODERATE AT TIME OF OBSERVATION,6 OKTAS     7/10-8/10,towed CTD,0,0,197.6725,0,4,2.174,4,0,34.102,5,0,199.5,4\n" +
"CANADA,CA019465,181C05632,10749307,51.2133,-53.85,86182.78125,20051217,18.75,2026318698,WILFRED TEMPLEMAN (CCGS;F/R/V;call sign CGDV; built 1981;IMO7907099),206.0,1.5 METER,5 SECONDS OR LESS,95 DEGREES - 104 DEGREES,19.8288,1032.0,-1.0E10,-1.0E10,CONTINUOUS FALL OF SNOW FLAKES-MODERATE AT TIME OF OBSERVATION,6 OKTAS     7/10-8/10,towed CTD,0,0,197.77153,0,4,2.175,4,0,34.102,5,0,199.6,4\n" +
"CANADA,CA019465,181C05632,10749307,51.2133,-53.85,86182.78125,20051217,18.75,2026318698,WILFRED TEMPLEMAN (CCGS;F/R/V;call sign CGDV; built 1981;IMO7907099),206.0,1.5 METER,5 SECONDS OR LESS,95 DEGREES - 104 DEGREES,19.8288,1032.0,-1.0E10,-1.0E10,CONTINUOUS FALL OF SNOW FLAKES-MODERATE AT TIME OF OBSERVATION,6 OKTAS     7/10-8/10,towed CTD,0,0,197.87054,0,4,2.178,4,0,34.102,5,0,199.7,4\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
        }


        //read outer and inner col with outer constraint
        fullName = dir + "wod_uor_2005.nc";
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast"}), 
            new StringArray(new String[]{"="}), 
            new StringArray(new String[]{"10749307"}));
        results = table.dataToString(5);
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"10749307,86182.78125,0.0,0.751,0\n" +
"10749307,86182.78125,0.099131815,0.776,0\n" +
"10749307,86182.78125,0.19826359,0.751,0\n" +
"10749307,86182.78125,0.29739532,0.777,0\n" +
"10749307,86182.78125,0.49565855,0.775,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //outer and inner constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast", "Temperature"}), 
            new StringArray(new String[]{"=", "="}), 
            new StringArray(new String[]{"10749307", "0.751"}));
        results = table.dataToString();
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"10749307,86182.78125,0.0,0.751,0\n" +
"10749307,86182.78125,0.19826359,0.751,0\n" +
"10749307,86182.78125,2.4782808,0.751,0\n" +
"10749307,86182.78125,4.0643644,0.751,0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);



        //*** read all xbt
        fullName = dir + "wod_xbt_2005.nc";
        if (doAll) {
            table.readInvalidCRA(fullName, null, 0,  //standardizeWhat=0
                null, null, null);
            results = table.toString(5);
            expected = 
"{\n" +
"dimensions:\n" +
"\trow = 25164853 ;\n" +
"\tcountry_strlen = 14 ;\n" +
"\tWOD_cruise_identifier_strlen = 8 ;\n" +
"\toriginators_cruise_identifier_strlen = 15 ;\n" +
"\toriginators_station_identifier_strlen = 10 ;\n" +
"\tProject_strlen = 59 ;\n" +
"\tPlatform_strlen = 80 ;\n" +
"\tInstitute_strlen = 79 ;\n" +
"\tWater_Color_strlen = 37 ;\n" +
"\tWave_Height_strlen = 9 ;\n" +
"\tWave_Period_strlen = 17 ;\n" +
"\tWind_Direction_strlen = 25 ;\n" +
"\tWeather_Condition_strlen = 169 ;\n" +
"\tCloud_Type_strlen = 17 ;\n" +
"\tCloud_Cover_strlen = 65 ;\n" +
"\tdataset_strlen = 3 ;\n" +
"\tRecorder_strlen = 47 ;\n" +
"\tdepth_eq_strlen = 9 ;\n" +
"\tRef_Type_strlen = 6 ;\n" +
"\tVisibility_strlen = 24 ;\n" +
"\tneeds_z_fix_strlen = 39 ;\n" +
"\treal_time_strlen = 14 ;\n" +
"\tdbase_orig_strlen = 13 ;\n" +
"\torigflagset_strlen = 4 ;\n" +
"\tTemperature_Instrument_strlen = 34 ;\n" +
"\tPrimary_Investigator_strlen = 28 ;\n" +
"\tPrimary_Investigator_VAR_strlen = 13 ;\n" +
"variables:\n" +
"\tchar country(row, country_strlen) ;\n" +
"\tchar WOD_cruise_identifier(row, WOD_cruise_identifier_strlen) ;\n" +
"\t\tWOD_cruise_identifier:comment = \"two byte country code + WOD cruise number (unique to country code)\" ;\n" +
"\t\tWOD_cruise_identifier:long_name = \"WOD_cruise_identifier\" ;\n" +
"\tchar originators_cruise_identifier(row, originators_cruise_identifier_strlen) ;\n" +
"\tint wod_unique_cast(row) ;\n" +
"\t\twod_unique_cast:cf_role = \"profile_id\" ;\n" +
"\tchar originators_station_identifier(row, originators_station_identifier_strlen) ;\n" +
"\t\toriginators_station_identifier:long_name = \"originators_station_identifier\" ;\n" +
"\tfloat lat(row) ;\n" +
"\t\tlat:long_name = \"latitude\" ;\n" +
"\t\tlat:standard_name = \"latitude\" ;\n" +
"\t\tlat:units = \"degrees_north\" ;\n" +
"\tfloat lon(row) ;\n" +
"\t\tlon:long_name = \"longitude\" ;\n" +
"\t\tlon:standard_name = \"longitude\" ;\n" +
"\t\tlon:units = \"degrees_east\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:long_name = \"time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:units = \"days since 1770-01-01 00:00:00 UTC\" ;\n" +
"\tint date(row) ;\n" +
"\t\tdate:comment = \"YYYYMMDD\" ;\n" +
"\t\tdate:long_name = \"date\" ;\n" +
"\tfloat GMT_time(row) ;\n" +
"\t\tGMT_time:long_name = \"GMT_time\" ;\n" +
"\t\tGMT_time:units = \"hours\" ;\n" +
"\tint Access_no(row) ;\n" +
"\t\tAccess_no:_FillValue = -99999 ;\n" +
"\t\tAccess_no:comment = \"used to find original data at NODC\" ;\n" +
"\t\tAccess_no:long_name = \"NODC_accession_number\" ;\n" +
"\t\tAccess_no:units_wod = \"NODC_code\" ;\n" +
"\tchar Project(row, Project_strlen) ;\n" +
"\t\tProject:comment = \"name or acronym of project under which data were measured\" ;\n" +
"\t\tProject:long_name = \"Project_name\" ;\n" +
"\tchar Platform(row, Platform_strlen) ;\n" +
"\t\tPlatform:comment = \"name of platform from which measurements were taken\" ;\n" +
"\t\tPlatform:long_name = \"Platform_name\" ;\n" +
"\tchar Institute(row, Institute_strlen) ;\n" +
"\t\tInstitute:comment = \"name of institute which collected data\" ;\n" +
"\t\tInstitute:long_name = \"Responsible_institute\" ;\n" +
"\tint Orig_Stat_Num(row) ;\n" +
"\t\tOrig_Stat_Num:_FillValue = -99999 ;\n" +
"\t\tOrig_Stat_Num:comment = \"number assigned to a given station by data originator\" ;\n" +
"\t\tOrig_Stat_Num:long_name = \"Originators_Station_Number\" ;\n" +
"\tfloat Bottom_Depth(row) ;\n" +
"\t\tBottom_Depth:_FillValue = -1.0E10f ;\n" +
"\t\tBottom_Depth:standard_name = \"sea_floor_depth_below_sea_surface\" ;\n" +
"\t\tBottom_Depth:units = \"meters\" ;\n" +
"\tchar Water_Color(row, Water_Color_strlen) ;\n" +
"\t\tWater_Color:long_name = \"Water_Color\" ;\n" +
"\t\tWater_Color:units_wod = \"Forel-Ule scale (00 to 21)\" ;\n" +
"\tfloat Water_Transpar(row) ;\n" +
"\t\tWater_Transpar:_FillValue = -1.0E10f ;\n" +
"\t\tWater_Transpar:comment = \"Secchi disk depth\" ;\n" +
"\t\tWater_Transpar:long_name = \"Water_Transparency\" ;\n" +
"\t\tWater_Transpar:units = \"meters\" ;\n" +
"\tchar Wave_Height(row, Wave_Height_strlen) ;\n" +
"\t\tWave_Height:long_name = \"Wave_Height\" ;\n" +
"\t\tWave_Height:units_wod = \"WMO 1555 or NODC 0104\" ;\n" +
"\tchar Wave_Period(row, Wave_Period_strlen) ;\n" +
"\t\tWave_Period:long_name = \"Wave_Period\" ;\n" +
"\t\tWave_Period:units_wod = \"WMO 3155 or NODC 0378\" ;\n" +
"\tchar Wind_Direction(row, Wind_Direction_strlen) ;\n" +
"\t\tWind_Direction:long_name = \"Wind_Direction\" ;\n" +
"\t\tWind_Direction:units_wod = \"WMO 0877 or NODC 0110\" ;\n" +
"\tfloat Wind_Speed(row) ;\n" +
"\t\tWind_Speed:_FillValue = -1.0E10f ;\n" +
"\t\tWind_Speed:standard_name = \"wind_speed\" ;\n" +
"\t\tWind_Speed:units = \"knots\" ;\n" +
"\tfloat Barometric_Pres(row) ;\n" +
"\t\tBarometric_Pres:_FillValue = -1.0E10f ;\n" +
"\t\tBarometric_Pres:long_name = \"Barometric_Pressure\" ;\n" +
"\t\tBarometric_Pres:units = \"millibars\" ;\n" +
"\tfloat Dry_Bulb_Temp(row) ;\n" +
"\t\tDry_Bulb_Temp:_FillValue = -1.0E10f ;\n" +
"\t\tDry_Bulb_Temp:long_name = \"Dry_Bulb_Air_Temperature\" ;\n" +
"\t\tDry_Bulb_Temp:units = \"degree_C\" ;\n" +
"\tfloat Wet_Bulb_Temp(row) ;\n" +
"\t\tWet_Bulb_Temp:_FillValue = -1.0E10f ;\n" +
"\t\tWet_Bulb_Temp:long_name = \"Wet_Bulb_Air_Temperature\" ;\n" +
"\t\tWet_Bulb_Temp:units = \"degree_C\" ;\n" +
"\tchar Weather_Condition(row, Weather_Condition_strlen) ;\n" +
"\t\tWeather_Condition:comment = \"Weather conditions at time of measurements\" ;\n" +
"\t\tWeather_Condition:long_name = \"Weather_Condition\" ;\n" +
"\tchar Cloud_Type(row, Cloud_Type_strlen) ;\n" +
"\t\tCloud_Type:long_name = \"Cloud_Type\" ;\n" +
"\t\tCloud_Type:units_wod = \"WMO 0500 or NODC 0053\" ;\n" +
"\tchar Cloud_Cover(row, Cloud_Cover_strlen) ;\n" +
"\t\tCloud_Cover:long_name = \"Cloud_Cover\" ;\n" +
"\t\tCloud_Cover:units_wod = \"WMO 2700 or NODC 0105\" ;\n" +
"\tchar dataset(row, dataset_strlen) ;\n" +
"\t\tdataset:long_name = \"WOD_dataset\" ;\n" +
"\tchar Recorder(row, Recorder_strlen) ;\n" +
"\t\tRecorder:comment = \"Device which recorded measurements\" ;\n" +
"\t\tRecorder:long_name = \"Recorder\" ;\n" +
"\t\tRecorder:units_wod = \"WMO code 4770\" ;\n" +
"\tchar depth_eq(row, depth_eq_strlen) ;\n" +
"\t\tdepth_eq:comment = \"which drop rate equation was used\" ;\n" +
"\t\tdepth_eq:long_name = \"depth_equation_used\" ;\n" +
"\tbyte Bottom_Hit(row) ;\n" +
"\t\tBottom_Hit:_FillValue = -9 ;\n" +
"\t\tBottom_Hit:comment = \"set to one if instrument hit bottom\" ;\n" +
"\t\tBottom_Hit:long_name = \"Bottom_Hit\" ;\n" +
"\tchar Ref_Type(row, Ref_Type_strlen) ;\n" +
"\t\tRef_Type:comment = \"Instrument for reference temperature\" ;\n" +
"\t\tRef_Type:long_name = \"Reference_Instrument\" ;\n" +
"\tchar Visibility(row, Visibility_strlen) ;\n" +
"\t\tVisibility:long_name = \"Horizontal_visibility\" ;\n" +
"\t\tVisibility:units_wod = \"WMO Code 4300\" ;\n" +
"\tfloat Ref_Surf_Temp(row) ;\n" +
"\t\tRef_Surf_Temp:_FillValue = -1.0E10f ;\n" +
"\t\tRef_Surf_Temp:comment = \"Reference_or_Sea_Surface_Temperature\" ;\n" +
"\t\tRef_Surf_Temp:units = \"degree_C\" ;\n" +
"\tchar needs_z_fix(row, needs_z_fix_strlen) ;\n" +
"\t\tneeds_z_fix:comment = \"instruction for fixing depths\" ;\n" +
"\t\tneeds_z_fix:long_name = \"z_fix_instructions\" ;\n" +
"\t\tneeds_z_fix:units_wod = \"WOD_code\" ;\n" +
"\tchar real_time(row, real_time_strlen) ;\n" +
"\t\treal_time:comment = \"timeliness and quality status\" ;\n" +
"\t\treal_time:long_name = \"real_time_data\" ;\n" +
"\tfloat Launch_height(row) ;\n" +
"\t\tLaunch_height:_FillValue = -1.0E10f ;\n" +
"\t\tLaunch_height:long_name = \"Height_of_instrument_launch\" ;\n" +
"\t\tLaunch_height:units = \"meters\" ;\n" +
"\tfloat sensor_depth(row) ;\n" +
"\t\tsensor_depth:_FillValue = -1.0E10f ;\n" +
"\t\tsensor_depth:long_name = \"Depth_of_sea_surface_sensor\" ;\n" +
"\t\tsensor_depth:units = \"meters\" ;\n" +
"\tchar dbase_orig(row, dbase_orig_strlen) ;\n" +
"\t\tdbase_orig:comment = \"Database from which data were extracted\" ;\n" +
"\t\tdbase_orig:long_name = \"database_origin\" ;\n" +
"\tchar origflagset(row, origflagset_strlen) ;\n" +
"\t\torigflagset:comment = \"set of originators flag codes to use\" ;\n" +
"\tbyte Temperature_WODprofileflag(row) ;\n" +
"\t\tTemperature_WODprofileflag:flag_meanings = \"accepted annual_sd_out density_inversion cruise seasonal_sd_out monthly_sd_out annual+seasonal_sd_out anomaly_or_annual+monthly_sd_out seasonal+monthly_sd_out annual+seasonal+monthly_sd_out\" ;\n" +
"\t\tTemperature_WODprofileflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODprofileflag:long_name = \"WOD_profile_flag\" ;\n" +
"\tchar Temperature_Instrument(row, Temperature_Instrument_strlen) ;\n" +
"\t\tTemperature_Instrument:comment = \"Device used for measurement\" ;\n" +
"\t\tTemperature_Instrument:long_name = \"Instrument\" ;\n" +
"\tchar Primary_Investigator(row, Primary_Investigator_strlen) ;\n" +
"\tchar Primary_Investigator_VAR(row, Primary_Investigator_VAR_strlen) ;\n" +
"\tfloat z(row) ;\n" +
"\t\tz:ancillary_variables = \"z_sigfigs z_WODflag z_origflag\" ;\n" +
"\t\tz:long_name = \"depth_below_sea_surface\" ;\n" +
"\t\tz:positive = \"down\" ;\n" +
"\t\tz:standard_name = \"depth\" ;\n" +
"\t\tz:units = \"m\" ;\n" +
"\tbyte z_WODflag(row) ;\n" +
"\t\tz_WODflag:flag_meanings = \"accepted duplicate_or_inversion density_inversion\" ;\n" +
"\t\tz_WODflag:flag_values = 0, 1, 2 ;\n" +
"\t\tz_WODflag:long_name = \"WOD_depth_level_flag\" ;\n" +
"\t\tz_WODflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_origflag(row) ;\n" +
"\t\tz_origflag:_FillValue = -9 ;\n" +
"\t\tz_origflag:comment = \"Originator flags are dependent on origflagset\" ;\n" +
"\t\tz_origflag:standard_name = \"depth status_flag\" ;\n" +
"\tbyte z_sigfigs(row) ;\n" +
"\t\tz_sigfigs:long_name = \"depth significant figures   \" ;\n" +
"\tfloat Temperature(row) ;\n" +
"\t\tTemperature:_FillValue = -1.0E10f ;\n" +
"\t\tTemperature:ancillary_variables = \"Temperature_sigfigs Temperature_WODflag Temperature_WODprofileflag Temperature_origflag\" ;\n" +
"\t\tTemperature:coordinates = \"time lat lon z\" ;\n" +
"\t\tTemperature:grid_mapping = \"crs\" ;\n" +
"\t\tTemperature:long_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:standard_name = \"sea_water_temperature\" ;\n" +
"\t\tTemperature:units = \"degree_C\" ;\n" +
"\tbyte Temperature_sigfigs(row) ;\n" +
"\t\tTemperature_sigfigs:long_name = \"sea_water_temperature significant_figures\" ;\n" +
"\tbyte Temperature_WODflag(row) ;\n" +
"\t\tTemperature_WODflag:flag_meanings = \"accepted range_out inversion gradient anomaly gradient+inversion range+inversion range+gradient range+anomaly range+inversion+gradient\" ;\n" +
"\t\tTemperature_WODflag:flag_values = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ;\n" +
"\t\tTemperature_WODflag:long_name = \"WOD_observation_flag\" ;\n" +
"\t\tTemperature_WODflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\tbyte Temperature_origflag(row) ;\n" +
"\t\tTemperature_origflag:_FillValue = -9 ;\n" +
"\t\tTemperature_origflag:flag_definitions = \"flag definitions dependent on origflagset\" ;\n" +
"\t\tTemperature_origflag:standard_name = \"sea_water_temperature status_flag\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"country, WOD_cruise_identifier, originators_cruise_identifier, wod_unique_cast, originators_station_identifier, latitude, longitude, time, date, GMT_time, Access_no, Project, Platform, Institute, Orig_Stat_Num, Bottom_Depth, Water_Color, Water_Transpar, Wave_Height, Wave_Period, Wind_Direction, Wind_Speed, Barometric_Pres, Dry_Bulb_Temp, Wet_Bulb_Temp, Weather_Condition, Cloud_Type, Cloud_Cover, dataset, Recorder, depth_eq, Bottom_Hit, Ref_Type, Visibility, Ref_Surf_Temp, needs_z_fix, real_time, Launch_height, sensor_depth, dbase_orig, origflagset, Temperature_WODprofileflag, Temperature_Instrument, Primary_Investigator, Primary_Investigator_VAR\" ;\n" +
"\t\t:Conventions = \"CF-1.6\" ;\n" +
"\t\t:creator_email = \"OCLhelp@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Ocean Climate Lab/NCEI\" ;\n" +
"\t\t:creator_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:crs_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:crs_grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:crs_inverse_flattening = 298.25723f ;\n" +
"\t\t:crs_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:crs_semi_major_axis = 6378137.0f ;\n" +
"\t\t:date_created = \"2018-03-24\" ;\n" +
"\t\t:date_modified = \"2018-03-24\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 79.0612f ;\n" +
"\t\t:geospatial_lat_min = -77.556f ;\n" +
"\t\t:geospatial_lat_resolution = \"point\" ;\n" +
"\t\t:geospatial_lon_max = -0.011505127f ;\n" +
"\t\t:geospatial_lon_min = 180.0f ;\n" +
"\t\t:geospatial_lon_resolution = \"point\" ;\n" +
"\t\t:geospatial_vertical_max = 3124.0f ;\n" +
"\t\t:geospatial_vertical_min = 0.0f ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"meters\" ;\n" +
"\t\t:grid_mapping_epsg_code = \"EPSG:4326\" ;\n" +
"\t\t:grid_mapping_inverse_flattening = 298.25723f ;\n" +
"\t\t:grid_mapping_longitude_of_prime_meridian = 0.0f ;\n" +
"\t\t:grid_mapping_name = \"latitude_longitude\" ;\n" +
"\t\t:grid_mapping_semi_major_axis = 6378137.0f ;\n" +
"\t\t:id = \"/nodc/data/oc5.clim.0/wod_update_nc/2005/wod_xbt_2005.nc\" ;\n" +
"\t\t:institution = \"National Centers for Environmental Information (NCEI), NOAA\" ;\n" +
"\t\t:naming_authority = \"gov.noaa.nodc\" ;\n" +
"\t\t:project = \"World Ocean Database\" ;\n" +
"\t\t:publisher_email = \"NODC.Services@noaa.gov\" ;\n" +
"\t\t:publisher_name = \"US DOC; NESDIS; NATIONAL CENTERS FOR ENVIRONMENTAL INFORMATION\" ;\n" +
"\t\t:publisher_url = \"http://www.nodc.noaa.gov\" ;\n" +
"\t\t:references = \"World Ocean Database 2013. URL:http://data.nodc.noaa.gov/woa/WOD/DOC/wod_intro.pdf\" ;\n" +
"\t\t:source = \"World Ocean Database\" ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v41\" ;\n" +
"\t\t:summary = \"Data for multiple casts from the World Ocean Database\" ;\n" +
"\t\t:time_coverage_end = \"2005-12-31\" ;\n" +
"\t\t:time_coverage_start = \"2005-01-01\" ;\n" +
"\t\t:title = \"World Ocean Database - Multi-cast file\" ;\n" +
"}\n" +
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,originators_station_identifier,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Orig_Stat_Num,Bottom_Depth,Water_Color,Water_Transpar,Wave_Height,Wave_Period,Wind_Direction,Wind_Speed,Barometric_Pres,Dry_Bulb_Temp,Wet_Bulb_Temp,Weather_Condition,Cloud_Type,Cloud_Cover,dataset,Recorder,depth_eq,Bottom_Hit,Ref_Type,Visibility,Ref_Surf_Temp,needs_z_fix,real_time,Launch_height,sensor_depth,dbase_orig,origflagset,Temperature_WODprofileflag,Temperature_Instrument,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag\n" +
"UNITED STATES,US155628,WCY7054,10216693,,57.51,-147.63,85832.02569444478,20050101,0.6166667,1959,,HMI CAPE LOOKOUT SHOALS (Call Sign WCY7054),,2477204,-1.0E10,,-1.0E10,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,XBT,SIPPICAN MK-12,original,-9,,,-1.0E10,needs Hanawa et al.; 1994 applied (XBT),real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: DEEP BLUE (SIPPICAN),,,1.0,0,-9,2,5.0,4,0,-9\n" +
"UNITED STATES,US155628,WCY7054,10216693,,57.51,-147.63,85832.02569444478,20050101,0.6166667,1959,,HMI CAPE LOOKOUT SHOALS (Call Sign WCY7054),,2477204,-1.0E10,,-1.0E10,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,XBT,SIPPICAN MK-12,original,-9,,,-1.0E10,needs Hanawa et al.; 1994 applied (XBT),real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: DEEP BLUE (SIPPICAN),,,5.0,0,-9,2,5.0,4,0,-9\n" +
"UNITED STATES,US155628,WCY7054,10216693,,57.51,-147.63,85832.02569444478,20050101,0.6166667,1959,,HMI CAPE LOOKOUT SHOALS (Call Sign WCY7054),,2477204,-1.0E10,,-1.0E10,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,XBT,SIPPICAN MK-12,original,-9,,,-1.0E10,needs Hanawa et al.; 1994 applied (XBT),real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: DEEP BLUE (SIPPICAN),,,73.0,0,-9,3,5.1,4,0,-9\n" +
"UNITED STATES,US155628,WCY7054,10216693,,57.51,-147.63,85832.02569444478,20050101,0.6166667,1959,,HMI CAPE LOOKOUT SHOALS (Call Sign WCY7054),,2477204,-1.0E10,,-1.0E10,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,XBT,SIPPICAN MK-12,original,-9,,,-1.0E10,needs Hanawa et al.; 1994 applied (XBT),real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: DEEP BLUE (SIPPICAN),,,77.0,0,-9,3,4.9,4,0,-9\n" +
"UNITED STATES,US155628,WCY7054,10216693,,57.51,-147.63,85832.02569444478,20050101,0.6166667,1959,,HMI CAPE LOOKOUT SHOALS (Call Sign WCY7054),,2477204,-1.0E10,,-1.0E10,,,,-1.0E10,-1.0E10,-1.0E10,-1.0E10,,,,XBT,SIPPICAN MK-12,original,-9,,,-1.0E10,needs Hanawa et al.; 1994 applied (XBT),real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: DEEP BLUE (SIPPICAN),,,89.0,0,-9,3,5.0,4,0,-9\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            table.removeRows(0, 25164853 - 5);
            results = table.dataToString();
            expected = 
"country,WOD_cruise_identifier,originators_cruise_identifier,wod_unique_cast,originators_station_identifier,lat,lon,time,date,GMT_time,Access_no,Project,Platform,Institute,Orig_Stat_Num,Bottom_Depth,Water_Color,Water_Transpar,Wave_Height,Wave_Period,Wind_Direction,Wind_Speed,Barometric_Pres,Dry_Bulb_Temp,Wet_Bulb_Temp,Weather_Condition,Cloud_Type,Cloud_Cover,dataset,Recorder,depth_eq,Bottom_Hit,Ref_Type,Visibility,Ref_Surf_Temp,needs_z_fix,real_time,Launch_height,sensor_depth,dbase_orig,origflagset,Temperature_WODprofileflag,Temperature_Instrument,Primary_Investigator,Primary_Investigator_VAR,z,z_WODflag,z_origflag,z_sigfigs,Temperature,Temperature_sigfigs,Temperature_WODflag,Temperature_origflag\n" +
"UNKNOWN,,,10731585,,36.55,13.6667,86196.0,20051231,9.96921E36,2516,,,,3028589,-1.0E10,,-1.0E10,,,165 DEGREES - 174 DEGREES,27.216,-1.0E10,-1.0E10,-1.0E10,,,,XBT,,,-9,,,-1.0E10,insufficient information,real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: TYPE UNKNOWN,,,88.0,0,-9,3,15.3,5,0,-9\n" +
"UNKNOWN,,,10731585,,36.55,13.6667,86196.0,20051231,9.96921E36,2516,,,,3028589,-1.0E10,,-1.0E10,,,165 DEGREES - 174 DEGREES,27.216,-1.0E10,-1.0E10,-1.0E10,,,,XBT,,,-9,,,-1.0E10,insufficient information,real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: TYPE UNKNOWN,,,98.0,0,-9,3,15.1,5,0,-9\n" +
"UNKNOWN,,,10731585,,36.55,13.6667,86196.0,20051231,9.96921E36,2516,,,,3028589,-1.0E10,,-1.0E10,,,165 DEGREES - 174 DEGREES,27.216,-1.0E10,-1.0E10,-1.0E10,,,,XBT,,,-9,,,-1.0E10,insufficient information,real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: TYPE UNKNOWN,,,102.0,0,-9,4,14.7,5,0,-9\n" +
"UNKNOWN,,,10731585,,36.55,13.6667,86196.0,20051231,9.96921E36,2516,,,,3028589,-1.0E10,,-1.0E10,,,165 DEGREES - 174 DEGREES,27.216,-1.0E10,-1.0E10,-1.0E10,,,,XBT,,,-9,,,-1.0E10,insufficient information,real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: TYPE UNKNOWN,,,167.0,0,-9,4,14.7,5,0,-9\n" +
"UNKNOWN,,,10731585,,36.55,13.6667,86196.0,20051231,9.96921E36,2516,,,,3028589,-1.0E10,,-1.0E10,,,165 DEGREES - 174 DEGREES,27.216,-1.0E10,-1.0E10,-1.0E10,,,,XBT,,,-9,,,-1.0E10,insufficient information,real-time data,-1.0E10,-1.0E10,GTSP Project,,0,XBT: TYPE UNKNOWN,,,200.0,0,-9,4,14.5,5,0,-9\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
        }


        //read outer and inner col with outer constraint
        fullName = dir + "wod_xbt_2005.nc";
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast"}), 
            new StringArray(new String[]{"="}), 
            new StringArray(new String[]{"10731585"}));
        results = table.dataToString(5);
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"10731585,86196.0,0.0,15.8,0\n" +
"10731585,86196.0,23.0,15.7,0\n" +
"10731585,86196.0,47.0,15.3,0\n" +
"10731585,86196.0,50.0,15.4,0\n" +
"10731585,86196.0,65.0,15.2,0\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //outer and inner constraint
        table.readInvalidCRA(fullName, 
            new StringArray(new String[]{"wod_unique_cast", "time", "z", "Temperature","Temperature_WODflag"}), 
            0,  //standardizeWhat=0
            new StringArray(new String[]{"wod_unique_cast", "Temperature"}), 
            new StringArray(new String[]{"=", "="}), 
            new StringArray(new String[]{"10731585", "15.3"}));
        results = table.dataToString();
        expected = 
"wod_unique_cast,time,z,Temperature,Temperature_WODflag\n" +
"10731585,86196.0,47.0,15.3,0\n" +
"10731585,86196.0,88.0,15.3,0\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        
        /* */

        table.debugMode = false;
    }

    /**
     * This reads data from an audio file 
     * (AudioFileFormat.Type: AU, WAVE, SND (not tested), 
     * and AIFF/AIFF-C (should work but aren't supported)).
     * See https://docs.oracle.com/javase/tutorial/sound/converters.html
     * There may be other classes/jars from other groups that support other file types.
     *
     * @param readData This method always reads metadata. If readData=true,
     *   this also reads the data.
     * @param addElapsedTimeColumn if true, column[0] will be elapsedTime
     *   with double values in seconds (starting at 0)
     * @throws Exception if trouble 
     */
    public void readAudioFile(String fullName, boolean readData, 
        boolean addElapsedTimeColumn) throws Exception {
        //FUTURE: read audio waveform data by using Java methods to convert other formats to PCM
        //See also https://howlerjs.com/

        int totalFramesRead = 0;

        clear();
        AudioInputStream audioInputStream = null;
        DataInputStream dis = null;
        String msg = "  Table.readAudioFile " + fullName;
        String errorWhile = String2.ERROR + " in" + msg + ": ";
        try {
            long startTime = System.currentTimeMillis();

            java.io.File audioFile = new java.io.File(fullName);
            if (debugMode) {
                AudioFileFormat aff = AudioSystem.getAudioFileFormat(audioFile);
                msg += "\naff.properties()=" + aff.properties().toString();
            }
           
            audioInputStream = AudioSystem.getAudioInputStream(audioFile);

            //get the metadata
            AudioFormat af = audioInputStream.getFormat();

            int bytesPerFrame = af.getFrameSize();
            if (bytesPerFrame == AudioSystem.NOT_SPECIFIED || bytesPerFrame <= 0) {
                // some audio formats may have unspecified frame size
                // in that case we may read any amount of bytes
                bytesPerFrame = 1;
            }
            int nChannels = af.getChannels();
            int nBits = af.getSampleSizeInBits();
            //AudioFormat.Encoding: ALAW, PCM_FLOAT, PCM_SIGNED, PCM_UNSIGNED, ULAW
            String encoding = af.getEncoding().toString();
            boolean isALAW         = encoding.equals("ALAW");
            boolean isULAW         = encoding.equals("ULAW");
            boolean isPcmFloat     = encoding.equals("PCM_FLOAT");  
            boolean isPcmUnsigned  = encoding.equals("PCM_UNSIGNED");  
            boolean isPcmSigned    = encoding.equals("PCM_SIGNED");  
            boolean isBigEndian = af.isBigEndian();
            boolean is24Bit     = nBits == 24;
            if (!isALAW && !isULAW && !isPcmFloat && !isPcmUnsigned && !isPcmSigned)
                new SimpleException(errorWhile + "Unsupported audioSampleSizeInBits=" + nBits + ".");

            int frameSize = af.getFrameSize();
            globalAttributes.set("audioBigEndian",        "" + isBigEndian);
            globalAttributes.set("audioChannels",         nChannels);
            globalAttributes.set("audioEncoding",         encoding);
            globalAttributes.set("audioFrameRate",        af.getFrameRate()); //may be different than sampleRate if compressed
            globalAttributes.set("audioFrameSize",        frameSize); //bytes
            globalAttributes.set("audioSampleRate",       af.getSampleRate());
            globalAttributes.set("audioSampleSizeInBits", nBits);
            Map props = af.properties();
            Iterator it = props.entrySet().iterator();
            while (it.hasNext()) {
                Map.Entry pair = (Map.Entry)it.next();
                //use prefix=audio_ to distinguish these props from method values above
                //and to avoid clash if same name
                //but map common properties to CF terms if possible 
                //(see list in Javadocs for AudioFileFormat)
                String key = pair.getKey().toString();
                if      (key.equals("author"))    key = "creator_name";
                else if (key.equals("comment"))   key = "summary";
                else if (key.equals("copyright")) key = "license";
                else if (key.equals("date"))      key = "date_created";
                else if (key.equals("title"))     key = "title";
                else                              key = "audio_" + key;
                globalAttributes.set(key, PrimitiveArray.factory(pair.getValue()));
            }

            //BUG in java: 
            //  https://bugs.openjdk.java.net/browse/JDK-8038138
            //  And this causes incorrect getFrameLength()
            //  https://bugs.openjdk.java.net/browse/JDK-8038139
            //  with String2.unitTestDataDir + "audio/wav/aco_acoustic.20141119_000000.wav"
            //  file has 24000 samples/sec * 300 sec = 7,200,000 samples and 4 bytes/sample,
            //  but lNFrames is 28,000,000!  (should be 7,200,000)
            //so treat it as nBytes but this is TROUBLE!
            long lNFrames = audioInputStream.getFrameLength();
            if (lNFrames * frameSize > File2.length(fullName))   //a more emprical test than isPcmFloat
                lNFrames /= frameSize;
            if (lNFrames >= Integer.MAX_VALUE)
                throw new SimpleException(errorWhile + "The file's nFrames=" + lNFrames + 
                    " is greater than maxAllowed=" + (Integer.MAX_VALUE - 1) + ".");
            int nFrames = Math2.narrowToInt(lNFrames);

            //make the columns
            PrimitiveArray pa[] = new PrimitiveArray[nChannels];
            int tSize = readData? nFrames : 1;
            for (int c = 0; c < nChannels; c++) {
                if (isPcmFloat && af.isBigEndian()) {  //java is bigEndian
                    //if littleEndian, store in integer type (below), then reverseBytes, then convert to float
                    if      (nBits == 32) pa[c] = new FloatArray( tSize, false);
                    else if (nBits == 64) pa[c] = new DoubleArray(tSize, false);
                    else throw new SimpleException(errorWhile + 
                        "Unsupported audioSampleSizeInBits=" + nBits + ".");
                } else {
                    if      (nBits ==  8) pa[c] = new ByteArray( tSize, false);  
                    //12 is not supported yet because each value is 1.5 bytes -- hard to deal with when >1 channel in a dis
                    else if (nBits == 16) pa[c] = new ShortArray(tSize, false);
                    else if (nBits == 24) pa[c] = new IntArray(  tSize, false);
                    else if (nBits == 32) pa[c] = new IntArray(  tSize, false);
                    else if (nBits == 64) pa[c] = new LongArray( tSize, false);
                    else throw new SimpleException(errorWhile + 
                        "Unsupported audioSampleSizeInBits=" + nBits + ".");
                }
                addColumn(c, "channel_" + (c+1), pa[c], 
                    (new Attributes()).add("long_name", "Channel " + (c+1)));
            }

            Attributes elapsedTimeAtts = null;
            if (addElapsedTimeColumn) 
                elapsedTimeAtts = (new Attributes())
                    .add("long_name", "Elapsed Time")
                    .add("units", "seconds");

            //return with just metadata?
            if (!readData) {
                audioInputStream.close();
                audioInputStream = null;

                //make simple versions of changes below
                for (int c = 0; c < nChannels; c++) {
                    if (isALAW || isULAW) {
                        setColumn(c, new ShortArray());
                    } else if (!af.isBigEndian() && isPcmFloat) {  //24 bit was done when read
                        if (nBits <= 32) 
                            setColumn(c, new FloatArray());
                        else if (nBits <= 64) 
                            setColumn(c, new DoubleArray());
                    }
                }
                if (addElapsedTimeColumn)
                    addColumn(0, ELAPSED_TIME, new DoubleArray(), elapsedTimeAtts);
                return;
            }

            //get the data 
            dis = new DataInputStream(new BufferedInputStream(audioInputStream));                       
            if (is24Bit) {
                if (nChannels == 1) {
                    ((IntArray)pa[0]).read24BitDisAudio(dis, nFrames, isBigEndian);
                } else {
                    IntArray ia[] = new IntArray[nChannels];
                    for (int c = 0; c < nChannels; c++) 
                        ia[c] = (IntArray)pa[c];
                    for (int f = 0; f < nFrames; f++) 
                        for (int c = 0; c < nChannels; c++) 
                            ia[c].read24BitDisAudio(dis, 1, isBigEndian);
                }

            } else if (nChannels == 1) {
                pa[0].readDis(dis, nFrames);

            } else {
                for (int f = 0; f < nFrames; f++) 
                    for (int c = 0; c < nChannels; c++) 
                        pa[c].readDis(dis, 1);
            }

            //clean up the data
            //2020-08-11 I tried reading directly into unsigned PAs, but trouble (didn't pursue it), so I reverted
            if (isPcmUnsigned) {
                //what were read as signed:    0  127 -128  -1
                //should become   unsigned: -128   -1    0 127
                for (int c = 0; c < nChannels; c++) 
                    pa[c].changeSignedToFromUnsigned();
            }

            if (isALAW) {
                //convert encoded byte to short
                //see https://stackoverflow.com/questions/26824663/how-do-i-use-audio-sample-data-from-java-sound
                //I'M NOT CONVINCED THIS IS EXACTLY RIGHT. IT SOUNDS BETTER DIRECTLY IN BROWSER.
                //FUTURE: USE JAVA AUDIO STREAMS TO DO THE CONVERSION TO PCM
                double d0 = 1.0 + Math.log(87.7);
                double d1 = 1.0 / d0;
                double d2 = d0 / 87.7;
                double sm1 = (Short.MAX_VALUE * 16) - 1; // *16 because too small otherwise (???!!!)
                for (int c = 0; c < nChannels; c++) {
                    ByteArray ba = (ByteArray)pa[c];
                    ShortArray sa = new ShortArray(nFrames, true);
                    short sar[] = sa.array;
                    setColumn(c, sa);
                    long lmin = Long.MAX_VALUE;
                    long lmax = Long.MIN_VALUE;
                    int min = Integer.MAX_VALUE;
                    int max = Integer.MIN_VALUE;
                    for (int f = 0; f < nFrames; f++) {
                        long tl = (ba.array[f] & 0xffL) ^ 0x55L;
                        if ((tl & 0x80L) == 0x80L) 
                            tl = -(tl ^ 0x80L);
                        lmin = Math.min(lmin, tl);
                        lmax = Math.max(lmax, tl);
                        double sample = tl / 255.0;
                        double signum = Math.signum(sample);
                        sample = Math.abs(sample);
                        if (sample < d1) 
                            sample = sample * d2;
                        else
                            sample = Math.exp((sample * d0) - 1.0) / 87.7;
                        sample = signum * sample;                    
                        sar[f] = Math2.roundToShort(sm1 * sample);  //sample is +/-1
                        min = Math.min(min, sar[f]);
                        max = Math.max(max, sar[f]);
                    }
                    if (reallyVerbose) msg +="\n col=" + c + " inMin=" + lmin + " inMax=" + lmax + " outMin=" + min + " outMax=" + max;
                }


            } else if (isULAW) {
                //convert encoded byte to short
                //see https://stackoverflow.com/questions/26824663/how-do-i-use-audio-sample-data-from-java-sound
                //I'M NOT CONVINCED THIS IS EXACTLY RIGHT. IT SOUNDS BETTER DIRECTLY IN BROWSER.
                //FUTURE: USE JAVA AUDIO STREAMS TO DO THE CONVERSION TO PCM
                double d0 = 1.0 / 255.0;
                double sm1 = (Short.MAX_VALUE * 16) - 1; // *16 because too small otherwise (???!!!)
                for (int c = 0; c < nChannels; c++) {
                    ByteArray ba = (ByteArray)pa[c];
                    ShortArray sa = new ShortArray(nFrames, true);
                    short sar[] = sa.array;
                    setColumn(c, sa);
                    long lmin = Long.MAX_VALUE;
                    long lmax = Long.MIN_VALUE;
                    int min = Integer.MAX_VALUE;
                    int max = Integer.MIN_VALUE;
                    for (int f = 0; f < nFrames; f++) {
                        long tl = (ba.array[f] & 0xffL) ^ 0xffL;
                        if ((tl & 0x80L) == 0x80L) 
                            tl = -(tl ^ 0x80L);
                        lmin = Math.min(lmin, tl);
                        lmax = Math.max(lmax, tl);
                        double sample = tl / 255.0;
                        sample = Math.signum(sample) * d0 * 
                            (Math.pow(256.0, Math.abs(sample)) - 1.0);
                        sar[f] = Math2.roundToShort(sm1 * sample);
                        min = Math.min(min, sar[f]);
                        max = Math.max(max, sar[f]);
                    }
                    if (reallyVerbose) msg += "\n  col=" + c + " inMin=" + lmin + " inMax=" + lmax + " outMin=" + min + " outMax=" + max;
                }


            } else if (!af.isBigEndian() && !is24Bit) {  //24 bit was done when read
                //reverse the bytes?
                for (int c = 0; c < nChannels; c++) {
                    pa[c].reverseBytes();  //this works because they are only integer-type arrays

                    //if littleEndian and float, convert to float
                    if (isPcmFloat) {
                        //if littleEndian, store in integer type, then reverseBytes, then convert to float
                        if      (nBits <= 32) {
                            FloatArray fa = new FloatArray(nFrames, true);
                            float far[] = fa.array;
                            for (int f = 0; f < nFrames; f++) 
                                far[f] = Float.intBitsToFloat(pa[c].getInt(f));
                            pa[c] = fa;
                            setColumn(c, fa);
                        } else if (nBits <= 64) {
                            DoubleArray da = new DoubleArray(nFrames, true);
                            double dar[] = da.array;
                            for (int f = 0; f < nFrames; f++) 
                                dar[f] = Double.longBitsToDouble(pa[c].getLong(f));
                            pa[c] = da;
                            setColumn(c, da);
                        } 
                    }
                }
            }

            //add elapsedTime
            if (addElapsedTimeColumn) {
                double sampleRate = af.getSampleRate(); //double so calculations below as double
                DoubleArray da = new DoubleArray(nFrames, true);
                double dar[] = da.array;
                for (int f = 0; f < nFrames; f++) 
                    dar[f] = f / sampleRate; //that's the most precise way to calculate it
                addColumn(0, ELAPSED_TIME, da, elapsedTimeAtts);
            }

            //close dis
            dis.close();
            dis = null;
            audioInputStream = null;
            if (reallyVerbose) msg += 
                " finished. nRows=" + nFrames + 
                " nChannels=" + nChannels + " encoding=" + encoding + 
                " isBigEndian=" + isBigEndian + 
                " nBits=" + nBits + " isPcmFloat=" + isPcmFloat + 
                " time=" + (System.currentTimeMillis() - startTime) + "ms";

        } catch (Exception e) {
            try {
                if (dis != null) {
                    dis.close(); 
                    dis = null;
                    audioInputStream = null;
                }
            } catch (Exception e2) { }
            try {
                if (audioInputStream != null) 
                    audioInputStream.close(); 
            } catch (Exception e2) { }

            //clear()?
            if (!reallyVerbose) String2.log(msg);
            throw e;

        } finally {
            if (reallyVerbose) String2.log(msg);
        }

    }

    /**
     * This tests readAudioFile with stereo 16 bit data.
     * This is a destructive test: it removes the first second of the data.
     *
     * @param fullName e.g., String2.unitTestDataDir + "audio/M1F1-int16-AFsp.wav" or my test re-write of it:
     * from http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/WAVE/Samples.html
     */
    public static void testReadShortAudioFile(String fullName) throws Exception {
        String2.log("* testReadShortAudioFile(" + fullName + ")");
        Table table = new Table();
        String results, expected;

        //without elapsed time
        table.readAudioFile(fullName, true, false); //readData, addElapsedTime
        results = table.toString(10);
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 23493 ;\n" +
"variables:\n" +
"\tshort channel_1(row) ;\n" +
"\t\tchannel_1:long_name = \"Channel 1\" ;\n" +
"\tshort channel_2(row) ;\n" +
"\t\tchannel_2:long_name = \"Channel 2\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:audioBigEndian = \"false\" ;\n" +
"\t\t:audioChannels = 2 ;\n" +
"\t\t:audioEncoding = \"PCM_SIGNED\" ;\n" +
"\t\t:audioFrameRate = 8000.0f ;\n" +
"\t\t:audioFrameSize = 4 ;\n" +
"\t\t:audioSampleRate = 8000.0f ;\n" +
"\t\t:audioSampleSizeInBits = 16 ;\n" +
"}\n" +
"channel_1,channel_2\n" +
"0,0\n" +
"0,0\n" +
"1,2\n" +
"-3,0\n" +
"0,-4\n" +
"6,4\n" +
"-2,1\n" +
"-2,-2\n" +
"1,-4\n" +
"-1,-4\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //get elapsed time
        table.readAudioFile(fullName, true, true); //readData, addElapsedTime
        results = table.toString(10);
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 23493 ;\n" +
"variables:\n" +
"\tdouble elapsedTime(row) ;\n" +
"\t\telapsedTime:long_name = \"Elapsed Time\" ;\n" +
"\t\telapsedTime:units = \"seconds\" ;\n" +
"\tshort channel_1(row) ;\n" +
"\t\tchannel_1:long_name = \"Channel 1\" ;\n" +
"\tshort channel_2(row) ;\n" +
"\t\tchannel_2:long_name = \"Channel 2\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:audioBigEndian = \"false\" ;\n" +
"\t\t:audioChannels = 2 ;\n" +
"\t\t:audioEncoding = \"PCM_SIGNED\" ;\n" +
"\t\t:audioFrameRate = 8000.0f ;\n" +
"\t\t:audioFrameSize = 4 ;\n" +
"\t\t:audioSampleRate = 8000.0f ;\n" +
"\t\t:audioSampleSizeInBits = 16 ;\n" +
"}\n" +
"elapsedTime,channel_1,channel_2\n" +
"0.0,0,0\n" +
"1.25E-4,0,0\n" +
"2.5E-4,1,2\n" +
"3.75E-4,-3,0\n" +
"5.0E-4,0,-4\n" +
"6.25E-4,6,4\n" +
"7.5E-4,-2,1\n" +
"8.75E-4,-2,-2\n" +
"0.001,1,-4\n" +
"0.001125,-1,-4\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        SSR.displayInBrowser("file://" + fullName);
        String2.pressEnterToContinue("Close the audio player if file is okay.");
    }

    /**
     * This tests reading a wav file with stereo float data.
     *
     * @param fullName String2.unitTestDataDir + "audio/M1F1-float32-AFsp.wav" or my test re-write of it:
     *   from http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/WAVE/Samples.html
     */
    public static void testReadFloatAudioFile(String fullName) throws Exception {
        String2.log("* testReadFloatAudioFile(" + fullName + ")");
        Table table = new Table();
        String results, expected;

        table.readAudioFile(fullName, true, false); //readData, addElapsedTime 
        results = table.toString(10);
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 23493 ;\n" +
"variables:\n" +
"\tfloat channel_1(row) ;\n" +
"\t\tchannel_1:long_name = \"Channel 1\" ;\n" +
"\tfloat channel_2(row) ;\n" +
"\t\tchannel_2:long_name = \"Channel 2\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:audioBigEndian = \"false\" ;\n" +
"\t\t:audioChannels = 2 ;\n" +
"\t\t:audioEncoding = \"PCM_FLOAT\" ;\n" +
"\t\t:audioFrameRate = 8000.0f ;\n" +
"\t\t:audioFrameSize = 8 ;\n" +
"\t\t:audioSampleRate = 8000.0f ;\n" +
"\t\t:audioSampleSizeInBits = 32 ;\n" +
"}\n" +
"channel_1,channel_2\n" +
"0.0,0.0\n" +
"0.0,0.0\n" +
"3.0517578E-5,6.1035156E-5\n" +
"-9.1552734E-5,0.0\n" +
"0.0,-1.2207031E-4\n" +
"1.8310547E-4,1.2207031E-4\n" +
"-6.1035156E-5,3.0517578E-5\n" +
"-6.1035156E-5,-6.1035156E-5\n" +
"3.0517578E-5,-1.2207031E-4\n" +
"-3.0517578E-5,-1.2207031E-4\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        SSR.displayInBrowser("file://" + fullName);
        String2.pressEnterToContinue("Close the audio player if file is okay.");
    }


    /**
     * This writes the data to a PCM_SIGNED (for int types) or PCM_FLOAT (for float types)
     * WAVE file.
     * All columns must be of the same type.
     * This writes to a temporary file, then renames to correct name.
     * Long data is always written as int's because wav doesn't seem to support it.
* UNTIL JAVA 9, BECAUSE OF JAVA BUG, this writes float/double data as int's.
     *
     * @param fullOutName the dir + name + .wav for the .wav file
     * @throws Exception if trouble.
     *    If trouble, this makes an effort not to leave any (partial) file.
     */
    public void writeWaveFile(String fullOutName) throws Exception {

        //this method creates file with the data
        //  and at the end it calls the other writeWaveFile method to create fullOutName
        long startTime = System.currentTimeMillis();
        String errorWhile = String2.ERROR + " while writing .wav file=" + fullOutName + ": ";
        int nCol = nColumns();
        int nRow = nRows();
        Test.ensureTrue(nCol > 0 && nRow > 0,
            errorWhile + "There is no data.");
        String tPAType = getColumn(0).elementTypeString();
        int randomInt = Math2.random(Integer.MAX_VALUE);
        String fullInName = fullOutName + ".data" + randomInt;
        File2.delete(fullOutName);

        //gather pa[] and just deal with that (so changes don't affect the table)
        Test.ensureTrue(!tPAType.equals("String") && !tPAType.equals("char"), 
            errorWhile + "All data columns must be numeric.");
        PrimitiveArray pa[] = new PrimitiveArray[nCol];     
        for (int c = 0; c < nCol; c++) {
            pa[c] = columns.get(c);
            Test.ensureEqual(tPAType, pa[c].elementTypeString(),
                errorWhile + "All data columns must be of the same data type.");
        }

        //TEMPORARY: DEAL WITH JAVA 1.8 BUG: 
        //Java code can't write PCM_FLOAT: says it is PCM_SIGNED instead
        //https://bugs.openjdk.java.net/browse/JDK-8064800
        //This is said to be fixed in Java 9 
        boolean java8 = System.getProperty("java.version").startsWith("1.8.");
        if (java8 &&
            (tPAType.equals("long") || tPAType.equals("float") || tPAType.equals("double"))) {

            //get the range of all columns
            double min =  Double.MAX_VALUE;
            double max = -Double.MAX_VALUE; //min_value is close to 0
            for (int c = 0; c < nCol; c++) {
                //get range
                PrimitiveArray da = pa[c];
                double[] stats = da.calculateStats();
                min = Math.min(min, stats[PrimitiveArray.STATS_MIN]);
                max = Math.max(max, stats[PrimitiveArray.STATS_MAX]);
            }
            double range = max - min;

            //save as int (scaled into int range)
            for (int c = 0; c < nCol; c++) {
                PrimitiveArray da = pa[c];
                IntArray ia = new IntArray(nRow, false);
                for (int row = 0; row < nRow; row++) {
                    double d = da.getDouble(row);
                    if (Double.isNaN(d)) 
                        ia.add(0);
                    else ia.add(Math2.roundToInt(-2000000000.0 + ((d-min)/range) * 4000000000.0));
                }
                pa[c] = ia;
            }
            tPAType = "int";
        }
         
        //write the data to a file (slower, but saving memory is important here)
        //FUTURE: isn't there a way to open the wav file, write data to it, then close it?
        //  very low level: https://stackoverflow.com/questions/5810164/how-can-i-write-a-wav-file-from-byte-array-in-java
        DataOutputStream dos = new DataOutputStream(new BufferedOutputStream(
            new FileOutputStream(fullInName)));
        try {
            for (int row = 0; row < nRow; row++)
                for (int col = 0; col < nCol; col++)
                    pa[col].writeDos(dos, row);
            dos.close();
            dos = null;

        } catch (Exception e) {
            if (dos != null) {
                dos.close();
                File2.delete(fullInName);
            }
            throw e;
        }

        //make the wav file
        writeWaveFile(fullInName, nCol, nRow, tPAType, globalAttributes, 
            randomInt, fullOutName, startTime); // throws Exception 

        //delete the temp in file
        File2.delete(fullInName);
    }


    /**
     * This STATIC method writes the data to a PCM_SIGNED (for integer types) 
     * or PCM_FLOAT (for float types) WAVE file.
     * All columns must be of the same type.
     * This writes to a temporary file, then renames to correct name.
     * If neither the audioFrameRate or audioSampleRate are in globalAttributes,
     * a sample rate of 10000Hz will be assumed.
     *
     * @param fullInName  the dir + name + ext for the data stream file, 
     *    ready to go (columns interspersed).
     * @param nCol
     * @param nRow
     * @param tPAType a numeric type. 
     *   UNTIL JAVA 9, BECAUSE OF JAVA BUG, this must be an integer type.
     * @param globalAtts
     * @param randomInt
     * @param fullOutName the dir + name + .wav for the .wav file
     * @throws Exception if trouble.
     *    If trouble, this makes an effort not to leave any (partial) file.
     */
    public static void writeWaveFile(String fullInName, int nCol, long nRow, 
        String tPAType, Attributes globalAtts, 
        int randomInt, String fullOutName, long startTime) throws Exception {

        File2.delete(fullOutName);
        String msg = "  Table.writeWaveFile " + fullOutName;
        String errorWhile = String2.ERROR + " while writing .wav file=" + fullOutName + ": ";
        boolean isFloat = tPAType.equals("double") || tPAType.equals("float");
        Test.ensureTrue(!tPAType.equals("String") && !tPAType.equals("char"), 
            errorWhile + "All data columns must be numeric.");

        //gather info. Ensure all columns are same type.

        //gather required metadata and properties (from globalAtts)
        float frameRate  = Float.NaN; 
        float sampleRate = Float.NaN; 
        String keys[] = globalAtts.getNames();
        HashMap<String,Object> props = new HashMap();
        for (int ki = 0; ki < keys.length; ki++) {
            String k = keys[ki];
            if      (k.equals("audioBigEndian"))  {} //don't pass through
            else if (k.equals("audioChannels"))   {} //don't pass through
            else if (k.equals("audioEncoding"))   {} //don't pass through
            else if (k.equals("audioFrameRate"))  frameRate  = globalAtts.getFloat(k);
            else if (k.equals("audioFrameSize"))  {} //don't pass through
            else if (k.equals("audioSampleRate")) sampleRate = globalAtts.getFloat(k);
            else if (k.equals("audioSampleSizeInBits")) {} //don't pass through
            else {
                String k2 = k;
                if (k.startsWith("audio_"))
                    k2 = k.substring(6);
                PrimitiveArray pa = globalAtts.get(k);
                PAType paPAType = pa.elementType();
                if      (paPAType.equals(PAType.BYTE  )) props.put(k2, Math2.narrowToByte( globalAtts.getInt(k)));
                else if (paPAType.equals(PAType.SHORT )) props.put(k2, Math2.narrowToShort(globalAtts.getInt(k)));
                else if (paPAType.equals(PAType.INT   )) props.put(k2, globalAtts.getInt(k));
                else if (paPAType.equals(PAType.LONG  )) props.put(k2, globalAtts.getLong(k));
                else if (paPAType.equals(PAType.FLOAT )) props.put(k2, globalAtts.getFloat(k));
                else if (paPAType.equals(PAType.DOUBLE)) props.put(k2, globalAtts.getDouble(k));
                else                                   props.put(k2, globalAtts.getString(k));
            }
        }

        if (frameRate < 0 || !Float.isFinite(frameRate))
            frameRate = sampleRate;
        if (sampleRate < 0 || !Float.isFinite(sampleRate))
            sampleRate = frameRate;
        if (sampleRate < 0 || !Float.isFinite(sampleRate)) {
            frameRate = 10000; //a low frame/sampleRate, and a round number
            sampleRate = 10000;
        }

        //https://stackoverflow.com/questions/10991391/saving-audio-byte-to-a-wav-file
        AudioFormat.Encoding encoding = isFloat? 
            AudioFormat.Encoding.PCM_FLOAT : 
            AudioFormat.Encoding.PCM_SIGNED;
        int nBits = PAType.elementSize(tPAType) * 8; //bits per element
        AudioFormat af = new AudioFormat(encoding,
            sampleRate, nBits, nCol, (nCol * nBits) / 8, frameRate, 
            true, //bigEndian. My data is bigEndian, but I think Java always swaps and writes littleEndian
            props);

        DataInputStream dis = new DataInputStream(File2.getDecompressedBufferedInputStream(fullInName));
        try {

            //create the .wav
            AudioInputStream ais = new AudioInputStream(dis, af, nRow);  //nFrames
            try {
                AudioSystem.write(ais, AudioFileFormat.Type.WAVE, 
                    new java.io.File(fullOutName + randomInt));
            } finally {
                ais.close();
                dis = null;
            }

            File2.rename(fullOutName + randomInt, fullOutName); //throws Exception if trouble

            if (reallyVerbose) msg += " finished.  nRows=" + nRow + 
                " nChannels=" + nCol + " encoding=" + encoding.toString() + 
                " isBigEndian=true" +
                " nBits=" + nBits + " isFloat=" + isFloat + 
                " time=" + (System.currentTimeMillis() - startTime) + "ms";

        } catch (Exception e) {
            if (!reallyVerbose) String2.log(msg); 
            if (dis != null)
                dis.close();
            File2.delete(fullOutName + randomInt);
            throw e;

        } finally {
            if (reallyVerbose) String2.log(msg);
        }
    }

    /** 
     * This tests reading audio files and and writing WAVE files. 
     * @param stop use a big number will be converted to the max available */
    public static void testReadAudioWriteWaveFiles(int start, int stop) throws Exception {

        String dir = String2.unitTestDataDir + "audio/";
        String names[] = {
            //sample files from http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/WAVE/Samples.html
            "M1F1-int16-AFsp.wav",   "M1F1-int32-AFsp.wav", 
            "M1F1-uint8-AFsp.wav",   "M1F1-int24-AFsp.wav", 
            "M1F1-float32-AFsp.wav", "M1F1-mulaw-AFsp.wav", 
            "M1F1-Alaw-AFsp.wav",    "M1F1-int12-AFsp.wav",   //12bits is not supported
            "addf8-Alaw-GW.wav",     "addf8-mulaw-GW.wav",    
            //sample files from http://www.class-connection.com/8bit-ulaw.htm
            "Cuckoo_Clock.wav",      "ballgame1.wav",  //[10]
            //sample files from https://en.wikipedia.org/wiki/WAV
            "8k8bitpcm.wav",         "8k16bitpcm.wav", //[12]
            "8kulaw.wav",            "11k8bitpcm.wav",
            "11k16bitpcm.wav",       "11kulaw.wav",
            //sample files from http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/AU/Samples.html
            "M1F1-Alaw-AFsp.au",     "M1F1-mulaw-AFsp.au",   //[18]
            "M1F1-int8-AFsp.au",     "M1F1-int16-AFsp.au",   
            "M1F1-int24-AFsp.au",    "M1F1-int32-AFsp.au",   
            "M1F1-float32-AFsp.au",  "M1F1-float64-AFsp.au",  //float types FAIL: "file is not a supported file type"
            //sample files from http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/AIFF/Samples.html
            //CURRENTLY, ALL AIF SAMPLES FAIL
            "M1F1-AlawC-AFsp.aif",   "M1F1-mulawC-AFsp.aif", //[26]
            "M1F1-int8-AFsp.aif",    "M1F1-int8C-AFsp.aif",   
            "M1F1-int12-AFsp.aif",   "M1F1-int12C-AFsp.aif",   //12 bits is not supported
            "M1F1-int16-AFsp.aif",   "M1F1-int16C-AFsp.aif",   
            "M1F1-int24-AFsp.aif",   "M1F1-int24C-AFsp.aif",   
            "M1F1-int32-AFsp.aif",   "M1F1-int32C-AFsp.aif",   
            "M1F1-float32C-AFsp.aif","M1F1-float64C-AFsp.aif",   
            "M1F1-int16s-AFsp.aif",  ""};

        stop = Math.min(stop, names.length - 1);

        Table table = new Table();
        for (int i = start; i <= stop; i++) {
            try {
                String name = names[i];
                if (name.length() == 0)
                    continue;
                String2.log("\n* Table.testReadWriteWaveFiles #" + i + "=" + dir + name);
                String outName = File2.getSystemTempDirectory() + 
                    "write" + File2.forceExtension(name, ".wav");
                File2.delete(outName);
                table.readAudioFile(dir + name, true, false);  //readData, addElapsedTime
                String2.log(table.dataToString(16));

                table.writeWaveFile(outName);
                table.readAudioFile(outName, true, false);  //readData, addElapsedTime
                String2.log(table.dataToString(16));
                SSR.displayInBrowser("file://" + outName);

            } catch (Exception e) {
                String2.log(MustBe.throwableToString(e));
            }
            String2.pressEnterToContinue("Listen to the audio file. Then ");
        }
    }

    /** This tests writing a WAVE file with float stereo data. */
    public static void testReadWriteFloatWaveFile() throws Exception {
        String2.log("* testReadWriteFloatWaveFile");
        String fullName = File2.getSystemTempDirectory() + "testFloat.wav";
        File2.delete(fullName);
        Table table = new Table();
        table.readAudioFile(String2.unitTestDataDir + "audio/M1F1-float32-AFsp.wav", true, false);  //readData, addElapsedTime
        table.writeWaveFile(fullName);

        //read it  
        //DEAL WITH JAVA 8 BUG
        boolean java8 = System.getProperty("java.version").startsWith("1.8.");
        if (java8)
            SSR.displayInBrowser("file://" + fullName);
        else testReadFloatAudioFile(fullName);
        String2.pressEnterToContinue("Close the audio player if file is okay.");
    }

    /**
     * This is a minimalist readNetcdf which just reads specified rows
     * from specified variables from an .nc file and appends them
     * to the current data columns.
     * This doesn't read global attributes or variable attributes.
     * This doesn't unpack packed variables.
     * If the table initially has no columns, this creates columns
     * and reads column names; otherwise it doesn't read column names.
     *
     * @param loadVariables the variables in the .nc file which correspond
     *     to the columns in this table.
     *     They must all be ArrayXxx.D1 or ArrayChar.D2 variables and use the 
     *     same, one, dimension as the first dimension.
     *     If this is null or empty, nothing is done.
     * @param firstRow  the first row to be appended.
     * @param lastRow    the last row to be appended (inclusive).
     *   If lastRow is -1, firstRow is ignored and all of the data will be appended.
     * @throws Exception if trouble
     */
    public void appendNcRows(Variable loadVariables[], int firstRow, int lastRow) throws Exception {

        //if (reallyVerbose) String2.log("Table.appendNcRows firstRow=" + firstRow + 
        //    " lastRow=" + lastRow);
        if (loadVariables == null || loadVariables.length == 0) {
            if (verbose) String2.log("Table.appendNcRows: nVariables=0 so nothing done");
            return;
        }

        boolean needToAddColumns = nColumns() == 0;
        for (int col = 0; col < loadVariables.length; col++) {

            //get the data 
            Variable variable = loadVariables[col];
            PrimitiveArray pa = lastRow == -1?
                NcHelper.getPrimitiveArray(variable) :
                NcHelper.getPrimitiveArray(variable, firstRow, lastRow);
            //2016-05-20 If chars in ArrayChar.D1 were read as 1 string, 
            //  convert the 1 string into a CharArray
            if (variable.getDataType() == DataType.CHAR && 
                variable.getRank() == 1 &&
                pa instanceof StringArray && pa.size() == 1) {                
                pa = new CharArray(pa.getString(0).toCharArray());
            }
            if (needToAddColumns) {
                addColumn(variable.getShortName(), pa);
            } else getColumn(col).append(pa);
        }
    }


    /**
     * This appends the okRows from a .nc file.
     * This doesn't read global attributes or variable attributes.
     * This doesn't unpack packed variables.
     * If the table initially has no columns, this creates columns
     * and reads column names; otherwise it doesn't read column names.
     *
     * @param loadVariables the variables to be loaded.
     *     They must all be ArrayXxx.D1 or ArrayChar.D2 variables and use the 
     *     same, one, dimension as the first dimension.
     *     This must not be null or empty.
     *     If you have variable names, use ncFile.findVariable(name);
     * @param okRows  
     * @throws Exception if trouble
     */
    public void appendNcRows(Variable loadVariables[], BitSet okRows) throws Exception {
        //this is tested in PointSubset

        String errorInMethod = String2.ERROR + " in appendNcRows: ";
        long time = System.currentTimeMillis();

        //get the desired rows   (first call adds pa's to data and adds columnNames)
        int n = okRows.size();
        int firstRow = okRows.nextSetBit(0);
        int nAppendCalls = 0;
        while (firstRow >= 0) {
            //find end of sequence of okRows
            int endRow = firstRow == n-1? n : okRows.nextClearBit(firstRow + 1);
            if (endRow == -1)
                endRow = n;

            //get the data
            appendNcRows(loadVariables, firstRow, endRow - 1);
            nAppendCalls++;
            
            //first start of next sequence of okRows
            if (endRow >= n - 1)
                firstRow = -1;
            else firstRow = okRows.nextSetBit(endRow + 1); 
        }
        String2.log("Table.appendNcRows done. nAppendCalls=" + nAppendCalls +
            " nRows=" + nRows() + 
            " TIME=" + (System.currentTimeMillis() - time) + "ms");

    }



    /**
     * This appends okRows rows from a .nc file by doing one big read
     * and then removing unwanted rows -- thus it may be more suited
     * for opendap since it may avoid huge numbers of separate reads.
     * This doesn't read global attributes or variable attributes.
     * This doesn't unpack packed variables.
     * If the table initially has no columns, this creates columns
     * and reads column names; otherwise it doesn't read column names.
     *
     * @param loadVariables the variables to be loaded.
     *     They must all be ArrayXxx.D1 or ArrayChar.D2 variables and use the 
     *     same, one, dimension as the first dimension.
     *     This must not be null or empty.
     * @param okRows
     * @throws Exception if trouble
     */
    public void blockAppendNcRows(Variable loadVariables[], BitSet okRows) throws Exception {
        //this is tested in PointSubset

        String errorInMethod = String2.ERROR + " in blockAppendNcRows: ";
        long time = System.currentTimeMillis();
      
        //!!****THIS HASN'T BEEN MODIFIED TO DO BLOCK READ YET

        //get the desired rows   (first call adds pa's to data and adds columnNames)
        int n = okRows.size();
        int firstRow = okRows.nextSetBit(0);
        int nAppendCalls = 0;
        while (firstRow >= 0) {
            //find end of sequence of okRows
            int endRow = firstRow == n-1? n : okRows.nextClearBit(firstRow + 1);
            if (endRow == -1)
                endRow = n;

            //get the data
            appendNcRows(loadVariables, firstRow, endRow - 1);
            nAppendCalls++;
            
            //first start of next sequence of okRows
            if (endRow >= n - 1)
                firstRow = -1;
            else firstRow = okRows.nextSetBit(endRow + 1); 
        }
        String2.log("Table.blockAppendNcRows done. nAppendCalls=" + nAppendCalls +
            " nRows=" + nRows() + 
            " TIME=" + (System.currentTimeMillis() - time) + "ms");

    }

    /**
     * This calls convertToStandardMissingValues for all columns.
     *
     * <p>!!!This is used inside the readXxx methods. 
     * And this is used inside saveAsXxx methods to convert fake missing values
     * back to NaNs. It is rarely called elsewhere.
     *
     */
    public void convertToStandardMissingValues() {
        int nColumns = nColumns();
        for (int col = 0; col < nColumns; col++)
            convertToStandardMissingValues(col);
    }

    /**
     * If this column has _FillValue and/or missing_value attributes,
     * those values are converted to standard PrimitiveArray-style missing values
     * and the attributes are removed.
     *
     * <p>!!!This is used inside the readXxx methods. 
     * And this is used inside saveAsXxx methods to convert fake missing values
     * back to NaNs. It is rarely called elsewhere.
     *
     * @param column
     */
    public void convertToStandardMissingValues(int column) {
        Attributes colAtt = columnAttributes(column);
        //double mv = colAtt.getDouble("missing_value");
        //String2.log(">> Table.convert " + getColumnName(column) + "\n" + colAtt.toString());
        int nSwitched = getColumn(column).convertToStandardMissingValues( 
            colAtt.getString("_FillValue"),
            colAtt.getString("missing_value"));
        //if (!Double.isNaN(mv)) String2.log("  convertToStandardMissingValues mv=" + mv + " n=" + nSwitched);

        //remove current attributes or define new _FillValue
        colAtt.remove("missing_value");
        PrimitiveArray pa = getColumn(column);
        PAType paPAType = pa.elementType();
        if (pa.isFloatingPointType() || paPAType == PAType.STRING) { 
            colAtt.remove("_FillValue");
        } else {  //integer or char
            colAtt.set("_FillValue", PrimitiveArray.factory(paPAType, 1, ""));
        }
    }


    /**
     * This calls convertToFakeMissingValues for all columns.
     * !!!This is used inside the saveAsXxx methods to temporarily 
     * convert to fake missing values. It is rarely called elsewhere.
     *
     */
    public void convertToFakeMissingValues() {
        int nColumns = nColumns();
        for (int col = 0; col < nColumns; col++)
            convertToFakeMissingValues(col);
    }

    /**
     * This sets (or revises) the missing_value and _FillValue metadata
     * to DataHelper.FAKE_MISSING_VALUE for FloatArray and DoubleArray 
     * and the standard missing value (e.g., Xxx.MAX_VALUE) for other PrimitiveArrays.
     * This works on the current (possibly packed) data. So call this when the
     * data is packed.
     * If the column is a StringArray or CharArray column, nothing will be done.
     *
     * <p>!!!This is used inside the saveAsXxx methods to temporarily 
     * convert to fake missing values. It is rarely called elsewhere.
     *
     * @param column
     */
    public void convertToFakeMissingValues(int column) {
        //String2.log("Table.convertToFakeMissingValues column=" + column);
        PrimitiveArray pa = getColumn(column);
        PAType paType = pa.elementType();
        if (paType == PAType.STRING ||
            paType == PAType.CHAR) 
            return;
        //boolean removeMVF = false;  //commented out 2010-10-26 so NDBC files have consistent _FillValue
        if        (paType == PAType.CHAR) {
            columnAttributes(column).set("missing_value", Character.MAX_VALUE);
            columnAttributes(column).set("_FillValue",    Character.MAX_VALUE);
            //removeMVF = ((CharArray)pa).indexOf(Character.MAX_VALUE, 0) < 0;
        } else if (paType == PAType.BYTE) {
            columnAttributes(column).set("missing_value", Byte.MAX_VALUE);
            columnAttributes(column).set("_FillValue",    Byte.MAX_VALUE);
            //removeMVF = ((ByteArray)pa).indexOf(Byte.MAX_VALUE, 0) < 0;
        } else if (paType == PAType.UBYTE) {
            columnAttributes(column).set("missing_value", UByteArray.MAX_VALUE);
            columnAttributes(column).set("_FillValue",    UByteArray.MAX_VALUE);
        } else if (paType == PAType.SHORT) {
            columnAttributes(column).set("missing_value", Short.MAX_VALUE);
            columnAttributes(column).set("_FillValue",    Short.MAX_VALUE);
            //removeMVF = ((ShortArray)pa).indexOf(Short.MAX_VALUE, 0) < 0;
        } else if (paType == PAType.USHORT) {
            columnAttributes(column).set("missing_value", UShortArray.MAX_VALUE);
            columnAttributes(column).set("_FillValue",    UShortArray.MAX_VALUE);
        } else if (paType == PAType.INT) {
            columnAttributes(column).set("missing_value", Integer.MAX_VALUE);
            columnAttributes(column).set("_FillValue",    Integer.MAX_VALUE);
            //removeMVF = ((IntArray)pa).indexOf(Integer.MAX_VALUE, 0) < 0;
        } else if (paType == PAType.UINT) {
            columnAttributes(column).set("missing_value", UIntArray.MAX_VALUE);
            columnAttributes(column).set("_FillValue",    UIntArray.MAX_VALUE);
        } else if (paType == PAType.LONG) {
            columnAttributes(column).set("missing_value", Long.MAX_VALUE);
            columnAttributes(column).set("_FillValue",    Long.MAX_VALUE);
            //removeMVF = ((LongArray)pa).indexOf(Long.MAX_VALUE, 0) < 0;
        } else if (paType == PAType.ULONG) {
            columnAttributes(column).set("missing_value", ULongArray.MAX_VALUE);
            columnAttributes(column).set("_FillValue",    ULongArray.MAX_VALUE);
        } else if (paType == PAType.FLOAT) {
            columnAttributes(column).set("missing_value", (float)DataHelper.FAKE_MISSING_VALUE);
            columnAttributes(column).set("_FillValue",    (float)DataHelper.FAKE_MISSING_VALUE);
            pa.switchFromTo("", "" + DataHelper.FAKE_MISSING_VALUE);
            //removeMVF = ((FloatArray)pa).indexOf((float)DataHelper.FAKE_MISSING_VALUE, 0) < 0; //safer to search, in case values were already fake mv
        } else if (paType == PAType.DOUBLE) {
            columnAttributes(column).set("missing_value", DataHelper.FAKE_MISSING_VALUE);
            columnAttributes(column).set("_FillValue",    DataHelper.FAKE_MISSING_VALUE);
            pa.switchFromTo("", "" + DataHelper.FAKE_MISSING_VALUE);
            //removeMVF = ((DoubleArray)pa).indexOf(DataHelper.FAKE_MISSING_VALUE, 0) < 0; //safer to search, in case values were already fake mv
        } else return; //do nothing if e.g., StringArray

        //if there are no mv's, remove missing_value and _FillValue attributes.
        //For example, coordinate columns (lon, lat, depth, time) should have
        //no missing values and hence no missing_value information.
        //Also, there is trouble with new FAKE_MISSING_VALUE (-9999999) being used for 
        //climatology time column: it is a valid time.
        //if (removeMVF) {
        //    columnAttributes(column).remove("missing_value");
        //    columnAttributes(column).remove("_FillValue");
        //}

    }


    /**
     * This does the equivalent of a left outer join 
     * (https://en.wikipedia.org/wiki/Join_%28SQL%29#Left_outer_join) 
     * -- by matching a keyColumn(s) 
     * in this table and the first column(s) (the key(s)) in the lookUpTable, 
     * the other columns in the lookUpTable are inserted right after keyColumn(s)
     * in this table with the values from the matching row with the matching key(s).
     *
     * <p>The names and attributes of this table's key columns are not changed.
     *
     * <p>The keys are matched via their string representation, so they can have
     * different elementPAType as long as their strings match.
     * E.g., byte, short, int, long, String are usually compatible.
     * Warning: But double = int will probably fail because "1.0" != "1".
     *
     * <p>If the keyCol value(s) isn't found in the lookUpTable, the
     * missing_value attribute (or _FillValue, or "") for the new columns provides the mv.
     *
     * <p>If you don't want to keep the original keyCol, just removeColumn(keyCol) afterwards.
     *
     * <p>If reallyVerbose, this tallies the not matched items and displays the top 50 to String2.log.
     *
     * @param nKeys  1 or more
     * @param keyCol the first key column in this table.
     *   If nKeys&gt;1, the others must immediately follow it.
     * @param mvKey if the key found in this table is "", this mvKey is used (or "" or null if not needed).
     *   E.g., if key="" is found, you might want to treat it as if key="0".
     *   If nKeys&gt;1, mvKey has the parts stored tab separated.
     * @param lookUpTable with its keyCol(s) as column 0+, in the same order
     *   as in this table (but not necessarily with identical columnNames). 
     *   This method won't change the lookUpTable.
     * @return a 'keep' BitSet indicating which rows were matched (set bits) 
     *   and which rows had no match in the lookUpTable (clear bits).
     * @throws RuntimeException if trouble (e.g., nKeys < 1, keyCol is invalid,
     *   or lookUpTable is null
     */
    public BitSet join(int nKeys, int keyCol, String mvKey, Table lookUpTable) {
        if (debugMode) {
            String2.log("  Debug: pre join(nKeys=" + nKeys + 
                " keyCol=#" + keyCol + "=" + getColumnName(keyCol) +  
                " mvKey=" + mvKey + "\n" +
                "    this table:  nColumns=" + nColumns() + ": " + getColumnNamesCSSVString());
            ensureValid();
            String2.log("    lookUpTable: nColumns=" + lookUpTable.nColumns() + 
                ": " + lookUpTable.getColumnNamesCSSVString());
            lookUpTable.ensureValid();
        }
        if (nKeys < 1) 
            throw new RuntimeException(String2.ERROR + " in Table.join: nKeys=" +
                nKeys + " must be at least 1.");
        if (keyCol < 0 || keyCol + nKeys > nColumns())
            throw new RuntimeException(String2.ERROR + " in Table.join, in this table: nColumns=" + 
                nColumns() + 
                ". keyCol=#" + keyCol + " + nKeys=" + nKeys + " refers to non-existent columns.");
        if (nKeys == lookUpTable.nColumns()) {
            String2.log("WARNING: in Table.join: nKeys=lookUpTable.nColumns=" + nKeys + ",\n" +
                "  so there are no subsequent columns to be inserted in this table,\n" + 
                "  so there is nothing to be done, so returning immediately.\n" + 
                "  this table:  nColumns=" + nColumns() + ": " +getColumnNamesCSSVString() + "\n" +
                "  lookUpTable: nColumns=" + lookUpTable.nColumns() + 
                    ": " + lookUpTable.getColumnNamesCSSVString());
            //for some tests: throw new RuntimeException("For testing, that Warning is upgraded to be an ERROR.");
        }
        if (nKeys > lookUpTable.nColumns()) 
            throw new RuntimeException(String2.ERROR + " in Table.join, in lookUpTable: nColumns=" + 
                lookUpTable.nColumns() + 
                ". nKeys=" + nKeys + ", so lookUpTable has no related information.");
        if (mvKey == null)
            mvKey = "";
        long time = System.currentTimeMillis();
        Tally notMatchedTally = null;
        if (debugMode)
            notMatchedTally = new Tally();

        //gather keyPA's
        PrimitiveArray keyPA[]  = new PrimitiveArray[nKeys];
        PrimitiveArray lutKeyPA[] = new PrimitiveArray[nKeys];
        for (int key = 0; key < nKeys; key++) {
            keyPA[key]    = getColumn(keyCol + key);
            lutKeyPA[key] = lookUpTable.getColumn(key);
        }

        //make hashtable of keys->new Integer(row#) in lookUpTable
        //so join is fast with any number of rows in lookUpTable
        int lutNRows = lutKeyPA[0].size();
        HashMap<String,Integer> hashMap = new HashMap(Math2.roundToInt(1.4 * lutNRows));
        for (int row = 0; row < lutNRows; row++) {
            StringBuilder sb = new StringBuilder(lutKeyPA[0].getString(row));
            for (int key = 1; key < nKeys; key++) 
                sb.append("\t" + lutKeyPA[key].getString(row));
            hashMap.put(sb.toString(), new Integer(row));
        }
        
        //insert columns to be filled
        int nRows = nRows();
        int lutNCols = lookUpTable.nColumns();
        PrimitiveArray lutPA[] = new PrimitiveArray[lutNCols]; //from the lut
        PrimitiveArray newPA[] = new PrimitiveArray[lutNCols]; //paralleling the lutPA
        String mvString[]      = new String[lutNCols];
        StringArray insertedColumnNames = new StringArray();
        for (int lutCol = nKeys; lutCol < lutNCols; lutCol++) {
            lutPA[lutCol] = lookUpTable.getColumn(lutCol);
            PAType tPAType = lutPA[lutCol].elementType();
            Attributes lutAtts = lookUpTable.columnAttributes(lutCol);
            mvString[lutCol] = lutAtts.getString("missing_value"); //preferred
            if (mvString[lutCol] == null) {
                mvString[lutCol] = lutAtts.getString("_FillValue"); //second choice
                if (mvString[lutCol] == null) 
                    mvString[lutCol] = ""; //default
            }

            newPA[lutCol] = PrimitiveArray.factory(tPAType, nRows, mvString[lutCol]);
            String colName = lookUpTable.getColumnName(lutCol);
            insertedColumnNames.add(colName);
            addColumn(keyCol + lutCol, colName, newPA[lutCol],
                (Attributes)(lutAtts.clone()));
        }

        //fill the new columns by matching the looking up the key value
        int nMatched = 0;
        BitSet matched = new BitSet();
        matched.set(0, nRows); //all true
        for (int row = 0; row < nRows; row++) {
            StringBuilder sb = new StringBuilder(keyPA[0].getString(row));
            for (int key = 1; key < nKeys; key++) 
                sb.append("\t" + keyPA[key].getString(row));
            String s = sb.toString();
            if (s.length() == nKeys-1) //just tabs separating ""
                s = mvKey;
            Integer obj = hashMap.get(s);
            if (obj == null) {
                //don't change the missing values already in the pa
                matched.clear(row);
                if (debugMode) notMatchedTally.add("NotMatched", s);
            } else {
                //copy values from lutPA's to newPA's
                nMatched++;
                int fRow = obj.intValue();
                for (int lutCol = nKeys; lutCol < lutNCols; lutCol++) 
                    newPA[lutCol].setFromPA(row, lutPA[lutCol], fRow);
            }
        }
        if (reallyVerbose) 
            String2.log("  Table.join(nKeys=" + nKeys + 
                " keyCol=#" + keyCol + "=" + getColumnName(keyCol) + 
                " insertedColumns=" + insertedColumnNames.toString() +
                ") nMatched=" + nMatched + " nNotMatched=" + (nRows - nMatched) + 
                " time=" + (System.currentTimeMillis() - time) + "ms");
        if (debugMode) {
            if (nRows - nMatched > 0)        
                String2.log("  Debug: NotMatched tally:\n" + notMatchedTally.toString(50));
            ensureValid();
        }

        return matched;
    }
    
    /**
     * This updates the data in this table with better data from otherTable
     * by matching rows based on the values in key columns which are in both tables
     * (like a batch version of SQL's UPDATE https://www.w3schools.com/sql/sql_update.asp).
     * Afterwards, this table will have rows for *all* of the values of the key columns
     * from both tables.  This is very fast and efficient, but may need lots of memory.
     *
     * <p>Values are grabbed from the other table by matching column names,
     * so otherTable's values have precedence. 
     * The columns in the two tables need not be the same, nor in the same order.
     * If otherTable doesn't have a matching column, 
     *   the current value (if any) isn't changed, or the new value will be
     *   the missing_value (or _FillValue) for the column (or "" if none).
     *
     * <p>The names and attributes of this table's columns won't be changed.
     * The initial rows in thisTable will be in the same order. 
     * New rows (for new key values) will be at the end (in their order
     * from otherTable).  
     *
     * <p>The key values are matched via their string representation, so they can have
     * different elementPATypes as long as their strings match.
     * E.g., byte, short, int, long, String are usually compatible.
     * Warning: But double = int will probably fail because "1.0" != "1".
     *
     * @param keyNames  these columns must be present in this table and otherTable
     * @param otherTable 
     * @return the number of existing rows that were matched.
     *    The number of new rows = otherTable.nRows() - nMatched.
     * @throws RuntimeException if trouble (e.g., keyCols not found
     *   or lookUpTable is null)
     */
    public int update(String keyNames[], Table otherTable) {
        String msg = String2.ERROR + " in Table.update: ";
        long time = System.currentTimeMillis();
        int nRows = nRows();
        int nOtherRows = otherTable.nRows();
        int nCols = nColumns();
        int nKeyCols = keyNames.length;
        if (nKeyCols < 1) 
            throw new RuntimeException(msg + "nKeys=" +
                nKeyCols + " must be at least 1.");
        int keyCols[]      = new int[nKeyCols];
        int otherKeyCols[] = new int[nKeyCols];
        PrimitiveArray keyPAs[]      = new PrimitiveArray[nKeyCols];
        PrimitiveArray otherKeyPAs[] = new PrimitiveArray[nKeyCols];
        for (int key = 0; key < nKeyCols; key++) {
            keyCols[     key] =            findColumnNumber(keyNames[key]);
            otherKeyCols[key] = otherTable.findColumnNumber(keyNames[key]);
            if (keyCols[key] < 0)
                throw new RuntimeException(msg + "keyName=" + keyNames[key] + 
                    " not found in this table.");
            if (otherKeyCols[key] < 0)
                throw new RuntimeException(msg + "keyName=" + keyNames[key] + 
                    " not found in otherTable.");
            keyPAs[     key] =            getColumn(     keyCols[key]);
            otherKeyPAs[key] = otherTable.getColumn(otherKeyCols[key]);
        }

        //make hashmap of this table's key values to row#
        HashMap rowHash = new HashMap(Math2.roundToInt(1.4 * nRows));
        for (int row = 0; row < nRows; row++) {
            StringBuilder sb = new StringBuilder();
            for (int key = 0; key < nKeyCols; key++) 
                sb.append(keyPAs[key].getString(row) + "\n");
            rowHash.put(sb.toString(), new Integer(row));
        }

        //find columns in otherTable which correspond to the columns in this table
        int otherCols[] = new int[nCols];
        PrimitiveArray otherPAs[] = new PrimitiveArray[nCols];
        String missingValues[] = new String[nCols];
        Arrays.fill(missingValues, "");
        int nColsMatched = 0;
        StringArray colsNotMatched = new StringArray();
        for (int col = 0; col < nCols; col++) {
            otherCols[col] = otherTable.findColumnNumber(getColumnName(col));
            if (otherCols[col] >= 0) {
                nColsMatched++;
                otherPAs[col] = otherTable.getColumn(otherCols[col]);
            } else {
                colsNotMatched.add(getColumnName(col));
            }

            //collect missing values
            Attributes atts = columnAttributes(col);
            String mv = atts.getString("missing_value");
            if (mv == null)
                mv = atts.getString("_FillValue");
            if (mv != null)
                missingValues[col] = mv;
        }

        //go through rows of otherTable
        int nNewRows = 0;
        int nRowsMatched = 0;
        for (int otherRow = 0; otherRow < nOtherRows; otherRow++) {
            //for each, find the matching row in this table (or not)
            StringBuilder sb = new StringBuilder();
            for (int key = 0; key < nKeyCols; key++) 
                sb.append(otherKeyPAs[key].getString(otherRow) + "\n");
            String sbString = sb.toString();
            Object thisRowI = rowHash.get(sbString);
            if (thisRowI == null) {
                //add blank row at end
                nNewRows++;
                rowHash.put(sbString, new Integer(nRows++));
                for (int col = 0; col < nCols; col++) {
                    if (otherPAs[col] == null)
                         getColumn(col).addString(missingValues[col]);
                    else getColumn(col).addFromPA(otherPAs[col], otherRow);
                }
            } else {
                //replace current values
                nRowsMatched++;
                for (int col = 0; col < nCols; col++) {
                    //if otherTable doesn't have matching column, current value isn't changed
                    if (otherPAs[col] != null) 
                        getColumn(col).setFromPA(((Integer)thisRowI).intValue(), 
                            otherPAs[col], otherRow);
                }
            }
        }
        if (reallyVerbose) String2.log("Table.update finished." +
            " nColsMatched=" + nColsMatched + " of " + nCols + 
              (nColsMatched == nCols? "" : " (missing: " + colsNotMatched.toString() + ")") +
            ", nRowsMatched=" + nRowsMatched +
            ", nNewRows=" + nNewRows + 
            ", time=" + (System.currentTimeMillis() - time) + "ms");
        return nRowsMatched;
    }
    

    /* *  THIS IS INACTIVE.
     * This reads a NetCDF file with no structure or groups, but with
     * at least one dimension and at least 1 1D array variable that uses that 
     * dimension, and populates the public variables.
     * Suitable files include LAS Intermediate NetCDF files.
     *
     * <p>If there is a time variable with attribute "units"="seconds",
     *   and storing seconds since 1970-01-01T00:00:00Z. 
     *   See [COARDS] "Time or date dimension".
     * <p>The file may have a lat variable with attribute "units"="degrees_north" 
     *   to identify the latitude variable. See [COARDS] "Latitude Dimension".
     *   It can be of any numeric data type.
     * <p>The file may have a lon variable with attribute "units"="degrees_east" 
     *   to identify the longitude variable. See [COARDS] "Longitude Dimension".
     *   It can be of any numeric data type.
     *
     * <p>netcdf files are read with code in
     * netcdf-X.X.XX.jar which is part of the
     * <a href="https://www.unidata.ucar.edu/software/netcdf-java/"
     * >NetCDF Java Library</a>
     * renamed as netcdf-latest.jar.
     * Put it in the classpath for the compiler and for Java.
     *
     * <p>This sets globalAttributes and columnAttributes.
     *
     * @param fullFileName the full name of the file, for diagnostic messages.
     * @param ncFile an open ncFile
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat
     * @param okRows indicates which rows should be kept.
     *   This is used as the starting point for the tests (the tests may reject
     *   rows which are initially ok) or can be used without tests. It may be null.
     * @param testColumns the names of the columns to be tested (null = no tests).
     *   All of the test columns must use the same, one, dimension that the
     *   loadColumns use.
     *   Ideally, the first tests will greatly restrict the range of valid rows.
     * @param testMin the minimum allowed value for each testColumn (null = no tests)
     * @param testMax the maximum allowed value for each testColumn (null = no tests)
     * @param loadColumns the names of the columns to be loaded.
     *     They must all be ArrayXxx.D1 or ArrayChar.D2 variables and use the 
     *     same, one, dimension as the first dimension.
     *     If loadColumns is null, this will read all of the variables in the
     *     main group which use the biggest rootGroup dimension as their 
     *     one and only dimension.
     * @throws Exception if trouble
     */
/*    public void readNetCDF(String fullFileName, NetcdfFile ncFile, 
        int standardizeWhat, BitSet okRows,
        String testColumns[], double testMin[], double testMax[], 
        String loadColumns[]) throws Exception {

        //if (reallyVerbose) String2.log(File2.hexDump(fullFileName, 300));
        if (reallyVerbose) String2.log("Table.readNetCDF" +
            "\n  testColumns=" + String2.toCSSVString(testColumns) + 
            "\n  testMin=" + String2.toCSSVString(testMin) + 
            "\n  testMax=" + String2.toCSSVString(testMax) + 
            "\n  loadColumns=" + String2.toCSSVString(loadColumns)); 
        
        //setup
        long time = System.currentTimeMillis();
        clear();
        String errorInMethod = String2.ERROR + " in Table.readNetCDF(" + fullFileName + "):\n"; 

        //*** ncdump  //this is very slow for big files
        //if (reallyVerbose) String2.log(NcHelper.ncdump(fullFileName, "-h"));

        //read the globalAttributes
        if (reallyVerbose) String2.log("  read the globalAttributes");
        globalAttributes = new ArrayList();
        List globalAttList = ncFile.globalAttributes();
        for (int att = 0; att < globalAttList.size(); att++) {
            Attribute gAtt = (Attribute)globalAttList.get(att);
            globalAttributes.add(gAtt.getShortName());
            globalAttributes.add(PrimitiveArray.factory(
                DataHelper.getArray(gAtt.getValues())));
        }

        //find the mainDimension
        Dimension mainDimension = null;
        if (loadColumns == null) {
            //assume mainDimension is the biggest dimension
            //FUTURE: better to look for 1d arrays and find the largest?
            //   Not really, because lat and lon could have same number 
            //   but they are different dimension.
            List dimensions = ncFile.getDimensions(); //next nc version: rootGroup.getDimensions();
            if (dimensions.size() == 0)
                throw new SimpleException(errorInMethod + "the file has no dimensions.");
            mainDimension = (Dimension)dimensions.get(0);
            if (!mainDimension.isUnlimited()) {
                for (int i = 1; i < dimensions.size(); i++) {
                    if (reallyVerbose) String2.log("  look for biggest dimension, check " + i);
                    Dimension tDimension = (Dimension)dimensions.get(i);
                    if (tDimension.isUnlimited()) {
                        mainDimension = tDimension;
                        break;
                    }
                    if (tDimension.getLength() > mainDimension.getLength())
                        mainDimension = tDimension;
                }
            }
        } else {
            //if loadColumns was specified, get mainDimension from loadColumns[0]
            if (reallyVerbose) String2.log("  get mainDimension from loadColumns[0]");
            Variable v = ncFile.findVariable(loadColumns[0]);
            mainDimension = v.getDimension(0);
        } 


        //make a list of the needed variables (loadColumns and testColumns)
        ArrayList allVariables = new ArrayList();
        if (loadColumns == null) {
            //get a list of all variables which use just mainDimension
            List variableList = ncFile.getVariables();
            for (int i = 0; i < variableList.size(); i++) {
                if (reallyVerbose) String2.log("  get all variables which use mainDimension, check " + i);
                Variable tVariable = (Variable)variableList.get(i);
                List tDimensions = tVariable.getDimensions();
                int nDimensions = tDimensions.size();
                if (reallyVerbose) String2.log("i=" + i + " name=" + tVariable.getFullName() + 
                    " type=" + tVariable.getDataType());
                if ((nDimensions == 1 && tDimensions.get(0).equals(mainDimension)) ||
                    (nDimensions == 2 && tDimensions.get(0).equals(mainDimension) && 
                         tVariable.getDataType() == DataType.CHAR)) {
                        allVariables.add(tVariable);
                }
            }
        } else {
            //make the list from the loadColumns and testColumns
            for (int i = 0; i < loadColumns.length; i++) {
                if (reallyVerbose) String2.log("  getLoadColumns " + i);
                allVariables.add(ncFile.findVariable(loadColumns[i]));
            }
            if (testColumns != null) {
                for (int i = 0; i < testColumns.length; i++) {
                    if (String2.indexOf(loadColumns, testColumns[i]) < 0) {
                        if (reallyVerbose) String2.log("  getTestColumns " + i);
                        allVariables.add(ncFile.findVariable(testColumns[i]));
                    }
                }
            }
        }
        if (reallyVerbose) String2.log("  got AllVariables " + allVariables.size());

        //get the data
        getNetcdfSubset(errorInMethod, allVariables, standardizeWhat, okRows,
            testColumns, testMin, testMax, loadColumns);

        if (reallyVerbose)
            String2.log("Table.readNetCDF nColumns=" + nColumns() +
                " nRows=" + nRows() + " time=" + (System.currentTimeMillis() - time) + "ms");
     
    }


    /**  THIS IS NOT YET FINISHED.
     * This reads all rows of all of the specified columns from an opendap
     * dataset.
     * This also reads global and variable attributes.
     * The data is always unpacked.
     *
     * <p>If the fullName is an http address, the name needs to start with "http:\\" 
     * (upper or lower case) and the server needs to support "byte ranges"
     * (see ucar.nc2.NetcdfFile documentation).
     * 
     * @param fullName This may be a local file name, an "http:" address of a
     *    .nc file, or an opendap url.
     * @param loadColumns if null, this searches for the (pseudo)structure variables
     * @throws Exception if trouble
     */
    public void readOpendap(String fullName, String loadColumns[]) throws Exception {

        //get information
        String msg = "  Table.readOpendap " + fullName;
        long time = System.currentTimeMillis();
        NetcdfFile netcdfFile = NcHelper.openFile(fullName);
        Attributes gridMappingAtts = null;
        try {
            Variable loadVariables[] = NcHelper.findVariables(netcdfFile, loadColumns);

            //fill the table
            clear();
            appendNcRows(loadVariables, 0, -1);
            NcHelper.getGlobalAttributes(netcdfFile, globalAttributes());
            for (int col = 0; col < loadVariables.length; col++) {
                NcHelper.getVariableAttributes(loadVariables[col], columnAttributes(col));

                //does this var point to the pseudo-data var with CF grid_mapping (projection) information?
                if (gridMappingAtts == null) {
                    gridMappingAtts = NcHelper.getGridMappingAtts(netcdfFile, 
                        columnAttributes(col).getString("grid_mapping"));
                    if (gridMappingAtts != null)
                        globalAttributes.add(gridMappingAtts);
                }
            }

            if (reallyVerbose) msg +=  
                " finished. nColumns=" + nColumns() + " nRows=" + nRows() + 
                " TIME=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            netcdfFile.close();
            if (reallyVerbose) String2.log(msg);
        }

    }
    

    /**
     * For compatibility with older programs, this calls readOpendapSequence(url, false).
     * 2016-12-07: With versions of Tomcat somewhere after 8.0, the url must be stongly percent-encoded.
     *
     * @param url  the url, already SSR.percentEncoded as needed
     */
    public void readOpendapSequence(String url) throws Exception {
        readOpendapSequence(url, false);
    }

    /**
     * This populates the table from an opendap one level or two-level (Dapper-style) sequence response.
     * See Opendap info: https://www.opendap.org/pdf/dap_2_data_model.pdf .
     * See Dapper Conventions: https://www.pmel.noaa.gov/epic/software/dapper/dapperdocs/conventions/ .
     * 2016-12-07: With versions of Tomcat somewhere after 8.0, the url must be stongly percent-encoded.
     *
     * <p>A typical dapper-style two-level nested sequence is:
     * <pre>
      Dataset {
          Sequence {
              Float32 lat;
              Float64 time;
              Float32 lon;
              Int32 _id;
              Sequence {
                  Float32 depth;
                  Float32 temp;
                  Float32 salinity;
                  Float32 pressure;
              } profile;
          } location;
      } northAtlantic;
     * </pre>
     * The resulting flat table created by this method has a column
     * for each variable (lat, time, lon, _id, depth, temp, salinity, pressure)
     * and a row for each measurement. 
     *
     * <p>Following the JDAP getValue return type, DUInt16 is converted to a Java short 
     * and DUInt32 is converted to a Java int.
     * 
     * <p>!!! Unlike the DAPPER convention, this method only supports one inner sequence;
     * otherwise, the response couldn't be represented as a simple table.
     *
     * <p>!!! Two-level sequences from DAPPER always seems to have 
     * data from different inner sequences separated by a row of NaNs 
     * (in the inner sequence variables)
     * to mark the end of the upper inner sequence's info.
     * I believe Dapper is doing this to mark the transition from one 
     * inner sequence to the next.
     *
     * <p>!!! Dapper doesn't return variables in the order that you requested 
     * them. It is unclear (to me) what determines the order.
     * 
     * <p>Remember that Dapper doesn't support constraints on non-axis 
     * variables! 
     *
     * <p>This clears the table before starting.
     * This sets the global and data attributes (see javadocs for DataHelper.getAttributesFromOpendap).
     *
     * <p>!!!I don't know if the opendap server auto-unpacks (scale, offset) the variables.
     * I have no test cases. This method just passes through what it gets.
     *
     * @param url This may include a constraint expression at the end
     *    e.g., ?latitude,longitude,time,WTMP&time>=1124463600.
     *    The url (pre "?") should have no extension, e.g., .dods, at the end.
     *    The query should already be SSR.percentEncoded as needed.
     * @param skipDapperSpacerRows if true, this skips the last row of each 
     *     innerSequence other than the last innerSequence (because Dapper
     *     puts NaNs in the row to act as a spacer).
     * @throws Exception if trouble
     */
    public void readOpendapSequence(String url, boolean skipDapperSpacerRows) throws Exception {

        if (reallyVerbose) String2.log("Table.readOpendapSequence url=\n" + url);
        String errorInMethod = String2.ERROR + " in Table.readOpendapSequence(" + url + "):\n";
        long time = System.currentTimeMillis();
        clear();
        DConnect dConnect = new DConnect(url, opendapAcceptDeflate, 1, 1);
        DAS das = dConnect.getDAS(OpendapHelper.DEFAULT_TIMEOUT);
        OpendapHelper.getAttributes(das, "GLOBAL", globalAttributes());

        //get the outerSequence information
        DataDDS dataDds = dConnect.getData(null); //null = no statusUI
        if (reallyVerbose)
            String2.log("  dConnect.getData time=" + (System.currentTimeMillis() - time) + "ms");
        BaseType firstVariable = (BaseType)dataDds.getVariables().nextElement();
        if (!(firstVariable instanceof DSequence)) 
            throw new Exception(errorInMethod + "firstVariable not a DSequence: name=" + 
                firstVariable.getName() + " type=" + firstVariable.getTypeName());
        DSequence outerSequence = (DSequence)firstVariable;
        int nOuterRows = outerSequence.getRowCount();
        int nOuterColumns = outerSequence.elementCount();
        AttributeTable outerAttributeTable = das.getAttributeTable(
            outerSequence.getLongName()); //I think getLongName == getName() here
        //String2.log("outerAttributeTable=" + outerAttributeTable);

        //create the columns
        int innerSequenceColumn = -1; //the outerCol with the inner sequence (or -1 if none)
        int nInnerColumns = 0;  //0 important if no innerSequenceColumn
        for (int outerCol = 0; outerCol < nOuterColumns; outerCol++) {
            //create the columns
            BaseType obt = outerSequence.getVar(outerCol); //this doesn't have data, just description of obt
            if      (obt instanceof DByte)    addColumn(obt.getName(), new ByteArray());
            else if (obt instanceof DFloat32) addColumn(obt.getName(), new FloatArray());
            else if (obt instanceof DFloat64) addColumn(obt.getName(), new DoubleArray());
            else if (obt instanceof DInt16)   addColumn(obt.getName(), new ShortArray());
            else if (obt instanceof DUInt16)  addColumn(obt.getName(), new ShortArray());
            else if (obt instanceof DInt32)   addColumn(obt.getName(), new IntArray());
            else if (obt instanceof DUInt32)  addColumn(obt.getName(), new IntArray());
            else if (obt instanceof DBoolean) addColumn(obt.getName(), new ByteArray()); //.nc doesn't support booleans, so store byte=0|1
            else if (obt instanceof DString)  addColumn(obt.getName(), new StringArray());
            else if (obt instanceof DSequence) {
                //*** Start Dealing With InnerSequence
                //Ensure this is the first innerSequence.
                //If there are two, the response can't be represented as a simple table.
                if (innerSequenceColumn != -1)
                    throw new Exception(errorInMethod + 
                        "The response has more than one inner sequence: " +
                        getColumnName(innerSequenceColumn) + " and " + obt.getName() + ".");
                innerSequenceColumn = outerCol;
                if (reallyVerbose) String2.log("  innerSequenceColumn=" + innerSequenceColumn);

                //deal with the inner sequence
                DSequence innerSequence = (DSequence)obt;
                nInnerColumns = innerSequence.elementCount();
                AttributeTable innerAttributeTable = das.getAttributeTable(innerSequence.getName());
                //String2.log("innerAttributeTable=" + innerAttributeTable);
                for (int innerCol = 0; innerCol < nInnerColumns; innerCol++) {

                    //create the columns
                    BaseType ibt = innerSequence.getVar(innerCol); //this doesn't have data, just description of ibt
                    if      (ibt instanceof DByte)    addColumn(ibt.getName(), new ByteArray());
                    else if (ibt instanceof DFloat32) addColumn(ibt.getName(), new FloatArray());
                    else if (ibt instanceof DFloat64) addColumn(ibt.getName(), new DoubleArray());
                    else if (ibt instanceof DInt16)   addColumn(ibt.getName(), new ShortArray());
                    else if (ibt instanceof DUInt16)  addColumn(ibt.getName(), new ShortArray());
                    else if (ibt instanceof DInt32)   addColumn(ibt.getName(), new IntArray());
                    else if (ibt instanceof DUInt32)  addColumn(ibt.getName(), new IntArray());
                    else if (ibt instanceof DBoolean) addColumn(ibt.getName(), new ByteArray()); //.nc doesn't support booleans, so store byte=0|1
                    else if (ibt instanceof DString)  addColumn(ibt.getName(), new StringArray());
                    else throw new Exception(errorInMethod + "Unexpected inner variable type=" + 
                        ibt.getTypeName() + " for name=" + ibt.getName());

                    //get the ibt attributes  
                    //(some servers return innerAttributeTable, some don't -- see test cases)
                    if (innerAttributeTable == null) {
                        //Dapper needs this approach
                        //note use of getLongName here
                        Attributes tAtt = columnAttributes(nColumns() - 1);
                        OpendapHelper.getAttributes(das, ibt.getLongName(), tAtt);
                        if (tAtt.size() == 0)
                            OpendapHelper.getAttributes(das, ibt.getName(), tAtt);
                    } else {
                        //note use of getName in this section
                        int tCol = nColumns() - 1; //the table column just created
                        //String2.log("try getting attributes for inner " + getColumnName(col));
                        dods.dap.Attribute attribute = innerAttributeTable.getAttribute(ibt.getName());
                        //it should be a container with the attributes for this column
                        if (attribute == null) {
                            String2.log(errorInMethod + "Unexpected: no attribute for innerVar=" + 
                                ibt.getName() + ".");
                        } else if (attribute.isContainer()) { 
                            OpendapHelper.getAttributes(attribute.getContainer(), 
                                columnAttributes(tCol));
                        } else {
                            String2.log(errorInMethod + "Unexpected: attribute for innerVar=" + 
                                ibt.getName() + " not a container: " + 
                                attribute.getName() + "=" + attribute.getValueAt(0));
                        }
                    }
                }
                //*** End Dealing With InnerSequence

            } else throw new Exception(errorInMethod + "Unexpected outer variable type=" + 
                obt.getTypeName() + " for name=" + obt.getName());

            //get the obt attributes 
            //(some servers return outerAttributeTable, some don't -- see test cases)
            if (obt instanceof DSequence) {
                //it is the innerSequence, so attributes already read
            } else if (outerAttributeTable == null) {
                //Dapper needs this approach
                //note use of getLongName here
                Attributes tAtt = columnAttributes(nColumns() - 1);
                OpendapHelper.getAttributes(das, obt.getLongName(), tAtt);
                //drds needs this approach
                if (tAtt.size() == 0)
                    OpendapHelper.getAttributes(das, obt.getName(), tAtt);
            } else {            
                //note use of getName in this section
                int tCol = nColumns() - 1; //the table column just created
                //String2.log("try getting attributes for outer " + getColumnName(col));
                dods.dap.Attribute attribute = outerAttributeTable.getAttribute(obt.getName());
                //it should be a container with the attributes for this column
                if (attribute == null) {
                    String2.log(errorInMethod + 
                        "Unexpected: no attribute for outerVar=" + obt.getName() + ".");
                } else if (attribute.isContainer()) { 
                    OpendapHelper.getAttributes(attribute.getContainer(), 
                        columnAttributes(tCol));
                } else {
                    String2.log(errorInMethod + "Unexpected: attribute for outerVar=" + 
                        obt.getName() + " not a container: " + 
                        attribute.getName() + "=" + attribute.getValueAt(0));
                }
            }
        }
        //if (reallyVerbose) String2.log("  columns were created.");

        //Don't ensure that an innerSequence was found
        //so that this method can be used for 1 or 2 level sequences.
        //String2.log("nOuterRows=" + nOuterRows);
        //String2.log(toString());

        //*** read the data (row-by-row, as it wants)
        for (int outerRow = 0; outerRow < nOuterRows; outerRow++) {
            Vector outerVector = outerSequence.getRow(outerRow);
            int col;

            //get data from innerSequence first (so nInnerRows is known)
            int nInnerRows = 1; //1 is important if no innerSequence
            if (innerSequenceColumn >= 0) {
                DSequence innerSequence = (DSequence)outerVector.get(innerSequenceColumn);
                nInnerRows = innerSequence.getRowCount();
                if (skipDapperSpacerRows && outerRow < nOuterRows -1)
                    nInnerRows--;
                //if (reallyVerbose) String2.log("  nInnerRows=" + nInnerRows + " nInnerCols=" + nInnerColumns);
                Test.ensureEqual(nInnerColumns, innerSequence.elementCount(),
                    errorInMethod + "Unexpected nInnerColumns for outer row #" + outerRow);
                col = innerSequenceColumn;
                for (int innerRow = 0; innerRow < nInnerRows; innerRow++) {
                    Vector innerVector = innerSequence.getRow(innerRow);
                    for (int innerCol = 0; innerCol < nInnerColumns; innerCol++) {
                        //if (reallyVerbose) String2.log("  OR=" + outerRow + " OC=" + col + " IR=" + innerRow + " IC=" + innerCol);
                        BaseType ibt = (BaseType)innerVector.get(innerCol); 
                        if      (ibt instanceof DByte)    (  (ByteArray)columns.get(col + innerCol)).add(((DByte)ibt).getValue());
                        else if (ibt instanceof DFloat32) ( (FloatArray)columns.get(col + innerCol)).add(((DFloat32)ibt).getValue());
                        else if (ibt instanceof DFloat64) ((DoubleArray)columns.get(col + innerCol)).add(((DFloat64)ibt).getValue());
                        else if (ibt instanceof DInt16)   ( (ShortArray)columns.get(col + innerCol)).add(((DInt16)ibt).getValue());
                        else if (ibt instanceof DUInt16)  ( (ShortArray)columns.get(col + innerCol)).add(((DUInt16)ibt).getValue());
                        else if (ibt instanceof DInt32)   (   (IntArray)columns.get(col + innerCol)).add(((DInt32)ibt).getValue());
                        else if (ibt instanceof DUInt32)  (   (IntArray)columns.get(col + innerCol)).add(((DUInt32)ibt).getValue());
                        else if (ibt instanceof DBoolean) (  (ByteArray)columns.get(col + innerCol)).add((byte)(((DBoolean)ibt).getValue()? 1 : 0)); //.nc doesn't support booleans, so store byte=0|1
                        else if (ibt instanceof DString)  ((StringArray)columns.get(col + innerCol)).add(((DString)ibt).getValue());
                        else throw new Exception(errorInMethod + "Unexpected inner variable type=" + 
                            ibt.getTypeName() + " for name=" + ibt.getName());
                    }
                }
            }

            //process the other outerCol
            //if (reallyVerbose) String2.log("  process the other outer col");
            col = 0; //restart at 0
            for (int outerCol = 0; outerCol < nOuterColumns; outerCol++) {
                //innerSequenceColumn already processed above
                if (outerCol == innerSequenceColumn) {
                    col += nInnerColumns;
                    continue; 
                }

                //note addN (not add)
                //I tried storing type of column to avoid instanceof, but no faster.
                BaseType obt = (BaseType)outerVector.get(outerCol);
                if      (obt instanceof DByte)    (  (ByteArray)columns.get(col++)).addN(nInnerRows, ((DByte)obt).getValue());
                else if (obt instanceof DFloat32) ( (FloatArray)columns.get(col++)).addN(nInnerRows, ((DFloat32)obt).getValue());
                else if (obt instanceof DFloat64) ((DoubleArray)columns.get(col++)).addN(nInnerRows, ((DFloat64)obt).getValue());
                else if (obt instanceof DInt16)   ( (ShortArray)columns.get(col++)).addN(nInnerRows, ((DInt16)obt).getValue());
                else if (obt instanceof DUInt16)  ( (ShortArray)columns.get(col++)).addN(nInnerRows, ((DUInt16)obt).getValue());
                else if (obt instanceof DInt32)   (   (IntArray)columns.get(col++)).addN(nInnerRows, ((DInt32)obt).getValue());
                else if (obt instanceof DUInt32)  (   (IntArray)columns.get(col++)).addN(nInnerRows, ((DUInt32)obt).getValue());
                else if (obt instanceof DBoolean) (  (ByteArray)columns.get(col++)).addN(nInnerRows, (byte)(((DBoolean)obt).getValue()? 1 : 0)); //.nc doesn't support booleans, so store byte=0|1
                else if (obt instanceof DString)  ((StringArray)columns.get(col++)).addN(nInnerRows, ((DString)obt).getValue());
                else throw new Exception(errorInMethod + "Unexpected outer variable type=" +
                    obt.getTypeName() + " for name=" + obt.getName());
            }
        }

        //since addition of data to different columns is helter-skelter,
        //ensure resulting table is valid (it's a fast test)
        ensureValid(); //throws Exception if not

        if (reallyVerbose) String2.log("  Table.readOpendapSequence done. url=" + url + 
            " nColumns=" + nColumns() + " nRows=" + nRows() + 
            " TOTAL TIME=" + (System.currentTimeMillis() - time) + "ms");
    }

    /**
     * This populates the table from an opendap sequence.
     * The test information and loadColumns will be used generate
     * a new url with a constraint expression. Opendap sequences
     * support constraint expressions; many other opendap datasets do not.
     * The testColumns and loadColumns must be in the same sequence.
     *
     * <p>!!!I don't know if this auto-unpacks (scale, offset) the variables.
     * I have no test cases.
     *
     * @param url The url may not include a constraint expression,
     *    since them method generates one to do the tests
     * @param testColumns the names of the columns to be tested. 
     *   If testColumns is null, no tests will be done.
     * @param testMin the minimum allowed value for each testColumn.
     *    Ignored if testColumns is null.
     * @param testMax the maximum allowed value for each testColumn.
     *    Ignored if testColumns is null.
     * @param loadColumns The columns to be downloaded for the rows were
     *    the test result is 'true'. If null, all columns will be loaded.
     * @param skipDapperSpacerRows if true, this skips the last row of each 
     *     innerSequence (other than the last innerSequence (because Dapper
     *     puts NaNs in the row to act as a spacer).
     * @throws Exception if trouble
     */
    public void readOpendapSequence(String url, 
        String testColumns[], double testMin[], double testMax[],
        String loadColumns[], boolean skipDapperSpacerRows) throws Exception {

        if (reallyVerbose) String2.log("Table.readOpendapSequence with restrictions...");
        StringBuilder qSB = new StringBuilder();
        if (loadColumns != null && loadColumns.length > 0) {
            qSB.append(loadColumns[0]);
            for (int col = 1; col < loadColumns.length; col++) 
                qSB.append("," + loadColumns[col]);
        }
        if (testColumns != null) {
            for (int col = 0; col < testColumns.length; col++) {
                qSB.append("&" + testColumns[col] + "%3E=" + testMin[col]);
                qSB.append("&" + testColumns[col] + "%3C=" + testMax[col]);
            }
        }
        readOpendapSequence(url + "?" + qSB.toString(), skipDapperSpacerRows);
    }


    /**
     * This populates the table from an opendap response.
     *
     * @param url This may include a constraint expression
     *    e.g., ?latitude,longitude,time,WTMP&time>==1124463600
     * @param loadColumns The columns from the response to be saved in the
     *    table (use null for have the methods search for all variables
     *    in a (pseudo)structure). These columns are not appended to the
     *    url.
     * @throws Exception if trouble
     */
/*    public void readOpendap(String url, String loadColumns[]) throws Exception {

        //get information
        String msg = "  Table.readOpendap " + url;
        long time = System.currentTimeMillis();
        NetcdfFile netcdfFile = NetcdfDataset.openDataset(url); //NetcdfDataset needed for opendap.
        try {
            List loadVariables = findNcVariables(netcdfFile, loadColumns);

            //fill the table
            clear();
            globalAttributes = getNcGlobalAttributes(netcdfFile);
            columnAttributes = getNcVariableAttributes(loadVariables);
            appendNcRows(loadVariables, 0, -1);
            if (reallyVerbose) msg += 
                " finished. nColumns=" + nColumns() + " nRows=" + nRows() + 
                " TIME=" + (System.currentTimeMillis() - time) + "ms");

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            try {
                netcdfFile.close(); //make sure it is explicitly closed
            } catch (Exception e) {
            }
            if (reallyVerbose) String2.log(msg);
        }
    }
*/


    /**
     * This forces the values in lonAr to be +/-180 or 0..360.
     * THIS ONLY WORKS IF MINLON AND MAXLON ARE BOTH WESTERN OR EASTERN HEMISPHERE.
     *
     * @param lonArray 
     * @param pm180 If true, lon values are forced to be +/-180. 
     *     If false, lon values are forced to be 0..360.
     */
    public static void forceLonPM180(PrimitiveArray lonArray, boolean pm180) {
        double stats[] = lonArray.calculateStats();
        int nRows = lonArray.size();
        String2.log("forceLon stats=" + String2.toCSSVString(stats));
        if (pm180 && stats[PrimitiveArray.STATS_MAX] > 180) {
            String2.log("  force >");
            for (int row = 0; row < nRows; row++) {
                lonArray.setDouble(row, Math2.looserAnglePM180(lonArray.getDouble(row))); 
            }
        } else if (!pm180 && stats[PrimitiveArray.STATS_MIN] < 0) {
            String2.log("  force <");
            for (int row = 0; row < nRows; row++) {
                lonArray.setDouble(row, Math2.looserAngle0360(lonArray.getDouble(row)));
            }
        }
    }


    /**
     * Make a subset of this data by retaining only the rows which 
     * pass the test.
     * For each column number in testColumns, there is a corresponding
     * min and max.
     * Rows of data will be kept if, for the value in each testColumns,
     * the value isn't NaN and is &gt;= min  and &lt;= max.
     * This doesn't touch xxxAttributes.
     * 
     * @param testColumnNumbers the column numbers to be tested
     * @param min the corresponding min allowed value
     * @param max the corresponding max allowed value
     */
    public void subset(int testColumnNumbers[], double min[], double max[]) {

        int nRows = nRows();
        int nColumns = nColumns();
        int nTestColumns = testColumnNumbers.length;
        PrimitiveArray testColumns[] = new PrimitiveArray[nTestColumns];
        for (int col = 0; col < nTestColumns; col++) {
            testColumns[col] = getColumn(testColumnNumbers[col]);
        }

        //go through the data looking for valid rows
        //copy successes to position nGood
        int nGood = 0;
        for (int row = 0; row < nRows; row++) {
            boolean ok = true;
            for (int testCol = 0; testCol < nTestColumns; testCol++) {
                double d = testColumns[testCol].getDouble(row);
                if (Double.isFinite(d) && d >= min[testCol] && d <= max[testCol]) {
                } else {
                    ok = false;
                    break;
                }
            }
            if (ok) {
                for (int col = 0; col < nColumns; col++)
                    getColumn(col).copy(row, nGood);
                nGood++;
            }
        }

        //remove excess at end of column
        for (int col = 0; col < nColumns; col++)
            getColumn(col).removeRange(nGood, getColumn(col).size());
    }

    /**
     * This is like tryToApplyConstraints, but just keeps the constraints=true rows (which may be 0).
     *
     * @param idCol  For reallyVerbose only: rejected rows will log the value 
     *    in this column (e.g., stationID) (or row= if idCol < 0). 
     * @param conNames may be null or size 0
     * @return the number of rows remaining in the table (may be 0)
     */
    public int tryToApplyConstraintsAndKeep(int idCol,
        StringArray conNames, StringArray conOps, StringArray conVals) {

        //no constraints 
        if (conNames == null || conNames.size() == 0)
            return nRows();

        //try to apply constraints
        BitSet keep = new BitSet();
        keep.set(0, nRows());
        int cardinality = tryToApplyConstraints(idCol, conNames, conOps, conVals, keep);
        if (cardinality == 0)
            removeAllRows();
        else justKeep(keep);

        return cardinality;
    }

    /**
     * This is like tryToApplyConstraint, but works on multiple constraints.
     * The table won't be changed.
     *
     * @param idCol  For reallyVerbose only: rejected rows will log the value 
     *    in this column (e.g., stationID) (or row# if idCol < 0). 
     * @param keep the bitset that will be modified. 
     *    If you are setting up keep for this, set the bit for each row to true.
     *    Rows where the bit is initially false won't even be checked.    
     * @return the number of keep=true rows (may be 0).  No rows are actually removed.
     */
    public int tryToApplyConstraints(int idCol,
        StringArray conNames, StringArray conOps, StringArray conVals, BitSet keep) {

        //no constraints
        if (conNames == null || conNames.size() == 0)
            return keep.cardinality();

        //try to apply constraints
        int cardinality = -1;  //it will be set below
        for (int i = 0; i < conNames.size(); i++) {
            cardinality = lowApplyConstraint(false, idCol, 
                conNames.get(i), conOps.get(i), conVals.get(i), keep);
            if (cardinality == 0) 
                return 0;
        }
        return cardinality;
    }

    /**
     * This tries to clear bits of keep (each representing a row), based on a constraint.
     * The table won't be changed.
     *
     * @param idCol  For reallyVerbose only: rejected rows will log the value 
     *    in this column (e.g., stationID) (or row= if idCol < 0). 
     * @param conName perhaps a column name in the table.   If not, this constraint is ignored.
     *    This correctly deals with float, double, and other data types.
     * @param conOp    an EDDTable-operator, e.g., "="
     * @param conVal  
     * @param keep the bitset that will be modified. 
     *    If you are setting up keep for this, set the bit for each row to true.
     *    Rows where the bit is initially false won't even be checked.    
     * @return keep.cardinality()
     */
    public int tryToApplyConstraint(int idCol,
        String conName, String conOp, String conVal, BitSet keep) {

        return lowApplyConstraint(false, idCol, conName, conOp, conVal, keep);
    }


    /**
     * This is like tryToApplyConstraint, but requires that the constraintVariable exist
     * in the table.
     *
     * @param keep the bitset that will be modified. 
     *    If you are setting up keep for this, set the bit for each row to true.
     *    Rows where the bit is initially false won't even be checked.    
     * @return keep.cardinality()
     */
    public int applyConstraint(int idCol,
        String conName, String conOp, String conVal, BitSet keep) {

        return lowApplyConstraint(true, idCol, conName, conOp, conVal, keep);
    }

    /** The low level method for tryToApplyConstraint and applyConstraint 
     *
     * @param keep the bitset that will be modified. 
     *    If you are setting up keep for this, set the bit for each row to true.
     *    Rows where the bit is initially false won't even be checked.    
     * @return keep.cardinality()
     */
    public int lowApplyConstraint(boolean requireConName, int idCol,
        String conName, String conOp, String conVal, BitSet keep) {

        if (keep.isEmpty())
            return 0;

        //if (debugMode) String2.log("\n    tryToApplyConstraint " + conName + conOp + conVal);

        //PrimitiveArray idPa = idCol >= 0? getColumn(idCol) : null;

        //is conName in the table?
        int conNameCol = findColumnNumber(conName);
        if (conNameCol < 0) {
            if (requireConName || reallyVerbose) {
                String msg = (requireConName? String2.ERROR + ": " : "") +
                     "applyConstraint: constraintVariable=" + conName + 
                     " isn't in the table (" + getColumnNamesCSVString() + ").";
                if (requireConName)
                    throw new RuntimeException(msg);
                if (debugMode) String2.log("    " + msg);
            }
            return keep.cardinality(); //unfortunate that time is perhaps wasted to calculate this
        }

        //test the keep=true rows for this constraint
        PrimitiveArray conPa = getColumn(conNameCol);
        int nKeep = conPa.applyConstraint(false, keep, conOp, conVal);

        if (reallyVerbose) 
            String2.log("    applyConstraint: after " + conName + conOp + "\"" + conVal + "\", " +
                nKeep + " rows remain");
        return nKeep;
    }


    /**
     * This is like ApplyConstraint, but actually removes the rows that don't match
     * the constraint.
     *
     * @return table.nRows()
     */
    public int oneStepApplyConstraint(int idCol,
        String conName, String conOp, String conVal) {

        BitSet keep = new BitSet();
        keep.set(0, nRows());
        lowApplyConstraint(true, idCol, conName, conOp, conVal, keep);
        justKeep(keep);
        return nRows();
    }


    /**
     * Make a subset of this data by retaining only the keep(row)==true rows.
     * 
     * @param keep This method won't modify the values in keep.
     * @return nRows
     */
    public void justKeep(BitSet keep) {
        int nColumns = nColumns();
        for (int col = 0; col < nColumns; col++)
            getColumn(col).justKeep(keep);
    }


    /**
     * This returns list of &amp;-separated parts, in their original order, from a percent encoded dapQuery.
     * This is like split('&amp;'), but smarter.
     * This accepts:
     * <ul>
     * <li>connecting &amp;'s already visible (within a part, 
     *     &amp;'s must be percent-encoded (should be) or within double quotes)
     * <li>connecting &amp;'s are percent encoded (they shouldn't be!) (within a part, 
     *     &amp;'s must be within double quotes).
     * </ul>
     *
     * @param dapQuery the part after the '?', still percentEncoded, may be null.
     * @return a String[] with the percentDecoded parts, in their original order,
     *   without the connecting &amp;'s.
     *   This part#0 is always the varnames (or "" if none).
     *   A null or "" dapQuery will return String[1] with #0=""
     * @throws Throwable if trouble (e.g., invalid percentEncoding)
     */
    public static String[] getDapQueryParts(String dapQuery) throws Exception {
        if (dapQuery == null || dapQuery.length() == 0)
            return new String[]{""};

        boolean stillEncoded = true;
        if (dapQuery.indexOf('&') < 0) {
            //perhaps user percentEncoded everything, even the connecting &'s, so decode everything right away
            dapQuery = SSR.percentDecode(dapQuery);
            stillEncoded = false;
        }
        //String2.log(">> dapQuery=" + dapQuery);

        //one way or another, connecting &'s should now be visible
        dapQuery += "&"; //& triggers grabbing final part
        int dapQueryLength = dapQuery.length();
        int start = 0;
        boolean inQuotes = false;
        StringArray parts = new StringArray(); 
        for (int po = 0; po < dapQueryLength; po++) {
            char ch = dapQuery.charAt(po);
            //String2.log(">> ch=" + ch);
            if (ch == '\\') {     //next char is \\ escaped
                if (po < dapQueryLength)
                    po++;
            } else if (ch == '"') {      
                inQuotes = !inQuotes;
            } else if (ch == '&' && !inQuotes) {
                String part = dapQuery.substring(start, po);
                parts.add(stillEncoded? SSR.percentDecode(part) : part);
                //String2.log(">> part=" + parts.get(parts.size() - 1));
                start = po + 1;
            }
        }
        if (inQuotes)
            throw new SimpleException(QUERY_ERROR + "A closing doublequote is missing.");
        //String2.log(">> parts=" + parts.toNewlineString());
        return parts.toArray();
    }

    /** This tests getDapQueryParts. */
    public static void testGetDapQueryParts() throws Exception {
        String2.log("\n*** Table.testGetDapQueryParts");

        //test Table.getDapQueryParts   
        Test.ensureEqual(getDapQueryParts(null), new String[]{""}, "");
        Test.ensureEqual(getDapQueryParts(""), new String[]{""}, "");
        Test.ensureEqual(getDapQueryParts("  "), new String[]{"  "}, "");
        Test.ensureEqual(getDapQueryParts("ab%3dc"), new String[]{"ab=c"}, "");  
        Test.ensureEqual(getDapQueryParts("a&b&c"), new String[]{"a", "b", "c"}, "");
        Test.ensureEqual(getDapQueryParts("&&"), new String[]{"", "", ""}, "");
        Test.ensureEqual(getDapQueryParts("a&b=R%26D"), new String[]{"a", "b=R&D"}, "");  //& visible
        Test.ensureEqual(getDapQueryParts("a%26b=\"R%26D\""), new String[]{"a", "b=\"R&D\""}, ""); //& encoded
        Test.ensureEqual(getDapQueryParts("a%26b=\"R%26D\"%26c"), new String[]{"a", "b=\"R&D\"", "c"}, ""); //& encoded
        Test.ensureEqual(getDapQueryParts("a%26b%3dR-D"), new String[]{"a", "b=R-D"}, ""); 

        //*** test getDapQueryParts (decoded) with invalid queries
        String error = "";
        try {
            getDapQueryParts("a%26b=\"R%26D");  //decoded.  unclosed "

        } catch (Throwable t) {
            error = MustBe.throwableToString(t);
        }

        Test.ensureEqual(String2.split(error, '\n')[0],
            "SimpleException: Query error: A closing doublequote is missing.", 
            "error=" + error);

        String2.log("\n*** Table.testGetDapQueryParts succeeded");
    }


    /**
     * This parses a PERCENT ENCODED OPeNDAP DAP-style query intended to subset this table.
     * This checks the validity of the resultsVariable and constraintVariable names.
     *
     * <p>Unofficially (e.g., for testing) the query can be already percent decoded
     * if there are no %dd in the query.
     *
     * <p>There can be a constraints on variables that
     * aren't in the user-specified results variables.
     * This procedure adds those variables to the returned resultsVariables.
     *
     * <p>If the constraintVariable is time, the value
     * can be numeric ("seconds since 1970-01-01") 
     * or String (ISO format, e.g., "1996-01-31T12:40:00", at least yyyy-MM)
     * or now(+|-)(seconds|minutes|hours|days|months|years).
     * All variants are converted to epochSeconds.
     *
     * <p>Different from ERDDAP: To work as expected, timestamp columns are assumed
     * to have double epoch seconds values and have Calendar2.isTimeUnits(units) metadata.
     *
     * @param dapQuery is the opendap DAP-style query, 
     *      after the '?', still percentEncoded (shouldn't be null), e.g.,
     *      <tt>var1,var2,var3&amp;var4=value4&amp;var5%3E=value5</tt> .
     *    <br>Values for String variable constraints should be in double quotes.
     *    <br>A more specific example is 
     *      <tt>genus,species&amp;genus="Macrocystis"&amp;LAT%3C=53&amp;LAT%3C=54</tt> .
     *    <br>If no results variables are specified, all will be returned.
     *      See OPeNDAP specification, section 6.1.1.
     *    <br>Note that each constraint's left hand side must be a variable
     *      and its right hand side must be a value.
     *    <br>The valid operators (for numeric and String variables) are "=", "!=", "&lt;", "&lt;=",  
     *      "&gt;", "&gt;=", and "=~" (REGEX_OP, which looks for data values
     *      matching the regular expression on the right hand side),
     *      but in percent encoded form. 
     *      (see https://docs.opendap.org/index.php/UserGuideOPeNDAPMessages#Selecting_Data:_Using_Constraint_Expressions).
     *    <br>If an &amp;-separated part is "distinct()", "orderBy("...")", 
     *      "orderByMax("...")", "orderByMin("...")", "orderByMinMax("...")", 
     *      "orderByCount("...")", 
     *      "orderByClosest("...")", "orderByLimit("...")", "units("...")", 
     *      it is ignored.
     *    <br>If an &amp;-separated part starts with ".", it is ignored.
     *      It can't be a variable name.
     *      &amp;.[param]=value is used to pass special values (e.g., &amp;.colorBar=...).
     * @param resultsVariables to be appended with the results variables' 
     *    destinationNames, e.g., {var1,var2,var3}.
     *    <br>If a variable is needed for constraint testing in standardizeResultsTable
     *      but is not among the user-requested resultsVariables, it won't be added 
     *      to resultsVariables.
     * @param constraintVariables to be appended with the constraint variables' 
     *    destinationNames, e.g., {var4,var5}.
     *    This method makes sure they are valid.
     *    These will not be percent encoded.
     * @param constraintOps to be appended with the constraint operators, e.g., {"=", "&gt;="}.
     *    These will not be percent encoded.
     * @param constraintValues to be appended with the constraint values, e.g., {value4,value5}.
     *    These will not be percent encoded.
     *    Non-regex EDVTimeStamp constraintValues will be returned as epochSeconds.
     * @param repair if true, this method tries to do its best repair problems (guess at intent), 
     *     not to throw exceptions 
     * @throws Throwable if invalid query
     *     (0 resultsVariables is a valid query)
     */
    public void parseDapQuery(String dapQuery, 
        StringArray resultsVariables,
        StringArray constraintVariables, StringArray constraintOps, StringArray constraintValues,
        boolean repair) throws Exception {
        //!!! Table.parseDapQuery and EDDTable.parseUserDapQuery ARE ALMOST IDENTICAL!!!
        //IF YOU MAKE CHANGES TO ONE, MAKE CHANGES TO THE OTHER.

        //parse dapQuery into parts
        String parts[] = getDapQueryParts(dapQuery); //decoded.  always at least 1 part (may be "")
        resultsVariables.clear();
        constraintVariables.clear(); 
        constraintOps.clear(); 
        constraintValues.clear();

        //expand no resultsVariables (or entire sequence) into all results variables
        //look at part0 with comma-separated vars 
        int nCols = nColumns();
        if (parts[0].length() == 0 || parts[0].equals(SEQUENCE_NAME)) {
            if (debugMode) String2.log("  dapQuery parts[0]=\"" + parts[0] + 
                "\" is expanded to request all variables.");
            for (int v = 0; v < nCols; v++) {
                resultsVariables.add(columnNames.get(v));
            }
        } else {
            String cParts[] = String2.split(parts[0], ',');
            for (int cp = 0; cp < cParts.length; cp++) {

                //request uses sequence.dataVarName notation?
                String tVar = cParts[cp].trim();
                int period = tVar.indexOf('.');
                if (period > 0 && tVar.substring(0, period).equals(SEQUENCE_NAME)) 
                    tVar = tVar.substring(period + 1);

                //is it a valid destinationName?
                int po = columnNames.indexOf(tVar);
                if (po < 0) {
                    if (!repair) {
                        if (tVar.equals(SEQUENCE_NAME))
                            throw new SimpleException(QUERY_ERROR +
                                 "If " + SEQUENCE_NAME + " is requested, it must be the only requested variable.");
                        for (int op = 0; op < OPERATORS.length; op++) {
                            int opPo = tVar.indexOf(OPERATORS[op]);
                            if (opPo >= 0)
                                throw new SimpleException(
                                    QUERY_ERROR + "All constraints (including \"" +
                                    tVar.substring(0, opPo + OPERATORS[op].length()) + 
                                    "...\") must be preceded by '&'.");
                        }
                        throw new SimpleException(QUERY_ERROR +
                             "Unrecognized variable=\"" + tVar + "\".");
                    }
                } else {
                    //it's valid; is it a duplicate?
                    if (resultsVariables.indexOf(tVar) >= 0) {
                        if (!repair) 
                            throw new SimpleException(QUERY_ERROR +
                                "variable=" + tVar + " is listed twice in the results variables list.");
                    } else {
                        resultsVariables.add(tVar);
                    }
                }
            }
        }
        //String2.log("resultsVariables=" + resultsVariables);

        //get the constraints 
        for (int p = 1; p < parts.length; p++) {
            //deal with one constraint at a time
            String constraint = parts[p]; 
            int constraintLength = constraint.length();
            //String2.log("constraint=" + constraint); 
            int quotePo = constraint.indexOf('"');
            String constraintBeforeQuotes = quotePo >= 0? constraint.substring(0, quotePo) : constraint;            
            
            //special case: ignore constraint starting with "." 
            //(can't be a variable name)
            //use for e.g., .colorBar=...
            if (constraint.startsWith("."))
                continue;

            //special case: server-side functions
            if (constraint.equals("distinct()") ||
                (constraint.endsWith("\")") &&
                 (constraint.startsWith("orderBy(\"") ||
                  constraint.startsWith("orderByClosest(\"") ||
                  constraint.startsWith("orderByCount(\"") ||
                  constraint.startsWith("orderByLimit(\"") ||
                  constraint.startsWith("orderByMax(\"") ||
                  constraint.startsWith("orderByMin(\"") ||
                  constraint.startsWith("orderByMinMax(\"") ||
                  constraint.startsWith("units(\""))))
                continue;

            //look for == (common mistake, but not allowed)
            int eepo = constraintBeforeQuotes.indexOf("==");
            if (eepo >= 0) {
                if (repair) {
                    constraint = constraint.substring(0, eepo) + constraint.substring(eepo + 1);
                    quotePo = constraint.indexOf('"');
                    constraintBeforeQuotes = quotePo >= 0? constraint.substring(0, quotePo) : constraint;            
                } else {
                    throw new SimpleException(QUERY_ERROR +
                        "Use '=' instead of '==' in constraints.");
                }
            }

            //look for ~= (common mistake, but not allowed)
            if (constraintBeforeQuotes.indexOf("~=") >= 0) {
                if (repair) {
                    constraint = String2.replaceAll(constraint, "~=", "=~");
                    quotePo = constraint.indexOf('"');
                    constraintBeforeQuotes = quotePo >= 0? constraint.substring(0, quotePo) : constraint;            
                } else {
                    throw new SimpleException(QUERY_ERROR +
                        "Use '=~' instead of '~=' in constraints.");
                }
            }

            //find the valid op within constraintBeforeQuotes
            int op = 0;
            int opPo = -1;
            while (op < OPERATORS.length && 
                (opPo = constraintBeforeQuotes.indexOf(OPERATORS[op])) < 0)
                op++;
            if (opPo < 0) {
                if (repair) continue; //was IllegalArgumentException
                else throw new SimpleException(QUERY_ERROR +
                    "No operator found in constraint=\"" + constraint + "\".");
            }

            //request uses sequenceName.dataVarName notation?
            String tName = constraint.substring(0, opPo);
            int period = tName.indexOf('.');
            if (period > 0 && tName.substring(0, period).equals(SEQUENCE_NAME)) 
                tName = tName.substring(period + 1);

            //is it a valid destinationName?
            int dvi = columnNames.indexOf(tName);
            if (dvi < 0) {
                if (repair) continue;
                else throw new SimpleException(QUERY_ERROR +
                    "Unrecognized constraint variable=\"" + tName + "\"."
                    //+ "\nValid=" + String2.toCSSVString(dataVariableDestionNames())
                    );
            }

            constraintVariables.add(tName);
            constraintOps.add(OPERATORS[op]);
            String tValue = constraint.substring(opPo + OPERATORS[op].length());
            constraintValues.add(tValue);
            double conValueD = Double.NaN;

            if (debugMode) String2.log(">> constraint: " + tName + OPERATORS[op] + tValue);

            //convert <time><op><isoString> to <time><op><epochSeconds>   
            boolean constrainTimeStamp = Calendar2.isTimeUnits(
                columnAttributes(dvi).getString("units"));
            if (constrainTimeStamp) {
                //this isn't precise!!!   should it be required??? or forbidden???
                if (debugMode) String2.log(">> isTimeStamp=true");
                if (tValue.startsWith("\"") && tValue.endsWith("\"")) { 
                    tValue = String2.fromJsonNotNull(tValue);
                    constraintValues.set(constraintValues.size() - 1, tValue);
                }                

                //if not for regex, convert isoString to epochSeconds 
                if (OPERATORS[op] != PrimitiveArray.REGEX_OP) {
                    if (Calendar2.isIsoDate(tValue)) {
                        conValueD = repair? Calendar2.safeIsoStringToEpochSeconds(tValue) :
                            Calendar2.isoStringToEpochSeconds(tValue);
                        constraintValues.set(constraintValues.size() - 1,
                            "" + conValueD);
                        if (debugMode) String2.log(">> TIME CONSTRAINT converted in parseDapQuery: " + 
                            tValue + " -> " + conValueD);

                    } else if (tValue.toLowerCase().startsWith("now")) {
                        if (repair)
                             conValueD = Calendar2.safeNowStringToEpochSeconds(tValue, 
                                 (double)Math2.hiDiv(System.currentTimeMillis(), 1000));
                        else conValueD = Calendar2.nowStringToEpochSeconds(tValue);
                        constraintValues.set(constraintValues.size() - 1, "" + conValueD);


                    } else {
                        //it must be a number (epochSeconds)
                        //test that value=NaN must use NaN or "", not just an invalidly formatted number
                        conValueD = String2.parseDouble(tValue);
                        if (!Double.isFinite(conValueD) && !tValue.equals("NaN") && !tValue.equals("")) {
                            if (repair) {
                                tValue = "NaN";
                                conValueD = Double.NaN;
                                constraintValues.set(constraintValues.size() - 1, tValue);
                            } else {
                                throw new SimpleException(QUERY_ERROR +
                                    "Test for missing time values must use \"NaN\" or \"\", not value=\"" + tValue + "\".");
                            }
                        }
                    }
                }

            } else if (getColumn(dvi) instanceof StringArray) {

                //String variables must have " around constraintValues
                if ((tValue.startsWith("\"") && tValue.endsWith("\"")) || repair) {
                    //repair if needed
                    if (!tValue.startsWith("\""))
                        tValue = "\"" + tValue;
                    if (!tValue.endsWith("\""))
                        tValue = tValue + "\"";

                    //decode
                    tValue = String2.fromJsonNotNull(tValue);
                    constraintValues.set(constraintValues.size() - 1, tValue);

                } else {
                    throw new SimpleException(QUERY_ERROR +
                        "For constraints of String variables, " +
                        "the right-hand-side value must be surrounded by double quotes.\n" +
                        "Bad constraint: " + constraint);
                }

            } else {
                //numeric variables

                //if op=regex, value must have "'s around it
                if (OPERATORS[op] == PrimitiveArray.REGEX_OP) {
                    if ((tValue.startsWith("\"") && tValue.endsWith("\"")) || repair) {
                        //repair if needed
                        if (!tValue.startsWith("\""))
                            tValue = "\"" + tValue;
                        if (!tValue.endsWith("\""))
                            tValue = tValue + "\"";

                        //decode
                        tValue = String2.fromJsonNotNull(tValue);
                        constraintValues.set(constraintValues.size() - 1, tValue);
                    } else {
                        throw new SimpleException(QUERY_ERROR +
                            "For =~ constraints of numeric variables, " +
                            "the right-hand-side value must be surrounded by double quotes.\n" +
                            "Bad constraint: " + constraint);
                    }

                } else {
                    //if op!=regex, numbers must NOT have "'s around them
                    if (tValue.startsWith("\"") || tValue.endsWith("\"")) {
                        if (repair) {
                            if (tValue.startsWith("\""))
                                tValue = tValue.substring(1);
                            if (tValue.endsWith("\""))
                                tValue = tValue.substring(0, tValue.length() - 1);
                            constraintValues.set(constraintValues.size() - 1, tValue);
                        } else {
                            throw new SimpleException(QUERY_ERROR +
                                "For non =~ constraints of numeric variables, " +
                                "the right-hand-side value must not be surrounded by double quotes.\n" +
                                "Bad constraint: " + constraint);
                        }
                    }

                    //test of value=NaN must use "NaN", not something just a badly formatted number
                    conValueD = String2.parseDouble(tValue);
                    if (!Double.isFinite(conValueD) && !tValue.equals("NaN")) {
                        if (repair) {
                            conValueD = Double.NaN;
                            tValue = "NaN";
                            constraintValues.set(constraintValues.size() - 1, tValue);
                        } else {
                            throw new SimpleException(QUERY_ERROR +
                                "Numeric tests of NaN must use \"NaN\", not value=\"" + tValue + "\".");
                        }
                    }
                }
            }
        }

        if (debugMode) {
            String2.log("  Output from parseDapQuery:" +
                "\n    resultsVariables=" + resultsVariables +
                "\n    constraintVariables=" + constraintVariables +
                "\n    constraintOps=" + constraintOps +
                "\n    constraintValues=" + constraintValues);
        }
    }


    /**
     * This tests parseDapQuery.
     */
    public static void testParseDapQuery() throws Exception {
        String2.log("\n*** Table.testParseDapQuery");
 
        Table table = makeEmptyTable(
            new String[]{"myDouble","myString","time","myInt"}, 
            new String[]{"double","String","double","int"});
        table.columnAttributes("time").add("units", Calendar2.SECONDS_SINCE_1970);
        StringArray rVar = new StringArray();
        StringArray cVar = new StringArray();
        StringArray cOp  = new StringArray();
        StringArray cVal = new StringArray();
        String results;        

        //*** test valid queries
        table.parseDapQuery("", rVar, cVar, cOp, cVal, false);  //fix
        Test.ensureEqual(rVar.toString(), "myDouble, myString, time, myInt", "");
        Test.ensureEqual(cVar.toString(), "", "");
        Test.ensureEqual(cOp.toString(),  "", "");
        Test.ensureEqual(cVal.toString(), "", "");

        table.parseDapQuery("myString,myDouble", rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "myString, myDouble", "");
        Test.ensureEqual(cVar.toString(), "", "");
        Test.ensureEqual(cOp.toString(),  "", "");
        Test.ensureEqual(cVal.toString(), "", "");

        table.parseDapQuery("myDouble&myString=\"something\"", rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "myDouble", "");
        Test.ensureEqual(cVar.toString(), "myString", "");
        Test.ensureEqual(cOp.toString(),  "=", "");
        Test.ensureEqual(cVal.toString(), "something", "");

        table.parseDapQuery("myDouble&myInt=~\"regex\"", rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "myDouble", "");
        Test.ensureEqual(cVar.toString(), "myInt", "");
        Test.ensureEqual(cOp.toString(),  "=~", "");
        Test.ensureEqual(cVal.toString(), "regex", "");

        table.parseDapQuery("myDouble&time>=1.4229216E9", rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "myDouble", "");
        Test.ensureEqual(cVar.toString(), "time", "");
        Test.ensureEqual(cOp.toString(),  ">=", "");
        Test.ensureEqual(cVal.toString(), "1.4229216E9", "");

        table.parseDapQuery("myDouble&time>=2015-02-03", rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "myDouble", "");
        Test.ensureEqual(cVar.toString(), "time", "");
        Test.ensureEqual(cOp.toString(),  ">=", "");
        Test.ensureEqual(cVal.toString(), "1.4229216E9", "");

        table.parseDapQuery("myDouble&myInt=NaN", rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "myDouble", "");
        Test.ensureEqual(cVar.toString(), "myInt", "");
        Test.ensureEqual(cOp.toString(),  "=", "");
        Test.ensureEqual(cVal.toString(), "NaN", "");

        table.parseDapQuery(
            "&time!=2015-02-03&myInt<5.1&myString=\"Nate\"&orderBy(\"myString,myInt\")&distinct()", 
            rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "myDouble, myString, time, myInt", "");
        Test.ensureEqual(cVar.toString(), "time, myInt, myString", "");
        Test.ensureEqual(cOp.toString(),  "!=, <, =", "");
        Test.ensureEqual(cVal.toString(), "1.4229216E9, 5.1, Nate", "");

        //s
        table.parseDapQuery("s", rVar, cVar, cOp, cVal, false);  //fix
        Test.ensureEqual(rVar.toString(), "myDouble, myString, time, myInt", "");
        Test.ensureEqual(cVar.toString(), "", "");
        Test.ensureEqual(cOp.toString(),  "", "");
        Test.ensureEqual(cVal.toString(), "", "");

        table.parseDapQuery("s.myDouble&s.time>=2015-02-03", rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "myDouble", "");
        Test.ensureEqual(cVar.toString(), "time", "");
        Test.ensureEqual(cOp.toString(),  ">=", "");
        Test.ensureEqual(cVal.toString(), "1.4229216E9", "");

        table.parseDapQuery(
            "&s.time!=2015-02-03&s.myInt<5.1&s.myString=\"Nate\"&orderBy(\"s.myString,s.myInt\")&distinct()", 
            rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "myDouble, myString, time, myInt", "");
        Test.ensureEqual(cVar.toString(), "time, myInt, myString", "");
        Test.ensureEqual(cOp.toString(),  "!=, <, =", "");
        Test.ensureEqual(cVal.toString(), "1.4229216E9, 5.1, Nate", "");

        //Tests of time related to "now"
        double now = System.currentTimeMillis() / 1000.0;
        String2.log("epochSecondsNow=" + now);
        table.parseDapQuery("time&time>now&time>now%2Bsecond&time>now-minute&time>now-44days", 
            rVar, cVar, cOp, cVal, false);  
        Test.ensureEqual(rVar.toString(), "time", "");
        Test.ensureEqual(cVar.toString(), "time, time, time, time", "");
        Test.ensureEqual(cOp.toString(),  ">, >, >, >", "");
        Test.ensureTrue(Math.abs(cVal.getDouble(0) - (now)        ) < 20, cVal.get(0));
        Test.ensureTrue(Math.abs(cVal.getDouble(1) - (now+1 )     ) < 20, cVal.get(1));
        Test.ensureTrue(Math.abs(cVal.getDouble(2) - (now-60)     ) < 20, cVal.get(2));
        Test.ensureTrue(Math.abs(cVal.getDouble(3) - (now-44*86400)) < 20, cVal.get(3));

  
        //********* tests that fail
        results = "invalid request var";
        try {
            table.parseDapQuery("time,MyInt", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Unrecognized variable=\"MyInt\".", "");

        results = "listed twice";
        try {
            table.parseDapQuery("time,myInt,time", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: variable=time is listed twice in the results variables list.", "");

        results = "invalid constraint var";
        try {
            table.parseDapQuery("time&MyDouble>5", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Unrecognized constraint variable=\"MyDouble\".", "");

        results = "missing &";
        try {
            table.parseDapQuery("myInt>5", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: All constraints (including \"myInt>...\") must be preceded by '&'.", "");

        results = "missing & with date with double col";
        try {
            table.parseDapQuery("myDouble>2014-01-01T00:00:00Z", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: All constraints (including \"myDouble>...\") must be preceded by '&'.", "");

        results = "invalid op";
        try {
            table.parseDapQuery("&myInt==5", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Use '=' instead of '==' in constraints.", "");

        results = "invalid NAN value";
        try {
            table.parseDapQuery("&myInt=NAN", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Numeric tests of NaN must use \"NaN\", not value=\"NAN\".", "");

        results = "invalid NaN value, something";
        try {
            table.parseDapQuery("&myInt=something", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Numeric tests of NaN must use \"NaN\", not value=\"something\".", "");

        results = "invalid NaN value";
        try {
            table.parseDapQuery("&myInt=1e1000", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Numeric tests of NaN must use \"NaN\", not value=\"1e1000\".", "");

        results = "invalid regex op";
        try {
            table.parseDapQuery("&myInt~=\"regex\"", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Use '=~' instead of '~=' in constraints.", "");

        results = "missing \"\" for string";
        try {
            table.parseDapQuery("&myString=something", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: For constraints of String variables, the right-hand-side value must be surrounded by double quotes.\n" +
            "Bad constraint: myString=something", 
            "results=" + results);

        results = "missing \"\" for regex";
        try {
            table.parseDapQuery("&myInt=~something", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: For =~ constraints of numeric variables, the right-hand-side value must be surrounded by double quotes.\n" +
            "Bad constraint: myInt=~something", 
            "results=" + results);

        results = "invalid now units";
        try {
            table.parseDapQuery("&time>now-2dayss", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Invalid \"now\" constraint: \"now-2dayss\". " +
            "Timestamp constraints with \"now\" must be in the form \"now[+|-positiveInteger[millis|seconds|minutes|hours|days|months|years]]\" (or singular units).", 
            "results=" + results);

        results = "invalid now option -";
        try {
            table.parseDapQuery("&time>now-", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Invalid \"now\" constraint: \"now-\". " +
            "Timestamp constraints with \"now\" must be in the form \"now[+|-positiveInteger[millis|seconds|minutes|hours|days|months|years]]\" (or singular units).", 
            "results=" + results);

        results = "invalid now option -+";
        try {
            table.parseDapQuery("&time>now-%2B4seconds", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Invalid \"now\" constraint: \"now-+4seconds\". " +
            "Timestamp constraints with \"now\" must be in the form \"now[+|-positiveInteger[millis|seconds|minutes|hours|days|months|years]]\" (or singular units).", 
            "results=" + results);

        results = "invalid now option +-";
        try {
            table.parseDapQuery("&time>now%2B-4seconds", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Invalid \"now\" constraint: \"now+-4seconds\". " +
            "Timestamp constraints with \"now\" must be in the form \"now[+|-positiveInteger[millis|seconds|minutes|hours|days|months|years]]\" (or singular units).", 
            "results=" + results);

        results = "invalid now option";
        try {
            table.parseDapQuery("&time>now=2days", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: Unrecognized constraint variable=\"time>now\".", 
            "results=" + results);

        results = "unknown filter";
        try {
            table.parseDapQuery("&Distinct()", rVar, cVar, cOp, cVal, false);  
        } catch (Throwable t) {
            results = t.toString();
        }
        Test.ensureEqual(results, 
            "com.cohort.util.SimpleException: Query error: No operator found in constraint=\"Distinct()\".", "");

        String2.log("\n*** Table.testParseDapQuery finished successfully.");
    }

    /**
     * This converts the missing values to standard (e.g., NaN) missing values,
     * but doesn't erase the missing_value and _FillValue metadata so the table can be reused.
     * This is a convenience for most orderBy() variants.
     *
     * @param keys Only the keys columns are converted.
     * @return true if some values were converted
     */
    public boolean temporarilyConvertToStandardMissingValues(int keys[]) { 
        boolean someConverted = false;
        int nKeys = keys.length;
        for (int key = 0; key < nKeys; key++) {
            if (temporarilyConvertToStandardMissingValues(keys[key]))
                someConverted = true;
         }
         return someConverted;
     }

    /**
     * This converts the missing values to standard (e.g., NaN) missing values,
     * but doesn't erase the missing_value and _FillValue metadata so the table can be reused.
     * This is a convenience for most orderBy() variants.
     *
     * @param col
     * @return true if some values were converted
     */
    public boolean temporarilyConvertToStandardMissingValues(int col) { 
        boolean someConverted = false;
        PrimitiveArray pa = getColumn(col);
        if (pa.elementType() == PAType.STRING)
            return someConverted;
        Attributes colAtt = columnAttributes(col);
        if (pa.convertToStandardMissingValues( 
            colAtt.getString("_FillValue"),
            colAtt.getString("missing_value")) > 0)
            someConverted = true;
         return someConverted;
     }

    /**
     * This converts all columns.
     */
    public boolean temporarilyConvertToStandardMissingValues() { 
        int nCols = nColumns();
        int keys[] = new int[nCols];
        for (int col = 0; col < nCols; col++) 
            keys[col] = col;
        return temporarilyConvertToStandardMissingValues(keys);
    }


    /**
     * This converts standard (e.g., NaN) missing values to the variable's 
     * missing_value or _FillValue (preferred).
     * This is a convenience for most orderBy() variants.
     *
     * @param keys Only the keys columns are converted.
     * @return true if some values were converted
     */
    public boolean temporarilySwitchNaNToFakeMissingValues(int keys[]) { 
        boolean someConverted = false;
        int nKeys = keys.length;
        for (int key = 0; key < nKeys; key++) {
            if (temporarilySwitchNaNToFakeMissingValues(keys[key]))
                someConverted = true;
        }
        return someConverted;
    }

    /**
     * This converts standard (e.g., NaN) missing values to the variable's 
     * missing_value or _FillValue (preferred).
     * This is a convenience for most orderBy() variants.
     *
     * @param col 
     * @return true if some values were converted
     */
    public boolean temporarilySwitchNaNToFakeMissingValues(int col) { 
        PrimitiveArray pa = getColumn(col);
        if (pa.elementType() == PAType.STRING)
            return false;
        Attributes colAtt = columnAttributes(col);
        String safeMV = colAtt.getString("_FillValue"); //fill has precedence
        if (safeMV == null || safeMV.equals("NaN"))
            safeMV = colAtt.getString("missing_value"); 
        if (safeMV == null || safeMV.equals("NaN")) {
            //no term was defined
            //for integerType and CharArray, if there are missing values...
            if (pa.getMaxIsMV()) {
                int which = pa.indexOf("");
                if (which >= 0) {
                    colAtt.set("_FillValue", pa.missingValue().pa());
                } else {
                    //there are no missing values, so maxIsMV is set unnecessarily
                    pa.setMaxIsMV(false);
                }
            }
            return false;
        }
        return pa.switchNaNToFakeMissingValue(safeMV) > 0;
    }

    /**
     * This converts all columns.
     */
    public boolean temporarilySwitchNaNToFakeMissingValues() { 
        int nCols = nColumns();
        int keys[] = new int[nCols];
        for (int col = 0; col < nCols; col++) 
            keys[col] = col;
        return temporarilySwitchNaNToFakeMissingValues(keys);
    }



    /**
     * Reduce the table to a subset via a PERCENT-ENCODED DAP query.
     * A variable may be needed only for a constraint; if so, it won't be in the results.
     *
     * @param dapQuery A PERCENT-ENCODED DAP query.
     *   Unofficially (e.g., for testing) the query can be already percent decoded
     *     if there are no %dd in the decoded query.
     *   This supports filters: distinct(), orderBy(), orderBy...(), but not orderByMean() or units().
     * @return the number of rows remaining (may be 0!).
     */
    public int subsetViaDapQuery(String dapQuery) throws Exception {
        String[] parts = getDapQueryParts(dapQuery); //always at least 1: ""
        int nParts = parts.length; 
        BitSet keep = null;
        //make SAs to catch results
        StringArray resultsVariables    = new StringArray();
        StringArray constraintVariables = new StringArray();
        StringArray constraintOps       = new StringArray();
        StringArray constraintValues    = new StringArray();

        parseDapQuery(dapQuery, resultsVariables, constraintVariables, 
            constraintOps, constraintValues, false); //repair
        int nCon = constraintVariables.size();
        if (nCon > 0) {
            keep = new BitSet();
            keep.set(0, nRows());
            for (int con = 0; con < nCon; con++) {
                String conName = constraintVariables.get(con);
                String conOp  = constraintOps.get(con);
                String conVal = constraintValues.get(con);
                int idCol = findColumnNumber(conName);
                int nRemain = lowApplyConstraint(true, idCol, 
                    conName, conOp, conVal, keep);
                if (debugMode) String2.log(">> nRemain=" + nRemain + 
                    " after " + conName + conOp + conVal);
                if (nRemain == 0) {
                    removeAllRows();
                    keep = null;
                    break;
                }
            }
        }

        //prune to just requested columns in requested order
        reorderColumns(resultsVariables, true); //discardOthers

        //finally remove unwanted rows
        if (keep != null)
            justKeep(keep);
        if (nRows() == 0)
            return 0;

        //deal with filters (e.g., orderBy()) the same way the TableWriters do
        for (int parti = 1; parti < nParts; parti++) {
            String part = parts[parti];
            int partL = part.length();
            if (part.equals("distinct()")) {
                leftToRightSort(nColumns());
                removeDuplicates();
            } else if (part.startsWith("orderBy(\"") && part.endsWith("\")")) {
                ascendingSort(StringArray.arrayFromCSV(part.substring(9, partL-2)));  
            } else if (part.startsWith("orderByClosest(\"") && part.endsWith("\")")) {
                orderByClosest(part.substring(16, partL-2));
            } else if (part.startsWith("orderByCount(\"") && part.endsWith("\")")) {
                orderByCount(StringArray.arrayFromCSV(part.substring(14, partL-2)));  
            } else if (part.startsWith("orderByLimit(\"") && part.endsWith("\")")) {
                orderByLimit(part.substring(14, partL-2));                            
            } else if (part.startsWith("orderByMin(\"") && part.endsWith("\")")) {
                orderByMin(StringArray.arrayFromCSV(part.substring(12, partL-2)));    
            } else if (part.startsWith("orderByMax(\"") && part.endsWith("\")")) {
                orderByMax(StringArray.arrayFromCSV(part.substring(12, partL-2)));    
            } else if (part.startsWith("orderByMinMax(\"") && part.endsWith("\")")) {
                orderByMinMax(StringArray.arrayFromCSV(part.substring(15, partL-2))); 
//orderByMean isn't supported here! It is just in TableWriterOrderByMean.
            }// else it's a constraint. If error, parseDapQuery would have caught it.
             // units() is ignored here 
        }

        return nRows();
    }

    /**
     * This tests subsetViaDapQuery.
     */
    public static void testSubsetViaDapQuery() throws Exception {
        String2.log("\n*** Table.testSubsetViaDapQuery");
        String results, expected;
        Table table;

        table = getTestTable(false, true);  //includeLongs, Strings
        table.subsetViaDapQuery("");
        results = table.dataToString();
        expected =
"Time,Longitude,Latitude,Double Data,Int Data,Short Data,Byte Data,Char Data,String Data\n" +
"0.0,-3,1.0,-1.0E300,-2000000000,-32000,-120,\",\",a\n" +
"1.125504062E9,-2,1.5,3.123,2,7,8,\"\"\"\",bb\n" +
"1.130954649E9,-1,2.0,1.0E300,2000000000,32000,120,\\u20ac,ccc\n" +
",,,,,,,,\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        // !=NaN
        table = getTestTable(false, true);  //includeLongs, Strings
        table.subsetViaDapQuery("&Latitude!=NaN");
        results = table.dataToString();
        expected =
"Time,Longitude,Latitude,Double Data,Int Data,Short Data,Byte Data,Char Data,String Data\n" +
"0.0,-3,1.0,-1.0E300,-2000000000,-32000,-120,\",\",a\n" +
"1.125504062E9,-2,1.5,3.123,2,7,8,\"\"\"\",bb\n" +
"1.130954649E9,-1,2.0,1.0E300,2000000000,32000,120,\\u20ac,ccc\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        // =NaN
        table = getTestTable(false, true);  //includeLongs, Strings
        table.subsetViaDapQuery("&Latitude=NaN");
        results = table.dataToString();
        expected =
"Time,Longitude,Latitude,Double Data,Int Data,Short Data,Byte Data,Char Data,String Data\n" +
",,,,,,,,\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //1125504062 seconds since 1970-01-01T00:00:00Z = 2005-08-31T16:01:02Z
        table = getTestTable(false, true);  //includeLongs, Strings
        table.subsetViaDapQuery("&Time>2005-08-31T16:01:02Z"); 
        results = table.dataToString();
        expected =
"Time,Longitude,Latitude,Double Data,Int Data,Short Data,Byte Data,Char Data,String Data\n" +
"1.130954649E9,-1,2.0,1.0E300,2000000000,32000,120,\\u20ac,ccc\n";
//mv row removed because tests related to NaN (except NaN=NaN) return false.
        Test.ensureEqual(results, expected, "results=\n" + results);

        //1125504062 seconds since 1970-01-01T00:00:00Z = 2005-08-31T16:01:02Z
        table = getTestTable(false, true);  //includeLongs, Strings
        table.subsetViaDapQuery("String Data,Time&Time>=2005-08-31T16:01:02Z"); 
        results = table.dataToString();
        expected =
"String Data,Time\n" +
"bb,1.125504062E9\n" +
"ccc,1.130954649E9\n";
//mv row removed because tests related to NaN (except NaN=NaN) return false.
        Test.ensureEqual(results, expected, "results=\n" + results);

        //constraint var needn't be in resultsVars
        table = getTestTable(false, true);  //includeLongs, Strings
        table.subsetViaDapQuery("String Data&Time>=2005-08-31T16:01:02Z"); 
        results = table.dataToString();
        expected =
"String Data\n" +
"bb\n" +
"ccc\n";
//mv row removed because tests related to NaN (except NaN=NaN) return false.
        Test.ensureEqual(results, expected, "results=\n" + results);

        //return 0 rows
        table = getTestTable(false, true);  //includeLongs, Strings
        table.subsetViaDapQuery("Longitude,Time&Time=2005-08-31");
        results = table.dataToString();
        expected =
"Longitude,Time\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //string
        table = getTestTable(false, true);  //includeLongs, Strings
        table.subsetViaDapQuery("String Data,Time&Time>1970-01-01&String Data=\"bb\"");
        results = table.dataToString();
        expected =
"String Data,Time\n" +
"bb,1.125504062E9\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //regex
        table = getTestTable(false, true);  //includeLongs, Strings
        table.subsetViaDapQuery("String Data,Time&String Data=~\"b{1,5}\"");
        results = table.dataToString();
        expected =
"String Data,Time\n" +
"bb,1.125504062E9\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        String2.log("\n*** Table.testSubsetViaDapQuery finished successfully");
    }

    /**
     * If two or more adjacent rows are duplicates, this removes
     * the duplicates (leaving the original row).
     * Presumably, the file is sorted in a way to make identical rows adjacent,
     * so simple sort() or sortIgnoreCase() are both okay.
     *
     * @return the number of duplicates removed
     */
    public int removeDuplicates() {
        return PrimitiveArray.removeDuplicates(columns);
    }

    /**
     * This moves the specified columns into place and removes other columns.
     *
     * @param colNames
     * @param extraErrorMessage (may be "")
     * @throws IllegalArgumentException if a colName not found.
     */
    public void justKeepColumns(String colNames[], String extraErrorMessage) {
        for (int col = 0; col < colNames.length; col++) {
            int tCol = findColumnNumber(colNames[col]); 
            if (tCol < 0)
                throw new IllegalArgumentException("column name=" + colNames[col] + " wasn't found." +
                    extraErrorMessage);
            moveColumn(tCol, col);
        }

        removeColumns(colNames.length, nColumns());
    }

    /**
     * This moves the specified columns into place and removes other columns.
     * This variant creates columns (with missing values) if they didn't exist.
     *
     * @param colNames  the desired columnNames
     * @param classes the class for each desired columnName
     */
    public void justKeepColumns(String colNames[], PAType paTypes[]) {
        for (int col = 0; col < colNames.length; col++) {
            int tCol = findColumnNumber(colNames[col]); 
            if (tCol >= 0) {
                moveColumn(tCol, col);
                setColumn(col, PrimitiveArray.factory(paTypes[tCol], getColumn(col)));
            } else {
                addColumn(col, colNames[col], 
                    PrimitiveArray.factory(paTypes[col], nRows(), ""),
                    new Attributes());
            }
        }
        int tnCols = nColumns();
        if (tnCols > colNames.length) {
            if (reallyVerbose) {
                StringArray sa = new StringArray();
                for (int col = colNames.length; col < tnCols; col++)
                    sa.add(getColumnName(col));
                String2.log("Table.justKeepColumns removing excess columns: " + 
                    sa.toString());
            }
            removeColumns(colNames.length, tnCols);
        }
    }



    /**
     * This removes rows in which the value in 'column' is less than
     * the value in the previous row.
     * Rows with values of NaN or bigger than 1e300 are also removed.
     * !!!Trouble: one erroneous big value will cause all subsequent valid values to be tossed.
     *
     * @param column the column which should be ascending
     * @return the number of rows removed
     */
    public int ensureAscending(int column) {
        return PrimitiveArray.ensureAscending(columns, column);
    }

    /**
     * The adds the data from each column in other to the end of each column
     * in this.
     * If old column is simpler than new column, old column is upgraded.
     * This column's metadata is unchanged.
     *
     * @param other another table with columns with the same meanings as this table
     */
    public void append(Table other) {
        int n = Math.min(nColumns(), other.nColumns());
        for (int col = 0; col < n; col++) {

            //if needed, make a new wider PrimitiveArray in table1
            PrimitiveArray pa1 =  this.getColumn(col);
            PrimitiveArray pa2 = other.getColumn(col);

            PAType needPAType = pa1.needPAType(pa2.elementType());
            if (pa1.elementType() != needPAType) {
                PrimitiveArray newPa1 = PrimitiveArray.factory(needPAType, pa1.size() + pa2.size(), false); //active?
                newPa1.append(pa1);
                pa1 = newPa1;
                this.setColumn(col, pa1);
            }

            //append the data from other
            pa1.append(pa2);
        }
    }

    /**
     * This ranks the rows of data in the table by some key columns
     * (each of which can be sorted ascending or descending).
     *
     * @param keyColumns the numbers of the key columns (first is most important)
     * @param ascending try if a given key column should be sorted ascending
     * @return an int[] with values (0 ... size-1) 
     *   which points to the row number for a row with a specific 
     *   rank (e.g., result[0].intValue() is the row number of the first item 
     *   in the sorted list, result[1].intValue() is the row number of the
     *   second item in the sorted list, ...).
     */
    public int[] rank(int keyColumns[], boolean ascending[]) {
        return PrimitiveArray.rank(columns, keyColumns, ascending);
    }

    /**
     * Like rank, but StringArrays are ranked in a case-insensitive way.
     *
     * @param keyColumns the numbers of the key columns (first is most important)
     * @param ascending try if a given key column should be ranked ascending
     */
    public int[] rankIgnoreCase(int keyColumns[], boolean ascending[]) {
        return PrimitiveArray.rankIgnoreCase(columns, keyColumns, ascending);
    }


    /**
     * This sorts the rows of data in the table by some key columns
     * (each of which can be sorted ascending or descending).
     *
     * <p>This sort is stable: equal elements will not be reordered as a result of the sort.
     *
     * @param keyColumns the numbers of the key columns (first is most important)
     * @param ascending try if a given key column should be sorted ascending
     */
    public void sort(int keyColumns[], boolean ascending[]) {

        //convert missingValues and _FillValue to NaNs 
        //(so mvs sorted consistently, not dependent on mv being a low or high value)
        //boolean someConverted = temporarilyConvertToStandardMissingValues(keyColumns);

        PrimitiveArray.sort(columns, keyColumns, ascending);

        //convert NaNs back to _FillValues
        //if (someConverted)
        //    temporarilySwitchNaNToFakeMissingValues(keyColumns);        
    }

    /**
     * This sorts the rows of data in the table by some key columns
     * (each of which can be sorted ascending or descending).
     *
     * <p>This sort is stable: equal elements will not be reordered as a result of the sort.
     *
     * @param keyColumns the numbers of the key columns (first is most important)
     */
    public void sort(int keyColumns[]) {
        boolean ascending[] = new boolean[keyColumns.length];
        Arrays.fill(ascending, true);

        sort(keyColumns, ascending); //handles missingValues and _FillValues 

    }
    /** Like the other sort, but assumes are are ascending. */
    public void sort(String keyNames[]) {
        sort(keyColumnNamesToNumbers("sort", keyNames)); //handles missingValues and _FillValues 
    }

    /** Like the other sort, but you can specify ascending. */
    public void sort(String keyNames[], boolean ascending[]) {
        sort(keyColumnNamesToNumbers("sort", keyNames), ascending); //handles missingValues and _FillValues 
    }

    /**
     * Like sort, but StringArrays are sorted in a case-insensitive way.
     * This is more sophisticated than Java's String.CASE_INSENSITIVE_ORDER.
     * E.g., all charAt(0) A's will sort by for all charAt(0) a's  (e.g., AA, Aa, aA, aa).
     *
     * <p>This sort is stable: equal elements will not be reordered as a result of the sort.
     *
     * @param keyColumns the numbers of the key columns (first is most important)
     * @param ascending try if a given key column should be sorted ascending
     */
    public void sortIgnoreCase(int keyColumns[], boolean ascending[]) {
        //convert missingValues and _FillValue to NaNs 
        //(so mvs sorted consistently, not dependent on mv being a low or high value)
        //boolean someConverted = temporarilyConvertToStandardMissingValues(keyColumns);

        PrimitiveArray.sortIgnoreCase(columns, keyColumns, ascending);

        //convert NaNs back to _FillValues
        //if (someConverted)
        //    temporarilySwitchNaNToFakeMissingValues(keyColumns);        
    }

    /** Like sortIgnoreCase, but based on key column's names. */
    public void sortIgnoreCase(String keyNames[], boolean ascending[]) {
        sortIgnoreCase(  
            keyColumnNamesToNumbers("sortIgnoreCase", keyNames),
            ascending);
    }

    /**
     * This sorts the rows of data in the table by some key columns
     * (each of which is sorted ascending).
     * This handles missingValues and _FillValues.
     *
     * <p>This sort is stable: equal elements will not be reordered as a result of the sort.
     *
     * @param keyColumns the numbers of the key columns (first is most important)
     */
    public void ascendingSort(int keyColumns[]) {
        boolean ascending[] = new boolean[keyColumns.length];
        Arrays.fill(ascending, true);
        sort(keyColumns, ascending); 
    }

    /** Like ascendingSort, but based on key column's names. */
    public void ascendingSort(String keyNames[]) {
        ascendingSort(keyColumnNamesToNumbers("orderBy", keyNames)); 
    }

    /**
     * Like ascendingSort, but StringArrays are sorted in a case-insensitive way.
     * This is more sophisticated than Java's String.CASE_INSENSITIVE_ORDER.
     * E.g., all charAt(0) A's will sort by for all charAt(0) a's  (e.g., AA, Aa, aA, aa).
     *
     * <p>This sort is stable: equal elements will not be reordered as a result of the sort.
     *
     * @param keyColumns the numbers of the key columns (first is most important)
     */
    public void ascendingSortIgnoreCase(int keyColumns[]) {
        boolean ascending[] = new boolean[keyColumns.length];
        Arrays.fill(ascending, true);
        sortIgnoreCase(keyColumns, ascending);  
    }

    /** Like ascendingSortIgnoreCase, but based on key column's names. */
    public void ascendingSortIgnoreCase(String keyNames[]) {
        ascendingSortIgnoreCase( 
            keyColumnNamesToNumbers("ascendingSortIgnoreCase", keyNames));
    }

    /**
     * This sorts based on the leftmost nSortColumns (leftmost is most important, all ascending).
     *
     * <p>This sort is stable: equal elements will not be reordered as a result of the sort.
     *
     * @param nSortColumns (leftmost is most important)
     */
    public void leftToRightSort(int nSortColumns) {
        boolean ascending[] = new boolean[nSortColumns];
        Arrays.fill(ascending, true);
        sort((new IntArray(0, nSortColumns-1)).toArray(), ascending); 
    }

    /**
     * Like leftToRightSort, but StringArrays are sorted in a case-insensitive way.
     * This is more sophisticated than Java's String.CASE_INSENSITIVE_ORDER.
     * E.g., all charAt(0) A's will sort by for all charAt(0) a's  (e.g., AA, Aa, aA, aa).
     *
     * <p>This sort is stable: equal elements will not be reordered as a result of the sort.
     *
     * @param nSortColumns (leftmost is most important)
     */
    public void leftToRightSortIgnoreCase(int nSortColumns) {
        boolean ascending[] = new boolean[nSortColumns];
        Arrays.fill(ascending, true);
        sortIgnoreCase((new IntArray(0, nSortColumns-1)).toArray(), ascending); 
    }

    /**
     * This sorts the table by the keyColumns. Then, it replaces
     * rows where the values in the keyColumns are equal, by
     * one row with their average.
     * If the number of rows is reduced to 1/2 or less, this
     * calls trimToSize on each of the PrimitiveArrays.
     * If there are no non-NaN values to average, the average is NaN.
     * 
     * @param keyColumns the numbers of the key columns (first is most important)
     */
    public void average(int keyColumns[]) {
        int nRows = nRows();
        if (nRows == 0)
            return;

        //sort
        sort(keyColumns); 

        averageAdjacentRows(keyColumns);
    }


    /**
     * This combines (averages) adjacent rows where the values of the keyColumns are equal.
     * If the number of rows is reduced to 1/2 or less, this
     * calls trimToSize on each of the PrimitiveArrays.
     * If there are no non-NaN values to average, the average is NaN.
     * 
     * @param keyColumns the numbers of the key columns
     */
    public void averageAdjacentRows(int keyColumns[]) {
        int nRows = nRows();
        if (nRows == 0)
            return;

        //make a bitset of sortColumnNumbers
        BitSet isSortColumn = (new IntArray(keyColumns)).toBitSet();

        //gather sort columns
        int nSortColumns = keyColumns.length;
        PrimitiveArray sortColumns[] = new PrimitiveArray[nSortColumns];
        for (int col = 0; col < nSortColumns; col++) 
            sortColumns[col] = getColumn(keyColumns[col]);

        //go through the data looking for groups of rows with constant values in the sortColumnNumbers
        int nColumns = nColumns();
        int nGood = 0;
        int firstRowInGroup = 0;
        while (firstRowInGroup < nRows) {
            //find lastRowInGroup
            int lastRowInGroup = firstRowInGroup;
            ROW_LOOP:
            for (int row = lastRowInGroup + 1; row < nRows; row++) {
                for (int col = 0; col < nSortColumns; col++) {
                    if (sortColumns[col].compare(firstRowInGroup, row) != 0)
                        break ROW_LOOP;
                }
                lastRowInGroup = row;
            }
            //if (reallyVerbose) String2.log("Table.average: first=" + firstRowInGroup +
            //    " last=" + lastRowInGroup);

            //average values in group and store in row nGood
            if (nGood != lastRowInGroup) { //so, the group is not one row, already in place
                for (int col = 0; col < nColumns; col++) {
                    PrimitiveArray pa = getColumn(col);
                    if (firstRowInGroup == lastRowInGroup || //only one row in group
                        isSortColumn.get(col)) {             //values in sortColumnNumbers in a group are all the same
                        pa.copy(firstRowInGroup, nGood);
                    } else {
                        double sum = 0;
                        int count = 0;
                        for (int row = firstRowInGroup; row <= lastRowInGroup; row++) {
                            double d = pa.getDouble(row);
                            if (!Double.isNaN(d)) {
                                count++;
                                sum += pa.getDouble(row);
                            }
                        }
                        pa.setDouble(nGood, count == 0? Double.NaN : sum / count);
                    }
                }
            }

            firstRowInGroup = lastRowInGroup + 1;
            nGood++;
        }

        //remove excess at end of column
        for (int col = 0; col < nColumns; col++)
            getColumn(col).removeRange(nGood, getColumn(col).size());

        //trimToSize
        if (nGood <= nRows / 2) {
            for (int col = 0; col < nColumns; col++)
                getColumn(col).trimToSize();
        }
        if (reallyVerbose) String2.log("Table.averageAdjacentRows done. old nRows=" + nRows +
            " new nRows=" + nGood);
    }

    /**
     * This sorts the table by keyColumns (all ascending) then, 
     * for each block where the nKeyColumns-1 values are constant,
     * this removes all rows except the one with the last/max value of the last keyColumn.
     * For example, orderByMax([stationID, time/1day, wtmp]) would sort by 
     * stationID, time/1day, wtmp, then just keep the row with the max wtmp
     * value for each stationID and time/1day.
     *
     * <p>Rows with missing values for the last column are removed.
     *
     * @param keyColumns  1 or more column numbers (0..).
     * @throws Exception if trouble (e.g., invalid column number).
     *    0 rows is not an error, but returns 0 rows.
     */
    public void orderByMax(int keyColumns[]) throws Exception {

        int nRows = nRows();
        if (nRows <= 1)
            return;
        int nKeyColumns = keyColumns.length;
        if (nKeyColumns == 0) 
            throw new IllegalArgumentException(
                String2.ERROR + " in Table.orderByMax: You must specify at least one keyColumn."); 
        int lastKeyColumn = keyColumns[nKeyColumns - 1];

        //Important: temporarily convert keyColumns to standard mv, so missingValues and _FillValues will be handled properly.
        // Convert back below (but just to one of missing_value or _FillValue -- 2 is impossible and confusing).
        boolean someConverted = temporarilyConvertToStandardMissingValues(keyColumns); 

        String lastKCMV = getColumn(lastKeyColumn).elementType() == PAType.STRING?
            "" : "NaN";
        //remove rows with mv for last keyColumn
        nRows = tryToApplyConstraintsAndKeep(lastKeyColumn,
            new StringArray(new String[]{getColumnName(lastKeyColumn)}), 
            new StringArray(new String[]{"!="}),
            new StringArray(new String[]{lastKCMV}));
        if (nRows == 0) 
            return;

        //sort based on keys
        ascendingSort(keyColumns); 

        //walk through the table, often marking previous row to be kept
        BitSet keep = new BitSet(nRows); //all false
        keep.set(nRows - 1); //always
        if (nKeyColumns > 1) {
            PrimitiveArray keyCols[] = new PrimitiveArray[nKeyColumns - 1];
            for (int kc = 0; kc < nKeyColumns - 1; kc++)
                keyCols[kc] = getColumn(keyColumns[kc]);
            for (int row = 1; row < nRows; row++) { //1 because I'm looking backwards

                //did keyColumns 0 ... n-2 change?
                //work backwards since last most likely to have changed
                //-2 since -1 is the one that is changing (e.g., time)
                for (int kc = nKeyColumns - 2; kc >= 0; kc--) { 
                    if (keyCols[kc].compare(row - 1, row) != 0) {
                        keep.set(row - 1);  //something changed, so keep the *previous* row
                        break;
                    }
                }
            }
        }
        justKeep(keep);

        //convert back to fake missing values
        if (someConverted)
            temporarilySwitchNaNToFakeMissingValues(keyColumns);
    }

    /**
     * This sorts the table by keyColumns (all ascending) then, 
     * for each block where the nKeyColumns-1 values are constant,
     * this removes all rows except the one with the first/min value of the last keyColumn.
     * For example, orderByMin([stationID, time]) would sort by stationID 
     * and time, then for each stationID, remove all rows except the one 
     * for the first time for that stationID.
     *
     * <p>Missing values are treated as however sort() treats them.
     * So they may sort low. 
     * So a missing value in the last keyColumn may be the min value.
     * To just get non-missing values, remove missing values ahead of time 
     * (e.g., via an ERDDAP query).
     *
     * @param keyColumns  1 or more column numbers (0..).
     * @throws Exception if trouble (e.g., invalid column number)
     *    0 rows is not an error, but returns 0 rows.
     */
    public void orderByMin(int keyColumns[]) throws Exception {

        int nRows = nRows();
        if (nRows <= 1)
            return;
        int nKeyColumns = keyColumns.length;
        if (nKeyColumns == 0) 
            throw new IllegalArgumentException(
                QUERY_ERROR + "in Table.orderByMin: You must specify at least one keyColumn."); 
        int lastKeyColumn = keyColumns[nKeyColumns - 1];

        //Important: temporarily convert keyColumns to standard mv, so missingValues and _FillValues will be handled properly.
        // Convert back below (but just to one of missing_value or _FillValue -- 2 is impossible and confusing).
        boolean someConverted = temporarilyConvertToStandardMissingValues(keyColumns); 

        String lastKCMV = getColumn(lastKeyColumn).elementType() == PAType.STRING?
            "" : "NaN";
        //remove rows with mv for last keyColumn
        nRows = tryToApplyConstraintsAndKeep(lastKeyColumn,
            new StringArray(new String[]{getColumnName(lastKeyColumn)}), 
            new StringArray(new String[]{"!="}),
            new StringArray(new String[]{lastKCMV}));
        if (nRows == 0) 
            return;

        //sort based on keys
        ascendingSort(keyColumns); 

        //walk through the table, often marking current row to be kept
        BitSet keep = new BitSet(nRows); //all false
        keep.set(0);  //always
        if (nKeyColumns > 1) {
            PrimitiveArray keyCols[] = new PrimitiveArray[nKeyColumns - 1];
            for (int kc = 0; kc < nKeyColumns - 1; kc++)
                keyCols[kc] = getColumn(keyColumns[kc]);
            for (int row = 1; row < nRows; row++) { //1 because I'm looking backwards

                //did keyColumns 0 ... n-2 change?
                //work backwards since last most likely to have changed
                //n-2 since n-1 is the one that is changing (e.g., time)
                for (int kc = nKeyColumns - 2; kc >= 0; kc--) { 
                    if (keyCols[kc].compare(row - 1, row) != 0) {
                        keep.set(row);  //something changed, so keep *this* row
                        break;
                    }
                }
            }
        }
        justKeep(keep);

        //convert back to fake missing values
        if (someConverted)
            temporarilySwitchNaNToFakeMissingValues(keyColumns);
    }

    /**
     * This sorts the table by keyColumns (all ascending) then, 
     * for each block where the nKeyColumns-1 values are constant,
     * this removes all rows except the one with the first/min value and the 
     * one with the last/max value of the last keyColumn.
     * For example, orderByMax([stationID, time]) would sort by stationID 
     * and time, then for each stationID, remove all rows except the ones 
     * for the first and last time for that stationID.
     *
     * <p>If an nKeyColumns-1 combo has only one row, it will be duplicated.
     * Hence, the resulting table will always have just pairs of rows.
     *
     * <p>Missing values are treated as however sort() treats them.
     * So they may sort low or high. 
     * So a missing value in the last keyColumn may be the min or max value.
     * To just get non-missing values, remove missing values ahead of time 
     * (e.g., via an ERDDAP query).
     *
     * @param keyColumns  1 or more column numbers (0..).
     * @throws Exception if trouble (e.g., invalid column number).
     *    0 rows is not an error, but returns 0 rows.
     */
    public void orderByMinMax(int keyColumns[]) throws Exception {

        int nRows = nRows();
        if (nRows == 0)
            return;
        int nKeyColumns = keyColumns.length;
        if (nKeyColumns == 0) 
            throw new IllegalArgumentException(
                QUERY_ERROR + "in Table.orderByMinMax: You must specify at least one keyColumn."); 
        int lastKeyColumn = keyColumns[nKeyColumns - 1];

        //Important: temporarily convert keyColumns to standard mv, so missingValues and _FillValues will be handled properly.
        // Convert back below (but just to one of missing_value or _FillValue -- 2 is impossible and confusing).
        boolean someConverted = temporarilyConvertToStandardMissingValues(keyColumns); 

        String lastKCMV = getColumn(lastKeyColumn).elementType() == PAType.STRING?
            "" : "NaN";
        //remove rows with mv for last keyColumn
        nRows = tryToApplyConstraintsAndKeep(lastKeyColumn,
            new StringArray(new String[]{getColumnName(lastKeyColumn)}), 
            new StringArray(new String[]{"!="}),
            new StringArray(new String[]{lastKCMV}));
        if (nRows == 0)
            return;

        //sort based on keys
        ascendingSort(keyColumns); 

        //minMax
        //walk through the table, often marking previous and current row to be kept
        BitSet keep = new BitSet(nRows); //all false
        keep.set(0); //always
        keep.set(nRows - 1); //always

        //and note which rows need to be duplicated
        ByteArray dupMe = (ByteArray)PrimitiveArray.factory(PAType.BYTE, nRows, "0");  //false
        addColumn("dupMe", dupMe);
        int nDupMe = 0;

        if (nKeyColumns > 1) {
            PrimitiveArray keyCols[] = new PrimitiveArray[nKeyColumns - 1];
            for (int kc = 0; kc < nKeyColumns - 1; kc++)
                keyCols[kc] = getColumn(keyColumns[kc]); //throws exception if not found
            int lastDifferentRow = 0;
            for (int row = 1; row < nRows; row++) { //1 because I'm looking backwards

                //did keyColumns 0 ... n-2 change?
                //work backwards since last most likely to have changed
                //-2 since -1 is the one that is changing (e.g., time)
                for (int kc = nKeyColumns - 2; kc >= 0; kc--) { 
                    if (keyCols[kc].compare(row - 1, row) != 0) {
                        keep.set(row - 1);  //something changed, so keep the *previous* row
                        keep.set(row);      //  and the *current* row
                        if (lastDifferentRow == row - 1) {
                            dupMe.set(row - 1, (byte)1); //true
                            nDupMe++;
                        }
                        lastDifferentRow = row;
                        break;
                    }
                }
            }
            if (lastDifferentRow == nRows - 1) {
                dupMe.set(nRows - 1, (byte)1); //true
                nDupMe++;
            }
        } else {
            if (nRows == 1) {
                dupMe.set(0, (byte)1); //true
                nDupMe++;
            }
        }
        justKeep(keep);
        nRows = nRows();
        removeColumn(nColumns() - 1); //the dupMe column

        //now duplicate the dupMe rows
        if (nDupMe > 0) {
            if (debugMode)
                String2.log(">> nDupMe=" + nDupMe);

            //do columns one at a time to save memory
            int nCols = nColumns(); //dupMe has been removed
            for (int col = 0; col < nCols; col++) {
                PrimitiveArray oldCol = getColumn(col);
                PrimitiveArray newCol = PrimitiveArray.factory(
                    oldCol.elementType(), nRows + nDupMe, false); //the elements are not active
            
                for (int row = 0; row < nRows; row++) {
                    newCol.addFromPA(oldCol, row);
                    if (dupMe.get(row) == 1) 
                        newCol.addFromPA(oldCol, row);
                }

                if (reallyVerbose && col == 0) 
                    Test.ensureEqual(newCol.size(), nRows + nDupMe, "newSize != expectedNewSize");
                //swap the newCol into place
                setColumn(col, newCol);            
            }
        }

        //convert back to fake missing values
        if (someConverted)
            temporarilySwitchNaNToFakeMissingValues(keyColumns);
    }

    /**
     * This converts an array of column names to column numbers.
     *
     * @param responsible The name of the caller (for an error message).
     * @param keyColumnNames
     * @return an array of column numbers
     * @throws SimpleException if name not found
     */
    public int[] keyColumnNamesToNumbers(String responsible, String[] keyColumnNames) {
        //find the key column numbers
        int keys[] = new int[keyColumnNames.length];
        for (int kc = 0; kc < keyColumnNames.length; kc++) {
            keys[kc] = findColumnNumber(keyColumnNames[kc]);
            if (keys[kc] < 0)
                throw new SimpleException(QUERY_ERROR +
                    "\"" + responsible + "\" column=" + keyColumnNames[kc] + 
                    " isn't in the results table (" + columnNames.toString() + ").");
        }
        return keys;
    }

    /**
     * keyColumnNameToNumber for one keyColumnName.
     */
    public int keyColumnNameToNumber(final String responsible, final String keyColumnName) {
        return keyColumnNamesToNumbers(responsible, new String[] { keyColumnName })[0];
    }

    /**
     * Like the other orderByCount, but based on keyColumnNames.
     *
     * @param keyColumnNames  1 or more column names.
     * @throws Exception if trouble (e.g., a keyColumnName not found)
     */
    public void orderByCount(String keyColumnNames[]) throws Exception {
        withRounding("orderByCount", keyColumnNames, true, 
            (keyColNames) -> orderByCount(keyColumnNamesToNumbers("orderByCount", keyColNames))
        );
    }

    /**
     * Like the other orderByMax, but based on keyColumnNames.
     *
     * @param keyColumnNames  1 or more column names.
     * @throws Exception if trouble (e.g., a keyColumnName not found)
     */
    public void orderByMax(String keyColumnNames[]) throws Exception {
        withRounding("orderByMax", keyColumnNames, false,
            (keyColNames) -> orderByMax(keyColumnNamesToNumbers("orderByMax", keyColNames))
        );
    }

    /**
     * Like the other orderByMin, but based on keyColumnNames.
     *
     * @param keyColumnNames  1 or more column names.
     * @throws Exception if trouble (e.g., a keyColumnName not found)
     */
    public void orderByMin(String keyColumnNames[]) throws Exception {
        withRounding("orderByMin", keyColumnNames, false,
            (keyColNames) -> orderByMin(keyColumnNamesToNumbers("orderByMin", keyColNames))
        );
    }

    /**
     * Like the other orderByMinMax, but based on keyColumnNames.
     *
     * @param keyColumnNames  1 or more column names.
     * @throws Exception if trouble (e.g., a keyColumnName not found)
     */
    public void orderByMinMax(String keyColumnNames[]) throws Exception {
        withRounding("orderByMinMax", keyColumnNames, false,
            (keyColNames) -> orderByMinMax(keyColumnNamesToNumbers("orderByMinMax", keyColNames))
        );
    }

    /**
     * Apply any rounding defined in the keyColumnNames, eg time/1day.
     * Method is private as temporary columns may be created and must be cleaned up afterwards by calling this.removeTempOrderByColumns();
     * @param responsible    name of the function responsible
     * @param keyColumnNames    an array of the column names used as keys, each maybe having rounding
     * @return the keyColumnNames without rounding directive.
     */
    private void withRounding(final String responsible, String[] keyColumnNames, 
        final boolean isOutputRounded, final WithColumnNames action) throws Exception {

        final List<Integer> tempOrderByCols = new ArrayList<Integer>();
        final String[] sortKeyColumnNames = deriveActualColumnNames(keyColumnNames);
        final int nRows = nRows();
        final int nKeyColumnNames = keyColumnNames.length;
        for(int i = 0; i < nKeyColumnNames; i++) {
            if (sortKeyColumnNames[i] == keyColumnNames[i].trim()) {
                continue;
            }

            //Bob added
            if (i == nKeyColumnNames - 1 &&
                keyColumnNames[i].indexOf('/') >= 0 &&
                (responsible.equals("orderByMax") || responsible.startsWith("orderByMin"))) //catches orderByMinMax too
                throw new IllegalArgumentException(Table.QUERY_ERROR + responsible +  
                    " cannot apply rounding to " + keyColumnNames[i] + 
                    " because it is the last variable in the CSV list.");                 

            final int srcColNumber = keyColumnNameToNumber(responsible, sortKeyColumnNames[i]);
            final PrimitiveArray srcColumn = getColumn(srcColNumber);
            int targetColNumber = srcColNumber;
            if (!isOutputRounded) {
                final String keyColumnName = keyColumnNames[i].replaceAll("\\W", "."); // eg time/1day -> time.1day
                targetColNumber = findColumnNumber(keyColumnName);//eg time/1day

                //Bob added
                if (!(srcColumn.isFloatingPointType() || srcColumn.isIntegerType())) {
                    // cannot apply rounding to this.
                    throw new IllegalArgumentException(Table.QUERY_ERROR + responsible +  
                        " cannot apply rounding to " + keyColumnNames[i] + 
                        " because it is not a numeric data type.");
                }

                DoubleArray roundedArray = new DoubleArray(srcColumn);
                if (targetColNumber < 0) {
                    targetColNumber = this.addColumn(keyColumnName, roundedArray);
                    tempOrderByCols.add(0, targetColNumber);
                } else {
                    this.setColumn(targetColNumber, roundedArray);
                }
                sortKeyColumnNames[i] = keyColumnName;
            }
            final PrimitiveArray targetColumn = getColumn(targetColNumber);
            if (!(targetColumn.isFloatingPointType() || targetColumn.isIntegerType())) {
                // cannot apply rounding to this.
                throw new IllegalArgumentException(Table.QUERY_ERROR + responsible +  
                    " cannot apply rounding to " + keyColumnNames[i] + 
                    " because it is not a numeric data type.");
            }
            final Rounder rounder = createRounder(responsible, keyColumnNames[i]);
            for(int row = 0; row < nRows; row++) {
                double value = targetColumn.getNiceDouble(row);
                if (!Double.isNaN(value)) {
                    try {
                        final double rounded = rounder.round(value);
                        if (rounded != value) {
                            targetColumn.setDouble(row, rounded);
                        }
                    } catch (Exception e) {
                        throw new SimpleException(responsible+" problem rounding "+keyColumnNames[i]+" for value="+value+" because "+e,e);
                    }
                }
            }

        }
        try {
            action.apply(sortKeyColumnNames);
        } finally {
            while (tempOrderByCols.size() > 0) {
                this.removeColumn(tempOrderByCols.remove(0));
            }
        }
    }

    /** This tests orderByMax, orderByMin, orderByMinMax */
    public static void testOrderByMinMax() throws Exception {

        for (int proc = 0; proc < 3; proc++) {
            String2.log("Table.testOrderBy" + 
                (proc == 1? "" : "Max") +
                (proc == 0? "" : "Min"));

            //*** test #1
            PrimitiveArray substation = PrimitiveArray.csvFactory(PAType.INT,    
                "10, 20, 20, 30, 10, 10, 10");
            PrimitiveArray station    = PrimitiveArray.csvFactory(PAType.STRING, 
                " a,  a,  a,  b,  c,  c,  c");
            PrimitiveArray time       = PrimitiveArray.csvFactory(PAType.INT,    
                " 1,  1,  2,  1,  1,  2,  3");
            PrimitiveArray other      = PrimitiveArray.csvFactory(PAType.INT,    
                "99, 95, 92, 91, 93, 98, 90");
            Table table = new Table();
            table.addColumn("substation", substation);
            table.addColumn("station",    station);
            table.addColumn("time",       time);
            table.addColumn("other",      other);

            //unsort by sorting on 'other'
            table.ascendingSort(new int[]{3}); 

            //orderBy...
            String vars[] = new String[]{"station", "substation", "time"};
            if (proc == 0) table.orderByMax(vars);
            if (proc == 1) table.orderByMin(vars);
            if (proc == 2) table.orderByMinMax(vars);
            String results = table.dataToString();
            String expected[] = new String[]{
"substation,station,time,other\n" +
"10,a,1,99\n" +
"20,a,2,92\n" +
"30,b,1,91\n" +
"10,c,3,90\n",
"substation,station,time,other\n" +
"10,a,1,99\n" +
"20,a,1,95\n" +
"30,b,1,91\n" +
"10,c,1,93\n",
"substation,station,time,other\n" +
"10,a,1,99\n" +  //note duplicate of 1 row of data
"10,a,1,99\n" +
"20,a,1,95\n" +
"20,a,2,92\n" +
"30,b,1,91\n" +  //note duplicate
"30,b,1,91\n" +
"10,c,1,93\n" +
"10,c,3,90\n"};
            Test.ensureEqual(results, expected[proc], "proc=" + proc + " results=\n" + results);             


            //*** test #2
            PrimitiveArray time2       = PrimitiveArray.csvFactory(PAType.INT,    
                " 1,  1,  2,  1,  1,  2,  3");
            PrimitiveArray other2      = PrimitiveArray.csvFactory(PAType.INT,    
                "99, 95, 92, 91, 93, 98, 90");
            table = new Table();
            table.addColumn("time",       time2);
            table.addColumn("other",      other2);

            //unsort by sorting on 'other'
            table.ascendingSort(new int[]{1}); 

            //orderBy...
            vars = new String[]{"time"};
            if (proc == 0) table.orderByMax(vars);
            if (proc == 1) table.orderByMin(vars);
            if (proc == 2) table.orderByMinMax(vars);
            results = table.dataToString();
            expected = new String[]{
"time,other\n" +
"3,90\n",
"time,other\n" +
"1,91\n",  //for ties, the one that is picked isn't specified.  unsort above causes 91 to be first.
"time,other\n" +
"1,91\n" + //for ties, the one that is picked isn't specified.  unsort above causes 91 to be first.
"3,90\n"}; 

            Test.ensureEqual(results, expected[proc], "proc=" + proc + " results=\n" + results);             


            //*** test #3
            PrimitiveArray time3       = PrimitiveArray.csvFactory(PAType.INT,    
                " 1");
            PrimitiveArray other3      = PrimitiveArray.csvFactory(PAType.INT,    
                "99");
            table = new Table();
            table.addColumn("time",       time3);
            table.addColumn("other",      other3);

            //unsort by sorting on 'other'
            table.ascendingSort(new int[]{1}); 

            //orderBy...
            vars = new String[]{"time"};
            if (proc == 0) table.orderByMax(vars);
            if (proc == 1) table.orderByMin(vars);
            if (proc == 2) table.orderByMinMax(vars);
            results = table.dataToString();
            expected = new String[]{
"time,other\n" +
"1,99\n",
"time,other\n" +
"1,99\n",
"time,other\n" +
"1,99\n" +  
"1,99\n"}; 
            Test.ensureEqual(results, expected[proc], "proc=" + proc + " results=\n" + results);             


            //*** test #4
            PrimitiveArray time4   = new IntArray();
            PrimitiveArray other4  = new IntArray();
            table = new Table();
            table.addColumn("time",  time4);
            table.addColumn("other", other4);

            //orderBy...
            vars = new String[]{"time"};
            if (proc == 0) table.orderByMax(vars);
            if (proc == 1) table.orderByMin(vars);
            if (proc == 2) table.orderByMinMax(vars);
            results = table.dataToString();
            String expected4 = "time,other\n";  
            Test.ensureEqual(results, expected4, "proc=" + proc + " results=\n" + results);             
        }

    }

    /** 
     * This is a higher level orderByClosest that takes the csv string
     * with the names of the orderBy columns plus the interval 
     * (e.g., "10 minutes" becomes 600 seconds).
     */
    public void orderByClosest(String orderByCSV) throws Exception {

        if (orderByCSV == null || orderByCSV.trim().length() == 0)
            throw new SimpleException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                " (no csv)");
        String csv[] = String2.split(orderByCSV, ',');
        if (csv.length < 2)
            throw new SimpleException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                " (csv.length<2)");

        int nKeyCols = csv.length - 1;
        int keyCols[] = new int[nKeyCols];
        for (int k = 0; k < nKeyCols; k++) {
            keyCols[k] = findColumnNumber(csv[k]);
            if (keyCols[k] < 0)
                throw new SimpleException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                    " (unknown orderBy column=" + csv[k] + ")");
        }

        double numberTimeUnits[] = Calendar2.parseNumberTimeUnits(csv[nKeyCols]); //throws Exception

        orderByClosest(keyCols, numberTimeUnits);
    }

    /** 
     * This is a higher level orderByClosest.
     */
    public void orderByClosest(String orderBy[], double numberTimeUnits[]) throws Exception {

        int nKeyCols = orderBy.length;
        int keyCols[] = new int[nKeyCols];
        for (int k = 0; k < nKeyCols; k++) {
            keyCols[k] = findColumnNumber(orderBy[k]);
            if (keyCols[k] < 0)
                throw new SimpleException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                    " (unknown orderBy column=" + orderBy[k] + ")");
        }

        orderByClosest(keyCols, numberTimeUnits);
    }

    /**
     * This sorts by keyColumnNames (the last of which must be a timestamp's 
     * doubles / epoch seconds), and then just keeps rows which are
     * closest to the time interval (e.g., 10 minutes).
     * Rows with time=NaN are not kept, so this may return 0 rows.
     *
     * @param keyColumns  1 or more column numbers (0..).
     * @param numberTimeUnits e.g., 10 minutes is represented as [numer=10, timeUnits=60]
     *   timeUnits are from Calendar2.factorToGetSeconds.
     *   Note that Jan is the 0th month: so 2 months rounds to Jan 1, Mar 1, May 1, ....
     *   When the last keyColumn isn't a time variable, use TimeUnits=1.
     *   This handles timeUnits for Month (30*SECONDS_PER_DAY) and 
     *   Year (360*SECONDS_PER_DAY) specially (as calendar months and years).
     * @throws Exception if trouble (e.g., a keyColumnName not found)
     */
    public void orderByClosest(int keyColumns[], double numberTimeUnits[]) throws Exception {

        //just 0 rows?
        int nRows = nRows();
        if (nRows == 0)
            return;

        int nKeyColumns = keyColumns.length;
        if (nKeyColumns == 0) 
            throw new SimpleException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                " (orderBy.length=0)"); 
        int lastKeyColumn = keyColumns[nKeyColumns - 1];
        PrimitiveArray lastKeyCol = getColumn(lastKeyColumn);

        //ensure lastKeyCol is numeric
        if (lastKeyCol instanceof StringArray)
            throw new IllegalArgumentException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                " (The last orderBy column=" + getColumnName(lastKeyColumn) + 
                " isn't numeric.)"); 

        //just 1 row?
        if (nRows == 1) {
            if (Double.isNaN(lastKeyCol.getDouble(0)))
                removeRow(0);
            return;
        }

        //interval
        if (numberTimeUnits == null || numberTimeUnits.length != 2)
            throw new IllegalArgumentException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                " (numberTimeUnits.length must be 2)"); 
        if (!Double.isFinite(numberTimeUnits[0]) || 
            !Double.isFinite(numberTimeUnits[1]))
            throw new IllegalArgumentException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                " (numberTimeUnits values can't be NaNs)"); 
        if (numberTimeUnits[0] <= 0 || numberTimeUnits[1] <= 0)
            throw new IllegalArgumentException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                " (numberTimeUnits values must be positive numbers)"); 
        double simpleInterval = numberTimeUnits[0] * numberTimeUnits[1];
        int field = 
            numberTimeUnits[1] ==  30 * Calendar2.SECONDS_PER_DAY? Calendar2.MONTH :
            numberTimeUnits[1] == 360 * Calendar2.SECONDS_PER_DAY? Calendar2.YEAR : //but see getYear below
            Integer.MAX_VALUE;
        int intNumber = Math2.roundToInt(numberTimeUnits[0]); //used for Month and Year
        if (field != Integer.MAX_VALUE &&
            (intNumber < 1 || intNumber != numberTimeUnits[0])) 
            throw new IllegalArgumentException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                " (The number of months or years must be a positive integer.)"); 
        if (field == Calendar2.MONTH && intNumber > 6) 
            throw new IllegalArgumentException(QUERY_ERROR + ORDER_BY_CLOSEST_ERROR + 
                " (The number of months must be 1 ... 6.)"); 

        //handle missing_value and _FillValue 
        boolean someConverted = temporarilyConvertToStandardMissingValues(keyColumns); 

        //sort based on keys
        ascendingSort(keyColumns); 

        //walk through the table, within a group:
        //  keep either this row or previous row
        BitSet keep = new BitSet(); //all false
        keep.set(0, nRows); //now keep all / all true
        PrimitiveArray keyCols[] = new PrimitiveArray[nKeyColumns - 1]; //not including time
        for (int kc = 0; kc < nKeyColumns - 1; kc++)
            keyCols[kc] = getColumn(keyColumns[kc]);
        ROW:
        for (int row = 1; row < nRows; row++) { //1 because I'm looking backwards

            //are we at start of a new group / did keyColumns 0 ... n-2 change?
            //  If so, continue to next row (no changes to current or previous row's keep value)
            //work backwards since last most likely to have changed
            //-2 since -1 is the one that is changing (e.g., time)
            for (int kc = nKeyColumns - 2; kc >= 0; kc--) { 
                if (keyCols[kc].compare(row - 1, row) != 0) {
                    if (Double.isNaN(lastKeyCol.getDouble(row)))
                        keep.clear(row);
                    continue ROW;  //use a label because we are in a local loop
                }
            }

            //if prev or this row is NaN, continue to next row
            double prevRT = lastKeyCol.getDouble(row - 1);
            double thisRT = lastKeyCol.getDouble(row);
            //check isNaN(thisRT) first
            if (Double.isNaN(thisRT)) { //prev has already been checked/cleared.
                keep.clear(row); 
                continue;
            }
            if (Double.isNaN(prevRT)) 
                continue;

            //now both prev and this are in same orderBy group and finite
            if (field == Integer.MAX_VALUE) {
                //use simpleInterval
                //if prev and this resolve to different roundTo, continue to next row
                prevRT /= simpleInterval;
                thisRT /= simpleInterval;
                double prevRint = Math.rint(prevRT);
                double thisRint = Math.rint(thisRT);
                if (prevRint != thisRint)
                    continue;

                //now both prev and this are in same group, finite, and roundTo same int
                //clear the further of this or previous
                //> vs >= is arbitrary
                keep.clear(Math.abs(prevRT - prevRint) > Math.abs(thisRT - thisRint)? 
                    row - 1 : row);

            } else { //month or year
                //month

                //prev
                //Finding floor is hard because of BC time and YEAR field being year within era
                //  (so I using getYear(gc) not gc.get(YEAR))
                //I'm sure there is a more efficient way, but this is quick, easy, correct.
                //This is only inefficient when intNumber is big which is unlikely for month and year.
                GregorianCalendar gc = Calendar2.epochSecondsToGc(prevRT);
                Calendar2.clearSmallerFields(gc, field);
                while ((field == Calendar2.YEAR? Calendar2.getYear(gc) : gc.get(field)) % intNumber != 0 ||
                       Calendar2.gcToEpochSeconds(gc) > prevRT)
                    gc.add(field, -1);
                double prevFloor = Calendar2.gcToEpochSeconds(gc);
                gc.add(field, intNumber);
                double prevCeil  = Calendar2.gcToEpochSeconds(gc);
                //< vs <= is arbitrary
                double prevClosest = Math.abs(prevRT - prevFloor) < Math.abs(prevRT - prevCeil)?
                    prevFloor : prevCeil;

                //this
                gc = Calendar2.epochSecondsToGc(thisRT);
                Calendar2.clearSmallerFields(gc, field);
                //String2.log(">> YEAR=" + Calendar2.getYear(gc));
                while ((field == Calendar2.YEAR? Calendar2.getYear(gc) : gc.get(field)) % intNumber != 0 ||
                       Calendar2.gcToEpochSeconds(gc) > thisRT)
                    gc.add(field, -1);
                double thisFloor = Calendar2.gcToEpochSeconds(gc);
                if (debugMode) String2.log(">> this=" + Calendar2.safeEpochSecondsToIsoStringTZ(thisRT,    "") +
                    " floor=" + Calendar2.safeEpochSecondsToIsoStringTZ(thisFloor, "") +
                    " YEAR=" + Calendar2.getYear(gc));
                gc.add(field, intNumber);
                double thisCeil  = Calendar2.gcToEpochSeconds(gc);
                //< vs <= is arbitrary
                double thisClosest = Math.abs(thisRT - thisFloor) < Math.abs(thisRT - thisCeil)?
                    thisFloor : thisCeil;

                //if prev and this resolve to different roundTo, continue to next row
                if (prevClosest != thisClosest)
                    continue;

                //now both prev and this are in same group, finite, and roundTo same int
                //clear the further of this or previous
                //> vs >= is arbitrary
                keep.clear(Math.abs(prevRT - prevClosest) > Math.abs(thisRT - thisClosest)? 
                    row - 1 : row);                
            }

        }
        //String2.log("\nkeep=" + keep.toString() + "\n" + dataToString());
        justKeep(keep);

        //convert back to fake missing values
        if (someConverted)
            temporarilySwitchNaNToFakeMissingValues(keyColumns); 
    }

    /**
     * This tests orderByClosest.
     */
    public static void testOrderByClosest() throws Exception {
        String2.log("\n*** Table.testOrderByClosest()");

        //regular: 2 minutes
        String2.log("\nTest 2 minutes");
        StringArray sar = new StringArray(new String[]{
            "b", "b", "b",        "b", "b", "b", "c", "a",  "d",  "a"});
        DoubleArray dar = new DoubleArray(new double[]{
            -121,-100, Double.NaN, 110, 132, -2, 1e30,  132, 1e30, 125});
        IntArray    iar = new    IntArray(new int[]   {
            0,    1,    2,         3,   4,   5,   6,   7,    8,    9});  
        Table table = new Table();
        table.addColumn("iar", iar);
        table.addColumn("sar", sar);
        table.addColumn("dar", dar);
        table.orderByClosest("sar, dar, 2 minutes");
        String results = table.dataToString();
        String expected = 
"iar,sar,dar\n" +
"9,a,125.0\n" +
"0,b,-121.0\n" +
"5,b,-2.0\n" +
"3,b,110.0\n" +
"6,c,1.0E30\n" +
"8,d,1.0E30\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //2 months: 
        //note that Jan is the 0th month: so 2 months rounds to Jan 1, Mar 1, May 1
        String2.log("\nTest 2 months");
        sar = new StringArray(new String[]{
            "b", "b", "b",        "b", "b", "b", "c", "a",  "d", "a"});
        String sa[] = {
            "-0002-08-28",   //0 b -121
            "-0002-09-28",   //1 b -100
            "",              //2 b NaN
            "2014-06-25",    //3 b 110, 
            "2014-07-25",    //4 b 132, 
            "-912345-12-28", //5 b -2,  
            "2010-04-05",    //6 c 82,  
            "2016-09-25",    //7 a 132,  
            "2010-04-05",    //8 d 82,  
            "2016-09-10"};   //9 a 125});
        dar = new DoubleArray();
        for (int i = 0; i < 10; i++)
            dar.add(Calendar2.safeIsoStringToEpochSeconds(sa[i]));
        iar = new    IntArray(new int[]   {
            0,    1,    2,         3,   4,   5,   6,   7,   8, 9});  
        table.clear();
        table.addColumn("iar", iar);
        table.addColumn("sar", sar);
        table.addColumn("dar", dar);
        table.orderByClosest("sar, dar, 2 months");
        StringArray sar2 = new StringArray();
        for (int i = 0; i < dar.size(); i++)
            sar2.add(Calendar2.safeEpochSecondsToIsoStringTZ(dar.get(i), ""));
        table.setColumn(2, sar2);
        results = table.dataToString();
        expected = 
"iar,sar,dar\n" +
"9,a,2016-09-10T00:00:00Z\n" +
"5,b,-912345-12-28T00:00:00Z\n" +
"0,b,-0002-08-28T00:00:00Z\n" +
"3,b,2014-06-25T00:00:00Z\n" +
"6,c,2010-04-05T00:00:00Z\n" +
"8,d,2010-04-05T00:00:00Z\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //10 years:   beware BC AD transition, see Calendar2.getYear 
        String2.log("\nTest 10 years");
        sar = new StringArray(new String[]{
            "b", "b", "b",        "b", "b", "b", "c", "a",  "d", "a"});
        sa = new String[] {
            "-0002-12-30",  //0 b -121
            "0004-01-14",   //1 b -100
            "",             //2 b NaN
            "2018-06-25",   //3 b 110, 
            "2024-07-25",   //4 b 132, 
            "-912345-12-28",//5 b -2,  
            "0211-04-05",   //6 c 82,  
            "2024-09-25",   //7 a 132,  
            "0211-04-05",   //8 d 82,  
            "2023-09-10"};  //9 a 125});
        dar = new DoubleArray();
        for (int i = 0; i < 10; i++)
            dar.add(Calendar2.safeIsoStringToEpochSeconds(sa[i]));
        iar = new    IntArray(new int[]   {
            0,    1,    2,         3,   4,   5,   6,   7,    8, 9});  
        table.clear();
        table.addColumn("iar", iar);
        table.addColumn("sar", sar);
        table.addColumn("dar", dar);
        table.orderByClosest("sar, dar, 10 years");
        sar2 = new StringArray();
        for (int i = 0; i < dar.size(); i++)
            sar2.add(Calendar2.safeEpochSecondsToIsoStringTZ(dar.get(i), ""));
        table.setColumn(2, sar2);
        results = table.dataToString();
        expected = 
"iar,sar,dar\n" +
"9,a,2023-09-10T00:00:00Z\n" +
"5,b,-912345-12-28T00:00:00Z\n" +
"0,b,-0002-12-30T00:00:00Z\n" +
"3,b,2018-06-25T00:00:00Z\n" +
"6,c,0211-04-05T00:00:00Z\n" +
"8,d,0211-04-05T00:00:00Z\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

    }


    /**
     * This sorts the table by keyColumns (all ascending) then, 
     * for each block where the nKeyColumns-1 values are constant,
     * makes just one row with the count of all non-NaN, non-missingValue, non-_FillValue 
     * values of each variable. 
     * For example, orderByCount([stationID]) would sort by stationID, 
     * then for each stationID, just return a count of the number
     * of non-NaN values for each other variable.
     *
     * <p>Missing values for the keyColumns are treated as however sort() treats them.
     * So they may sort low. 
     * So a missing value in the last keyColumn may be the min value.
     * 
     * <p>If there are 0 rows:
     * <br>There must still be all keyCols.
     * <br>The non-keyCols will be changed to be IntArrays with size=0.
     *
     * @param keyColumns  0 or more column numbers (0..).
     * @throws Exception if trouble (e.g., invalid column number).
     *    0 rows is not an error, but returns 0 rows.
     */
    public void orderByCount(int keyCols[]) throws Exception {
        if (reallyVerbose) String2.log("* orderByCount(" + String2.toCSSVString(keyCols) + ")");
        int nRows = nRows();
        int nCols = nColumns();
        int nKeyCols = keyCols.length;

        //note which are keyCol
        boolean isKeyCol[] = new boolean[nCols]; //all false
        for (int kc = 0; kc < nKeyCols; kc++) 
            isKeyCol[keyCols[kc]] = true;

        //important: convert all vars to standard mv, so missingValues and _FillValues will be caught
        //do keyCols in reversible way
        boolean someConverted = false;
        for (int col = 0; col < nCols; col++) {
            if (isKeyCol[col]) {
                if (temporarilyConvertToStandardMissingValues(col))
                    someConverted = true;
            } else {
                convertToStandardMissingValues(col);
            }
        }

        //sort based on keys
        if (nKeyCols > 0)
            ascendingSort(keyCols); 
        //String2.log(dataToString());


        //make resultPAs for count columns (IntArrays)
        //and set units to "count"
        PrimitiveArray resultPAs[] = new PrimitiveArray[nCols];
        for (int col = 0; col < nCols; col++) {
            if (!isKeyCol[col]) {
                resultPAs[col] = new IntArray(32, false);
                columnAttributes(col).set("units", "count");
            }
        }

        //walk through the table
        int resultsRow = -1;
        BitSet keep = new BitSet(nRows); //all false
        for (int row = 0; row < nRows; row++) { 

            //isNewGroup?
            boolean isNewGroup = true;
            if (row > 0) {
                isNewGroup = false;
                if (nKeyCols > 0) {
                    for (int kc = nKeyCols - 1; kc >= 0; kc--) { //count down more likely to find change sooner
                        if (columns.get(keyCols[kc]).compare(row - 1, row) != 0) {
                            isNewGroup = true;
                            break;
                        }
                    }
                }
            }

            if (isNewGroup) {
                resultsRow++;
                keep.set(row);
                //add a row to resultsPAs
                for (int col = 0; col < nCols; col++) {
                    if (!isKeyCol[col]) 
                        resultPAs[col].addInt(0);
                }
            }

            //increment count?
            for (int col = 0; col < nCols; col++) {
                //String2.log("row=" + row + " col=" + col + "value=\"" + columns.get(col).getString(row) + "\"");
                if (!isKeyCol[col] && String2.isSomething(columns.get(col).getString(row))) {
                    resultPAs[col].setInt(resultsRow, 
                        resultPAs[col].getInt(resultsRow) + 1);
                }
            }
        }

        //just keep new group 
        justKeep(keep);

        //swap resultPAs into place, and remove any missing_value or _FillValue
        for (int col = 0; col < nCols; col++) {
            if (!isKeyCol[col]) {
                columns.set(col, resultPAs[col]); 
                Attributes atts = columnAttributes(col);
                atts.remove("missing_value");
                atts.remove("_FillValue");
            }
        }

        //convert keyColumns back 
        if (someConverted)
            temporarilySwitchNaNToFakeMissingValues(keyCols);        
    }


    /**
     * This tests orderByCount.
     */
    public static void testOrderByCount() throws Exception {
        String2.log("\n*** Table.testOrderByCount()");

        //test 2 orderyBy variables
        ShortArray shar = new ShortArray(new short[]{
            100, 100, 100,        100, 100, 100, 100, 100,  100,  100,   2,   2,   2});      
        StringArray sar = new StringArray(new String[]{
            "b", "b", "b",        "b", "b", "b", "c", "a",  "d",  "a", "c", "a",  ""});
        DoubleArray dar = new DoubleArray(new double[]{
            -121,-100, Double.NaN, 110, 132, -2, 1e30,  132, 1e30,125, 1.1, 1.2, 1.3});
        ByteArray    bar = (ByteArray) new    ByteArray(new byte[]{ //127=NaN
            0,   127,    2,         3,   4,   5,   6,   7,    8,    9,  10,  11,  12}).setMaxIsMV(true);  
        Table table = new Table();
        table.addColumn("shar",shar);
        table.addColumn("bar", bar);
        table.addColumn("sar", sar);
        table.addColumn("dar", dar);
        table.orderByCount(new String[]{"shar","sar"});
        String results = table.toString();
        String expected = 
"{\n" +
"dimensions:\n" +
"\trow = 7 ;\n" +
"\tsar_strlen = 1 ;\n" +
"variables:\n" +
"\tshort shar(row) ;\n" +
"\tint bar(row) ;\n" +
"\t\tbar:units = \"count\" ;\n" +
"\tchar sar(row, sar_strlen) ;\n" +
"\tint dar(row) ;\n" +
"\t\tdar:units = \"count\" ;\n" +
"\n" +
"// global attributes:\n" +
"}\n" +
"shar,bar,sar,dar\n" +
"2,1,,1\n" +
"2,1,a,1\n" +
"2,1,c,1\n" +
"100,2,a,2\n" +
"100,5,b,5\n" +
"100,1,c,1\n" +
"100,1,d,1\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //test 0 orderBy variables
        sar = new StringArray(new String[]{
            "b", "b", "b",        "b", "b", "b", "c", "a",  "d",  "a", "c", "a",  ""});
        dar = new DoubleArray(new double[]{
            -121,-100, Double.NaN, 110, 132, -2, 1e30,  132, 1e30,125, 1.1, 1.2, 1.3});
        bar = (ByteArray)new    ByteArray(new byte[]{ //127=NaN
            0,   127,    2,         3,   4,   5,   6,   7,    8,    9,  10,  11,  12}).setMaxIsMV(true);  
        table = new Table();
        table.addColumn("bar", bar);
        table.addColumn("sar", sar);
        table.addColumn("dar", dar);
        table.orderByCount(new String[]{});
        results = table.toString();
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 1 ;\n" +
"variables:\n" +
"\tint bar(row) ;\n" +
"\t\tbar:units = \"count\" ;\n" +
"\tint sar(row) ;\n" +
"\t\tsar:units = \"count\" ;\n" +
"\tint dar(row) ;\n" +
"\t\tdar:units = \"count\" ;\n" +
"\n" +
"// global attributes:\n" +
"}\n" +
"bar,sar,dar\n" +
"12,12,12\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

    }


    
    /** 
     * This is a higher level orderByLimit that takes the csv string
     * with the names of the orderBy columns (may be none) plus the limitN 
     * (e.g., "10").
     */
    public void orderByLimit(String orderByCSV) throws Exception {

        if (orderByCSV == null || orderByCSV.trim().length() == 0)
            throw new SimpleException(QUERY_ERROR + ORDER_BY_LIMIT_ERROR + 
                " (no csv)");
        String csv[] = String2.split(orderByCSV, ',');
        if (csv.length == 0)
            throw new SimpleException(QUERY_ERROR + ORDER_BY_LIMIT_ERROR + 
                " (csv.length=0)");

        int nKeyCols = csv.length - 1;
        int limitN = String2.parseInt(csv[nKeyCols]);
        String[] keyColumnNames = new String[nKeyCols];
        System.arraycopy(csv, 0, keyColumnNames, 0, nKeyCols);

        orderByLimit(keyColumnNames, limitN);
        //withRounding("orderByLimit", keyColumnNames, false,
        //    (keyColNames) -> orderByLimit(keyColumnNamesToNumbers("orderByLimit", keyColNames), limitN)
        //);
    }

    /** 
     * This is a higher level orderByLimit.
     */
    public void orderByLimit(String orderBy[], int limitN) throws Exception {

        withRounding("orderByLimit", orderBy, false,
            (keyColNames) -> orderByLimit(keyColumnNamesToNumbers("orderByLimit", keyColNames), limitN)
        );
    }

    /**
     * This sorts by keyColumnNames (may be none) and then just keeps at most
     * limitN rows from each group.
     *
     * @param keyColumns  1 or more column numbers (0..).
     * @param limitN a positive integer, e.g., 10 
     * @throws Exception if trouble (e.g., a keyColumnName not found)
     */
    public void orderByLimit(int keyColumns[], int limitN) throws Exception {

        //limitN
        if (limitN < 0 || limitN == Integer.MAX_VALUE)
            throw new IllegalArgumentException(QUERY_ERROR + ORDER_BY_LIMIT_ERROR + 
                " (limitN=" + limitN + " must be a positive integer)"); 

        //just 0 or 1 rows?
        int nRows = nRows();
        if (nRows <= 1)
            return;

        //Important: temporarily convert keyColumns to standard mv, so missingValues and _FillValues will be handled properly.
        // Convert back below (but just to one of missing_value or _FillValue -- 2 is impossible and confusing).
        boolean someConverted = temporarilyConvertToStandardMissingValues(keyColumns); 

        //sort based on keys
        int nKeyColumns = keyColumns.length;
        if (nKeyColumns > 0)
            ascendingSort(keyColumns); 

        //walk through the table, within a group:
        //  keep either this row or previous row
        BitSet keep = new BitSet(); //all false
        keep.set(0, nRows); //now keep all / all true
        PrimitiveArray keyCols[] = new PrimitiveArray[nKeyColumns]; 
        for (int kc = 0; kc < nKeyColumns; kc++)
            keyCols[kc] = getColumn(keyColumns[kc]);
        int count = 1; //since starting on row 1
        ROW:
        for (int row = 1; row < nRows; row++) { //1 because I'm looking backwards

            //are we at start of a new group / did keyColumns 0 ... n-1 change?
            //  If so, continue to next row (no changes to current or previous row's keep value)
            //work backwards since last most likely to have changed
            for (int kc = nKeyColumns - 1; kc >= 0; kc--) { 
                if (keyCols[kc].compare(row - 1, row) != 0) {
                    count = 1; //this is first row in new group
                    continue ROW; //use a label because we are in a local loop
                }
            }

            //is count > limitN?
            if (++count > limitN)
                keep.clear(row); 
        }
        //String2.log("\nkeep=" + keep.toString() + "\n" + dataToString());
        justKeep(keep);

        //convert back to fake missing values
        if (someConverted)
            temporarilySwitchNaNToFakeMissingValues(keyColumns);
    }

    /**
     * This tests orderByLimit.
     */
    public static void testOrderByLimit() throws Exception {
        String2.log("\n*** Table.testOrderByLimit()");

        StringArray sar = new StringArray(new String[]{
            "b", "b", "b", "b", "b", "b", "c", "a", "d", "a"});
        IntArray    iar = new    IntArray(new int[]   {
             0,   1,   2,   3,   4,   5,   6,   7,   8,   9});  
        Table table = new Table();
        table.addColumn("iar", iar);
        table.addColumn("sar", sar);
        table.orderByLimit("sar, 2");
        String results = table.dataToString();
        String expected = 
"iar,sar\n" +
"7,a\n" +
"9,a\n" +
"0,b\n" +
"1,b\n" +
"6,c\n" +
"8,d\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
    }


    /**
     * This is like the other saveAsMatlab, but writes to a file.
     *
     * @param fullName The full file name (dir + name + ext (usually .mat))
     * @param varName  if varName isn't a valid Matlab variable name,
     *    it will be made so via String2.modifyToBeVariableNameSafe().
     */
    public void saveAsMatlab(String fullName, String varName) throws Exception {
        if (reallyVerbose) String2.log("Table.saveAsMatlab " + fullName); 
        long time = System.currentTimeMillis();

        //POLICY: because this procedure may be used in more than one thread,
        //do work on unique temp files names using randomInt, then rename to proper file name.
        //If procedure fails half way through, there won't be a half-finished file.
        int randomInt = Math2.random(Integer.MAX_VALUE);


        //write to dataOutputStream 
        BufferedOutputStream bos = new BufferedOutputStream(
            new FileOutputStream(fullName + randomInt));

        try {
            saveAsMatlab(bos, varName);  //it calls modifyToBeVariableNameSafe
            bos.close();
            bos = null;

            //rename the file to the specified name, instantly replacing the original file     
            File2.rename(fullName + randomInt, fullName); //throws Exception if trouble

        } catch (Exception e) {
            //try to close the file
            try {
                if (bos != null)
                    bos.close(); 
            } catch (Exception e2) {
                //don't care
            }

            //delete the partial file
            File2.delete(fullName + randomInt);
            //delete any existing file
            File2.delete(fullName);

            throw e;
        }

        //Old way relies on script which calls Matlab.
        //This relies on a proprietary program, so good to remove it.
        //cShell("/u00/chump/grdtomatlab " + fullGrdName + " " + 
        //    fullResultName + randomInt + ".mat " + varName); 

        if (reallyVerbose) String2.log("  Table.saveAsMatlab done. fileName=" + fullName + " TIME=" + 
            (System.currentTimeMillis() - time) + "ms");
    }


    /**
     * Save this table data as a Matlab .mat file.
     * This writes the lon values as they are currently in this table
     *    (e.g., +-180 or 0..360).
     * This overwrites any existing file of the specified name.
     * This makes an effort not to create a partial file if there is an error.
     * If no exception is thrown, the file was successfully created.
     * 
     * @param outputStream usually already buffered.
     *    Afterwards, it is flushed, not closed.
     * @param varName the name to use for the variable which holds all of the data, 
     *    usually the dataset's internal name.
     * @throws Exception 
     */
/* commented out 2008-02-07
    public void saveAsMatlab(OutputStream outputStream, String varName) 
        throws Exception {
        if (reallyVerbose) String2.log("Table.saveAsMatlab outputStream"); 
        long time = System.currentTimeMillis();

        String errorInMethod = String2.ERROR + " in Table.saveAsMatlab:\n";

        //make sure there is data
        if (nRows() == 0)
            throw new SimpleException(errorInMethod + MustBe.THERE_IS_NO_DATA);

        //open a dataOutputStream 
        DataOutputStream dos = new DataOutputStream(outputStream);

        //write the header
        Matlab.writeMatlabHeader(dos);

        //make an array of the data[row][col]
        int tnRows = nRows();
        int tnCols = nColumns();
        double ar[][] = new double[tnRows][tnCols];
        for (int col = 0; col < tnCols; col++) {
            PrimitiveArray pa = getColumn(col);
            if (pa.elementType() == PAType.STRING) {
                for (int row = 0; row < tnRows; row++) {
                    ar[row][col] = Double.NaN; //can't store strings in a double array                  
                }                
            } else {
                for (int row = 0; row < tnRows; row++)
                    ar[row][col] = pa.getNiceDouble(row);
            }
        }
        Matlab.write2DDoubleArray(dos, varName, ar);

        //this doesn't write attributes because .mat files don't store attributes
        //setStatsAttributes(true); //true = double
        //write the attributes...

        dos.flush(); //essential

        if (reallyVerbose) String2.log("  Table.saveAsMatlab done. TIME=" + 
            (System.currentTimeMillis() - time) + "ms");
    }
*/
    /**
     * Save this table data as a Matlab .mat file.
     * This writes the lon values as they are currently in this table
     *    (e.g., +-180 or 0..360).
     * This overwrites any existing file of the specified name.
     * This makes an effort not to create a partial file if there is an error.
     * If no exception is thrown, the file was successfully created.
     * This maintains the data types (Strings become char[][]).
     * Missing values should already be stored as NaNs (perhaps via convertToStandardMissingValues()).
     *
     * <p>If the columns have different lengths, they will be stored that way in the file(!).
     * 
     * @param outputStream usually already buffered.
     *    Afterwards, it is flushed, not closed.
     * @param structureName the name to use for the Matlab structure which holds all of the data, 
     *    usually the dataset's internal name.
     *    If varName isn't a valid Matlab variable name,
     *    it will be made so via String2.encodeMatlabNameSafe().
     * @throws Exception 
     */
    public void saveAsMatlab(OutputStream outputStream, String structureName) 
        throws Exception {
        if (reallyVerbose) String2.log("Table.saveAsMatlab outputStream"); 
        long time = System.currentTimeMillis();
        structureName = String2.encodeMatlabNameSafe(structureName);

        String errorInMethod = String2.ERROR + " in Table.saveAsMatlab:\n";

        //make sure there is data
        if (nRows() == 0)
            throw new SimpleException(errorInMethod + MustBe.THERE_IS_NO_DATA + " (nRows = 0)");

        //calculate the size of the structure
        int nCols = nColumns();
        byte structureNameInfo[] = Matlab.nameInfo(structureName); 
        NDimensionalIndex ndIndex[] = new NDimensionalIndex[nCols];
        long cumSize = //see 1-32
            16 + //for array flags
            16 + //my structure array is always 2 dimensions 
            structureNameInfo.length +
            8 + //field name length (for all fields)
            8 + nCols * 32; //field names
        for (int col = 0; col < nCols; col++) {
            //String ndIndex takes time to make; so make it and store it for use below
            ndIndex[col] = Matlab.make2DNDIndex(getColumn(col)); 
            //if (reallyVerbose) String2.log("  " + getColumnName(col) + " " + ndIndex[col]);
            //add size of each cell
            cumSize += 8 + //type and size
                Matlab.sizeOfNDimensionalArray(  //throws exception if too big for Matlab
                    "", //without column names (they're stored separately)
                    getColumn(col), ndIndex[col]);
        }
        if (cumSize >= Integer.MAX_VALUE - 1000)
            throw new RuntimeException("Too much data: Matlab structures must be < Integer.MAX_VALUE bytes.");

        //open a dataOutputStream 
        DataOutputStream stream = new DataOutputStream(outputStream);

        //******** Matlab Structure
        //*** THIS CODE MIMICS EDDTable.saveAsMatlab. If make changes here, make them there, too.
        //    The code in EDDGrid.saveAsMatlab is similar, too.
        //write the header
        Matlab.writeMatlabHeader(stream);

        //*** write Matlab Structure  see 1-32
        //write the miMatrix dataType and nBytes
        stream.writeInt(Matlab.miMATRIX);        //dataType
        stream.writeInt((int)cumSize); //safe since checked above

        //write array flags 
        stream.writeInt(Matlab.miUINT32); //dataType
        stream.writeInt(8);  //fixed nBytes of data
        stream.writeInt(Matlab.mxSTRUCT_CLASS); //array flags  
        stream.writeInt(0); //reserved; ends on 8 byte boundary

        //write structure's dimension array 
        stream.writeInt(Matlab.miINT32); //dataType
        stream.writeInt(2 * 4);  //nBytes
        //matlab docs have 2,1, octave has 1,1. 
        //Think of structure as one row of a table, where elements are entire arrays:  e.g., sst.lon sst.lat sst.sst.
        //Having multidimensions (e.g., 2 here) lets you have additional rows, e.g., sst(2).lon sst(2).lat sst(2).sst.
        //So 1,1 makes sense.
        stream.writeInt(1);  
        stream.writeInt(1);
         
        //write structure name 
        stream.write(structureNameInfo, 0, structureNameInfo.length);

        //write length for all field names (always 32)  (short form)
        stream.writeShort(4);                //nBytes
        stream.writeShort(Matlab.miINT32);    //dataType
        stream.writeInt(32);                 //nBytes per field name

        //write the field names (each 32 bytes)
        stream.writeInt(Matlab.miINT8);    //dataType
        stream.writeInt(nCols * 32);      //nBytes per field name
        String nulls = String2.makeString('\u0000', 32);
        for (int col = 0; col < nCols; col++) 
            stream.write(String2.toByteArray(
                String2.noLongerThan(
                    String2.encodeMatlabNameSafe(getColumnName(col)), 
                    31) + nulls), 0, 32); //EEEK! better not be longer!!!

        //write the structure's elements (one for each col)
        for (int col = 0; col < nCols; col++) 
            Matlab.writeNDimensionalArray(stream, "", //without column names (they're stored separately)
                getColumn(col), ndIndex[col]);

        //this doesn't write attributes because .mat files don't store attributes

        stream.flush(); //essential

        if (reallyVerbose) String2.log("  Table.saveAsMatlab done. TIME=" + 
            (System.currentTimeMillis() - time) + "ms");

    }

    /**
     * This tests saveAsMatlab().
     *
     * @throws Exception if trouble
     */
    public static void testSaveAsMatlab() throws Exception {
        verbose = true;
        reallyVerbose = true;
        //see gov.noaa.pfel.coastwatch.griddata.Matlab class for summary of Matlab commands

        String2.log("\n***** Table.testSaveAsMatlab");
        Table table = new Table();
        table.addColumn("ints", new IntArray(new int[]{1,2,3}));
        table.addColumn("floats", new FloatArray(new float[]{1.1f, 2.2f, 3.3f}));
        table.addColumn("Strings", new StringArray(new String[]{"a", "bb", "ccc"}));
        table.addColumn("doubles", new DoubleArray(new double[]{1.111, 2.222, 3.333}));
        String dir = "c:/temp/";
        File2.delete(dir + "temp.mat");
        table.saveAsMatlab(dir + "temp.mat", "sst"); //names of length 3,4,5 were a challenge
        String mhd = File2.hexDump(dir + "temp.mat", 1000);
        String2.log(mhd);
        //String2.log("\nsst.mat=\n" + File2.hexDump(dir + "sst.mat", 1000));
        Test.ensureEqual(
            mhd.substring(0, 71 * 4) + mhd.substring(71 * 7), //remove the creation dateTime
"4d 41 54 4c 41 42 20 35   2e 30 20 4d 41 54 2d 66   MATLAB 5.0 MAT-f |\n" +
"69 6c 65 2c 20 43 72 65   61 74 65 64 20 62 79 3a   ile, Created by: |\n" +
"20 67 6f 76 2e 6e 6f 61   61 2e 70 66 65 6c 2e 63    gov.noaa.pfel.c |\n" +
"6f 61 73 74 77 61 74 63   68 2e 4d 61 74 6c 61 62   oastwatch.Matlab |\n" +
//"2c 20 43 72 65 61 74 65   64 20 6f 6e 3a 20 4d 6f   , Created on: Mo |\n" +
//"6e 20 46 65 62 20 31 31   20 30 39 3a 31 31 3a 30   n Feb 11 09:11:0 |\n" +
//"30 20 32 30 30 38 20 20   20 20 20 20 20 20 20 20   0 2008           |\n" +
"20 20 20 20 00 00 00 00   00 00 00 00 01 00 4d 49                 MI |\n" +
"00 00 00 0e 00 00 01 e8   00 00 00 06 00 00 00 08                    |\n" +
"00 00 00 02 00 00 00 00   00 00 00 05 00 00 00 08                    |\n" +
"00 00 00 01 00 00 00 01   00 03 00 01 73 73 74 00               sst  |\n" +
"00 04 00 05 00 00 00 20   00 00 00 01 00 00 00 80                    |\n" +
"69 6e 74 73 00 00 00 00   00 00 00 00 00 00 00 00   ints             |\n" +
"00 00 00 00 00 00 00 00   00 00 00 00 00 00 00 00                    |\n" +
"66 6c 6f 61 74 73 00 00   00 00 00 00 00 00 00 00   floats           |\n" +
"00 00 00 00 00 00 00 00   00 00 00 00 00 00 00 00                    |\n" +
"53 74 72 69 6e 67 73 00   00 00 00 00 00 00 00 00   Strings          |\n" +
"00 00 00 00 00 00 00 00   00 00 00 00 00 00 00 00                    |\n" +
"64 6f 75 62 6c 65 73 00   00 00 00 00 00 00 00 00   doubles          |\n" +
"00 00 00 00 00 00 00 00   00 00 00 00 00 00 00 00                    |\n" +
"00 00 00 0e 00 00 00 40   00 00 00 06 00 00 00 08          @         |\n" +
"00 00 00 0c 00 00 00 00   00 00 00 05 00 00 00 08                    |\n" +
"00 00 00 03 00 00 00 01   00 00 00 01 00 00 00 00                    |\n" +
"00 00 00 05 00 00 00 0c   00 00 00 01 00 00 00 02                    |\n" +
"00 00 00 03 00 00 00 00   00 00 00 0e 00 00 00 40                  @ |\n" +
"00 00 00 06 00 00 00 08   00 00 00 07 00 00 00 00                    |\n" +
"00 00 00 05 00 00 00 08   00 00 00 03 00 00 00 01                    |\n" +
"00 00 00 01 00 00 00 00   00 00 00 07 00 00 00 0c                    |\n" +
"3f 8c cc cd 40 0c cc cd   40 53 33 33 00 00 00 00   ?   @   @S33     |\n" +
"00 00 00 0e 00 00 00 48   00 00 00 06 00 00 00 08          H         |\n" +
"00 00 00 04 00 00 00 00   00 00 00 05 00 00 00 08                    |\n" +
"00 00 00 03 00 00 00 03   00 00 00 01 00 00 00 00                    |\n" +
"00 00 00 04 00 00 00 12   00 61 00 62 00 63 00 20            a b c   |\n" +
"00 62 00 63 00 20 00 20   00 63 00 00 00 00 00 00    b c     c       |\n" +
"00 00 00 0e 00 00 00 48   00 00 00 06 00 00 00 08          H         |\n" +
"00 00 00 06 00 00 00 00   00 00 00 05 00 00 00 08                    |\n" +
"00 00 00 03 00 00 00 01   00 00 00 01 00 00 00 00                    |\n" +
"00 00 00 09 00 00 00 18   3f f1 c6 a7 ef 9d b2 2d           ?      - |\n" +
"40 01 c6 a7 ef 9d b2 2d   40 0a a9 fb e7 6c 8b 44   @      -@    l D |\n",
"mhd=" + mhd);
        //File2.delete(dir + "temp.mat");
    }


    /**
     * Save this table of data as a flat netCDF .nc file (a column for each 
     * variable, all referencing one dimension) using the currently
     * available attributes.
     * <br>The data are written as separate variables, sharing a common dimension
     *   "observation", not as a Structure.
     * <br>The data values are written as their current data type 
     *   (e.g., float or int).
     * <br>This writes the lon values as they are currently in this table
     *   (e.g., +-180 or 0..360).
     * <br>This overwrites any existing file of the specified name.
     * <br>This makes an effort not to create a partial file if there is an error.
     * <br>If no exception is thrown, the file was successfully created.
     * <br>!!!The file must have at least one row, or an Exception will be thrown
     *   (nc dimensions can't be 0 length).
     * <br>!!!The table should initially have missing values stored as NaNs.
     *    NaN's are converted to DataHelper.FAKE_MISSING_VALUE temporarily.
     * 
     * @param fullName The full file name (dir + name + ext (usually .nc))
     * @param dimensionName the name for the rows dimension, 
     *    e.g., usually "time", "station", "observation", "trajectory", "row", or ...?
     *    <p>OBSOLETE [To conform to the Unidata Observation Dataset Conventions
     *    (https://www.unidata.ucar.edu/software/netcdf-java/formats/UnidataObsConvention.html):
     *    This sets the global attribute observationDimension={dimensionName}.]
     * @throws Exception 
     */
    public void saveAsFlatNc(String fullName, String dimensionName) throws Exception {
        saveAsFlatNc(fullName, dimensionName, true);
    }

    /**
     * Save this table of data as a flat netCDF .nc file (a column for each 
     * variable, all referencing one dimension) using the currently
     * available attributes.
     * <br>The data are written as separate variables, sharing a common dimension
     *   "observation", not as a Structure.
     * <br>The data values are written as their current data type 
     *   (e.g., float or int).
     * <br>This writes the lon values as they are currently in this table
     *   (e.g., +-180 or 0..360).
     * <br>This overwrites any existing file of the specified name.
     * <br>This makes an effort not to create a partial file if there is an error.
     * <br>If no exception is thrown, the file was successfully created.
     * <br>!!!The file must have at least one row, or an Exception will be thrown
     *   (nc dimensions can't be 0 length).
     * <br>LongArray columns are saved as DoubleArray.
     * 
     * @param fullName The full file name (dir + name + ext (usually .nc))
     * @param dimensionName the name for the rows dimension, 
     *    e.g., usually "time", "station", "observation", "trajectory", "row", or ...?
     *    <p>OBSOLETE [To conform to the Unidata Observation Dataset Conventions
     *    (https://www.unidata.ucar.edu/software/netcdf-java/formats/UnidataObsConvention.html): [GONE!]
     *    This sets the global attribute observationDimension={dimensionName}.]
     * @param convertToFakeMissingValues if true, 
     *    NaN's are converted to DataHelper.FAKE_MISSING_VALUE temporarily.
     * @throws Exception 
     */
    public void saveAsFlatNc(String fullName, String dimensionName, 
            boolean convertToFakeMissingValues) throws Exception {
        String msg = "  Table.saveAsFlatNc " + fullName; 
        long time = System.currentTimeMillis();

        //String2.log("saveAsFlatNc first 5 rows:" + toString(5));

        //this method checks validity because it is used as a fundamental part
        //of EDDGridFromFiles and EDDTableFromFiles fileTable
        //and because code below throws null pointer exception (not descriptive or helpful)
        //if 2 vars have same name
        ensureValid();  

        //POLICY: because this procedure may be used in more than one thread,
        //do work on unique temp files names using randomInt, then rename to proper file name.
        //If procedure fails half way through, there won't be a half-finished file.
        int randomInt = Math2.random(Integer.MAX_VALUE);

        //open the file (before 'try'); if it fails, no temp file to delete
        NetcdfFileWriter nc = NetcdfFileWriter.createNew(
            NetcdfFileWriter.Version.netcdf3, fullName + randomInt);
        boolean nc3Mode = true;
        try {
            Group rootGroup = nc.addGroup(null, "");
            nc.setFill(false);
        
            //items determined by looking at a .nc file; items written in that order 

            int nRows = nRows();
            int nColumns = nColumns();
            if (nRows == 0) {
                throw new Exception(String2.ERROR + " in" + msg + ":\n" + 
                    MustBe.THERE_IS_NO_DATA + " (nRows = 0)");
            }
            PrimitiveArray tPA[] = new PrimitiveArray[nColumns];

            //define the dimensions
            Dimension dimension  = nc.addDimension(rootGroup, dimensionName, nRows);
//javadoc says: if there is an unlimited dimension, all variables that use it are in a structure
//Dimension rowDimension  = nc.addDimension(rootGroup, "row", nRows, true, true, false); //isShared, isUnlimited, isUnknown
//String2.log("unlimitied dimension exists: " + (nc.getUnlimitedDimension() != null));

            //add the variables
            Variable colVars[] = new Variable[nColumns];
            for (int col = 0; col < nColumns; col++) {
                String tColName = getColumnNameWithoutSpaces(col);
                PrimitiveArray pa = getColumn(col);
                tPA[col] = pa;
                PAType type = pa.elementType();
                if (type == PAType.STRING) {
                    int max = Math.max(1, ((StringArray)pa).maxStringLength()); //nc libs want at least 1; 0 happens if no data
                    Dimension lengthDimension = nc.addDimension(rootGroup, 
                        tColName + NcHelper.StringLengthSuffix, max);
                    colVars[col] = nc.addVariable(rootGroup, tColName, DataType.CHAR, 
                        Arrays.asList(dimension, lengthDimension)); 
                } else {
                    colVars[col] = nc.addVariable(rootGroup, tColName, 
                        NcHelper.getNc3DataType(type), Arrays.asList(dimension)); 
                }
//nc.addMemberVariable(recordStructure, nc.findVariable(tColName));
            }

//boolean bool = nc.addRecordStructure(); //creates a structure variable called "record"         
//String2.log("addRecordStructure: " + bool);
//Structure recordStructure = (Structure)nc.findVariable("record");

            //set id attribute = file name
            //currently, only the .nc saveAs types use attributes!
            if (globalAttributes.get("id") == null)
                globalAttributes.set("id", File2.getNameNoExtension(fullName));

            //set the globalAttributes
            NcHelper.setAttributes(nc3Mode, rootGroup, globalAttributes);

            for (int col = 0; col < nColumns; col++) {
                //convert to fake MissingValues   (in time to write attributes)
                PAType tc = tPA[col].elementType();
                if (convertToFakeMissingValues) 
                    convertToFakeMissingValues(col);

                Attributes tAtts = new Attributes(columnAttributes(col)); //use a copy
                //String2.log(">> saveAsFlatNc col=" + tPA[col].elementTypeString() + " enc=" + tAtts.getString(String2.ENCODING));
                if (tc == PAType.STRING && 
                    tAtts.getString(String2.ENCODING) == null) //don't change if already specified
                    tAtts.add(String2.ENCODING, String2.ISO_8859_1);
// disabled until there is a standard
//                else if (tc == PAType.CHAR)
//                    tAtts.add(String2.CHARSET, String2.ISO_8859_1);

                NcHelper.setAttributes(nc3Mode, colVars[col], tAtts, tc.isUnsigned());
            }

            //leave "define" mode
            nc.create();

            //write the data
            for (int col = 0; col < nColumns; col++) {
                //String2.log("writing col=" + col + " " + getColumnName(col) + 
                //    " colVars[col]=" + colVars[col] +  
                //    " size=" + tPA[col].size() + " tPA[col]=" + tPA[col]);
                nc.write(colVars[col], NcHelper.get1DArray(tPA[col]));

                //convert back to standard MissingValues
                if (convertToFakeMissingValues) 
                    convertToStandardMissingValues(col);
            }

            //if close throws exception, it is trouble
            nc.close(); //it calls flush() and doesn't like flush called separately
            nc = null;

            //rename the file to the specified name, instantly replacing the original file
            File2.rename(fullName + randomInt, fullName); //throws Exception if trouble

            //diagnostic
            if (reallyVerbose) msg +=  
                " done. nColumns=" + nColumns() + " nRows=" + nRows() + 
                " TIME=" + (System.currentTimeMillis() - time) + "ms";
            //String2.log(NcHelper.ncdump(directory + name + ext, "-h");

        } catch (Exception e) {
            //try to close the file
            try {
                if (nc != null) nc.abort(); 
            } catch (Exception e2) {
                //don't care
            }

            //delete the partial file
            File2.delete(fullName + randomInt);

            //delete any existing file
            File2.delete(fullName);
            if (!reallyVerbose) String2.log(msg);

            throw e;

        } finally {
            if (reallyVerbose) String2.log(msg);
        }
    }

    /** THIS IS NOT FINISHED.
     * This creates or appends the data to a flat .nc file with an unlimited dimension.
     * If the file doesn't exist, it will be created.
     * If the file does exist, the data will be appended.
     *
     * <p>If the file is being created, the attributes are used (otherwise, they aren't).
     * String variables should have an integer "strlen" attribute which specifies the
     * maximum number of characters for the column (otherwise, strlen will be calculated
     * from the longest String in the current chunk of data and written as the strlen attribute).  
     *
     * <p>If the file exists and a colName in this table isn't in it, the column is ignored.
     *
     * <p>If the file exists and this table lacks a column in it, the column will be filled with
     * the file-defined _FillValue (first choice) or missing_value 
     * or the standard PrimitiveArray missing value (last choice).
     *
     * @param fileName
     * @param dimName  e.g., "time" or 
     * @throws Exception if trouble (but the file will be closed in all cases)
     */
/*    public static void saveAsUnlimitedNc(String fileName, String dimName) throws Exception {

        String msg = "  Table.saveAsUnlimited " + fileName;
        long time = System.currentTimeMillis();
        int nCols = nColumns();
        int nRows = nRows();
        int strlens[] = new int[nCols];  //all 0's
        boolean fileExists = File2.isFile(fileName);
        NetcdfFileWriter file = null;
        Group rootGroup = null;
        Dimension dim;

        try {
            
            if (fileExists) {
                file = NetcdfFileWriter.openExisting(fileName);
                rootGroup = file.getRootGroup();
                dim = file.findDimension(dimName);

            } else {
                //create the file
                file = NetcdfFileWriter.createNew(NetcdfFileWriter.Version.netcdf3, 
                    fileName);
                boolean nc3Mode = true;
                rootGroup = file.addGroup(null, "");

                NcHelper.setAttributes(rootGroup, globalAttributes());

                //define unlimited dimension
                dim = file.addUnlimitedDimension(dimName);
                ArrayList dims = new ArrayList();
                dims.add(dim);

                //define Variables
                Variable colVars[] = new Variable[nCols];
                for (int col = 0; col < nCols; col++) {
                    String colName = getColumnName(col);
                    PrimitiveArray pa = column(col);
                    Attributes atts = new Attributes(columnAttributes(col)); //use a copy
                    if (pa.elementType() == PAType.STRING) {
                        //create a string variable
                        int strlen = atts.getInt("strlen");
                        if (strlen <= 0 || strlen == Integer.MAX_VALUE) {
                            strlen = Math.max(1, ((StringArray)pa). maximumLength());
                            atts.set("strlen", strlen);
                        }
                        strlens[col] = strlen;
                        Dimension tDim = file.addUnlimitedDimension(colName + "_strlen");
                        ArrayList tDims = new ArrayList();
                        tDims.add(dim);
                        tDims.add(tDim);
                        colVars[col] = file.addStringVariable(colName, dims, strlen);                        

                    } else {
                        //create a non-string variable
                        colVars[col] = file.addVariable(rootGroup, colName, 
                            NcHelper.getNc3DataType(pa.elementType()), dims);
                    }

                    if (pa.elementType() == PAType.CHAR)
                        atts.add(String2.CHARSET, String2.ISO_8859_1);
                    else if (pa.elementType() == PAType.STRING)
                        atts.add(String2.ENCODING, String2.ISO_8859_1);
                    NcHelper.setAttributes(colVars[col], atts);
                }

                //switch to create mode
                file.create();
            }

            //add the data
            int fileNRows = dim.getLength();
            int[] origin1 = new int[] {row};    
            int[] origin2 = new int[] {row, 0};  
            vars
            while (...) {
                
                Variable var = vars.get  ;
                class elementPAType = NcHelper.  var.
                ArrayList tDims = var.getDimensions ();
                String colName = var.getFullName();
                Attributes atts = new Attributes();
                NcHelper.getAttributes(colName, atts);
                int col = findColumnNumber(colName);
                PrimitiveArray pa = null;
                if (col < 0) {
                    //the var has nothing comparable in this table, 
                    //so make a pa filled with missing values
                    if (ndims > 1) {
                        //string vars always use "" as mv
                        continue;
                    }
                    //make a primitive array 
                    PrimitiveArray pa = PrimitiveArray.factory(type, 1, false);
                    String mv = atts.getString("_FillValue");
                    if (mv == null)
                        mv = atts.getString("missing_value");
                    if (mv == null)
                        mv = pa.getMV();
                    pa.addNStrings(nRows, mv);

                } else {
                    //get data from this table
                    pa = getColumn(col);
                }

                //write the data
                if (pa.elementType() == PAType.STRING) {
                    //write string data
                    if (fileExists) {
                        ..just get one att from file
                        Attributes atts = columnAttributes(col);
                        strlens[col] = NcHelper.getAttribute ts.getInt("strlen");
                    }
                    if (strlens[col] <= 0 || strlens[col] == Integer.MAX_VALUE) 
                        throw new SimpleException("\"strlen\" attribute not found for variable=" + colName);

                    ArrayChar.D2 ac = new ArrayChar.D2(2, strlens[col]);
                    int n = pa.size();
                    for (int i = 0; i < n; i++) 
                        ac.setString(i, pa.getString(i));
                    file.write(colVars[col], origin2, ac);
                    
                } else {
                    //write non-string data
                    file.write(colVars[col], origin1, Array.factory(pa.toArray()));
                }
            }
            file.close();
            file = null;

            if (reallyVerbose) msg +=  
                " finished. nColumns=" + nColumns() + " nRows=" + nRows() + 
                " TIME=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            try {  if (file != null) file.abort(); 
            } catch (Throwable t2) {  }

            if (!reallyVerbose) String2.log(msg); 
            throw t;

        }
    }
*/

    /** 
     * This is like saveAs4DNc but with no StringVariable option.
     */
    public void saveAs4DNc(String fullName, int xColumn, int yColumn, 
            int zColumn, int tColumn) throws Exception {
 
        saveAs4DNc(fullName, xColumn, yColumn, 
            zColumn, tColumn, null, null, null);
    }

    /** 
     * This is like saveAs4DNc but removes stringVariableColumn (often column 4 = "ID", which
     * must have just 1 value, repeated)
     * and saves it as a stringVariable in the 4DNc file, 
     * and then reinserts the stringVariableColumn.
     * For files with just 1 station's data, Dapper and DChart like this format.
     *
     * @param stringVariableColumn is the column (
     */
    public void saveAs4DNcWithStringVariable(String fullName, int xColumn, int yColumn, 
            int zColumn, int tColumn, int stringVariableColumn) throws Exception {
 
        //remove ID column
        String tName = getColumnName(stringVariableColumn);
        Attributes tIdAtt = columnAttributes(stringVariableColumn);
        PrimitiveArray tIdPa = getColumn(stringVariableColumn);
        removeColumn(stringVariableColumn);

        //save as 4DNc
        saveAs4DNc(fullName, xColumn, yColumn, zColumn, tColumn, 
            tName, tIdPa.getString(0), tIdAtt);

        //reinsert ID column
        addColumn(stringVariableColumn, tName, tIdPa, tIdAtt);
    }

        

    /**
     * Save this table of data as a 4D netCDF .nc file using the currently
     * available attributes.
     * This method uses the terminology x,y,z,t, but does require
     *   that the data represent lon,lat,alt,time.
     * All columns other than the 4 dimension related columns are stored
     * as 4D arrays.
     * This will sort the values t (primary key), then z, then y, then x (least important key).
     * The data values are written as their current data type 
     * (e.g., float or int).
     * This writes the lon values as they are currently in this table
     * (e.g., +-180 or 0..360).
     * This overwrites any existing file of the specified name.
     * This makes an effort not to create a partial file if there is an error.
     * If no exception is thrown, the file was successfully created.
     * !!!The file must have at least one row, or an Exception will be thrown
     * (nc dimensions can't be 0 length).
     * This tries to look like it works instantaneously:
     *   it writes to a temp file then renames it to correct name.
     *
     * <p>This supports an optional stringVariable which is written
     * to the file as a 1D char array.   Dapper/DChart prefers this
     * to a 4D array for the ID info.
     * 
     * @param fullName The full file name (dir + name + ext (usually .nc))
     * @param xColumn the column with lon info.
     * @param yColumn the column with lat info.
     * @param zColumn the column with alt info.
     * @param tColumn the column with time info.
     * @param stringVariableName the name for the optional 1D String variable 
     *    (or null to not use this feature)
     * @param stringVariableValue the value for the optional 1D String variable
     *    (must be non-null non-"" if stringVariableName isn't null)
     * @param stringVariableAttributes the attributes for the optional 1D String variable
     *    (must be non-null if stringVariableName isn't null)
     * @throws Exception 
     */
    public void saveAs4DNc(String fullName, int xColumn, int yColumn, 
            int zColumn, int tColumn, String stringVariableName, 
            String stringVariableValue, Attributes stringVariableAttributes) throws Exception {
        String msg = "  Table.saveAs4DNc " + fullName; 
        long time = System.currentTimeMillis();

        //POLICY: because this procedure may be used in more than one thread,
        //do work on unique temp files names using randomInt, then rename to proper file name.
        //If procedure fails half way through, there won't be a half-finished file.
        int randomInt = Math2.random(Integer.MAX_VALUE);


        //ensure there is data
        String errorInMethod = String2.ERROR + " in" + msg + ":\n";
        if (stringVariableName != null) {
            Test.ensureNotEqual(stringVariableName.length(), 0, errorInMethod + "stringVariableName is \"\".");
            if (stringVariableValue == null)
                throw new SimpleException(errorInMethod + "stringVariableValue is null.");
            Test.ensureNotEqual(stringVariableValue.length(), 0, errorInMethod + "stringVariableValue is \"\".");
        }
        if (nRows() == 0) {
            throw new Exception(errorInMethod + MustBe.THERE_IS_NO_DATA + " (nRows = 0)");
        }

        //open the file (before 'try'); if it fails, no temp file to delete
        NetcdfFileWriter nc = NetcdfFileWriter.createNew(
            NetcdfFileWriter.Version.netcdf3, fullName + randomInt);
        long make4IndicesTime = -1;
        boolean nc3Mode = true;
        
        try {
            Group rootGroup = nc.addGroup(null, "");
            nc.setFill(false);

            //if (reallyVerbose) {
            //    String2.log("Table.saveAs4DNc" +
            //        "\n     raw X " + getColumn(xColumn).statsString() + 
            //        "\n     raw Y " + getColumn(yColumn).statsString() + 
            //        "\n     raw Z " + getColumn(zColumn).statsString() + 
            //        "\n     raw T " + getColumn(tColumn).statsString()); 
            //}

            //sort
            PrimitiveArray.sort(columns, 
                new int[]{tColumn, zColumn, yColumn, xColumn},
                new boolean[]{true, true, true, true});

            //add axis attributes
            columnAttributes(xColumn).set("axis", "X");
            columnAttributes(yColumn).set("axis", "Y");
            columnAttributes(zColumn).set("axis", "Z");
            columnAttributes(tColumn).set("axis", "T");

            //make the indices
            make4IndicesTime = System.currentTimeMillis();
            IntArray xIndices = new IntArray();
            IntArray yIndices = new IntArray();
            IntArray zIndices = new IntArray();
            IntArray tIndices = new IntArray();
            PrimitiveArray uniqueX = getColumn(xColumn).makeIndices(xIndices);
            PrimitiveArray uniqueY = getColumn(yColumn).makeIndices(yIndices);
            PrimitiveArray uniqueZ = getColumn(zColumn).makeIndices(zIndices);
            PrimitiveArray uniqueT = getColumn(tColumn).makeIndices(tIndices);
            make4IndicesTime = System.currentTimeMillis() - make4IndicesTime;
            //if (reallyVerbose) {
            //    String2.log("Table.saveAs4DNc" +
            //        "\n  unique X " + uniqueX.statsString() + 
            //        "\n  unique Y " + uniqueY.statsString() + 
            //        "\n  unique Z " + uniqueZ.statsString() + 
            //        "\n  unique T " + uniqueT.statsString()); 
            //    //String2.pressEnterToContinue();
            //}

            int nX = uniqueX.size();
            int nY = uniqueY.size();
            int nZ = uniqueZ.size();
            int nT = uniqueT.size();

            //items determined by looking at a .nc file; items written in that order 
            int nRows = nRows();
            int nColumns = nColumns();
            if (nRows == 0) {
                throw new Exception(String2.ERROR + " in Table.saveAs4DNc:\nThe table has no data.");
            }
            int stringLength[] = new int[nColumns];

            //define the dimensions
            Dimension xDimension  = nc.addDimension(rootGroup, getColumnNameWithoutSpaces(xColumn), nX);
            Dimension yDimension  = nc.addDimension(rootGroup, getColumnNameWithoutSpaces(yColumn), nY);
            Dimension zDimension  = nc.addDimension(rootGroup, getColumnNameWithoutSpaces(zColumn), nZ);
            Dimension tDimension  = nc.addDimension(rootGroup, getColumnNameWithoutSpaces(tColumn), nT);
//javadoc says: if there is an unlimited dimension, all variables that use it are in a structure
//Dimension rowDimension  = nc.addDimension(rootGroup, "row", nRows, true, true, false); //isShared, isUnlimited, isUnknown
//String2.log("unlimitied dimension exists: " + (nc.getUnlimitedDimension() != null));

            //add the variables
            Variable colVars[] = new Variable[nColumns];
            for (int col = 0; col < nColumns; col++) {

                //for x/y/z/t make a 1D variable
                PrimitiveArray pa = null;
                if  (col == xColumn || col == yColumn || 
                     col == zColumn || col == tColumn) {
                    Dimension aDimension = null;
                    if      (col == xColumn) {pa = uniqueX; aDimension = xDimension;}
                    else if (col == yColumn) {pa = uniqueY; aDimension = yDimension;}
                    else if (col == zColumn) {pa = uniqueZ; aDimension = zDimension;}
                    else if (col == tColumn) {pa = uniqueT; aDimension = tDimension;}
                    PAType type = pa.elementType();
                    String tColName = getColumnNameWithoutSpaces(col);
                    if (type == PAType.STRING) {
                        int max = Math.max(1, ((StringArray)pa).maxStringLength()); //nc libs want at least 1; 0 happens if no data
                        stringLength[col] = max;
                        Dimension lengthDimension = nc.addDimension(rootGroup, 
                            tColName + NcHelper.StringLengthSuffix, max);
                        colVars[col] = nc.addVariable(rootGroup, tColName, 
                            DataType.CHAR, 
                            Arrays.asList(aDimension, lengthDimension)); 
                    } else {
                        colVars[col] = nc.addVariable(rootGroup, tColName, 
                            NcHelper.getNc3DataType(type),
                            Arrays.asList(aDimension)); 
                    }
                } else {

                    //for other columns, make a 4D array
                    pa = getColumn(col);
                    PAType type = pa.elementType();
                    String tColName = getColumnNameWithoutSpaces(col);
                    if (type == PAType.STRING) {
                        int max = Math.max(1, ((StringArray)pa).maxStringLength()); //nc libs want at least 1; 0 happens if no data
                        stringLength[col] = max;
                        Dimension lengthDimension  = nc.addDimension(rootGroup, 
                            tColName + NcHelper.StringLengthSuffix, max);
                        colVars[col] = nc.addVariable(rootGroup, tColName, 
                            DataType.CHAR, 
                            Arrays.asList(tDimension, zDimension, yDimension, 
                                xDimension, lengthDimension)); 
                    } else {
                        colVars[col] = nc.addVariable(rootGroup, tColName, 
                            NcHelper.getNc3DataType(type),
                            Arrays.asList(tDimension, zDimension, yDimension, 
                                xDimension)); 
                    }

                    //convert to fake MissingValues
                    convertToFakeMissingValues(col);

                }
            }
//nc.addMemberVariable(recordStructure, nc.findVariable(tColName));

//boolean bool = nc.addRecordStructure(); //creates a structure variable called "record"         
//String2.log("addRecordStructure: " + bool);
//Structure recordStructure = (Structure)nc.findVariable("record");

            //if no id, set id=file name
            //currently, only the .nc saveAs types use attributes!
            if (globalAttributes.get("id") == null)
                globalAttributes.set("id", File2.getNameNoExtension(fullName));

            //write Attributes   (after adding variables since mv's and related attributes adjusted)
            NcHelper.setAttributes(nc3Mode, rootGroup, globalAttributes);
            for (int col = 0; col < nColumns; col++) {
                Attributes tAtts = new Attributes(columnAttributes(col)); //use a copy
                PAType paType = getColumn(col).elementType();
                if (paType == PAType.STRING)
                    tAtts.add(String2.ENCODING, String2.ISO_8859_1);
// disabled until there is a standard
//                else if (getColumn(col).elementType() == PAType.CHAR)
//                    tAtts.add(String2.CHARSET, String2.ISO_8859_1);

                NcHelper.setAttributes(nc3Mode, colVars[col], tAtts, paType.isUnsigned());
            }

            //create the stringVariable
            Variable stringVar = null;
            if (stringVariableName != null) {
                stringVariableName = String2.replaceAll(stringVariableName, " ", "_");

                Dimension lengthDimension = nc.addDimension(rootGroup, 
                    stringVariableName + NcHelper.StringLengthSuffix, 
                    Math.max(1, stringVariableValue.length())); //nclib wants at least 1
                stringVar = nc.addVariable(rootGroup, stringVariableName, DataType.CHAR, 
                    Arrays.asList(lengthDimension)); 

                //save the attributes
                Attributes tAtts = new Attributes(stringVariableAttributes); //use a copy
                tAtts.add(String2.ENCODING, String2.ISO_8859_1);                

                NcHelper.setAttributes(nc3Mode, stringVar, tAtts, false); //unsigned=false because it is a string var
            }

            //leave "define" mode
            //if (String2.OSIsWindows) Math2.sleep(100);
            nc.create();

            //write the data
            for (int col = 0; col < nColumns; col++) {
                //String2.log("  writing col=" + col);
                Array ar = null;
                PrimitiveArray pa = getColumn(col);

                if         (col == xColumn) { ar = NcHelper.get1DArray(uniqueX); 
                } else if  (col == yColumn) { ar = NcHelper.get1DArray(uniqueY);
                } else if  (col == zColumn) { ar = NcHelper.get1DArray(uniqueZ);
                } else if  (col == tColumn) { ar = NcHelper.get1DArray(uniqueT);
                } else {
                    //other columns are 4D arrays
                    if (pa instanceof StringArray) {
                        StringArray sa = (StringArray)pa;
                        ArrayChar.D5 tar = new ArrayChar.D5(nT, nZ, nY, nX, stringLength[col]);
                        ucar.ma2.Index index = tar.getIndex();
                        for (int row = 0; row < nRows; row++) 
                            tar.setString(index.set(tIndices.array[row], zIndices.array[row],
                                    yIndices.array[row], xIndices.array[row], 0), sa.get(row));
                        ar = tar;
                    } else {
                        if (pa instanceof LongArray || pa instanceof ULongArray)
                            pa = new DoubleArray(pa);
                        ar = Array.factory(NcHelper.getNc3DataType(pa.elementType()), 
                            new int[]{nT, nZ, nY, nX}, pa.toObjectArray());
                    }
                }

                //write the data
                nc.write(colVars[col], ar);

                //undo fakeMissingValue
                if  (col != xColumn && col != yColumn && 
                     col != zColumn && col != tColumn) {

                    //convert back to standard MissingValues
                    convertToStandardMissingValues(col);
                }
            }

            //write the stringVariable
            if (stringVariableName != null) {
                //ArrayChar.D1 ar = new ArrayChar.D1(stringVariableValue.length());
                //ar.setString(stringVariableValue);
                nc.write(stringVar, 
                    NcHelper.get1DArray(stringVariableValue, false));
            }


            //if close throws exception, it is trouble
            nc.close(); //it calls flush() and doesn't like flush called separately
            nc = null;

            //rename the file to the specified name, instantly replacing the original file
            File2.rename(fullName + randomInt, fullName); //throws Exception if trouble

            //diagnostic
            if (reallyVerbose) msg += 
                " done. make4IndicesTime=" + make4IndicesTime +
                " total TIME=" + (System.currentTimeMillis() - time) + "ms";
            //String2.log(NcHelper.ncdump(fullName, "-h"));

        } catch (Exception e) {
            //try to close the file
            try {
                if (nc != null) nc.abort(); 
            } catch (Exception e2) {
                //don't care
            }

            //delete the partial file
            File2.delete(fullName + randomInt);

            //delete the original file
            File2.delete(fullName);
            if (!reallyVerbose) String2.log(msg);

            throw e;

        } finally {
            if (reallyVerbose) String2.log(msg);
        }


    }


    /**
     * This populates the table with the data from a sql resultsSet.
     * See readSql.
     *
     * @param rs
     * @throws Exception if trouble
     */
    public void readSqlResultSet(ResultSet rs) throws Exception {

        if (reallyVerbose) String2.log("  Table.readSqlResultSet");
        long time = System.currentTimeMillis();
        clear();

        //set up columns in table
        ResultSetMetaData metadata = rs.getMetaData();
        int nCol = metadata.getColumnCount();
        PrimitiveArray paArray[] = new PrimitiveArray[nCol];
        boolean getString[]  = new boolean[nCol]; 
        boolean getInt[]     = new boolean[nCol];
        boolean getLong[]    = new boolean[nCol];
        boolean getDouble[]  = new boolean[nCol];
        boolean getDate[]    = new boolean[nCol]; //read as String, then convert to seconds since epoch
        for (int col = 0; col < nCol; col++) {
            //note that sql counts 1...
            int colType = metadata.getColumnType(1 + col);
            paArray[col] = PrimitiveArray.sqlFactory(colType);
            PAType tPAType = paArray[col].elementType();
            if      (tPAType == PAType.STRING) getString[col] = true;
            else if (colType == Types.DATE ||
                     colType == Types.TIMESTAMP) getDate[col] = true;
            else if (tPAType == PAType.DOUBLE) getDouble[col] = true;
            else if (tPAType == PAType.LONG)     getLong[col] = true;
            else getInt[col] = true;

            //actually add the column
            String colName = metadata.getColumnName(1 + col); //getColumnName == getColumnLabel
            addColumn(colName, paArray[col]);
            //if (reallyVerbose) String2.log("    col=" + col + " name=" + metadata.getColumnName(1 + col));
        }

        //process the rows of data
        while (rs.next()) {
            for (int col = 0; col < nCol; col++) {
                if      (getString[col])  {
                    String ts = rs.getString(1 + col); 
                    paArray[col].addString(ts == null? "" : ts); 
                } else if (getInt[col])     paArray[col].addInt(rs.getInt(1 + col)); 
                else if (getLong[col])    ((LongArray)paArray[col]).add(rs.getLong(1 + col)); 
                else if (getDouble[col])  paArray[col].addDouble(rs.getDouble(1 + col)); 
                //date string is always in form yyyy-mm-dd
                //timestamp string is always in form yyyy-mm-dd hh:mm:ss.fffffffff 
                else if (getDate[col]) {
                    //convert timestamp and date to epochSeconds
                    Timestamp ts = rs.getTimestamp(1 + col);
                    paArray[col].addDouble(ts == null? Double.NaN : ts.getTime() / 1000.0);                    
                } else throw new SimpleException(
                    String2.ERROR + " in Table.readSqlResultSet: process unknown column(" + 
                    col + ") type."); 
            }
        }

        if (reallyVerbose) String2.log("    Table.readSqlResultSet done. nColumns=" + nColumns() +
            " nRows=" + nRows() + " TIME=" + (System.currentTimeMillis() - time) + "ms");
    }

    /**
     * This reads data from the resultsSet from an sql query using jdbc.
     * !!!WARNING - THIS APPROACH OFFERS NO PROTECTION FROM SQL INJECTION.
     * ONLY USE THIS IF YOU, NOT SOME POSSIBLY MALICIOUS USER, SPECIFIED
     * THE QUERY.
     *
     * <p>Examples of things done to prepare to use this method:
     * <ul>
     * <li>Class.forName("org.postgresql.Driver");
     * <li>String url = "jdbc:postgresql://otter.pfeg.noaa.gov/posttest";  //database name
     * <li>String user = "postadmin";
     * <li>String password = String2.getPasswordFromSystemIn("Password for '" + user + "'? ");
     * <li>Connection con = DriverManager.getConnection(url, user, password);
     * </ul>
     *
     * @param con a Connection (these are sometimes pooled to save time)
     * @param query e.g., "SELECT * FROM names WHERE id = 3"
     * @throws Exception if trouble
     */
    public void readSql(Connection con, String query) throws Exception {

        String msg = "  Table.readSql " + query;
        long time = System.currentTimeMillis();
        clear();

        //create the statement and execute the query
        Statement statement = con.createStatement();
        try {
            readSqlResultSet(statement.executeQuery(query));
            if (reallyVerbose) msg += " finished. nColumns=" + nColumns() +
                " nRows=" + nRows() + " TIME=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            statement.close();
            if (reallyVerbose) String2.log(msg);
        }

    }


    /**
     * This inserts the rows of data in this table to a sql table, using jdbc.
     * <ul>
     * <li> The column names in this table must match the column names in the database table.
     * <li> If createTable is true, the column names won't be changed (e.g., 
     *   spaces in column names will be retained.)
     * <li> If createTable is false, the column names in this table don't have to 
     *   be all of the column names in the database table, or in the same order.
     * <li> This assumes all columns (except primary key) accept nulls or have
     *   defaults defined.  If a value in this table is missing, 
     *   the default value will be put in the database table.
     * <li> The database timezone (in pgsql/data/postgresql.conf) should be set to -0 (UTC)
     *   so that dates and times are interpreted as being in UTC time zone.
     * </ul>
     *
     * <p>Examples of things done to prepare to use this method:
     * <ul>
     * <li>Class.forName("org.postgresql.Driver"); //to load the jdbc driver
     * <li>String url = "jdbc:postgresql://otter.pfeg.noaa.gov/posttest";  //database name
     * <li>String user = "postadmin";
     * <li>String password = String2.getPasswordFromSystemIn("Password for '" + user + "'? ");
     * <li>Connection con = DriverManager.getConnection(url, user, password);
     * </ul>
     *
     * @param con a Connection (these are sometimes pooled to save time)
     * @param createTable if createTable is true, a new table will be created 
     *   with all columns (except primaryKeyCol) allowing nulls.
     *   If you need more flexibility when creating the table, create it
     *   separately, then use this method to insert data into it.
     *   If createTable is true and a table by the same name exists, it will be deleted.
     *   If createTable is false, it must already exist.
     * @param tableName  the database's name for the table that this table's data
     *    will be inserted into, 
     *    e.g., "myTable" (equivalent in postgres to "public.myTable")
     *    or "mySchema.myTable".
     * @param primaryKeyCol is the primary key column (0..., or -1 if none).
     *    This is ignored if createTable is false.
     * @param dateCols a list of columns (0..) with dates, stored
     *    as seconds since epoch in DoubleArrays.
     * @param timestampCols a list of columns (0..) with timestamps (date + time), stored
     *    as seconds since epoch in DoubleArrays.
     *    Here, timestamp precision (decimal digits for seconds value) is always 0.
     *    If createTable is true, these columns show up (in postgresql) as
     *    "timestamp without time zone".
     * @param timeCols a list of columns (0..) with times (without dates), stored
     *    as strings in StringArrays (with format "hh:mm:ss", e.g., "23:59:59" 
     *    with implied time zone of UTC), 
     *    which will be stored as sql TIME values.
     *    Here, time precision (decimal digits for seconds value) is always 0.
     *    Missing values can be stored as "" or null.
     *    Improperly formatted time values throw an exception.
     *    If createTable is true, these columns show up (in postgresql) as
     *    "time without time zone".
     * @param stringLengthFactor for StringArrays, this is the factor (typically 1.5)  
     *   to be multiplied by the current max string length (then rounded up to 
     *   a multiple of 10) to estimate the varchar length.  
     * @throws Exception if trouble.
     *   If exception thrown, table may or may not have been created, but no
     *      data rows have been inserted.
     *   If no exception thrown, table was created (if requested) and all data 
     *       was inserted.
     */
    public void saveAsSql(Connection con, boolean createTable, String tableName,
        int primaryKeyCol, int dateCols[], int timestampCols[], int timeCols[],
        double stringLengthFactor) throws Exception {

//    * @param timeZoneOffset this identifies the time zone associated with the 
//    *    time columns.  (The Date and Timestamp columns are already UTC.)

        String msg = "  Table.saveAsSql " + tableName;
        String errorInMethod = String2.ERROR + " in" + msg + ":\n";
        long elapsedTime = System.currentTimeMillis();
        if (dateCols == null) dateCols = new int[0];
        if (timestampCols == null) timestampCols = new int[0];
        if (timeCols == null) timeCols = new int[0];
        int nCols = nColumns();       
        int nRows = nRows();       

        //make a local 'table' for faster access
        PrimitiveArray paArray[] = new PrimitiveArray[nCols];
        String sqlType[] = new String[nCols];
        for (int col = 0; col < nCols; col++) {
            paArray[col] = getColumn(col);
            sqlType[col] = paArray[col].getSqlTypeString(stringLengthFactor);
        }

        //swap in the dateCols
        boolean isDateCol[] = new boolean[nCols];
        for (int col = 0; col < dateCols.length; col++) {
            int tCol = dateCols[col];
            isDateCol[tCol] = true;
            sqlType[tCol] = "date";
        }

        //swap in the timestampCols
        boolean isTimestampCol[] = new boolean[nCols];
        for (int col = 0; col < timestampCols.length; col++) {
            int tCol = timestampCols[col];
            isTimestampCol[tCol] = true;
            sqlType[tCol] = "timestamp";
        }

        //identify timeCols
        boolean isTimeCol[] = new boolean[nCols];
        for (int col = 0; col < timeCols.length; col++) {
            int tCol = timeCols[col];
            isTimeCol[tCol] = true;
            sqlType[tCol] = "time";
        }

        //*** create the table   (in postgres, default for columns is: allow null)
        if (createTable) {
            //delete the table (if it exists)
            dropSqlTable(con, tableName, true);

            Statement statement = con.createStatement();
            try {
                StringBuilder create = new StringBuilder(
                    "CREATE TABLE " + tableName + " ( \"" + 
                    getColumnName(0) + "\" " + sqlType[0] + 
                        (primaryKeyCol == 0? " PRIMARY KEY" : ""));
                for (int col = 1; col < nCols; col++) 
                    create.append(", \"" + getColumnName(col) + "\" " + sqlType[col] + 
                        (primaryKeyCol == col? " PRIMARY KEY" : ""));
                create.append(" )");
                if (reallyVerbose) msg += "\n  create=" + create;
                statement.executeUpdate(create.toString());
            } finally {
                statement.close();
            }
        }

        //*** insert the rows of data into the table
        //There may be no improved efficiency from statement.executeBatch
        //as postgres may still be doing commands one at a time
        //(http://archives.free.net.ph/message/20070115.122431.93092975.en.html#pgsql-jdbc)
        //and it is more memory efficient to just do one at a time.
        //BUT batch is more efficient on other databases and
        //most important, it allows us to rollback.
        //See batch info:
        //http://www.jguru.com/faq/view.jsp?EID=5079
        //and  http://www.onjava.com/pub/a/onjava/excerpt/javaentnut_2/index3.html?page=2 (no error checking/rollback).

        //timezones
        //jdbc setTime setDate setTimestamp normally works with local time only.
        //To specify UTC timezone, you need to call setDate, setTime, setTimestamp
        //   with Calendar object which has the time zone used to interpret the date/time.
        //see http://www.idssoftware.com/faq-j.html  see J15
        Calendar cal = Calendar.getInstance(TimeZone.getTimeZone("UTC"));

        //make the prepared statement
        StringBuilder prep = new StringBuilder();
        prep.append("INSERT INTO " + tableName + " ( \"" + getColumnName(0) + "\"");
        for (int col = 1; col < nCols; col++) 
            prep.append(", \"" + getColumnName(col) + "\"");
        prep.append(") VALUES (?");
        for (int col = 1; col < nCols; col++) 
            prep.append(", ?");
        prep.append(")");
        if (reallyVerbose) msg += "\n  preparedStatement=" + prep;
        PreparedStatement pStatement = con.prepareStatement(prep.toString());

        //add each row's data to the prepared statement 
        for (int row = 0; row < nRows; row++) {
            //clear parameters, to ensure previous row's data is cleared and new values are set
            pStatement.clearParameters(); 

            //add this row's values
            for (int col = 0; col < nCols; col++) {
                PrimitiveArray pa = paArray[col];
                PAType et = pa.elementType();
                //col+1 because sql counts columns as 1...
                //check for date, timestamp, time columns before double and String
                if (isDateCol[col]) {    
                    double d = pa.getDouble(row);
                    if (Double.isFinite(d)) {
                        Date date = new Date(Math.round(d * 1000)); //set via UTC millis
                        pStatement.setDate(col + 1, date, cal); //cal specifies the UTC timezone
                    } else pStatement.setDate(col + 1, null);
                } else if (isTimestampCol[col]) {    
                    double d = pa.getDouble(row);
                    if (Double.isFinite(d)) {
                        Timestamp timestamp = new Timestamp(Math.round(d * 1000)); //set via UTC millis
                        pStatement.setTimestamp(col + 1, timestamp, cal); //cal specifies the UTC timezone
                    } else pStatement.setTimestamp(col + 1, null);
                } else if (isTimeCol[col]) {    
                    //data already a time string
                    String s = pa.getString(row);  
                    if (s == null || s.length() == 0) {
                        pStatement.setTime(col + 1, null);
                    } else if ( //ensure that format is HH:MM:SS
                        s.length() == 8 &&
                        String2.isDigit(s.charAt(0)) && String2.isDigit(s.charAt(1)) && s.charAt(2) == ':' && 
                        String2.isDigit(s.charAt(3)) && String2.isDigit(s.charAt(4)) && s.charAt(5) == ':' && 
                        String2.isDigit(s.charAt(6)) && String2.isDigit(s.charAt(7))) {
                        //Time documentation says Time is java Date object with date set to 1970-01-01
                        try {
                            double d = Calendar2.isoStringToEpochSeconds("1970-01-01T" + s);  //throws exception if trouble
                            //String2.log("date=" + s + " -> " + Calendar2.epochSecondsToIsoStringTZ(d));
                            Time time = new Time(Math.round(d * 1000)); 
                            pStatement.setTime(col + 1, time, cal); //cal specifies the UTC timezone
                        } catch (Exception e) {
                            pStatement.setTime(col + 1, null);
                        }
                    } else {
                        throw new SimpleException(errorInMethod + "Time format must be HH:MM:SS. Bad value=" +
                            s + " in row=" + row + " col=" + col);
                    }
                //for integer types, there seems to be no true null, so keep my missing value, e.g., Byte.MAX_VALUE
                } else if (et == PAType.BYTE) {  pStatement.setByte(  col + 1, ((ByteArray)pa).get(row)); 
                } else if (et == PAType.SHORT) { pStatement.setShort( col + 1, ((ShortArray)pa).get(row)); 
                } else if (et == PAType.INT) {   pStatement.setInt(   col + 1, pa.getInt(row)); 
                } else if (et == PAType.LONG) {  pStatement.setLong(  col + 1, pa.getLong(row)); 
                //for double and float, NaN is fine
                } else if (et == PAType.FLOAT) { pStatement.setFloat( col + 1, pa.getFloat(row));  
                } else if (et == PAType.DOUBLE) {pStatement.setDouble(col + 1, pa.getDouble(row)); 
                } else if (et == PAType.STRING || et == PAType.CHAR) {
                    pStatement.setString(col + 1, pa.getString(row));  //null is ok
                } else throw new SimpleException(errorInMethod + "Process column(" + 
                    col + ") unknown type=" + pa.elementTypeString()); 
            }

            //add this row's data to batch
            pStatement.addBatch();
        }

        //try to executeBatch 
        //setAutoCommit(false) seems to perform an implicit postgresql 
        //BEGIN command to start a transaction.
        //(Do this after all preparation in case exception thrown there.)
        con.setAutoCommit(false); //must be false for rollback to work
        int[] updateCounts = null;
        Exception caughtException = null;
        try {
            //NOTE that I don't try/catch the stuff above.
            //  If exception in preparation, no need to roll back
            //  (and don't want to roll back previous statement).
            //  But exception in executeBatch needs to be rolled back.

            //process the batch
            updateCounts = pStatement.executeBatch();

            //got here without exception? save the changes
            con.commit();

        } catch (Exception e) {          
            //get the caught exception
            caughtException = e; 
            try {
                if (e instanceof BatchUpdateException) {
                    //If e was BatchUpdateException there is additional information. 
                    //Try to combine the e exception (identifies bad row's data) 
                    //and bue.getNextException (says what the problem was).
                    Exception bue2 = ((BatchUpdateException)e).getNextException(); 
                    caughtException = new Exception(
                        errorInMethod +
                        "[BU ERROR] " + MustBe.throwableToString(e) + 
                        "[BU ERROR2] " + bue2.toString());
                } else {
                }
            } catch (Exception e2) {
                //oh well, e is best I can get
            }

            //since there was a failure, try to rollback the whole transaction.
            try {
                con.rollback();
            } catch (Exception rbe) {
                //hopefully won't happen
                caughtException = new Exception(
                    errorInMethod +
                    "[C ERROR] " + MustBe.throwableToString(caughtException) + 
                    "[RB ERROR] " + rbe.toString());
                msg += "\nsmall ERROR during rollback:\n" + 
                    MustBe.throwableToString(caughtException);
            }
        } 
        
        //other clean up
        try {
            //pStatement.close(); //not necessary?
            //go back to autoCommit; this signals end of transaction
            con.setAutoCommit(true); 
        } catch (Exception e) {
            //small potatoes
            msg += "\nsmall ERROR during cleanup:\n" + 
                MustBe.throwableToString(e);
        }

        //rethrow the big exception, so caller knows there was trouble
        if (caughtException != null)
            throw caughtException;

        //all is well, print diagnostics
        if (reallyVerbose) {
            IntArray failedRows = new IntArray();
            for (int i = 0; i < updateCounts.length; i++) {
                if (updateCounts[i] != 1) {
                    failedRows.add(i);
                }
            }
            if (failedRows.size() > 0) 
                msg += "\n  failedRows(0..)=" + failedRows.toString();
            String2.log(
                msg + "\n  done. nColumns=" + nColumns() +
                " nRowsSucceed=" + (nRows - failedRows.size()) + 
                " nRowsFailed=" + (failedRows.size()) + 
                " TIME=" + (System.currentTimeMillis() - elapsedTime) + "ms");
        }
    }


    /**
     * Get a connection to an Access .mdb file.  MS Access not needed.
     *
     * @param fileName  (forward slash in example)
     * @param user  use "" if none specified
     * @param password   use "" if none specified
     */
    public static Connection getConnectionToMdb(String fileName, String user, 
        String password) throws Exception {

        //from Sareth's answer at
        //https://stackoverflow.com/questions/9543722/java-create-msaccess-database-file-mdb-0r-accdb-using-java
        Class.forName("sun.jdbc.odbc.JdbcOdbcDriver");  //included in Java distribution
        return DriverManager.getConnection(
            "jdbc:odbc:Driver={Microsoft Access Driver (*.mdb, *.accdb)};" +
            "DBQ=" + fileName, //";DriverID=22;READONLY=true}",
            "", "");  //user, password
    }

    /** DOESN'T WORK.  Driver gives error:
    Exception in thread "main" java.sql.SQLException: [Microsoft][ODBC Microsoft Access Driver]Optional feature not implemented
        at sun.jdbc.odbc.JdbcOdbc.createSQLException(Unknown Source)
        ...
     */
    public static void testMdb() throws Exception {
        String fileName = 
            "c:\\data\\calcofi\\calcofi8102012.accdb";
            //"c:/fishbase/COUNTRY.mdb";
        Connection con = getConnectionToMdb(fileName, "", ""); //user, password
        //String2.log(getSqlSchemas(con).toString());
        //String schema = "";
        //String2.log(getSqlTableNames(con, schema, null).toString()); //null for all types
        String tableName = "EGG_COUNTS"; //"ACTIVITIES";
        //query = "SELECT * FROM names WHERE id = 3"
        String query = "SELECT * FROM " + tableName;
        Table table = new Table();
        table.readSql(con, query);
        String2.log(table.dataToString(5));
    }


    /**
     * This returns a list of schemas (subdirectories of this database) e.g., "public" 
     *
     * @return a list of schemas (subdirectories of this database) e.g., "public".
     *   Postgres always returns all lowercase names.
     * @throws Exception if trouble
     */
    public static StringArray getSqlSchemas(Connection con) throws Exception {

        DatabaseMetaData dm = con.getMetaData();
        Table schemas = new Table();
        schemas.readSqlResultSet(dm.getSchemas());
        return (StringArray)schemas.getColumn(0);

    }

    /**
     * This returns a list of tables of a certain type or types.
     *
     * @param con
     * @param schema a specific schema (a subdirectory of the database) e.g., "public" (not null)
     * @param types  null (for any) or String[] of one or more of 
     *   "TABLE", "VIEW", "SYSTEM TABLE", "GLOBAL TEMPORARY", "LOCAL TEMPORARY", "ALIAS", "SYNONYM".
     * @return a StringArray of matching table names.
     *   Postgres always returns all lowercase names.
     * @throws Exception if trouble
     */
    public static StringArray getSqlTableNames(Connection con, String schema,
        String types[]) throws Exception {

        if (schema == null)
            throw new SimpleException(String2.ERROR + " in Table.getSqlTableList: schema is null.");

        //getTables(catalogPattern, schemaPattern, tableNamePattern, String[] types)
        //"%" means match any substring of 0 or more characters, and 
        //"_" means match any one character. 
        //If a search pattern argument is set to null, that argument's criterion will be dropped from the search.
        DatabaseMetaData dm = con.getMetaData();
        Table tables = new Table();   //works with "posttest", "public", "names", null
        tables.readSqlResultSet(dm.getTables(null, schema.toLowerCase(), null, types));
        return (StringArray)(tables.getColumn(2)); //table name is always col (0..) 2
    }

    /**
     * Determines the type of a table (or if the table exists).
     *
     * @param schema a specific schema (a subdirectory of the database) e.g., "public" (not null)
     * @param tableName  a specific tableName (can't be null)
     * @return the table type:  
     *   "TABLE", "VIEW", "SYSTEM TABLE", "GLOBAL TEMPORARY", "LOCAL TEMPORARY", "ALIAS", "SYNONYM",
     *   or null if the table doesn't exist.
     * @throws Exception if trouble
     */
    public static String getSqlTableType(Connection con, String schema, 
        String tableName) throws Exception {

        if (schema == null)
            throw new SimpleException(String2.ERROR + " in Table.getSqlTableType: schema is null.");
        if (tableName == null)
            throw new SimpleException(String2.ERROR + " in Table.getSqlTableType: tableName is null.");

        //getTables(catalogPattern, schemaPattern, tableNamePattern, String[] types)
        //"%" means match any substring of 0 or more characters, and 
        //"_" means match any one character. 
        //If a search pattern argument is set to null, that argument's criterion will be dropped from the search.
        DatabaseMetaData dm = con.getMetaData();
        Table tables = new Table();   //works with "posttest", "public", "names", null
        tables.readSqlResultSet(dm.getTables(null, schema.toLowerCase(), 
            tableName.toLowerCase(), null));
        if (tables.nRows() == 0)
            return null;
        return tables.getStringData(3, 0); //table type is always col (0..) 3
    }

    /**
     * Drops (deletes) an sql table (if it exists).
     *
     * @param tableName a specific table name (not null),
     *    e.g., "myTable" (equivalent in postgres to "public.myTable")
     *    or "myShema.myTable".
     * @param cascade  This is only relevant if tableName is referenced by a view.
     *   If so, and cascade == true, the table will be deleted.
     *   If so, and cascade == false, the table will not be deleted.
     * @throws Exception if trouble (e.g., the table existed but couldn't be deleted,
     *    perhaps because connection's user doesn't have permission)
     */
    public static void dropSqlTable(Connection con, String tableName, boolean cascade) throws Exception {

        //create the statement and execute the query
        //DROP TABLE [ IF EXISTS ] name [, ...] [ CASCADE | RESTRICT ]
        Statement statement = con.createStatement();
        try {
            statement.executeUpdate("DROP TABLE IF EXISTS " + tableName + //case doesn't matter here
                (cascade? " CASCADE": "")); 
        } finally {
            statement.close();
        }
    }

    /**
     * THIS IS NOT YET FINISHED.
     * This converts the specified String column with 
     * date (with e.g., "2006-01-02"), 
     * time (with e.g., "23:59:59"), 
     * or timestamp values (with e.g., "2006-01-02 23:59:59" with any character
     * between the date and time) 
     * into a double column with secondSinceEpoch (1970-01-01 00:00:00 UTC time zone).
     * No metadata is changed by this method.
     *
     * @param col the number of the column (0..) with the date, time, or timestamp strings.
     * @param type indicates the type of data in the column: 
     *    0=date, 1=time, 2=timestamp.
     * @param timeZoneOffset this identifies the time zone associated with  
     *    col (e.g., 0 if already UTC, -7 for California in summer (DST), 
     *    and -8 for California in winter, so that the data can be converted
     *    to UTC timezone. 
     * @param strict If true, this throws an exception if a value is
     *    improperly formatted. (Missing values of "" or null are allowed.)
     *    If false, improperly formatted values are silently converted to 
     *    missing values (Double.NaN).
     *    Regardless of 'strict', the method rolls components as needed,
     *    for example, Jan 32 becomes Feb 1.
     * @return the number of valid values.
     * @throws Exception if trouble (and no changes will have been made)
     */
    public int isoStringToEpochSeconds(int col, int type, 
        int timeZoneOffset, boolean strict) throws Exception {
       
        String errorInMethod = String2.ERROR + " in Table.isoStringToEpochSeconds(col=" + col + "):\n";
        Test.ensureTrue(type >= 0 && type <= 2, errorInMethod + "type=" + type +
            " must be between 0 and 2.");
        String isoDatePattern = "[1-2][0-9]{3}\\-[0-1][0-9]\\-[0-3][0-9]";
        String isoTimePattern = "[0-2][0-9]\\:[0-5][0-9]\\:[0-5][0-9]";
        String stringPattern = type == 0? isoDatePattern : 
            type == 1? isoTimePattern : isoDatePattern + "." + isoTimePattern;          
        Pattern pattern = Pattern.compile(stringPattern);
        StringArray sa = (StringArray)getColumn(col);
        int n = sa.size();
        DoubleArray da = new DoubleArray(n, true);
        int nGood = 0;
        int adjust = timeZoneOffset * Calendar2.SECONDS_PER_HOUR;
        for (int row = 0; row < n; row++) {
            String s = sa.get(row);

            //catch allowed missing values
            if (s == null || s.length() == 0) {
                da.array[row] = Double.NaN;            
                continue;
            }

            //catch improperly formatted values (stricter than Calendar2.isoStringToEpochSeconds below)
            if (strict && !pattern.matcher(s).matches()) 
                throw new SimpleException(errorInMethod + "value=" + s + " on row=" + row +
                    " is improperly formatted.");

            //parse the string
            if (type == 1) 
                s = "1970-01-01 " + s;
            double d = Calendar2.isoStringToEpochSeconds(s); //throws exception
            if (!Double.isNaN(d)) {
                nGood++;
                d -= adjust;
            }
            da.array[row] = d;            
        }
        setColumn(col, da);
        return nGood;
    }

    /**
     * This tests the readSql and saveAsSql methods.
     * @throws Exception if trouble
     */
    public static void testSql() throws Exception {
        String2.log("\n*** Table.testSql");
        verbose = true;
        reallyVerbose = true;

        //load the sql driver  (the actual driver .jar must be in the classpath)
        Class.forName("org.postgresql.Driver");

        //set up connection and query
        String url = "jdbc:postgresql://otter.pfeg.noaa.gov/posttest";  //database name
        String user = "postadmin";
        String password = String2.getPasswordFromSystemIn("Password for '" + user + "'? ");
        if (password.length() == 0) {
            String2.log("No password, so skipping the test.");
            return;
        }
        long tTime = System.currentTimeMillis();
        Connection con = DriverManager.getConnection(url, user, password);
        String2.log("getConnection time=" + (System.currentTimeMillis() - tTime) + "ms"); //often 9s !

        DatabaseMetaData dm = con.getMetaData();
        String2.log("getMaxRowSize=" + dm.getMaxRowSize());  //1GB

        //get catalog info  -- has one col with name(s) of databases for this user
        //...

        //test getSqlSchemas
        StringArray schemas = getSqlSchemas(con);
        Test.ensureTrue(schemas.indexOf("public") >= 0, "schemas=" + schemas.toString());

        //sometimes: make names table
        if (false) {
            Table namesTable = new Table();
            namesTable.addColumn("id",         PrimitiveArray.factory(new int[]{1,2,3}));
            namesTable.addColumn("first_name", PrimitiveArray.factory(new String[]{"Bob", "Nate", "Nancy"}));
            namesTable.addColumn("last_name",  PrimitiveArray.factory(new String[]{"Smith", "Smith", "Jones"}));
            namesTable.saveAsSql( 
                con, true, //'true' tests dropSqlTable, too
                "names", 0, null, null, null, 2);       
        }

        //test getSqlTableNames
        StringArray tableNames = getSqlTableNames(con, "public", new String[]{"TABLE"});
        String2.log("tableNames=" + tableNames);
        Test.ensureTrue(tableNames.indexOf("names") >= 0, "tableNames=" + tableNames.toString()); 
        Test.ensureTrue(tableNames.indexOf("zztop") <  0, "tableNames=" + tableNames.toString()); //doesn't exist

        //test getSqlTableType
        Test.ensureEqual(getSqlTableType(con, "public", "names"), "TABLE", "");
        Test.ensureEqual(getSqlTableType(con, "public", "zztop"), null, ""); //doesn't exist


        //*** test saveAsSql  (create a table)    (this tests dropSqlTable, too)
        if (true) {
            String tempTableName = "TempTest";
            String dates[] = {"1960-01-02", "1971-01-02", null, "2020-12-31"};
            double dateDoubles[] = new double[4];
            String timestamps[] = {"1960-01-02 01:02:03", "1971-01-02 07:08:09", null, "2020-12-31 23:59:59"};
            double timestampDoubles[] = new double[4];
            String times[] = {"01:02:03", "07:08:09", null, "23:59:59"};
            for (int i = 0; i < 4; i++) {
                dateDoubles[i]      = dates[i]      == null? Double.NaN : Calendar2.isoStringToEpochSeconds(dates[i]);
                timestampDoubles[i] = timestamps[i] == null? Double.NaN : Calendar2.isoStringToEpochSeconds(timestamps[i]);
            }
            Table tempTable = new Table();
            tempTable.addColumn("uid",       PrimitiveArray.factory(new int[]{1,2,3,4}));
            tempTable.addColumn("short",     PrimitiveArray.factory(new short[]{-10, 0, Short.MAX_VALUE, 10}));
            //Math2.random makes this test different every time. ensures old table is dropped and new one created.
            tempTable.addColumn("int",       PrimitiveArray.factory(new int[]{Math2.random(1000), 0, Integer.MAX_VALUE, 20}));
            tempTable.addColumn("long",      PrimitiveArray.factory(new long[]{-30, 0, Long.MAX_VALUE, 30}));
            tempTable.addColumn("float",     PrimitiveArray.factory(new float[]{-44.4f, 0f, Float.NaN, 44.4f}));
            tempTable.addColumn("double",    PrimitiveArray.factory(new double[]{-55.5, 0, Double.NaN, 55.5}));
            tempTable.addColumn("string",    PrimitiveArray.factory(new String[]{"ab", "", null, "longer"}));
            tempTable.addColumn("date",      PrimitiveArray.factory(dateDoubles));
            tempTable.addColumn("timestamp", PrimitiveArray.factory(timestampDoubles));
            tempTable.addColumn("time",      PrimitiveArray.factory(times));
            tempTable.saveAsSql( 
                con, true, //'true' tests dropSqlTable, too
                tempTableName, 0, new int[]{7}, new int[]{8}, new int[]{9}, 1.5);       

            //test readSql  (read a table)
            Table tempTable2 = new Table();
            tempTable2.readSql(con, "SELECT * FROM " + tempTableName);
            Test.ensureEqual(tempTable, tempTable2, "");


            //*** test rollback: add data that causes database to throw exception
            tempTable2.setIntData(0, 0, 5); //ok
            tempTable2.setIntData(0, 1, 6); //ok
            tempTable2.setIntData(0, 2, 7); //ok
            tempTable2.setIntData(0, 3, 1); //not ok because not unique
            try { //try to add new tempTable2 to database table
                tempTable2.saveAsSql( 
                    con, false, //false, so added to previous data
                    tempTableName, 0, new int[]{7}, new int[]{8}, new int[]{9}, 1.5); 
                String2.log("Shouldn't get here."); Math2.sleep(60000);
            } catch (Exception e) {
                //this error is expected
                //make sure it has both parts of the error message
                String2.log("\nEXPECTED " + String2.ERROR + ":\n" + MustBe.throwableToString(e));
                Test.ensureTrue(e.toString().indexOf(
                    "PSQLException: " + String2.ERROR + 
                    ": duplicate key violates unique constraint \"temptest_pkey\"") >= 0, 
                    "(A) The error was: " + e.toString());
                Test.ensureTrue(e.toString().indexOf(
                    "java.sql.BatchUpdateException: Batch entry 3 INSERT INTO TempTest (") >= 0, 
                    "(B)The error was: " + e.toString());
            }

            //and ensure database was rolled back to previous state
            tempTable2.readSql(con, "SELECT * FROM " + tempTableName);
            Test.ensureEqual(tempTable, tempTable2, "");


            //*** test pre-execute errors: add data that causes saveAsSql to throw exception
            tempTable2.setIntData(0, 0, 5); //ok, so new rows can be added
            tempTable2.setIntData(0, 1, 6); //ok
            tempTable2.setIntData(0, 2, 7); //ok
            tempTable2.setIntData(0, 3, 8); //ok
            int timeCol = tempTable2.findColumnNumber("time");
            //invalid date will be caught before statement is fully prepared
            tempTable2.setStringData(timeCol, 3, "20.1/30"); //first 3 rows succeed, this should fail
            try { //try to add new tempTable2 to database table
                tempTable2.saveAsSql(
                    con, false, //false, so added to previous data
                    tempTableName, 0, new int[]{7}, new int[]{8}, new int[]{9}, 1.5); 
                String2.log("Shouldn't get here."); Math2.sleep(60000);
            } catch (Exception e) {
                //this error is expected
                //make sure it is the right error
                String2.log("\nEXPECTED " + String2.ERROR + ":\n" + MustBe.throwableToString(e));
                Test.ensureTrue(e.toString().indexOf(
                    "java.lang.RuntimeException: ERROR in Table.saveAsSql(TempTest):\n" +
                        "Time format must be " +
                        "HH:MM:SS. Bad value=20.1/30 in row=3 col=9") >= 0, 
                    "error=" + e.toString());
            }

            //and ensure it rolls back to previous state
            tempTable2.readSql(con, "SELECT * FROM " + tempTableName);
            Test.ensureEqual(tempTable, tempTable2, "");


            //*** test successfully add data (and ensure previous rollbacks worked
            //assign row numbers so new rows can be added (and so different from possibly added 5,6,7,8)
            tempTable2.setIntData(0, 0, 9); //ok, 
            tempTable2.setIntData(0, 1, 10); //ok
            tempTable2.setIntData(0, 2, 11); //ok
            tempTable2.setIntData(0, 3, 12); //ok
            tempTable2.saveAsSql(
                con, false, //false, so added to previous data
                tempTableName, 0, new int[]{7}, new int[]{8}, new int[]{9}, 1.5); 

            //and ensure result has 8 rows
            tempTable2.readSql(con, "SELECT uid, string FROM " + tempTableName); 
            Test.ensureEqual(tempTable2.getColumn(0).toString(), "1, 2, 3, 4, 9, 10, 11, 12", "");
            Test.ensureEqual(tempTable2.getColumn(1).toString(), "ab, , [null], longer, ab, , [null], longer", "");
        }

        //don't drop the table, so I can view it in phpPgAdmin

//how read just column names and types?   query that returns no rows???

    }


    /**
     * This is like the other saveAsTabbedASCII that writes to a file,
     * but this uses the ISO-8859-1 charset.
     *
     * @param fullFileName the complete file name (including directory and
     *    extension, usually ".asc").
     *    An existing file with this name will be overwritten.
     * @throws Exception 
     */
    public void saveAsTabbedASCII(String fullFileName) throws Exception {
        saveAsTabbedASCII(fullFileName, String2.ISO_8859_1);
    }

    /**
     * This is like the other saveAsTabbedASCII, but writes to a file.
     * The second line has units.
     *
     * @param fullFileName the complete file name (including directory and
     *    extension, usually ".asc").
     *    An existing file with this name will be overwritten.
     * @param charset e.g., ISO-8859-1 (default, used if charset is null or "") or UTF-8.
     * @throws Exception 
     */
    public void saveAsTabbedASCII(String fullFileName, String charset) throws Exception {
        if (reallyVerbose) String2.log("Table.saveAsTabbedASCII " + fullFileName); 
        long time = System.currentTimeMillis();

        //POLICY: because this procedure may be used in more than one thread,
        //do work on unique temp files names using randomInt, then rename to proper file name.
        //If procedure fails half way through, there won't be a half-finished file.
        int randomInt = Math2.random(Integer.MAX_VALUE);

        //open the file (before 'try'); if it fails, no temp file to delete
        OutputStream os = new BufferedOutputStream(new FileOutputStream(fullFileName + randomInt));

        try {
            saveAsTabbedASCII(os, charset);
            os.close();
            os = null;

            //rename the file to the specified name, instantly replacing the original file
            File2.rename(fullFileName + randomInt, fullFileName); //throws Exception if trouble

        } catch (Exception e) {
            if (os != null) {
                try {os.close();
                } catch (Exception e2) {}
            }

            File2.delete(fullFileName + randomInt);
            //delete any existing file
            File2.delete(fullFileName);

            throw e;
        }

    }

    /**
     * Save this data as a tab-separated ASCII outputStream.
     * The second line has units.
     * This writes the lon values as they are currently in this table
     *    (e.g., +-180 or 0..360). 
     * If no exception is thrown, the data was successfully written.
     * NaN's are written as "NaN".
     *
     * @param outputStream There is no need for it to be buffered.
     *    Afterwards, it is flushed, not closed.
     * @throws Exception 
     */
    public void saveAsTabbedASCII(OutputStream outputStream) throws Exception {
        saveAsSeparatedAscii(outputStream, null, "\t");
    }

    public void saveAsTabbedASCII(OutputStream outputStream, String charset) throws Exception {
        saveAsSeparatedAscii(outputStream, charset, "\t");
    }

    /**
     * This is like the other saveAsCsvASCII, but writes to a file.
     *
     * @param fullFileName the complete file name (including directory and
     *    extension, usually ".csv"). 
     *    An existing file with this name will be overwritten.
     * @throws Exception 
     */
    public void saveAsCsvASCII(String fullFileName) throws Exception {
        if (reallyVerbose) String2.log("Table.saveAsCsvASCII " + fullFileName); 
        long time = System.currentTimeMillis();


        //POLICY: because this procedure may be used in more than one thread,
        //do work on unique temp files names using randomInt, then rename to proper file name.
        //If procedure fails half way through, there won't be a half-finished file.
        int randomInt = Math2.random(Integer.MAX_VALUE);

        //open the file (before 'try'); if it fails, no temp file to delete
        OutputStream os = new BufferedOutputStream(new FileOutputStream(fullFileName + randomInt));

        try {
            saveAsCsvASCII(os);
            os.close();
            os = null;

            //rename the file to the specified name, instantly replacing the original file
            File2.rename(fullFileName + randomInt, fullFileName); //throws Exception if trouble

        } catch (Exception e) {
            try {  if (os != null) os.close();
            } catch (Exception e2) {}

            File2.delete(fullFileName + randomInt);
            //delete any existing file
            File2.delete(fullFileName);

            throw e;
        }

    }

    /**
     * This returns the table as a CSV String.
     * The second line has units.
     * This is generally used for diagnostics, as the String will be large
     * if the table is large.
     */
    public String saveAsCsvASCIIString() throws Exception {
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        saveAsCsvASCII(baos);
        return baos.toString();
    }

    /**
     * Save this data as a comma-separated ASCII file.
     * The second line has units.
     * This writes the lon values as they are currently in this table
     *    (e.g., +-180 or 0..360). 
     * If no exception is thrown, the data was successfully written.
     * NaN's are written as "NaN".
     *
     * @param outputStream There is no need for it to be buffered.
     *    Afterwards, it is flushed, not closed.
     * @throws Exception 
     */
    public void saveAsCsvASCII(OutputStream outputStream) throws Exception {
        saveAsSeparatedAscii(outputStream, null, ",");
    }

    public void saveAsCsvASCII(OutputStream outputStream, String charset) throws Exception {
        saveAsSeparatedAscii(outputStream, charset, ",");
    }

    /**
     * Save this data as a separated value ASCII outputStream.
     * The second line has units.
     * This writes the lon values as they are currently in this table
     *    (e.g., +-180 or 0..360). 
     * If no exception is thrown, the data was successfully written.
     * NaN's are written as "NaN".
     *
     * @param outputStream There is no need for it to be buffered.
     *    Afterwards, it is flushed, not closed.
     * @param charset e.g., ISO-8859-1 (default, used if charset is null or "") or UTF-8.
     * @param separator  usually a tab or a comma
     * @throws Exception 
     */
    public void saveAsSeparatedAscii(OutputStream outputStream, String charset,
        String separator) throws Exception {

        //ensure there is data
        if (nRows() == 0) {
            throw new Exception(String2.ERROR + " in Table.saveAsSeparatedAscii:\n" + 
                MustBe.THERE_IS_NO_DATA + " (nRows = 0)");
        }

        long time = System.currentTimeMillis();
        if (charset == null || charset.length() == 0)
            charset = String2.ISO_8859_1;
        BufferedWriter writer = String2.getBufferedOutputStreamWriter(outputStream, charset);

        //write the column names   
        boolean tabMode = separator.equals("\t");
        int nColumns = nColumns();
        if (columnNames != null && columnNames.size() == nColumns) { //isn't this always true???
            for (int col = 0; col < nColumns; col++) {
                writer.write(tabMode? columnNames.getTsvString(col) :
                                      columnNames.getNccsvDataString(col));
                writer.write(col == nColumns -1? "\n" : separator);
            }
        }

        //write the units
        for (int col = 0; col < nColumns; col++) {
            String s = columnAttributes(col).getString("units");
            writer.write(tabMode? String2.toTsvString(s) :
                                  String2.toNccsvDataString(s));
            writer.write(col == nColumns -1? "\n" : separator);
        }

        //get columnTypes
        boolean isCharArray[] = new boolean[nColumns];
        for (int col = 0; col < nColumns; col++) {
            isCharArray[col] = getColumn(col).elementType() == PAType.STRING;
        }

        //write the data
        int nRows = nRows();
        for (int row = 0; row < nRows; row++) {
            for (int col = 0; col < nColumns; col++) {
                writer.write(tabMode? getColumn(col).getTsvString(row) :
                                      getColumn(col).getNccsvDataString(row));
                writer.write(col == nColumns -1? "\n" : separator);
            }
        }

        writer.flush(); //essential

        //diagnostic
        if (reallyVerbose)
            String2.log("  Table.saveAsSeparatedASCII done. TIME=" + 
                (System.currentTimeMillis() - time) + "ms");

    }


    /**
     * Save this data in this table as a json file.
     * <br>Missing values should already be stored as NaNs (perhaps via convertToStandardMissingValues()).
     *
     * @param fileName the full file name
     * @param timeColumn the column number of the column that has 
     *    seconds since 1970-01-01 double data that should be saved as 
     *    an ISO string (or -1 if none)
     *    An existing file with this name will be overwritten.
     * @param writeUnits if true, columnUnits will be written with
     *    the "units" attribute for each column
     *    Note that timeColumn will have units "UTC".
     * @throws Exception (no error if there is no data)
     */
    public void saveAsJson(String fileName, int timeColumn, 
        boolean writeUnits) throws Exception {
        OutputStream fos = new BufferedOutputStream(new FileOutputStream(fileName));
        try {
            saveAsJson(fos, timeColumn, writeUnits);
        } finally {
            fos.close();
        }
    }

    /**
     * Save this file as a json string.
     * <br>This is usually just used for diagnostics, since the string might be very large.
     * <br>Missing values should already be stored as NaNs (perhaps via convertToStandardMissingValues()).
     * 
     * @param timeColumn
     * @param writeUnits
     */
    public String saveAsJsonString(int timeColumn, boolean writeUnits) throws Exception {
        StringWriter sw = new StringWriter();
        saveAsJson(sw, timeColumn, writeUnits);
        return sw.toString();
    }

    /**
     * Save this data in this table as a json outputStream.
     * <br>There is no standard way to do this (that I am aware of),
     *   so I just made one up.
     * <br>This writes the lon values as they are currently in this table
     *    (e.g., +-180 or 0..360). 
     * <br>If no exception is thrown, the data was successfully written.
     * <br>Missing values should already be stored as NaNs (perhaps via convertToStandardMissingValues()).
     * <br>NaN's are written as "null" (to match the json library standard).
     *
     * @param outputStream There is no need for it to be buffered.
     *    A UTF-8 OutputStreamWriter is generated from it temporarily.
     *    Afterwards, it is flushed, not closed.
     * @param timeColumn the column number of the column that has 
     *    seconds since 1970-01-01 double data that should be saved as 
     *    an ISO string (or -1 if none)
     * @param writeUnits if true, columnUnits will be written with
     *    the "units" attribute for each column
     *    Note that timeColumn will have units "UTC".
     * @throws Exception (no error if there is no data)
     */
    public void saveAsJson(OutputStream outputStream, int timeColumn, 
        boolean writeUnits) throws Exception {

        BufferedWriter writer = String2.getBufferedOutputStreamWriterUtf8(outputStream);
        saveAsJson(writer, timeColumn, writeUnits);
    }

    /**
     * Save this table as a json writer.
     * <br>The writer is flushed, but not closed at the end.
     * <br>nRows and nColumns may be 0.
     * <br>Missing values should already be stored as NaNs (perhaps via convertToStandardMissingValues()).
     * <br>NaN's are written as "null" (to match the json library standard).
     */
    public void saveAsJson(Writer writer, int timeColumn, 
        boolean writeUnits) throws Exception {

        long time = System.currentTimeMillis();

        //write the column names   
        int nColumns = nColumns();
        int nRows = nRows();
        boolean isCharOrString[] = new boolean[nColumns];
        writer.write(
            "{\n" +
            "  \"table\": {\n" + //begin main structure
            "    \"columnNames\": [");
        for (int col = 0; col < nColumns; col++) {
            isCharOrString[col] = 
                getColumn(col).elementType() == PAType.CHAR ||
                getColumn(col).elementType() == PAType.STRING;
            writer.write(String2.toJson(getColumnName(col)));
            writer.write(col == nColumns - 1? "],\n" : ", ");
        }

        //write the types   
        writer.write("    \"columnTypes\": [");
        for (int col = 0; col < nColumns; col++) {
            String s = getColumn(col).elementTypeString();
            if (col == timeColumn)
                s = "String"; //not "double"
            writer.write(String2.toJson(s));  //nulls written as: null
            writer.write(col == nColumns - 1? "],\n" : ", ");
        }

        //write the units   
        if (writeUnits) {
            writer.write("    \"columnUnits\": [");
            for (int col = 0; col < nColumns; col++) {
                String s = columnAttributes(col).getString("units");
                if (col == timeColumn)
                    s = "UTC"; //not "seconds since 1970-01-01..."
                writer.write(String2.toJson(s));  //nulls written as: null
                writer.write(col == nColumns - 1? "],\n" : ", ");
            }
        }

        //write the data
        writer.write("    \"rows\": [\n");
        for (int row = 0; row < nRows; row++) {
            writer.write("      ["); //beginRow
            for (int col = 0; col < nColumns; col++) {
                if (col == timeColumn) {
                    double d = getDoubleData(col, row);
                    String s = Double.isNaN(d)? "null" : 
                        "\"" + Calendar2.epochSecondsToIsoStringTZ(d) + "\"";
                    writer.write(s);
                } else if (isCharOrString[col]) {
                    String s = getStringData(col, row);
                    writer.write(String2.toJson(s));
                } else {
                    String s = getStringData(col, row);
                    //represent NaN as null? yes, that is what json library does
                    writer.write(s.length() == 0? "null" : s); 
                }
                if (col < nColumns - 1) writer.write(", "); 
            }
            writer.write(row < nRows - 1? "],\n" : "]"); //endRow
        }       

        //end of big array
        writer.write(
            "\n" +
            "    ]\n" + //end of rows array
            "  }\n" + //end of table
            "}\n"); //end of main structure
        writer.flush(); 

        if (reallyVerbose) String2.log("Table.saveAsJson done. time=" + 
            (System.currentTimeMillis() - time) + "ms");
    }

    /**
     * This reads data from json table (of the type written by saveAsJson).
     * <ul>
     * <li> If no exception is thrown, the file was successfully read.
     * <li> If there is a String column with units="UTC", the ISO 8601 values
     *    in the column are converted to doubles (seconds since 1970-01-01).   
     * </ul>
     *
     * @param fileName the full file name
     * @throws Exception if trouble
     */
    public void readJson(String fileName) throws Exception {
        //this can't use BufferedReader because json parsers need access to entire file's content
        String results[] = String2.readFromFile(fileName, String2.UTF_8, 2);
        if (results[0].length() > 0)
            throw new Exception(results[0]);
        readJson(fileName, results[1]);
    }


    /**
     * This reads data from json table (of the type written by saveAsJson).
     * This is a little stricter about the format that a JSON file has to be
     *  (e.g., columnNames/columnTypes/columnUnits/rowOfData, if present, must be on one line).
     * <ul>
     * <li> If no exception is thrown, the file was successfully read.
     * <li> If there is a String column with units="UTC", the ISO 8601 values
     *    in the column are converted to doubles (seconds since 1970-01-01).   
     * </ul>
     *
     * @param fileName for diagnostic messages only
     * @param source the json info
     * @throws Exception if trouble
     */
    public void readJson(String fileName, String source) throws Exception {
        if (reallyVerbose) String2.log("Table.readJson " + fileName); 
        long time = System.currentTimeMillis();
        String note = "In Table.readJson(" + fileName + "): ";
        String errorInMethod = String2.ERROR + " in Table.readJson(" + fileName + "):\n";

        //clear everything
        clear();
        JSONTokener tokener = new JSONTokener(source);
        char ch;
        String s, s2;
        String[] cNames = null, cTypes = null, cUnits = null;
        StringArray sa;
        int nCol = 0;
        PrimitiveArray pas[] = null;

//{
//  "table": {
//    "columnNames": ["longitude", "latitude", "time", "sea_surface_temperature"],
//    "columnTypes": ["float", "float", "String", "float"],
//    "columnUnits": ["degrees_east", "degrees_north", "UTC", "degree_C"],
//    "rows": [
//      [180.099, 0.032, "2007-10-04T12:00:00Z", 27.66],
//      [180.099, 0.032, null, null],
//      [189.971, -7.98, "2007-10-04T12:00:00Z", 29.08]
//    ]
//}
        if ((ch = tokener.nextClean()) != '{')     throw new IOException(errorInMethod + "Initial '{' not found (" + ch + ").");
        if ((ch = tokener.nextClean()) != '\"')    throw new IOException(errorInMethod + "\"table\" not found (" + ch + ").");
        if (!(s  = tokener.nextString('\"')).equals("table")) 
                                                   throw new IOException(errorInMethod + "\"table\" not found (" + s + ").");
        if ((ch = tokener.nextClean()) != ':')     throw new IOException(errorInMethod + "':' after \"table\" not found (" + ch + ").");
        if ((ch = tokener.nextClean()) != '{')     throw new IOException(errorInMethod + "'{' after \"table\": not found (" + ch + ").");
        ch = tokener.nextClean();
        while (ch == '\"') {
            s = tokener.nextString('\"');
            if ((ch = tokener.nextClean()) != ':') throw new IOException(errorInMethod + "':' after \"" + s + "\" not found (" + ch + ").");
            if ((ch = tokener.nextClean()) != '[') throw new IOException(errorInMethod + "'{' after \"" + s + "\": not found (" + ch + ").");
            if (s.equals("columnNames")) {
                s2 = tokener.nextTo('\n'); //assumes all content is on this line!
                if (!s2.endsWith("],")) throw new IOException(errorInMethod + "columnNames line should end with '],' (" + s2 + ").");
                cNames = StringArray.arrayFromCSV(s2.substring(0, s2.length() - 2));

            } else if (s.equals("columnTypes")) {
                s2 = tokener.nextTo('\n'); //assumes all content is on this line!
                if (!s2.endsWith("],")) throw new IOException(errorInMethod + "columnTypes line should end with '],' (" + s2 + ").");
                cTypes = StringArray.arrayFromCSV(s2.substring(0, s2.length() - 2));

            } else if (s.equals("columnUnits")) {
                s2 = tokener.nextTo('\n'); //assumes all content is on this line!
                if (!s2.endsWith("],")) throw new IOException(errorInMethod + "columnUnits line should end with '],' (" + s2 + ").");
                cUnits = StringArray.arrayFromCSV(s2.substring(0, s2.length() - 2));
                for (int i = 0; i < cUnits.length; i++)
                    if ("null".equals(cUnits[i]))
                        cUnits[i] = null;

            } else if (s.equals("rows")) {
                //build the table
                nCol = cNames.length;
                if (cTypes != null && cTypes.length != nCol) throw new IOException(errorInMethod + "columnTypes size=" + cTypes.length + " should be " + nCol + ".");
                if (cUnits != null && cUnits.length != nCol) throw new IOException(errorInMethod + "columnUnits size=" + cUnits.length + " should be " + nCol + ".");
                pas = new PrimitiveArray[nCol];
                //need isString since null in numeric col is NaN, but null in String col is the word null.
                boolean isString[] = new boolean[nCol]; //all false  (includes UTC times -- initially Strings)
                boolean isUTC[] = new boolean[nCol]; //all false
                for (int col = 0; col < nCol; col++) {
                    PAType elementPAType = cTypes == null? PAType.STRING : PAType.fromCohortString(cTypes[col]);
                    isString[col] = elementPAType == PAType.STRING;
                    Attributes atts = new Attributes();
                    if (cUnits != null) {
                        isUTC[col] = isString[col] && "UTC".equals(cUnits[col]);
                        if (isUTC[col]) {
                            elementPAType = PAType.DOUBLE;
                            cUnits[col] = Calendar2.SECONDS_SINCE_1970;
                        }
                        atts.add("units", cUnits[col]);
                    }
                    pas[col] = PrimitiveArray.factory(elementPAType, 128, false);
                    addColumn(col, cNames[col], pas[col], atts);
                }

                //read the rows of data
                //I can use StringArray.arrayFromCSV to process a row of data 
                //  even though it doesn't distinguish a null String from the word "null" in a String column
                //  because ERDDAP never has null Strings (closest thing is "").
                //  If this becomes a problem, switch to grabbing the nCol items separately
                //     utilizing the specifics of the json syntax.
                while ((ch = tokener.nextClean()) == '[') {
                    s2 = tokener.nextTo('\n'); //assumes all content is on this line!
                    if (s2.endsWith("],"))
                        s2 = s2.substring(0, s2.length() - 2);
                    else if (s2.endsWith("]"))
                        s2 = s2.substring(0, s2.length() - 1);
                    else throw new IOException(errorInMethod + "JSON syntax error (missing final ']'?) on data row #" + pas[0].size() + ".");
                    String sar[] = StringArray.arrayFromCSV(s2);
                    if (sar.length != nCol)
                        throw new IOException( errorInMethod + "JSON syntax error (incorrect number of data values?) on data row #" + pas[0].size() + ".");
                    for (int col = 0; col < nCol; col++) {
                        String ts = String2.fromJsonNotNull(sar[col]);
                        //String2.log(">> col=" + col + " ts=" + String2.annotatedString(ts));
                        if (isUTC[col]) 
                            pas[col].addDouble(Calendar2.safeIsoStringToEpochSeconds(ts)); //returns NaN if trouble

                        //For both null and "null, arrayFromCSV returns "null"!
                        //String columns will treat null (shouldn't be any) and "null" as the word "null", 
                        //  numeric columns will treat null as NaN.  So all is well.
                        else pas[col].addString(ts); 
                    }
                }

                //after last data row, should be ]
                if (ch != ']') throw new IOException(errorInMethod + "']' not found after all rows of data (" + ch + ").");

            } else {
                String2.log(note + "Unexpected \"" + s + "\".");
                //it better all be on this line.
            }
            ch = tokener.nextClean();
        }

        //current ch should be final }, but don't insist on it.

        //simplify
        if (cTypes == null)
            simplify();

        /*
        //convert times to epoch seconds  (after simplify, so dates are still Strings)
        int tnRows = nRows();
        if (cUnits != null) {
            for (int col = 0; col < nCol; col++) {
                String ttUnits = cUnits[col];
                if ((pas[col] instanceof StringArray) && 
                    ttUnits != null && ttUnits.equals("UTC")) {
                    sa = (StringArray)pas[col];
                    DoubleArray da = new DoubleArray(tnRows, false);
                    for (int row = 0; row < tnRows; row++) {
                        String iso = sa.get(row);
                        da.add((iso == null || iso.length() == 0)? 
                            Double.NaN : 
                            Calendar2.isoStringToEpochSeconds(iso));
                    }
                    setColumn(col, da);
                    columnAttributes(col).set("units", Calendar2.SECONDS_SINCE_1970);
                }
            }
        }*/

        //String2.log(" place3 nColumns=" + nColumns() + " nRows=" + nRows() + " nCells=" + (nColumns() * nRows()));
        //String2.log(toString(10));
        if (reallyVerbose) String2.log("  Table.readJson done. fileName=" + fileName + 
            " nColumns=" + nColumns() + " nRows=" + nRows() + 
            " TIME=" + (System.currentTimeMillis() - time) + "ms");
    }


    /**
     * This reads a table from a jsonLinesCsv file.
     *
     * @throws Exception if serious trouble
     */
    public void readJsonlCSV(String fullFileName, 
        StringArray colNames, String[] colTypes, boolean simplify) throws Exception {
        clear();
        BufferedReader reader = 
            File2.getDecompressedBufferedFileReader(fullFileName, String2.UTF_8);
        try {
            readJsonlCSV(reader, fullFileName, colNames, colTypes, simplify);
        } finally {
            reader.close();
        }            
    }


    
    /**
     * This reads a table from a Reader from a jsonLinesCsv file (or other source).
     * https://jsonlines.org/examples/
     * The first line must be column names.
     * The second line must be data values.
     * This stops (perhaps with error) at the first line that doesn't start with [
     * and end with ] and have same number of columns as the first line.
     * This doesn't simplify the columns at all. 
     * null values appear as empty strings.
     *
     * @param reader  This is usually a BufferedReader. This method doesn't close the reader.
     * @param fullFileName This is just used for error messages.
     * @param colNames If null, all columns will be loaded. 
     *  If not null, only these columns will be loaded (if found)
     *  and the returned table will be in this order.  
     * @param colTypes If not null, this parallels colNames to specify the data types.
     *  If null, all columns will be StringArray with simply parsed values 
     *  (e.g., json strings with surrounding double quotes).
     *  "boolean" says to interpret as boolean (true|false) but convert to byte (1|0).
     * @param simplify If colTypes=null and simplify=true, this tries to 
     *   simplify (determine the column data types).
     * @throws Exception if serious trouble
     */
    public void readJsonlCSV(Reader reader, String fullFileName, StringArray colNames, 
          String[] colTypes, boolean simplify) throws Exception {
        clear();
        StringBuilder sb = new StringBuilder();
        long time = System.currentTimeMillis();

        //read the column names
        //This doesn't just JsonTokener because it resolves to different data types,
        //  but I don't need that and don't want that (for one variable, 
        //  one line might have an int and the next a long).
        int line = 1;
        int ch = reader.read();
        while (ch != '\n' && ch != -1) {
            sb.append((char)ch);
            ch = reader.read();
        }
        String s = sb.toString(); 
        StringArray sa = StringArray.simpleFromJsonArray(s);
        int nc = sa.size();
        PrimitiveArray pas[] = new PrimitiveArray[nc];
        boolean fromJsonString[] = new boolean[nc];  //all false
        boolean isBoolean[]      = new boolean[nc];  //all false
        for (int c = 0; c < nc; c++) {
            String tColName = sa.get(c);
            tColName = tColName.equals("null")? "" : String2.fromJson(tColName);
            PrimitiveArray pa = null;
            if (colNames == null) {
                pa = new StringArray();
            } else {
                int which = colNames.indexOf(tColName);
                if (which >= 0) {
                    if (colTypes == null) {
                        pa = new StringArray();
                    } else {
                        PAType tPAType = PAType.fromCohortString(colTypes[which]); //it handles boolean
                        pa = PrimitiveArray.factory(tPAType, 8, false);
                        fromJsonString[c] = tPAType == PAType.STRING || tPAType == PAType.CHAR;
                        isBoolean[c] = "boolean".equals(colTypes[which]);
                    }
                }
            }
            if (pa != null) {
                pas[c] = pa;
                addColumn(tColName, pa);
            }
        }
        if (ch == -1) //eof
            return;

        //read rows of data
        StringBuilder warnings = new StringBuilder();
        while (true) {
            line++;
            sb.setLength(0);
            ch = reader.read();
            while (ch != '\n' && ch != -1) {
                sb.append((char)ch);
                ch = reader.read();
            }
            s = sb.toString().trim();
            if (ch == -1 && s.length() == 0)
                break; //eof
            try {
                sa = StringArray.simpleFromJsonArray(s); //throws SimpleException
                if (sa.size() == nc) {
                    for (int c = 0; c < nc; c++) {
                        if (pas[c] != null) {
                            String tValue = sa.get(c);
                            if (tValue.equals("null"))   tValue = "";
                            else if (fromJsonString[c])  tValue = String2.fromJson(tValue);
                            else if (isBoolean[c])       tValue = "true".equals(tValue)? "1" : "0";
                            //else leave as is
                            pas[c].addString(tValue);
                        }
                    }
                } else {
                    warnings.append(String2.WARNING + ": skipping line #" + line +  
                      ": unexpected number of items (observed=" + sa.size() + 
                         ", expected=" + nc + "). [e]\n");
                }
            } catch (Exception e) {
                warnings.append("  line #" + line + ": " + e.getMessage() + "\n");
            }
            if (ch == -1) //eof
                break;
        }

        if (warnings.length() > 0) 
            String2.log(WARNING_BAD_LINE_OF_DATA_IN + "readJsonlCSV(" + fullFileName + "):\n" +
                warnings.toString());

        if (colNames != null) 
            reorderColumns(colNames, false);

        if (colTypes == null && simplify) {
            nc = nColumns(); //may be different from previous use of nc / fewer columns
            int nr = nRows();
            for (int c = 0; c < nc; c++) {
                PrimitiveArray pa = getColumn(c);

                //are they all quoted strings?
                boolean isString = true;
                for (int r = 0; r < nr; r++) {
                    s = pa.getString(r);
                    if (s.length() > 0 && s.charAt(0) !='\"') {
                        isString = false;
                        break;
                    }
                }
                if (isString) {
                    ((StringArray)pa).fromJson();

                } else {
                    //are they all true|false? 
                    boolean tIsBoolean = true;
                    for (int r = 0; r < nr; r++) {
                        s = pa.getString(r);
                        if (s.length() > 0 && !"true".equals(s) && !"false".equals(s)) {
                            tIsBoolean = false;
                            break;
                        }
                    }

                    if (tIsBoolean) {
                        setColumn(c, ByteArray.toBooleanToByte(pa));

                    } else {
                        //It has numbers. It shouldn't have any quoted strings.
                        simplify(c);
                    }
                }
            }
        }

        if (reallyVerbose) String2.log("  Table.readJsonlCSV(" + fullFileName + 
            ") done. nColumns=" + nColumns() + " nRows=" + nRows() + 
            " TIME=" + (System.currentTimeMillis() - time) + "ms");
    }

    /** This writes the table to a jsonlines CSV file. */
    public void writeJsonlCSV(String fullFileName) throws Exception {
        writeJsonlCSV(fullFileName, false);
    }

    /**
     * This writes a table to a jsonlCSV UTF-8 file.
     * https://jsonlines.org/examples/
     *
     * @param fullFileName This is just used for error messages.
     * @param append  If false, any existing file is deleted and a new file is created.
     *   If true, if the file exists, it will be appended to. If it doesn't exist, it
     *   will be created and column names written.
     * @throws Exception if trouble, including observed nItems != expected nItems.
     */
    public void writeJsonlCSV(String fullFileName, boolean append) throws Exception {
        String msg = "  Table.writeJsonlCSV " + fullFileName;
        long time = System.currentTimeMillis();

        //this is focused on fast writing of file
        //this is not for multithreaded use with writers and readers 
        //    (if so, change to write to ByteArrayOutputStream 
        //    then write all in one blast to file, no bufferedWriter)
        BufferedWriter bw = null;
        int randomInt = Math2.random(Integer.MAX_VALUE);
        boolean writeColumnNames = !append || !File2.isFile(fullFileName);

        try {
            bw = String2.getBufferedOutputStreamWriterUtf8(
                new FileOutputStream(fullFileName + (append? "" : randomInt), append));

            //write the col names
            int nc = nColumns();
            if (writeColumnNames) {
                for (int c = 0; c < nc; c++) {
                    bw.write(c == 0? '[' : ',');
                    bw.write(String2.toJson(columnNames.get(c)));
                }
                bw.write("]\n");
            }

            //write the data
            int nr = nRows();
            for (int r = 0; r < nr; r++) {
                for (int c = 0; c < nc; c++) {
                    bw.write(c == 0? '[' : ',');
                    bw.write(columns.get(c).getJsonString(r)); 
                }
                bw.write("]\n");
            }

            bw.close(); 
            bw = null;
            if (!append)  //replace the existing file
              File2.rename(fullFileName + randomInt, fullFileName); //throws Exception if trouble

            if (reallyVerbose) msg +=  
                " finished. nColumns=" + nColumns() + " nRows=" + nRows() + 
                " TIME=" + (System.currentTimeMillis() - time) + "ms";

        } catch (Exception e) {
            if (bw != null) {
                try {bw.close();} catch (Throwable t2) {}
            }
            File2.delete(fullFileName + randomInt);
            File2.delete(fullFileName);

            if (!reallyVerbose) String2.log(msg);
            throw e;

        } finally {
            if (reallyVerbose) String2.log(msg);
        }

    }

    /**
     * The tests readJsonLinesCsv.
     */
    public static void testJsonlCSV() throws Exception {
        String2.log("\n* String2.testReadJsonlCSV()\n" +
            "The WARNING's below are expected...");

        String source = 
            "[\"a\",\"\",\"ccc\",\"dddd\"]\n" +
            "[2,1.5,\" c3\u00b5\u20acz\\\\q\\f\\n\\r\\t\\u00b5\\u20ac \",true]\n" +
            "[\"BAD ROW WITH WRONG NUMBER OF ITEMS\"]\n" +
            "[\"BAD ROW with unterminated string ]\n" +
            "BAD ROW WITHOUT JSON ARRAY.\n" +
            " [null, null, \"1\", null] \n" +
            "        ";

        //don't simplify
        StringReader sr = new StringReader(source);
        Table table = new Table();
        table.readJsonlCSV(sr, "[StringReader]", null, null, false);
        String results = table.dataToString();
        Test.ensureEqual(results, 
"a,,ccc,dddd\n" +
"2,1.5,\"\"\" c3\\u00b5\\u20acz\\\\\\\\q\\\\f\\\\n\\\\r\\\\t\\\\u00b5\\\\u20ac \"\"\",true\n" + //?! not sure if correct
",,\"\"\"1\"\"\",\n", 
            "results=\n" + results);

        //simplify
        sr = new StringReader(source);
        table = new Table();
        table.readJsonlCSV(sr, "[StringReader]", null, null, true);
        results = table.dataToString();
        Test.ensureEqual(results, 
"a,,ccc,dddd\n" +
"2,1.5,\" c3\\u00b5\\u20acz\\\\q\\f\\n\\r\\t\\u00b5\\u20ac \",1\n" +
",,1,\n", 
            "results=\n" + results);

        //specify colNames and simplify
        sr = new StringReader(source);
        table = new Table();
        table.readJsonlCSV(sr, "[StringReader]", StringArray.fromCSV("ccc,a,dddd"), null, true);
        results = table.dataToString();
        Test.ensureEqual(results, 
"ccc,a,dddd\n" +
"\" c3\\u00b5\\u20acz\\\\q\\f\\n\\r\\t\\u00b5\\u20ac \",2,1\n" +
"1,,\n", 
            "results=\n" + results);
        Test.ensureEqual(table.getColumn(0).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(1).elementTypeString(), "byte", "");
        Test.ensureEqual(table.getColumn(2).elementTypeString(), "byte", ""); //boolean -> byte

        //specify colNames and types
        sr = new StringReader(source);
        table = new Table();
        table.readJsonlCSV(sr, "[StringReader]", StringArray.fromCSV("ccc,a,dddd"), 
            new String[]{"String", "int", "boolean"}, true);
        results = table.dataToString();
        Test.ensureEqual(results, 
"ccc,a,dddd\n" +
"\" c3\\u00b5\\u20acz\\\\q\\f\\n\\r\\t\\u00b5\\u20ac \",2,1\n" +
"1,,\n", 
            "results=\n" + results);
        Test.ensureEqual(table.getColumn(0).elementTypeString(), "String", "");
        Test.ensureEqual(table.getColumn(1).elementTypeString(), "int", "");
        Test.ensureEqual(table.getColumn(2).elementTypeString(), "byte", ""); //boolean -> byte

        //tough test table
        String fullName = testDir + "testJsonCSV.jsonl";
        File2.delete(fullName);
        table = makeToughTestTable();
        results = table.dataToString();
        String expected = 
"aString,aChar,aByte,aUByte,aShort,aUShort,anInt,aUInt,aLong,aULong,aFloat,aDouble\n" +
"a\\u00fcb\\nc\\td\\u20ace,\\u00fc,-128,0,-32768,0,-2147483648,0,-9223372036854775808,0,-3.4028235E38,-1.7976931348623157E308\n" +
"ab,\\u0000,0,127,0,32767,0,7,0,1,2.2,3.3\n" +
",A,99,99,9999,9999,999999999,2147483647,8,9223372036854775807,1.4E-45,4.9E-324\n" +
"cd,\\t,126,254,32766,65534,2147483646,4294967294,9223372036854775806,18446744073709551614,3.4028235E38,1.7976931348623157E308\n" +
",\\u20ac,,,,,,,,,,\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        table.writeJsonlCSV(fullName);
        table.clear(); //doubly sure
        table.readJsonlCSV(fullName, null, null, true); //simplify
        results = table.dataToString();
        expected =  //differs in that aULong is now a double column (because simplify doesn't catch unsigned types)
"aString,aChar,aByte,aUByte,aShort,aUShort,anInt,aUInt,aLong,aULong,aFloat,aDouble\n" +
"a\\u00fcb\\nc\\td\\u20ace,\\u00fc,-128,0,-32768,0,-2147483648,0,-9223372036854775808,0.0,-3.4028235E38,-1.7976931348623157E308\n" +
"ab,\\u0000,0,127,0,32767,0,7,0,1.0,2.2,3.3\n" +
",A,99,99,9999,9999,999999999,2147483647,8,9.223372036854776E18,1.4E-45,4.9E-324\n" +
"cd,\\t,126,254,32766,65534,2147483646,4294967294,9223372036854775806,1.8446744073709552E19,3.4028235E38,1.7976931348623157E308\n" +
",\\u20ac,,,,,,,,,,\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        PAType tTypes[] = {
            PAType.STRING, PAType.STRING, PAType.BYTE,  PAType.SHORT, PAType.SHORT, //char->String, unsigned -> larger signed
            PAType.INT,    PAType.INT,    PAType.LONG,  PAType.LONG,  PAType.DOUBLE, //ULong -> Double
            PAType.DOUBLE, PAType.DOUBLE}; //float->double because lots of decimal digits
        for (int col = 0; col < 12; col++) 
            Test.ensureEqual(table.getColumn(col).elementType(), tTypes[col], "col=" + col);

        //another hard test
        fullName = String2.unitTestDataDir + "jsonl/sampleCSV.jsonl";
        table.readJsonlCSV(fullName, null, null, true); //simpify
        results = table.dataToString();
        Test.ensureEqual(results, 
"ship,time,lat,lon,status,testLong,sst\n" +
"Bell M. Shimada,2017-03-23T00:45:00Z,28.0002,-130.2576,A,-9223372036854775808,10.9\n" +
"Bell M. Shimada,2017-03-23T01:45:00Z,28.0003,-130.3472,\\u20ac,-1234567890123456,\n" +
"Bell M. Shimada,2017-03-23T02:45:00Z,28.0001,-130.4305,\\t,0,10.7\n" +
"Bell M. Shimada,2017-03-23T12:45:00Z,27.9998,-131.5578,\"\"\"\",1234567890123456,99.0\n" +
"\" a\\t~\\u00fc,\\n'z\"\"\\u20ac\",2017-03-23T21:45:00Z,28.0003,-132.0014,\\u00fc,9223372036854775806,10.0\n" +
",,,,,,\n", 
            "results=\n" + results);

        //*** write new file
        table = makeToughTestTable();
        fullName = File2.getSystemTempDirectory() + "testJsonlCSV.json";
        table.writeJsonlCSV(fullName);
        results = String2.directReadFromUtf8File(fullName);
        Test.ensureEqual(results, 
"[\"aString\",\"aChar\",\"aByte\",\"aUByte\",\"aShort\",\"aUShort\",\"anInt\",\"aUInt\",\"aLong\",\"aULong\",\"aFloat\",\"aDouble\"]\n" +
"[\"a\\u00fcb\\nc\\td\\u20ace\",\"\\u00fc\",-128,0,-32768,0,-2147483648,0,-9223372036854775808,0,-3.4028235E38,-1.7976931348623157E308]\n" +
"[\"ab\",\"\\u0000\",0,127,0,32767,0,7,0,1,2.2,3.3]\n" +
"[\"\",\"A\",99,99,9999,9999,999999999,2147483647,8,9223372036854775807,1.4E-45,4.9E-324]\n" +
"[\"cd\",\"\\t\",126,254,32766,65534,2147483646,4294967294,9223372036854775806,18446744073709551614,3.4028235E38,1.7976931348623157E308]\n" +
"[\"\",\"\\u20ac\",null,null,null,null,null,null,null,null,null,null]\n",
            "results=\n" + results);        

        //*** write/append new file
        table = makeToughTestTable();
        File2.delete(fullName);
        table.writeJsonlCSV(fullName, true);
        results = String2.directReadFromUtf8File(fullName);
        Test.ensureEqual(results, 
"[\"aString\",\"aChar\",\"aByte\",\"aUByte\",\"aShort\",\"aUShort\",\"anInt\",\"aUInt\",\"aLong\",\"aULong\",\"aFloat\",\"aDouble\"]\n" +
"[\"a\\u00fcb\\nc\\td\\u20ace\",\"\\u00fc\",-128,0,-32768,0,-2147483648,0,-9223372036854775808,0,-3.4028235E38,-1.7976931348623157E308]\n" +
"[\"ab\",\"\\u0000\",0,127,0,32767,0,7,0,1,2.2,3.3]\n" +
"[\"\",\"A\",99,99,9999,9999,999999999,2147483647,8,9223372036854775807,1.4E-45,4.9E-324]\n" +
"[\"cd\",\"\\t\",126,254,32766,65534,2147483646,4294967294,9223372036854775806,18446744073709551614,3.4028235E38,1.7976931348623157E308]\n" +
"[\"\",\"\\u20ac\",null,null,null,null,null,null,null,null,null,null]\n",
            "results=\n" + results);        

        //then append
        table.writeJsonlCSV(fullName, true);
        results = String2.directReadFromUtf8File(fullName);
        Test.ensureEqual(results, 
"[\"aString\",\"aChar\",\"aByte\",\"aUByte\",\"aShort\",\"aUShort\",\"anInt\",\"aUInt\",\"aLong\",\"aULong\",\"aFloat\",\"aDouble\"]\n" +
"[\"a\\u00fcb\\nc\\td\\u20ace\",\"\\u00fc\",-128,0,-32768,0,-2147483648,0,-9223372036854775808,0,-3.4028235E38,-1.7976931348623157E308]\n" +
"[\"ab\",\"\\u0000\",0,127,0,32767,0,7,0,1,2.2,3.3]\n" +
"[\"\",\"A\",99,99,9999,9999,999999999,2147483647,8,9223372036854775807,1.4E-45,4.9E-324]\n" +
"[\"cd\",\"\\t\",126,254,32766,65534,2147483646,4294967294,9223372036854775806,18446744073709551614,3.4028235E38,1.7976931348623157E308]\n" +
"[\"\",\"\\u20ac\",null,null,null,null,null,null,null,null,null,null]\n" +
"[\"a\\u00fcb\\nc\\td\\u20ace\",\"\\u00fc\",-128,0,-32768,0,-2147483648,0,-9223372036854775808,0,-3.4028235E38,-1.7976931348623157E308]\n" +
"[\"ab\",\"\\u0000\",0,127,0,32767,0,7,0,1,2.2,3.3]\n" +
"[\"\",\"A\",99,99,9999,9999,999999999,2147483647,8,9223372036854775807,1.4E-45,4.9E-324]\n" +
"[\"cd\",\"\\t\",126,254,32766,65534,2147483646,4294967294,9223372036854775806,18446744073709551614,3.4028235E38,1.7976931348623157E308]\n" +
"[\"\",\"\\u20ac\",null,null,null,null,null,null,null,null,null,null]\n",
            "results=\n" + results);        

    }



    /**
     * This returns an Igor-safe column name which doesn't match a name
     * already in IgorReservedNames or the cNamesHashset.
     * The new name will be added to colNamesHashset.
     *
     * @param colName The raw, initial column name.
     * @param colNamesHashset
     * @return the safe name.
     */
    public static String makeUniqueIgorColumnName(String colName, HashSet colNamesHashset) {
        colName = String2.encodeMatlabNameSafe(colName);
        for (int i = 1; i < 1000000; i++) {
            String tColName = colName + (i == 1? "" : "" + i);
            if (!IgorReservedNames.contains(tColName) &&
                colNamesHashset.add(tColName)) //true if not already present
                return tColName;
        }
        return colName + "ShouldntHappen";
    }

    /** 
     * This writes one column (pa) to a Igor Text File .itx.
     * 
     * @param colName This should be a name returned by makeUniqueIgorColumnName().
     * @param dimInfo The dimension info if multidimensional
     *   (e.g., "/N=(nY,nX,nZ,nT)", note flipped x,y order!)
     *   or null or "" if not.
     * @param pa If multidimensional, it is in standard ERDDAP row-major order.
     *  This should be already done: convertToStandardMissingValues() 
            atts.getDouble("_FillValue"), 
            atts.getDouble("missing_value"));
     * @param writer  At the end, it is flushed, not closed.
     * @param isTimeStamp if true, pa should be DoubleArray with epochSeconds values.
     * @param setScaleForDims ready-to-use SetScale info for the dimensions, or "".
     * @throws Exception if IO trouble.
     */
    public static void writeIgorWave(Writer writer, String colName, 
        String dimInfo, PrimitiveArray pa, String units, boolean isTimeStamp,
        String setScaleForDims) 
        throws Exception {

        int nRows = pa.size();
        double stats[] = pa.calculateStats(); //okay because using standardMissingValues       
        double colMin = stats[PrimitiveArray.STATS_MIN]; //may be NaN       
        double colMax = stats[PrimitiveArray.STATS_MAX]; //may be NaN       

        PAType paType = pa.elementType();
        String safeColName = String2.encodeMatlabNameSafe(colName);
        if (dimInfo == null)
            dimInfo = "";
        String it = //igor data type    //see page II-159 in File Reference document
            paType == PAType.BYTE?   "B" :
            paType == PAType.SHORT?  "W" :
            paType == PAType.INT?    "I" :
            paType == PAType.LONG?   "T" : //-> text. Not good, but no loss of precision.
            paType == PAType.FLOAT?  "S" :
            paType == PAType.DOUBLE? "D" :
            paType == PAType.UBYTE?  "B/U" : //U=unsigned
            paType == PAType.USHORT? "W/U" :
            paType == PAType.UINT?   "I/U" :
            paType == PAType.ULONG?  "T" : //-> text. Not good, but no loss of precision. 
            paType == PAType.CHAR?   "T" :
                                     "T";  //String and unexpected
        boolean asString = it.equals("T");
            
        writer.write(
            "WAVES/" + it +
                dimInfo +
                //don't use /O to overwrite existing waves. If conflict, user will be asked.                
                " " + safeColName + IgorEndOfLine + 
            "BEGIN" + IgorEndOfLine);

        //write the data
        if (asString) {
            for (int row = 0; row < nRows; row++) {
                //String data written as json strings (in double quotes with \ encoded chars)
                writer.write(String2.toJson(pa.getString(row)));
                writer.write(IgorEndOfLine);
            }
        } else if (isTimeStamp) {
            for (int row = 0; row < nRows; row++) {
                //igor stores datetime as seconds since 1/1/1904
                double d = pa.getDouble(row);
                if (Double.isFinite(d)) {
                    d = Calendar2.epochSecondsToUnitsSince(
                        IgorBaseSeconds, IgorFactorToGetSeconds, d);
                    writer.write("" + d);
                } else {
                    writer.write(IgorNanString);
                }
                writer.write(IgorEndOfLine);
           }
        } else { //numeric
            for (int row = 0; row < nRows; row++) {
                String s = pa.getString(row); //ints will be formatted as ints
                writer.write(s.length() == 0? IgorNanString : s);
                writer.write(IgorEndOfLine);
            }
        }

        //END
        writer.write("END" + IgorEndOfLine);

        //SetScale
        if (!asString) {
            if (units == null) units = "";
            if (isTimeStamp) {
                units = "dat"; //special case in igor
                colMin = Calendar2.epochSecondsToUnitsSince(
                    IgorBaseSeconds, IgorFactorToGetSeconds, colMin);
                colMax = Calendar2.epochSecondsToUnitsSince(
                    IgorBaseSeconds, IgorFactorToGetSeconds, colMax);
            }
            writer.write(
                "X SetScale d " + //d=specifying data full scale, ',' after d???
                (Double.isNaN(colMin)? "0,0" :  //???no non-MV data values; 0,0 is used in their examples
                 pa instanceof DoubleArray || 
                 pa instanceof ULongArray?  colMin + "," + colMax :
                 pa instanceof FloatArray? Math2.doubleToFloatNaN(colMin) + "," +
                                           Math2.doubleToFloatNaN(colMax) :
                 Math2.roundToLong(colMin) + "," + Math2.roundToLong(colMax)) + 
                ", " + String2.toJson(units) + 
                ", " + safeColName +
                IgorEndOfLine);
        }
        if (String2.isSomething(setScaleForDims))
            writer.write(setScaleForDims);

        writer.write(IgorEndOfLine);
        writer.flush(); //essential (at the end)

    }

    /**
     * Save the table's data as an Igor Text File .itx file.
     * <br>File reference: in Bob's /programs/igor/ or 
     *   https://www.wavemetrics.net/doc/igorman/II-09%20Data%20Import%20Export.pdf
     * <br>Command reference: in Bob's /programs/igor/ or 
     *   https://www.wavemetrics.net/doc/igorman/V-01%20Reference.pdf
     * <br>The file extension should be .itx
     *
     * <br>Timestamp columns should have epochSeconds vaules.
     * <br>This assumes missing values haven't yet been standardized (e.g., to NaN).
     * <br>This is tested by EDDGridFromNcFiles.testIgor() since
     *   EDDGrid.saveAsIgor uses this to save axisVars-only response.
     * 
     * @param writer It is always closed at the end.
     * @throws Throwable if trouble
     */
    public void saveAsIgor(Writer writer) throws Throwable {

        String msg = "  Table.saveAsIgor"; 
        long time = System.currentTimeMillis();
        try {

            if (nRows() == 0)
                throw new SimpleException(MustBe.THERE_IS_NO_DATA + " (at start of saveAsIgor)");

            //open an OutputStream   
            writer.write("IGOR" + IgorEndOfLine);

            //write each col as a wave separately, so data type is preserved
            HashSet colNamesHashset = new HashSet();
            int nCols = nColumns();
            for (int col = 0; col < nCols; col++) {
                Attributes atts = columnAttributes(col);
                String units = atts.getString("units");
                boolean isTimeStamp = units != null && 
                    (units.equals(Calendar2.SECONDS_SINCE_1970) || //EDV.TIME_UNITS
                     units.equals("s{since 1970-01-01T00:00:00Z}")); //EDV.TIME_UCUM_UNITS

                PrimitiveArray pa = getColumn(col);
                pa.convertToStandardMissingValues(
                    atts.getString("_FillValue"), 
                    atts.getString("missing_value"));

                writeIgorWave(writer, 
                    makeUniqueIgorColumnName(getColumnName(col), colNamesHashset), 
                    "", pa, units, 
                    isTimeStamp, "");
            }

            //done!
            if (reallyVerbose) msg += " finished. TIME=" + 
                (System.currentTimeMillis() - time) + "ms\n";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            writer.flush(); //essential
            writer.close();
            if (reallyVerbose) String2.log(msg);
        }

    }


    /**
     * This reads a table structure (everything but data) from an ERDDAP info url
     * for a TableDap dataset.
     * <ul>
     * <li> If no exception is thrown, the file was successfully read.
     * </ul>
     *
     * @param url e.g., http://localhost:8080/cwexperimental/info/pmelTaoDySst/index.json .
     *    It MUST be already percentEncoded as needed.
     * @throws Exception if trouble
     */
    public void readErddapInfo(String url) throws Exception {

        String msg = "  Table.readErddapInfo " + url; 
        if (reallyVerbose) String2.log(msg);
        String errorInMethod = String2.ERROR + " in" + msg + ":\n";

        //clear everything
        clear();

        //read the json source
        //"columnNames": ["Row Type", "Variable Name", "Attribute Name", "Java Type", "Value"],
        Table infoTable = new Table();
        infoTable.readJson(url, SSR.getUrlResponseStringUnchanged(url));
        String tColNames = " column not found in colNames=" + String2.toCSSVString(infoTable.getColumnNames());
        int nRows = infoTable.nRows();
        int rowTypeCol = infoTable.findColumnNumber("Row Type");
        int variableNameCol = infoTable.findColumnNumber("Variable Name");
        int attributeNameCol = infoTable.findColumnNumber("Attribute Name");
        int javaTypeCol = infoTable.findColumnNumber("Data Type");
        int valueCol = infoTable.findColumnNumber("Value");
        Test.ensureTrue(rowTypeCol       != -1, errorInMethod + "'Row Type'" + tColNames);
        Test.ensureTrue(variableNameCol  != -1, errorInMethod + "'Variable Name'" + tColNames);
        Test.ensureTrue(attributeNameCol != -1, errorInMethod + "'Attribute Name'" + tColNames);
        Test.ensureTrue(javaTypeCol      != -1, errorInMethod + "'Data Type'" + tColNames);
        Test.ensureTrue(valueCol         != -1, errorInMethod + "'Value'" + tColNames);
        for (int row = 0; row < nRows; row++) {
            String rowType = infoTable.getStringData(rowTypeCol, row);
            String variableName = infoTable.getStringData(variableNameCol, row);
            String javaType = infoTable.getStringData(javaTypeCol, row);
            PAType tPAType = PAType.fromCohortString(javaType);
            if (rowType.equals("attribute")) {
                String attributeName = infoTable.getStringData(attributeNameCol, row);
                String value = infoTable.getStringData(valueCol, row);
                PrimitiveArray pa = tPAType == PAType.STRING? 
                    new StringArray(String2.splitNoTrim(value, '\n')) : 
                    PrimitiveArray.csvFactory(tPAType, value);
                if (variableName.equals("GLOBAL") || variableName.equals("NC_GLOBAL")) 
                    globalAttributes.add(attributeName, pa);
                else columnAttributes(variableName).add(attributeName, pa);
            } else if (rowType.equals("variable")) {
                addColumn(variableName, PrimitiveArray.factory(tPAType, 1, false));
            } else throw new Exception("Unexpected rowType=" + rowType);
        }
    }

    /**
     * This mimics the a simple directory listing web page created by Apache.
     * <br>It mimics https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v4/netcdf/
     * stored on Bob's computer as c:/programs/apache/listing3.html
     * <br>***WARNING*** The URL that got the user to this page MUST be a 
     *   directoryURL ending in '/', or the links don't work (since they are implied
     *   to be relative to the current URL, not explicit)!
     * <br>This just writes the part inside the 'body' tag.
     * <br>If there is a parentDirectory, its link will be at the top of the list.
     * <br>The table need not be sorted initially. This method handles sorting.
     * <br>The table should have 4 columns: "Name" (String, dir names should end in /), 
     *    "Last modified" (long, in milliseconds, directories/unknown should have Long.MAX_VALUE), 
     *    "Size" (long, directories/unknown should have Long.MAX_VALUE), and 
     *    "Description" (String)
     * <br>The displayed Last Modified time will be Zulu timezone.
     * <br>The displayed size will be some number of bytes
     *    [was: truncated to some number of K (1024), M (1024^2), G (1024^3), or T (1024^4)]     
     *
     * @param localDir the actual local directory, so this can determine image size
     *    (or null if not a real dir or you don't want to do that)
     * @param showUrlDir the part of the URL directory name to be displayed (with trailing slash).
     *    This is for display only.
     * @param userQuery  may be null. Still percent encoded.  
     *   <br>The parameter options are listed at 
     *    https://httpd.apache.org/docs/2.0/mod/mod_autoindex.html
     *   <br>C=N sorts the directory by file name
     *   <br>C=M sorts the directory by last-modified date, then file name
     *   <br>C=S sorts the directory by size, then file name
     *   <br>C=D sorts the directory by description, then file name
     *   <br>O=A sorts the listing in Ascending Order
     *   <br>O=D sorts the listing in Descending Order
     *   <br>F=0 formats the listing as a simple list (not FancyIndexed)
     *   <br>F=1 formats the listing as a FancyIndexed list
     *   <br>F=2 formats the listing as an HTMLTable FancyIndexed list
     *   <br>V=0 disables version sorting
     *   <br>V=1 enables version sorting
     *   <br>P=pattern lists only files matching the given pattern
     *   <br>The default is "C=N;O=A".
     *   <br>Currently, only C= and O= parameters are supported.
     * @param iconUrlDir the public URL directory (with slash at end) with the icon files
     * @param addParentDir if true, this shows a link to the parent directory
     * @param dirNames is the list of subdirectories in the directory 
     *   just the individual words (and without trailing '/'), not the whole URL. 
     *   It will be sorted within directoryListing.
     * @param dirDescriptions may be null
     */
    public String directoryListing(String localDir, String showUrlDir, String userQuery,
        String iconUrlDir, String questionMarkImageUrl, boolean addParentDir, 
        StringArray dirNames, StringArray dirDescriptions) throws Exception {

        //String2.log("Table.directoryListing("showUrlDir=" + showUrlDir +
        //    "\n  userQuery=" + userQuery + 
        //    "\n  iconUrlDir=" + iconUrlDir +
        //    "\n  nDirNames=" + dirNames.size() + " table.nRows=" + nRows());
        if (localDir != null) {
            if (!File2.isDirectory(localDir)) {
                String2.log("Warning: directoryListing localDir=" + localDir + " isn't a directory.");
                localDir = null;
            }
        }

        //en/sure column names are as expected
        String ncssv = getColumnNamesCSSVString();
        String ncssvMust = "Name, Last modified, Size, Description";
        if (!ncssvMust.equals(ncssv))
             throw new SimpleException(
                String2.ERROR + " in directoryListing(), the table's column\n" +
                "names must be \"" + ncssvMust + "\".\n" +
                "The names are \"" + ncssv + "\".");
        PrimitiveArray namePA        = getColumn(0);
        PrimitiveArray modifiedPA    = getColumn(1);
        PrimitiveArray sizePA        = getColumn(2);
        PrimitiveArray descriptionPA = getColumn(3);
        modifiedPA.setMaxIsMV(true);
        sizePA.setMaxIsMV(true);

        //ensure column types are as expected
        String tcssv = getColumn(0).elementTypeString() + ", " +
                       getColumn(1).elementTypeString() + ", " +
                       getColumn(2).elementTypeString() + ", " +
                       getColumn(3).elementTypeString();
        String tcssvMust = "String, long, long, String";
        if (!tcssvMust.equals(tcssv))
             throw new SimpleException(
                String2.ERROR + " in directoryListing(), the table's column\n" +
                "types must be \"" + tcssvMust + "\".\n" +
                "The types are \"" + tcssv + "\".");

        //parse userQuery (e.g., C=N;O=A)  
        userQuery = userQuery == null? "" : 
            ";" + SSR.percentDecode(userQuery) + ";";  // ";" make it easy to search below
        int keyColumns[] =  //see definitions in javadocs above
            userQuery.indexOf(";C=N;") >= 0? new int[]{0, 1} : //2nd not needed, but be consistent
            userQuery.indexOf(";C=M;") >= 0? new int[]{1, 0} : 
            userQuery.indexOf(";C=S;") >= 0? new int[]{2, 0} : 
            userQuery.indexOf(";C=D;") >= 0? new int[]{3, 0} : 
                                             new int[]{0, 1};  
        boolean ascending[] =  //see definitions in javadocs above
            userQuery.indexOf(";O=D;") >= 0? new boolean[]{false, false} :
                                             new boolean[]{true, true};  
        //Order=A|D in column links will be 'A', 
        //  except currently selected column will offer !currentAscending
        char linkAD[] = {'A','A','A','A'};
        linkAD[keyColumns[0]] = ascending[0]? 'D' : 'A'; // !currentAscending        

        //and sort the table (while lastModified and size are still the raw values) 
        sortIgnoreCase(keyColumns, ascending);

        int tnRows = nRows();
        /*
        //convert LastModified to string  (after sorting)
        StringArray newModifiedPA = new StringArray(tnRows, false);
        for (int row = 0; row < tnRows; row++) {
            String newMod = "";
            try {
                long tl = modifiedPA.getLong(row);
                newMod = tl == Long.MAX_VALUE? "" : //show hh:mm, not more
                    Calendar2.formatAsDDMonYYYY(Calendar2.newGCalendarZulu(tl)).substring(0, 17); 
            } catch (Throwable t) {
            }
            newModifiedPA.add(newMod);
        }
        modifiedPA = newModifiedPA;
        */

        //convert sizes
        /*
        StringArray newSizePA = new StringArray(tnRows, false);
        for (int row = 0; row < tnRows; row++) {
            String newSize = "";
            try {
                //lim ensures the displayed number will be lim ... lim*1000-1
               //(values of 1...lim-1 are not as precise)
                int lim = 6;
                long tl = sizePA.getLong(row);
                newSize = tl == Long.MAX_VALUE? "" :  
                    (tl >= lim * Math2.BytesPerPB? (tl / Math2.BytesPerPB) + "P" :
                     tl >= lim * Math2.BytesPerTB? (tl / Math2.BytesPerTB) + "T" :
                     tl >= lim * Math2.BytesPerGB? (tl / Math2.BytesPerGB) + "G" :
                     tl >= lim * Math2.BytesPerMB? (tl / Math2.BytesPerMB) + "M" :
                     tl >= lim * Math2.BytesPerKB? (tl / Math2.BytesPerKB) + "K" : tl + "");
            } catch (Throwable t) {
            }
            newSizePA.add(newSize);
        }
        sizePA = newSizePA;
        */

//<table><tr><th><img src="/icons/blank.gif" alt="[ICO]"></th>
  //<th><a href="?C=N;O=D">Name</a></th>
  //<th><a href="?C=M;O=A">Last modified</a></th>
  //<th><a href="?C=S;O=A">Size</a></th>
  //<th><a href="?C=D;O=A">Description</a></th></tr>
  //<tr><th colspan="5"><hr></th></tr>
//<tr><td valign="top"><img src="/icons/folder.gif" alt="[DIR]"></td><td><a href="OEDV/">OEDV/</a></td><td align="right">26-Feb-2017 13:22  </td><td align="right">  - </td><td>&nbsp;</td></tr>

        //write showUrlDir
        StringBuilder sb = new StringBuilder();
        sb.append(HtmlWidgets.htmlTooltipScript(File2.getDirectory(questionMarkImageUrl)));

        //write column names and hr
        String iconStyle = ""; //" style=\"vertical-align:middle;\"";
        sb.append(
            "<table class=\"compact nowrap\" style=\"border-collapse:separate; border-spacing:12px 0px;\">\n" +
            "<tr><th><img class=\"B\" src=\"" + iconUrlDir + "blank.gif\" alt=\"[ICO]\"" + iconStyle + "></th>" + 
                "<th><a href=\"?C=N;O=" + linkAD[0] + "\">Name</a></th>" +
                "<th><a href=\"?C=M;O=" + linkAD[1] + "\">Last modified</a></th>" +
                "<th><a href=\"?C=S;O=" + linkAD[2] + "\">Size</a></th>" +
                "<th><a href=\"?C=D;O=" + linkAD[3] + "\">Description</a></th></tr>\n" +
            "<tr><th colspan=\"5\"><hr></th></tr>\n");

        //display the directories
        //if shown, parentDir always at top
        if (dirDescriptions == null) {
            dirNames.sortIgnoreCase();
        } else {
            Table dirTable = new Table();
            dirTable.addColumn("names", dirNames);
            dirTable.addColumn("desc", dirDescriptions);
            dirTable.leftToRightSortIgnoreCase(1);
        }
        if (keyColumns[0] == 0 && !ascending[0]) { //if sorted by Names, descending order
            dirNames.reverse();
            if (dirDescriptions != null)
                dirDescriptions.reverse();
        }
        if (addParentDir && dirNames.indexOf("..") < 0) { //.. always at top
            dirNames.atInsert(0, "..");
            if (dirDescriptions != null)
                dirDescriptions.atInsert(0, "");
        }
        int nDir = dirNames.size();
        for (int row = 0; row < nDir; row++) {
            try {
                String dirName = dirNames.get(row); 
                if (!dirName.equals(".."))
                    dirName += "/";
                String dirDes = dirDescriptions == null? "" : dirDescriptions.get(row);
                String showDirName = dirName;
                String iconFile = "dir.gif"; //default
                String iconAlt  = "DIR";  
                if (dirName.equals("..")) {
                    showDirName = "Parent Directory";
                    iconFile    = "back.gif";
                }
                sb.append(
                    "<tr>" +
                    "<td><img class=\"B\" src=\"" + iconUrlDir + iconFile + 
                        "\" alt=\"[" + iconAlt + "]\"" + iconStyle + "></td>" +  
                    "<td><a href=\"" + 
                      XML.encodeAsHTMLAttribute(dirName) + 
                      "\">" + XML.encodeAsXML(showDirName) + "</a></td>" +
                    "<td class=\"R\">-</td>" +  //lastMod
                    "<td class=\"R\">-</td>" +  //size
                    "<td>" + XML.encodeAsXML(dirDes) + "</td>" +
                    "</tr>\n"); 

            } catch (Throwable t) {
                String2.log(String2.ERROR + " for directoryListing(" +
                    showUrlDir + ")\n" +
                    MustBe.throwableToString(t));
            }
        }

        
        //display the files
        for (int row = 0; row < tnRows; row++) {
            try {
                String fileName = namePA.getString(row);
                String fileNameLC = fileName.toLowerCase();
                String encodedFileName = XML.encodeAsHTMLAttribute(fileName);

                //very similar code in Table.directoryListing and TableWriterHtmlTable.
                int whichIcon = File2.whichIcon(fileName);
                String iconFile = File2.ICON_FILENAME[whichIcon];
                String iconAlt  = File2.ICON_ALT[whichIcon]; //always 3 characters 
                String extLC = File2.getExtension(fileNameLC);

                //make HTML for a viewer?
                String viewer = "";
                String imgStyle = ""; 
                if (iconAlt.equals("SND")) {
                    //viewer = HtmlWidgets.htmlAudioControl(encodedFileName);
                    viewer = HtmlWidgets.cssTooltipAudio(
                        questionMarkImageUrl, "?", imgStyle,
                        fileName);

                //} else if (iconAlt.equals("IMG") && localDir != null) {
                //    //this system has to open the local file to get the image's size
                //    viewer = HtmlWidgets.imageInTooltip(localDir + fileName,
                //        encodedFileName, questionMarkImageUrl);

                } else if (iconAlt.equals("IMG")) { 
                    //this system doesn't need to know the size ahead of time
                    viewer = HtmlWidgets.cssTooltipImage(
                        questionMarkImageUrl, "?", imgStyle,
                        fileName, "img" + row);

                } else if (iconAlt.equals("MOV")) { 
                    viewer = HtmlWidgets.cssTooltipVideo(
                        questionMarkImageUrl, "?", imgStyle, fileName); 
                }

                //make DDMonYYYY HH:MM formatted lastModified time
                String newMod = "";
                long tl = modifiedPA.getLong(row);
                try {
                    newMod = tl == Long.MAX_VALUE? "" : //show hh:mm, not more
                        Calendar2.formatAsDDMonYYYY(Calendar2.newGCalendarZulu(tl)).substring(0, 17); 
                } catch (Throwable t) {
                    String2.log("Caught throwable while dealing with tl=" + tl + ":\n" +
                        MustBe.throwableToString(t));
                }

                String sizePAs = sizePA.getString(row);
                sb.append(
                    "<tr>" +
                    "<td><img class=\"B\" src=\"" + iconUrlDir + iconFile + 
                        "\" alt=\"[" + iconAlt + "]\"" + iconStyle + ">" + 
                        (viewer.length() > 0? "&nbsp;" + viewer : "") +
                        "</td>" +  
                    "<td><a rel=\"bookmark\" href=\"" + encodedFileName + "\">" + encodedFileName + "</a></td>" +
                    "<td class=\"R\">" + newMod + "</td>" +
                    "<td class=\"R\">" + (sizePAs.length() == 0? "-" : sizePAs) + "</td>" +
                    "<td>" + XML.encodeAsXML(descriptionPA.getString(row)) + "</td>" +
                    "</tr>\n"); 
            } catch (Throwable t) {
                String2.log(String2.ERROR + " for directoryListing(" +
                    showUrlDir + ")\n" +
                    MustBe.throwableToString(t));
            }
        }

        sb.append(
            "<tr><th colspan=\"5\"><hr></th></tr>\n" + //<hr>
            "</table>\n" +
            nDir   + (nDir   == 1? " directory, " : " directories, ") + 
            tnRows + (tnRows == 1? " file "       : " files") + 
            "\n\n");
        return sb.toString();
    } 


    /**
     * Test saveAsJson and readJson.
     *
     * @throws Exception if trouble
     */
    public static void testJson() throws Exception {
        String2.log("\n***** Table.testJson");
        verbose = true;
        reallyVerbose = true;

        //generate some data    
        Table table = getTestTable(true, true);

        //write it to a file
        String fileName = testDir + "tempTable.json";
        table.saveAsJson(fileName, 0, true);
        //String2.log(fileName + "=\n" + String2.readFromFile(fileName)[1]);
        //SSR.displayInBrowser("file://" + fileName);

        //read it from the file
        String results = String2.directReadFromUtf8File(fileName);
        Test.ensureEqual(results, 
"{\n" +
"  \"table\": {\n" +
"    \"columnNames\": [\"Time\", \"Longitude\", \"Latitude\", \"Double Data\", \"Long Data\", \"Int Data\", \"Short Data\", \"Byte Data\", \"Char Data\", \"String Data\"],\n" +
"    \"columnTypes\": [\"String\", \"int\", \"float\", \"double\", \"long\", \"int\", \"short\", \"byte\", \"char\", \"String\"],\n" +
"    \"columnUnits\": [\"UTC\", \"degrees_east\", \"degrees_north\", \"doubles\", \"longs\", \"ints\", \"shorts\", \"bytes\", \"chars\", \"Strings\"],\n" +
"    \"rows\": [\n" +
"      [\"1970-01-01T00:00:00Z\", -3, 1.0, -1.0E300, -2000000000000000, -2000000000, -32000, -120, \",\", \"a\"],\n" +
"      [\"2005-08-31T16:01:02Z\", -2, 1.5, 3.123, 2, 2, 7, 8, \"\\\"\", \"bb\"],\n" +
"      [\"2005-11-02T18:04:09Z\", -1, 2.0, 1.0E300, 2000000000000000, 2000000000, 32000, 120, \"\\u20ac\", \"ccc\"],\n" +
"      [null, null, null, null, null, null, null, null, \"\", \"\"]\n" +
"    ]\n" +
"  }\n" +
"}\n", 
        results);

        //read it
        Table table2 = new Table();
        table2.readJson(fileName);
        Test.ensureTrue(table.equals(table2), "");

        //finally 
        File2.delete(fileName);

        //******************* test readErddapInfo
        //String tUrl = "https://coastwatch.pfeg.noaa.gov/erddap2";
        //http://localhost:8080/cwexperimental/info/pmelTaoDySst/index.json
        String tUrl = "http://localhost:8080/cwexperimental";
        table.readErddapInfo(tUrl + "/info/pmelTaoDySst/index.json");
        String ncHeader = table.getNCHeader("row");
        Test.ensureEqual(table.globalAttributes.getString("cdm_data_type"), "TimeSeries", ncHeader);
        Test.ensureEqual(table.globalAttributes.getString("title"), 
            "TAO/TRITON, RAMA, and PIRATA Buoys, Daily, 1977-present, Sea Surface Temperature", 
            ncHeader);
        Test.ensureEqual(table.globalAttributes.get("history").size(), 3,  ncHeader);
        Test.ensureEqual(table.globalAttributes.get("history").getString(0), 
            "This dataset has data from the TAO/TRITON, RAMA, and PIRATA projects.", 
            ncHeader);
        Test.ensureEqual(table.globalAttributes.get("history").getString(1), 
            "This dataset is a product of the TAO Project Office at NOAA/PMEL.", 
            ncHeader);
        Test.repeatedlyTestLinesMatch(table.globalAttributes.get("history").getString(2), 
            "20\\d{2}-\\d{2}-\\d{2} Bob Simons at NOAA/NMFS/SWFSC/ERD \\(bob.simons@noaa.gov\\) " +
            "fully refreshed ERD's copy of this dataset by downloading all of the .cdf files from the PMEL TAO FTP site.  " +
            "Since then, the dataset has been partially refreshed everyday by downloading and merging the latest version of the last 25 days worth of data.", 
            ncHeader);
        Test.ensureEqual(table.nColumns(), 10, ncHeader);
        Test.ensureEqual(table.findColumnNumber("longitude"), 3, ncHeader);
        Test.ensureEqual(table.columnAttributes(3).getString("units"), "degrees_east", ncHeader);
        int t25Col = table.findColumnNumber("T_25");
        Test.ensureTrue(t25Col > 0, ncHeader);
        Test.ensureEqual(table.columnAttributes(t25Col).getString("ioos_category"), "Temperature", ncHeader);
        Test.ensureEqual(table.columnAttributes(t25Col).getString("units"), "degree_C", ncHeader);

    }

    /**
     * This saves the current table in some type of file.
     * If the file already exists, it is touched, and nothing else is done.
     *
     * @param fullFileName including directory and extension (e.g., ".asc"),
     *   but not including ".zip" if you want it zipped.
     * @param saveAsType one of the SAVE_AS constants.
     *   If SAVE_AS_4D_NC, it is assumed that column 1=lon, 2=lat, 3=depth, 4=time.
     * @param dimensionName usually "row", but e.g., may be "time", 
     *    "station", or "observation", or ...?
     * @param zipIt If true, creates a .zip file and deletes the
     *    intermediate file (e.g., .asc). If false, the specified
     *    saveAsType is created.
     * @throws Exception if trouble
     */
    public void saveAs(String fullFileName, 
            int saveAsType, String dimensionName, boolean zipIt) throws Exception {

        if (reallyVerbose) String2.log("Table.saveAs(name=" + fullFileName + " type=" + saveAsType + ")"); 
        if (saveAsType != SAVE_AS_TABBED_ASCII &&
            saveAsType != SAVE_AS_FLAT_NC &&
            saveAsType != SAVE_AS_4D_NC &&
            saveAsType != SAVE_AS_MATLAB
            )
            throw new RuntimeException(String2.ERROR + " in Table.saveAs: invalid saveAsType=" + saveAsType);
       
        String ext = SAVE_AS_EXTENSIONS[saveAsType];

        //does the file already exist?
        String finalName = fullFileName + (zipIt? ".zip" : "");
        if (File2.touch(finalName)) { 
            String2.log("Table.saveAs reusing " + finalName);
            return;
        }
     
        //save as ...
        long time = System.currentTimeMillis();
        if      (saveAsType == SAVE_AS_TABBED_ASCII) saveAsTabbedASCII(fullFileName);
        else if (saveAsType == SAVE_AS_FLAT_NC)      saveAsFlatNc(fullFileName, dimensionName);
        else if (saveAsType == SAVE_AS_4D_NC)        saveAs4DNc(fullFileName, 0, 1, 2, 3);
        else if (saveAsType == SAVE_AS_MATLAB)       saveAsMatlab(fullFileName, getColumnName(nColumns() - 1));

        if (zipIt) {
            //zip to a temporary zip file, -j: don't include dir info
            SSR.zip(         fullFileName + ".temp.zip",
                new String[]{fullFileName}, 20); 

            //delete the file that was zipped
            File2.delete(fullFileName); 

            //if all successful, rename to final name
            File2.rename(fullFileName + ".temp.zip", fullFileName + ".zip"); //throws Exception if trouble
        }
    }

    /**
     * This reads an input table file (or 1- or 2-level opendap sequence)
     * and saves it in a file (optionally zipped).
     * A test which reads data from an opendap 1-level sequence and writes it to an .nc file: 
     * convert("https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_bottle?t0,oxygen&month=\"5\"", 2, testDir + "convert.nc", 1, false);
     *
     * @param inFullName  the full name of the file (with the extension .zip
     *    if it is zipped) or opendap sequence url (optionally with a query). 
     *    <ul>
     *    <li>2016-12-07: With versions of Tomcat somewhere after 8.0, the url must be stongly percent-encoded.
     *    <li> If it is zipped, the data file should be the only file in the .zip file
     *      and the data file's name should be inFullName minus the directory 
     *      and the ".zip" at the end.
     *    <li> All of the data in the file will be read.
     *    <li> If the data is packed (e.g., scale_factor, add_offset), this will not unpack it.
     *    <li>ASCII files must have column names on the first line and data 
     *      starting on the second line.
     *       <ul>
     *       <li>The item separator on each line can be tab, comma, or 1 or more spaces.
     *       <li>Missing values for tab- and comma-separated files can be "" or "." or "NaN".
     *       <li>Missing values for space-separated files can be "." or "NaN".
     *       <li> All data rows must have the same number of data items. 
     *       <li> The data is initially read as Strings. Then columns are simplified
     *          (e.g., to doubles, ... or bytes) so they store the data compactly.
     *       <li> Currently, date strings are left as strings. 
     *       </ul>
     *    <li>For opendap sequence details, see readOpendapSequence  (query must already SSR.percentEncoded as needed).
     *    </ul>
     * @param inType the type of input file: READ_FLAT_NC, READ_ASCII, READ_OPENDAP_SEQUENCE
     * @param outFullName the full name of the output file (but without
     *    the .zip if you want it zipped).
     * @param outType the type of output file: SAVE_AS_MAT, SAVE_AS_TABBED_ASCII, 
     *    SAVE_AS_FLAT_NC, or SAVE_AS_4D_NC.
     * @param dimensionName usually "row", but, e.g., maybe "time",
     *     "station", or "observation", or ...?
     * @param zipIt true if you want the file to be zipped
     * @throws Exception if trouble
     */
    public static void convert(String inFullName, int inType,
        String outFullName, int outType, String dimensionName, boolean zipIt) throws Exception {

        if (reallyVerbose) 
            String2.log("Table.convert in=" + inFullName + " inType=" + inType +
            "  out=" + outFullName + " outType=" + outType + " zipIt=" + zipIt);

        //unzip inFullName
        boolean unzipped = inFullName.toLowerCase().endsWith(".zip"); 
        if (unzipped) {     
            String tempDir = File2.getSystemTempDirectory();
            if (reallyVerbose) String2.log("unzipping to systemTempDir = " + tempDir);
 
            SSR.unzip(inFullName, tempDir, true, 10000, null);
            inFullName = tempDir + 
                File2.getNameAndExtension(inFullName).substring(0, inFullName.length() - 4); //without .zip at end          
        }

        //read the file
        Table table = new Table();
        if (inType == READ_ASCII)
            table.readASCII(inFullName);
        else if (inType == READ_FLAT_NC)
            table.readFlatNc(inFullName, null, 0); //standardizeWhat=0
        else if (inType == READ_OPENDAP_SEQUENCE)
            table.readOpendapSequence(inFullName, false);
        else throw new Exception(String2.ERROR + " in Table.convert: unrecognized inType: " + inType);

        //if input file was unzipped, delete the unzipped file
        if (unzipped)
            File2.delete(inFullName);

        //save the file (and zipIt?)
        table.saveAs(outFullName, outType, dimensionName, zipIt);
    }


    /**
     * Test convert.
     */
    public static void testConvert() throws Exception {
        verbose = true;
        reallyVerbose = true;
        String url, fileName;
        Table table = new Table();

// /*
        //the original test from Roy
        //This is used as an example in various documentation. 
        //If url changes, do search and replace to change all references to it.
        url = "https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_bottle?t0,oxygen&month=\"5\"";
        String2.log("\ntesting Table.convert \n url=" + url);
        fileName = testDir + "convertOriginal.nc";
        convert(url, READ_OPENDAP_SEQUENCE, fileName, SAVE_AS_FLAT_NC, "row", false);
        table.readFlatNc(fileName, null, 0); //standardizeWhat=0, should be already unpacked. 
        String2.log(table.toString(3));
        Test.ensureEqual(table.nColumns(), 2, "");
        Test.ensureEqual(table.nRows(), 190, "");
        Test.ensureEqual(table.getColumnName(0), "t0", "");
        Test.ensureEqual(table.getColumnName(1), "oxygen", "");
        Test.ensureEqual(table.columnAttributes(0).getString("long_name"), "Temperature T0", "");
        Test.ensureEqual(table.columnAttributes(1).getString("long_name"), "Oxygen", "");
        Test.ensureEqual(table.getFloatData(0, 0), 12.1185f, "");
        Test.ensureEqual(table.getFloatData(0, 1), 12.1977f, "");
        Test.ensureEqual(table.getFloatData(1, 0), 6.56105f, "");
        Test.ensureEqual(table.getFloatData(1, 1), 6.95252f, "");
        File2.delete(fileName);
// */

// /*
        //The 8/16/06 test from osu
        //Test values below from html ascii request  (same as url below, but with .ascii before "?")
        //adcp95.yearday, adcp95.depth, adcp95.x, adcp95.y, adcp95.eastv
        //row0: 184.45120239257812, 22, -123.8656005859375, 48.287899017333984, -0.31200000643730164
        //last row: 185.99949645996094, 22, -125.98069763183594, 42.844200134277344, -0.15399999916553497
        url = "http://nwioos.coas.oregonstate.edu:8080/dods/drds/1995%20Hake%20Survey%20ADCP?ADCP95.yearday,ADCP95.Z,ADCP95.x,ADCP95.y,ADCP95.EV&ADCP95.yearday<186&ADCP95.Z<25";
        String2.log("\ntesting Table.convert \n url=" + url);
        fileName = testDir + "convertOSU.nc";
        convert(url, READ_OPENDAP_SEQUENCE, fileName, SAVE_AS_FLAT_NC, "row", false);
        table.readFlatNc(fileName, null, 0); //standardizeWhat=0, should be already unpacked. 
        String2.log(table.toString(3));
        Test.ensureEqual(table.nColumns(), 5, "");
        Test.ensureEqual(table.nRows(), 446, "");
        Test.ensureEqual(table.getColumnName(0), "yearday", "");
        Test.ensureEqual(table.getColumnName(1), "Z", "");
        Test.ensureEqual(table.getColumnName(2), "x", "");
        Test.ensureEqual(table.getColumnName(3), "y", "");
        Test.ensureEqual(table.getColumnName(4), "EV", "");
        //no attributes
        Test.ensureEqual(table.getDoubleData(0, 0), 184.45120239257812, "");
        Test.ensureEqual(table.getDoubleData(1, 0), 22, "");
        Test.ensureEqual(table.getDoubleData(2, 0), -123.8656005859375, "");
        Test.ensureEqual(table.getDoubleData(3, 0), 48.287899017333984, "");
        Test.ensureEqual(table.getDoubleData(4, 0), -0.31200000643730164, "");
        Test.ensureEqual(table.getDoubleData(0, 445), 185.99949645996094, "");
        Test.ensureEqual(table.getDoubleData(1, 445), 22, "");
        Test.ensureEqual(table.getDoubleData(2, 445), -125.98069763183594, "");
        Test.ensureEqual(table.getDoubleData(3, 445), 42.844200134277344, "");
        Test.ensureEqual(table.getDoubleData(4, 445), -0.15399999916553497, "");
        File2.delete(fileName);
// */

// /*
        //The 8/17/06 test from cimt
        //Test values below from html ascii request  (same as url below, but with .ascii before "?")
        //vCTD.latitude, vCTD.longitude, vCTD.station, vCTD.depth, vCTD.salinity
        //first: 36.895, -122.082, "T101", 1.0, 33.9202
        //last: 36.609, -121.989, "T702", 4.0, 33.4914
        url = "http://cimt.dyndns.org:8080/dods/drds/vCTD?vCTD.latitude,vCTD.longitude,vCTD.station,vCTD.depth,vCTD.salinity&vCTD.depth<5";
        String2.log("\ntesting Table.convert \n url=" + url);
        fileName = testDir + "convertCIMT.nc";
        convert(url, READ_OPENDAP_SEQUENCE, fileName, SAVE_AS_FLAT_NC, "row", false);
        table.readFlatNc(fileName, null, 0); //standardizeWhat=0, should be already unpacked. 
        String2.log(table.toString(3));
        Test.ensureEqual(table.nColumns(), 5, "");
        //Test.ensureEqual(table.nRows(), 1407, "");  //this changes; file is growing
        Test.ensureEqual(table.getColumnName(0), "latitude", "");
        Test.ensureEqual(table.getColumnName(1), "longitude", "");
        Test.ensureEqual(table.getColumnName(2), "station", "");
        Test.ensureEqual(table.getColumnName(3), "depth", "");
        Test.ensureEqual(table.getColumnName(4), "salinity", "");
        //no attributes
        Test.ensureEqual(table.getFloatData(0, 0), 36.895f, "");
        Test.ensureEqual(table.getFloatData(1, 0), -122.082f, "");
        Test.ensureEqual(table.getStringData(2, 0), "T101", "");
        Test.ensureEqual(table.getFloatData(3, 0), 1.0f, "");
        Test.ensureEqual(table.getFloatData(4, 0), 33.9202f, "");
        Test.ensureEqual(table.getFloatData(0, 1406), 36.609f, "");
        Test.ensureEqual(table.getFloatData(1, 1406), -121.989f, "");
        Test.ensureEqual(table.getStringData(2, 1406), "T702", "");
        Test.ensureEqual(table.getFloatData(3, 1406), 4.0f, "");
        Test.ensureEqual(table.getFloatData(4, 1406), 33.4914f, "");
        File2.delete(fileName);
// */
    }

    /**
     * This rearranges the columns to be by case-insensitive alphabetical column name.
     */
    public void sortColumnsByName() {
        StringArray tColNames = new StringArray(columnNames);
        tColNames.sortIgnoreCase();
        reorderColumns(tColNames, false);
    }

    /** 
     * This tests sortColumnsByName (and reorderColumns).
     */
    public static void testSortColumnsByName() {
        verbose = true;
        reallyVerbose = true;
        String2.log("\n***** Table.testSortColumnsByName");
        Table table = getTestTable(true, true);
        table.setColumnName(2, "latitude"); //to test case-insensitive

        table.sortColumnsByName();

        //byte
        Test.ensureEqual(table.getColumnName(0), "Byte Data", "");
        Test.ensureEqual(table.columnAttributes(0).getString("units"), "bytes", "");

        //char
        Test.ensureEqual(table.getColumnName(1), "Char Data", "");
        Test.ensureEqual(table.columnAttributes(1).getString("units"), "chars", "");

        //double
        Test.ensureEqual(table.getColumnName(2), "Double Data", "");
        Test.ensureEqual(table.columnAttributes(2).getString("units"), "doubles", "");

        //int
        Test.ensureEqual(table.getColumnName(3), "Int Data", "");
        Test.ensureEqual(table.columnAttributes(3).getString("units"), "ints", "");

        //Lat
        Test.ensureEqual(table.getColumnName(4), "latitude", "");
        Test.ensureEqual(table.columnAttributes(4).getString("units"), "degrees_north", "");

        //long  
        Test.ensureEqual(table.getColumnName(5), "Long Data", "");
        Test.ensureEqual(table.columnAttributes(5).getString("units"), "longs", "");

        //Lon
        Test.ensureEqual(table.getColumnName(6), "Longitude", "");
        Test.ensureEqual(table.columnAttributes(6).getString("units"), "degrees_east", "");

        //short
        Test.ensureEqual(table.getColumnName(7), "Short Data", "");
        Test.ensureEqual(table.columnAttributes(7).getString("units"), "shorts", "");

        //String
        Test.ensureEqual(table.getColumnName(8), "String Data", "");
        Test.ensureEqual(table.columnAttributes(8).getString("units"), "Strings", "");

        //Time
        Test.ensureEqual(table.getColumnName(9), "Time", "");
        Test.ensureEqual(table.columnAttributes(9).getString("units"), Calendar2.SECONDS_SINCE_1970, "");

    }

    /** THIS IS NOT FINISHED. 
     *
     * @param standardizeWhat see Attributes.unpackVariable's standardizeWhat
     */
    public void readArgoProfile(String fileName, int standardizeWhat) throws Exception {

        String msg = "  Table.readArgoProfile " + fileName;
        long tTime = System.currentTimeMillis();
        NetcdfFile nc = NcHelper.openFile(fileName);
        //Attributes gridMappingAtts = null; //method is unfinished
        try {
//   DATE_TIME = 14;
//   N_PROF = 632;
//   N_PARAM = 3;
//   N_LEVELS = 71;
//   N_CALIB = 1;
//   N_HISTORY = UNLIMITED;   // (0 currently)
            Variable var;
            PrimitiveArray pa;
            int col;
            NcHelper.getGlobalAttributes(nc, globalAttributes);

            //The plan is: make minimal changes here. Change metadata etc in ERDDAP.

            var = nc.findVariable("DATA_TYPE");
            if (var != null) {
                col = addColumn("dataType", NcHelper.getPrimitiveArray(var));
                NcHelper.getVariableAttributes(var, columnAttributes(col));
            }

            //skip char FORMAT_VERSION(STRING4=4);   :comment = "File format version";

            var = nc.findVariable("HANDBOOK_VERSION");
            if (var != null) {
                col = addColumn("handbookVersion", NcHelper.getPrimitiveArray(var));
                NcHelper.getVariableAttributes(var, columnAttributes(col));
            }

            var = nc.findVariable("REFERENCE_DATE_TIME"); //"YYYYMMDDHHMISS";
            if (var != null) {
                pa = NcHelper.getPrimitiveArray(var);
                double time = Double.NaN;
                try {
                    time = Calendar2.gcToEpochSeconds(Calendar2.parseCompactDateTimeZulu(pa.getString(0)));
                } catch (Exception e) {
                    String2.log(e.getMessage()); 
                }
                col = addColumn("time", PrimitiveArray.factory(new double[] {time}));
                NcHelper.getVariableAttributes(var, columnAttributes(col));
                columnAttributes(col).set("units", Calendar2.SECONDS_SINCE_1970);
            }

            var = nc.findVariable("PLATFORM_NUMBER");
            if (var != null) {
                col = addColumn("platformNumber", NcHelper.getPrimitiveArray(var));
                NcHelper.getVariableAttributes(var, columnAttributes(col));
            }

            var = nc.findVariable("PROJECTPLATFORM_NUMBER");
            if (var != null) {
                col = addColumn("platformNumber", NcHelper.getPrimitiveArray(var));
                NcHelper.getVariableAttributes(var, columnAttributes(col));
            }
   
/*   char PROJECT_NAME(N_PROF=632, STRING64=64);
     :comment = "Name of the project";
     :_FillValue = " ";
   char PI_NAME(N_PROF=632, STRING64=64);
     :comment = "Name of the principal investigator";
     :_FillValue = " ";
   char STATION_PARAMETERS(N_PROF=632, N_PARAM=3, STRING16=16);
     :long_name = "List of available parameters for the station";
     :conventions = "Argo reference table 3";
     :_FillValue = " ";
   int CYCLE_NUMBER(N_PROF=632);
     :long_name = "Float cycle number";
     :conventions = "0..N, 0 : launch cycle (if exists), 1 : first complete cycle";
     :_FillValue = 99999; // int
   char DIRECTION(N_PROF=632);
     :long_name = "Direction of the station profiles";
     :conventions = "A: ascending profiles, D: descending profiles";
     :_FillValue = " ";
   char DATA_CENTRE(N_PROF=632, STRING2=2);
     :long_name = "Data centre in charge of float data processing";
     :conventions = "Argo reference table 4";
     :_FillValue = " ";
   char DATE_CREATION(DATE_TIME=14);
     :comment = "Date of file creation";
     :conventions = "YYYYMMDDHHMISS";
     :_FillValue = " ";
   char DATE_UPDATE(DATE_TIME=14);
     :long_name = "Date of update of this file";
     :conventions = "YYYYMMDDHHMISS";
     :_FillValue = " ";
   char DC_REFERENCE(N_PROF=632, STRING32=32);
     :long_name = "Station unique identifier in data centre";
     :conventions = "Data centre convention";
     :_FillValue = " ";
   char DATA_STATE_INDICATOR(N_PROF=632, STRING4=4);
     :long_name = "Degree of processing the data have passed through";
     :conventions = "Argo reference table 6";
     :_FillValue = " ";
   char DATA_MODE(N_PROF=632);
     :long_name = "Delayed mode or real time data";
     :conventions = "R : real time; D : delayed mode; A : real time with adjustment";
     :_FillValue = " ";
   char INST_REFERENCE(N_PROF=632, STRING64=64);
     :long_name = "Instrument type";
     :conventions = "Brand, type, serial number";
     :_FillValue = " ";
   char WMO_INST_TYPE(N_PROF=632, STRING4=4);
     :long_name = "Coded instrument type";
     :conventions = "Argo reference table 8";
     :_FillValue = " ";
   double JULD(N_PROF=632);
     :long_name = "Julian day (UTC) of the station relative to REFERENCE_DATE_TIME";
     :units = "days since 1950-01-01 00:00:00 UTC";
     :conventions = "Relative julian days with decimal part (as parts of day)";
     :_FillValue = 999999.0; // double
   char JULD_QC(N_PROF=632);
     :long_name = "Quality on Date and Time";
     :conventions = "Argo reference table 2";
     :_FillValue = " ";
   double JULD_LOCATION(N_PROF=632);
     :long_name = "Julian day (UTC) of the location relative to REFERENCE_DATE_TIME";
     :units = "days since 1950-01-01 00:00:00 UTC";
     :conventions = "Relative julian days with decimal part (as parts of day)";
     :_FillValue = 999999.0; // double
   double LATITUDE(N_PROF=632);
     :long_name = "Latitude of the station, best estimate";
     :units = "degree_north";
     :_FillValue = 99999.0; // double
     :valid_min = -90.0; // double
     :valid_max = 90.0; // double
   double LONGITUDE(N_PROF=632);
     :long_name = "Longitude of the station, best estimate";
     :units = "degree_east";
     :_FillValue = 99999.0; // double
     :valid_min = -180.0; // double
     :valid_max = 180.0; // double
   char POSITION_QC(N_PROF=632);
     :long_name = "Quality on position (latitude and longitude)";
     :conventions = "Argo reference table 2";
     :_FillValue = " ";
   char POSITIONING_SYSTEM(N_PROF=632, STRING8=8);
     :long_name = "Positioning system";
     :_FillValue = " ";
   char PROFILE_PRES_QC(N_PROF=632);
     :long_name = "Global quality flag of PRES profile";
     :conventions = "Argo reference table 2a";
     :_FillValue = " ";
   char PROFILE_TEMP_QC(N_PROF=632);
     :long_name = "Global quality flag of TEMP profile";
     :conventions = "Argo reference table 2a";
     :_FillValue = " ";
   char PROFILE_PSAL_QC(N_PROF=632);
     :long_name = "Global quality flag of PSAL profile";
     :conventions = "Argo reference table 2a";
     :_FillValue = " ";
   float PRES(N_PROF=632, N_LEVELS=71);
     :long_name = "SEA PRESSURE";
     :_FillValue = 99999.0f; // float
     :units = "decibar";
     :valid_min = 0.0f; // float
     :valid_max = 12000.0f; // float
     :comment = "In situ measurement, sea surface = 0";
     :C_format = "%7.1f";
     :FORTRAN_format = "F7.1";
     :resolution = 0.1f; // float
   char PRES_QC(N_PROF=632, N_LEVELS=71);
     :long_name = "quality flag";
     :conventions = "Argo reference table 2";
     :_FillValue = " ";
   float PRES_ADJUSTED(N_PROF=632, N_LEVELS=71);
     :long_name = "SEA PRESSURE";
     :_FillValue = 99999.0f; // float
     :units = "decibar";
     :valid_min = 0.0f; // float
     :valid_max = 12000.0f; // float
     :comment = "In situ measurement, sea surface = 0";
     :C_format = "%7.1f";
     :FORTRAN_format = "F7.1";
     :resolution = 0.1f; // float
   char PRES_ADJUSTED_QC(N_PROF=632, N_LEVELS=71);
     :long_name = "quality flag";
     :conventions = "Argo reference table 2";
     :_FillValue = " ";
   float PRES_ADJUSTED_ERROR(N_PROF=632, N_LEVELS=71);
     :long_name = "SEA PRESSURE";
     :_FillValue = 99999.0f; // float
     :units = "decibar";
     :comment = "Contains the error on the adjusted values as determined by the delayed mode QC process.";
     :C_format = "%7.1f";
     :FORTRAN_format = "F7.1";
     :resolution = 0.1f; // float
   float TEMP(N_PROF=632, N_LEVELS=71);
     :long_name = "SEA TEMPERATURE IN SITU ITS-90 SCALE";
     :_FillValue = 99999.0f; // float
     :units = "degree_Celsius";
     :valid_min = -2.0f; // float
     :valid_max = 40.0f; // float
     :comment = "In situ measurement";
     :C_format = "%9.3f";
     :FORTRAN_format = "F9.3";
     :resolution = 0.001f; // float
   char TEMP_QC(N_PROF=632, N_LEVELS=71);
     :long_name = "quality flag";
     :conventions = "Argo reference table 2";
     :_FillValue = " ";
   float TEMP_ADJUSTED(N_PROF=632, N_LEVELS=71);
     :long_name = "SEA TEMPERATURE IN SITU ITS-90 SCALE";
     :_FillValue = 99999.0f; // float
     :units = "degree_Celsius";
     :valid_min = -2.0f; // float
     :valid_max = 40.0f; // float
     :comment = "In situ measurement";
     :C_format = "%9.3f";
     :FORTRAN_format = "F9.3";
     :resolution = 0.001f; // float
   char TEMP_ADJUSTED_QC(N_PROF=632, N_LEVELS=71);
     :long_name = "quality flag";
     :conventions = "Argo reference table 2";
     :_FillValue = " ";
   float TEMP_ADJUSTED_ERROR(N_PROF=632, N_LEVELS=71);
     :long_name = "SEA TEMPERATURE IN SITU ITS-90 SCALE";
     :_FillValue = 99999.0f; // float
     :units = "degree_Celsius";
     :comment = "Contains the error on the adjusted values as determined by the delayed mode QC process.";
     :C_format = "%9.3f";
     :FORTRAN_format = "F9.3";
     :resolution = 0.001f; // float
   float PSAL(N_PROF=632, N_LEVELS=71);
     :long_name = "PRACTICAL SALINITY";
     :_FillValue = 99999.0f; // float
     :units = "psu";
     :valid_min = 0.0f; // float
     :valid_max = 42.0f; // float
     :comment = "In situ measurement";
     :C_format = "%9.3f";
     :FORTRAN_format = "F9.3";
     :resolution = 0.001f; // float
   char PSAL_QC(N_PROF=632, N_LEVELS=71);
     :long_name = "quality flag";
     :conventions = "Argo reference table 2";
     :_FillValue = " ";
   float PSAL_ADJUSTED(N_PROF=632, N_LEVELS=71);
     :long_name = "PRACTICAL SALINITY";
     :_FillValue = 99999.0f; // float
     :units = "psu";
     :valid_min = 0.0f; // float
     :valid_max = 42.0f; // float
     :comment = "In situ measurement";
     :C_format = "%9.3f";
     :FORTRAN_format = "F9.3";
     :resolution = 0.001f; // float
   char PSAL_ADJUSTED_QC(N_PROF=632, N_LEVELS=71);
     :long_name = "quality flag";
     :conventions = "Argo reference table 2";
     :_FillValue = " ";
   float PSAL_ADJUSTED_ERROR(N_PROF=632, N_LEVELS=71);
     :long_name = "PRACTICAL SALINITY";
     :_FillValue = 99999.0f; // float
     :units = "psu";
     :comment = "Contains the error on the adjusted values as determined by the delayed mode QC process.";
     :C_format = "%9.3f";
     :FORTRAN_format = "F9.3";
     :resolution = 0.001f; // float
     */

            if (reallyVerbose) msg += " finished. nColumns=" + nColumns() +
                " nRows=" + nRows() + " TIME=" + (System.currentTimeMillis() - tTime) + "ms";

        } catch (Throwable t) {
            if (!reallyVerbose) String2.log(msg); 
            throw t;

        } finally {
            nc.close();
            if (reallyVerbose) String2.log(msg);
        }
    }

    /**
     * Make a test Table.
     *
     * @param includeLongs set this to true if you want a column with longs
     * @param includeStrings set this to true if you want a column with Strings
     * @return Table
     */
    public static Table getTestTable(boolean includeLongs, boolean includeStrings) {

        String testTimes[] = {"1970-01-01T00:00:00", "2005-08-31T16:01:02", "2005-11-02T18:04:09", ""};
        Table table = new Table();
        int nRows = testTimes.length;

        //global attributes
        table.globalAttributes().set("global_att1", "a string");
        table.globalAttributes().set("global_att2", new IntArray(new int[]{1,100}));

        //add the data variables (and their attributes)
        ArrayList variableAttributes;

        //0=seconds
        double[] ad = new double[nRows];
        for (int i = 0; i < nRows; i++)
            ad[i] = Calendar2.safeIsoStringToEpochSeconds(testTimes[i]);
        int col = table.addColumn("Time", new DoubleArray(ad));
        table.columnAttributes(col).set("units", Calendar2.SECONDS_SINCE_1970);
        table.columnAttributes(col).set("time_att2", new DoubleArray(new double[]{-1e300, 1e300}));

        //1=lon
        int[] ai = {-3, -2, -1, Integer.MAX_VALUE};
        col = table.addColumn("Longitude", new IntArray(ai).setMaxIsMV(true));
        table.columnAttributes(col).set("units", "degrees_east");
        table.columnAttributes(col).set("lon_att2", new IntArray(new int[]{-2000000000, 2000000000}));

        //2=lat
        float[] af = {1, 1.5f, 2, Float.NaN};
        col = table.addColumn("Latitude", new FloatArray(af));
        table.columnAttributes(col).set("units", "degrees_north");
        table.columnAttributes(col).set("lat_att2", new FloatArray(new float[]{-1e30f, 1e30f}));

        //3=double
        ad = new double[]{-1e300, 3.123, 1e300, Double.NaN};
        col = table.addColumn("Double Data", new DoubleArray(ad));
        table.columnAttributes(col).set("units", "doubles");
        table.columnAttributes(col).set("double_att2", new DoubleArray(new double[]{-1e300, 1e300}));

        //4=long  
        if (includeLongs) {
            long[] al = {-2000000000000000L, 2, 2000000000000000L, Long.MAX_VALUE};
            col = table.addColumn("Long Data", new LongArray(al).setMaxIsMV(true));
            table.columnAttributes(col).set("units", new StringArray(new String[]{"longs"}));
            table.columnAttributes(col).set("long_att2", new LongArray(new long[]{-2000000000000000L, 2000000000000000L}));
        }

        //5=int
        ai = new int[]{-2000000000, 2, 2000000000, Integer.MAX_VALUE};
        col = table.addColumn("Int Data", new IntArray(ai).setMaxIsMV(true));
        table.columnAttributes(col).set("units", new StringArray(new String[]{"ints"}));
        table.columnAttributes(col).set("int_att2", new IntArray(new int[]{-2000000000, 2000000000}));

        //6=short
        short[] as = {(short)-32000, (short)7, (short)32000, Short.MAX_VALUE};
        col = table.addColumn("Short Data", new ShortArray(as).setMaxIsMV(true));
        table.columnAttributes(col).set("units", new StringArray(new String[]{"shorts"}));
        table.columnAttributes(col).set("short_att2", new ShortArray(new short[]{(short)-30000, (short)30000}));

        //7=byte
        byte[] ab = {(byte)-120, (byte)8, (byte)120, Byte.MAX_VALUE};
        col = table.addColumn("Byte Data", new ByteArray(ab).setMaxIsMV(true));
        table.columnAttributes(col).set("units", "bytes");
        table.columnAttributes(col).set("byte_att2", new ByteArray(new byte[]{(byte)-120, (byte)120}));

        //8=String
        if (includeStrings) {
            char[] ac = {',', '"', '\u20ac', '\uffff'};
            col = table.addColumn("Char Data", new CharArray(ac).setMaxIsMV(true));
            table.columnAttributes(col).set("units", "chars");
            table.columnAttributes(col).set("char_att2", new CharArray(new char[]{',', '"', '\u00fc', '\u20ac'}));

            String[] aS = {"a", "bb", "ccc", ""};
            col = table.addColumn("String Data", new StringArray(aS));
            table.columnAttributes(col).set("units", "Strings");
            table.columnAttributes(col).set("String_att2", new StringArray(new String[]{"a string"}));
        }

        table.ensureValid(); //throws Exception if not
        return table;
    }     

    /**
     * Test the readASCII and saveAsASCII.
     *
     * @throws Exception if trouble
     */
    public static void testASCII() throws Exception {
        //*** test read all
        String2.log("\n***** Table.testASCII  read all");
        verbose = true;
        reallyVerbose = true;

        //generate some data    
        Table table = getTestTable(true, true);
        table.removeRow(3);  //remove the empty row at the end, since readASCII will remove it

        Table table1 = getTestTable(true, true);
        table1.removeRow(3);  //remove the empty row at the end, since readASCII will remove it

        //write it to a file
        String fileName = testDir + "tempTable.asc";
        table.saveAsTabbedASCII(fileName);
        String2.log(fileName + "=\n" + String2.directReadFrom88591File(fileName));

        //read it from the file
        Table table2 = new Table();
        //debugMode = true;
        table2.readASCII(fileName);
        //debugMode = false;

        //check units on 1st data row
        Test.ensureEqual(table2.getStringData(1, 0), "degrees_east", "");
        Test.ensureEqual(table2.getStringData(2, 0), "degrees_north", "");

        //remove units row
        table2.removeRow(0);
        table2.simplify();

        //are they the same (but column types may be different)?
        Test.ensureTrue(table1.equals(table2, false), 
            "\ntable=" + table.toString() + "\ntable2=" + table2.toString());

        //test simplification: see if column types are the same as original table
        int n = table.nColumns();
        for (int col = 2; col < n; col++) //skip first 2 columns which are intentionally initially stored in bigger type
            if (col != 4  &&   //LongArray -> StringArray
                col != 8)      //CharArray -> StringArray
                Test.ensureEqual(table.columns.get(col).elementType(),
                    table2.getColumn(col).elementType(), "test type of col#" + col);
        
        //*** test read subset
        String2.log("\n***** Table.testASCII  read subset");

        //read 2nd row from the file
        table2 = new Table();
        table2.readASCII(fileName, String2.ISO_8859_1,
            "", "", 0, 1, "", 
            new String[]{"Int Data"}, new double[]{0}, new double[]{4}, 
            new String[]{"Short Data", "String Data"}, true);
        Test.ensureEqual(table2.nColumns(), 2, "");
        Test.ensureEqual(table2.nRows(), 1, "");
        Test.ensureEqual(table2.getColumnName(0), "Short Data", "");
        Test.ensureEqual(table2.getColumnName(1), "String Data", "");
        Test.ensureEqual(table2.getDoubleData(0, 0), 7, "");
        Test.ensureEqual(table2.getStringData(1, 0), "bb", "");


        //*** test read subset with no column names (otherwise same as test above)
        String2.log("\n***** Table.testASCII  read subset with no column names");
        //read 3rd row from the file
        table2 = new Table();
        table2.readASCII(fileName, String2.ISO_8859_1,
            "", "", -1, 1, "",  //-1=no column names
            new String[]{"Column#5"}, new double[]{0}, new double[]{4}, 
            new String[]{"Column#6", "Column#8", "Column#9"}, true);
        Test.ensureEqual(table2.nColumns(), 3, "");
        Test.ensureEqual(table2.nRows(), 1, "");
        Test.ensureEqual(table2.getColumnName(0), "Column#6", "");
        Test.ensureEqual(table2.getColumnName(1), "Column#8", "");
        Test.ensureEqual(table2.getColumnName(2), "Column#9", "");
        Test.ensureEqual(table2.getDoubleData(0, 0), 7, "");
        Test.ensureEqual(table2.getStringData(1, 0), "\"", "");
        Test.ensureEqual(table2.getStringData(2, 0), "bb", "");
        
        //** finally 
        File2.delete(fileName);
    }

    /**
     * Test readStandardTabbedASCII.
     *
     * @throws Exception if trouble
     */
    public static void testReadStandardTabbedASCII() throws Exception {
        //*** test read all
        String2.log("\n***** Table.testReadStandardTabbedASCII");
        verbose = true;
        reallyVerbose = true;
       
        //generate some data    
        String lines = 
            "colA\tcolB\tcolC\n" +
            "1a\t1b\t1c\n" +
            "2\n" +
              "a\t2\n" +
              "b\t2c\n" +
            "3a\t3b\t3c";  //no terminal \n
        Table table = new Table();

        //read it from lines
        table.readStandardTabbedASCII("tFileName", 
            new BufferedReader(new StringReader(lines)), null, true);
        String2.log("nRows=" + table.nRows() + " nCols=" + table.nColumns());
        Test.ensureEqual(table.dataToString(), 
            "colA,colB,colC\n" +
            "1a,1b,1c\n" +
            "2\\na,2\\nb,2c\n" +
            "3a,3b,3c\n",
            "tFileName toCSVString=\n" + table.dataToString());

        //write it to a file
        String fileName = testDir + "tempTable.asc";
        String2.writeToFile(fileName, lines);

        //read all columns from the file
        Table table2 = new Table();
        table2.readStandardTabbedASCII(fileName, null, true);
        String2.log("nRows=" + table2.nRows() + " nCols=" + table2.nColumns());
        Test.ensureEqual(table2.dataToString(), 
            "colA,colB,colC\n" +
            "1a,1b,1c\n" +
            "2\\na,2\\nb,2c\n" +
            "3a,3b,3c\n",
            "table2 toCSVString=\n" + table2.dataToString());

        //just read cols B and C from the file
        table2 = new Table();
        table2.readStandardTabbedASCII(fileName, new String[]{"colB", "colC"}, true);
        String2.log("nRows=" + table2.nRows() + " nCols=" + table2.nColumns());
        Test.ensureEqual(table2.dataToString(), 
            "colB,colC\n" +
            "1b,1c\n" +
            "2\\nb,2c\n" +
            "3b,3c\n",
            "table2 toCSVString=\n" + table2.dataToString());

        //** finally 
        File2.delete(fileName);

    }

    /**
     * Test the saveAsHtml.
     *
     * @throws Exception if trouble
     */
    public static void testHtml() throws Exception {
        String2.log("\n***** Table.testHtml");
        verbose = true;
        reallyVerbose = true;

        //generate some data    
        Table table = getTestTable(true, true);

        //write it to html file
        String fileName = testDir + "tempTable.html";
        table.saveAsHtml(fileName, "preTextHtml\n<br>\n", "postTextHtml\n<br>", 
            null, BGCOLOR, 1, true, 0, true, //needEncodingAsHtml
            false);
        //String2.log(fileName + "=\n" + String2.directReadFromUtf8File(fileName));
        SSR.displayInBrowser("file://" + fileName);

        //read it from the file
        String results = String2.directReadFromUtf8File(fileName);
        Test.ensureEqual(results, 
"<!DOCTYPE HTML>\n" +
"<html lang=\"en-US\">\n" +
"<head>\n" +
"  <title>tempTable</title>\n" +
"  <meta charset=\"UTF-8\">\n" +
"  <link href=\"https://coastwatch.pfeg.noaa.gov/erddap/images/erddap2.css\" rel=\"stylesheet\" type=\"text/css\">\n" +
"</head>\n" +
"<body>\n" +
"preTextHtml\n" +
"<br>\n" +
"<table class=\"erd nowrap\" style=\"background-color:#ffffcc;\" >\n" +
"<tr>\n" +
"<th>Time\n" +
"<th>Longitude\n" +
"<th>Latitude\n" +
"<th>Double Data\n" +
"<th>Long Data\n" +
"<th>Int Data\n" +
"<th>Short Data\n" +
"<th>Byte Data\n" +
"<th>Char Data\n" +
"<th>String Data\n" +
"</tr>\n" +
"<tr>\n" +
"<th>UTC\n" +
"<th>degrees_east\n" +
"<th>degrees_north\n" +
"<th>doubles\n" +
"<th>longs\n" +
"<th>ints\n" +
"<th>shorts\n" +
"<th>bytes\n" +
"<th>chars\n" +
"<th>Strings\n" +
"</tr>\n" +
"<tr>\n" +
"<td>1970-01-01T00:00:00Z\n" +
"<td>-3\n" +
"<td>1.0\n" +
"<td>-1.0E300\n" +
"<td>-2000000000000000\n" +
"<td>-2000000000\n" +
"<td>-32000\n" +
"<td>-120\n" +
"<td>,\n" +
"<td>a\n" +
"</tr>\n" +
"<tr>\n" +
"<td>2005-08-31T16:01:02Z\n" +
"<td>-2\n" +
"<td>1.5\n" +
"<td>3.123\n" +
"<td>2\n" +
"<td>2\n" +
"<td>7\n" +
"<td>8\n" +
"<td>&quot;\n" +
"<td>bb\n" +
"</tr>\n" +
"<tr>\n" +
"<td>2005-11-02T18:04:09Z\n" +
"<td>-1\n" +
"<td>2.0\n" +
"<td>1.0E300\n" +
"<td>2000000000000000\n" +
"<td>2000000000\n" +
"<td>32000\n" +
"<td>120\n" +
"<td>&#x20ac;\n" +
"<td>ccc\n" +
"</tr>\n" +
"<tr>\n" +
"<td>\n" +
"<td>\n" +
"<td>\n" +
"<td>\n" +
"<td>\n" +
"<td>\n" +
"<td>\n" +
"<td>\n" +
"<td>\n" +
"<td>&nbsp;\n" +
"</tr>\n" +
"</table>\n" +
"postTextHtml\n" +
"<br></body>\n" +
"</html>\n", 
            results);

        //test readHtml - treat 2nd row as data
        Table table2 = new Table();
        table2.readHtml(fileName, results, 0, 
            false, true); //secondRowHasUnits, simplify
        String csv = String2.annotatedString(table2.dataToString());
        Test.ensureEqual(csv, //so units appear here as a row of data
"Time,Longitude,Latitude,Double Data,Long Data,Int Data,Short Data,Byte Data,Char Data,String Data[10]\n" +
"UTC,degrees_east,degrees_north,doubles,longs,ints,shorts,bytes,chars,Strings[10]\n" +
"1970-01-01T00:00:00Z,-3,1.0,-1.0E300,-2000000000000000,-2000000000,-32000,-120,\",\",a[10]\n" +
"2005-08-31T16:01:02Z,-2,1.5,3.123,2,2,7,8,\"\"\"\",bb[10]\n" +
"2005-11-02T18:04:09Z,-1,2.0,1.0E300,2000000000000000,2000000000,32000,120,\\u20ac,ccc[10]\n" +
",,,,,,,,,[10]\n" +
"[end]",
            csv);

        //test readHtml - treat 2nd row as units
        table2 = new Table();
        table2.readHtml(fileName, results, 0, 
            true, true); //secondRowHasUnits, simplify
        csv = String2.annotatedString(table2.dataToString());
        Test.ensureEqual(csv, //so units correctly stored as units
"Time,Longitude,Latitude,Double Data,Long Data,Int Data,Short Data,Byte Data,Char Data,String Data[10]\n" +
"1970-01-01T00:00:00Z,-3,1.0,-1.0E300,-2000000000000000,-2000000000,-32000,-120,\",\",a[10]\n" +
"2005-08-31T16:01:02Z,-2,1.5,3.123,2,2,7,8,\"\"\"\",bb[10]\n" +
"2005-11-02T18:04:09Z,-1,2.0,1.0E300,2000000000000000,2000000000,32000,120,\\u20ac,ccc[10]\n" +
",,,,,,,,,[10]\n" +
"[end]",
            csv);
        Test.ensureEqual(table2.columnAttributes(0).getString("units"), "UTC", "");
        Test.ensureEqual(table2.columnAttributes(1).getString("units"), "degrees_east", "");
        Test.ensureEqual(table2.columnAttributes(8).getString("units"), "chars", "");
        Test.ensureEqual(table2.columnAttributes(9).getString("units"), "Strings", "");

        //** finally 
        Math2.gc(10000); //in a test.  Do something useful while browser gets going to display the file.
        File2.delete(fileName);
    }


    /**
     * This is a test of readFlatNc and saveAsFlatNc.
     *
     * @throws Exception of trouble
     */
    public static void testFlatNc() throws Exception {

        //********** test reading all data 
        String2.log("\n*** Table.testFlatNc write and then read all");
        verbose = true;
        reallyVerbose = true;

        //generate some data
        Table table = getTestTable(false, true); //falses=.nc doesn't seem to take longs
        String2.log("*******table=" + table.toString());

        //write it to a file
        String fileName = testDir + "tempTable.nc";
        table.saveAsFlatNc(fileName, "time");

        //read it from the file
        Table table2 = new Table();
        table2.readFlatNc(fileName, null, 0); //standardizeWhat=0
        String2.log("*********table2=" + table2.toString());

        //replace ' ' with '_' in column names
        for (int i = 0; i < table.columnNames.size(); i++) 
            table.columnNames.set(i, String2.replaceAll(table.columnNames.get(i), " ", "_"));

        //do the test that the tables are equal
        String2.log("testFlatNc table.nColAtt=" + table.columnAttributes.size() +  //? why columnAtt?
                            " table2.nColAtt=" + table2.columnAttributes.size());
        //except char \\u20ac becomes "?" in nc file, so reset it
        Test.ensureEqual(
            table2.columns.get(7).getString(2), "?", "");
        table2.columns.get(7).setString(2, "\u20ac");
        if (table2.columns.get(7).getString(3).equals("?"))
            table2.columns.get(7).setString(3, "");
        String t1 = table.dataToString();
        String t2 = table.dataToString();
        String2.log("\nt1=\n" + t1 + "\nt2=\n" + t2);
        Test.ensureEqual(t1, t2, "");
        Test.ensureTrue(table.equals(table2), "Test table equality");
        
        //test if data types are the same
        int n = table.nColumns();
        for (int col = 0; col < n; col++) 
            Test.ensureEqual(table.columns.get(col).elementType(),
                table2.columns.get(col).elementType(), "test type of col#" + col);

        //clean up
        table2.clear();
        File2.delete(fileName);


        //***test unpack options     (and global and variable attributes)
        String2.log("\n*** Table.testFlatNc test unpack");
        //row of data from 41015h1993.txt
        //YY MM DD hh WD   WSPD GST  WVHT  DPD   APD  MWD  BAR    ATMP  WTMP  DEWP  VIS
        //93 05 24 11 194 02.5 02.8 00.70 04.20 04.90 185 1021.2  17.3  16.4 999.0 18.5   
        double seconds = Calendar2.isoStringToEpochSeconds("1993-05-24T11");
        String2.log("seconds=" + seconds);
        int[] testColumns = {0};
        double testMin[] = {seconds};
        double testMax[] = {seconds};

        //don't unpack
        table.readFlatNc(testDir + "41015.nc", new String[]{"time", "BAR"}, 0); //standardizeWhat=0
        //String2.log(table.toString(100));
        table.subset(testColumns, testMin, testMax);
        Test.ensureEqual(table.nColumns(), 2, "");
        Test.ensureEqual(table.nRows(), 1, "");
        Test.ensureEqual(table.getColumnName(0), "time", "");
        Test.ensureEqual(table.getColumnName(1), "BAR", "");
        Test.ensureEqual(table.getColumn(1).elementType(), PAType.SHORT, ""); //short
        Test.ensureEqual(table.getDoubleData(0, 0), seconds, "");
        Test.ensureEqual(table.getDoubleData(1, 0), 10212, "");

        //test global and variable attributes 
        Test.ensureEqual(table.globalAttributes().getString("creator_name"), "NOAA National Data Buoy Center", "");
        Test.ensureEqual(table.columnAttributes(1).getString("long_name"), "Sea Level Pressure", "");

        //unpack,  to float if that is recommended
        table.readFlatNc(testDir + "41015.nc", new String[]{"time", "BAR"}, 1); //standardizeWhat=1
        table.subset(testColumns, testMin, testMax);
        Test.ensureEqual(table.nColumns(), 2, "");
        Test.ensureEqual(table.nRows(), 1, "");
        Test.ensureEqual(table.getColumnName(0), "time", "");
        Test.ensureEqual(table.getColumnName(1), "BAR", "");
        Test.ensureEqual(table.getColumn(1).elementType(), PAType.FLOAT, ""); //float
        Test.ensureEqual(table.getDoubleData(0, 0), seconds, "");
        Test.ensureEqual(table.getFloatData(1, 0), 1021.2f, "");


        //********** test reading subset of data  via bitset (which uses read via firstrow/lastrow)
        String2.log("\n*** Table.testFlatNc read subset");
        table.clear();
        NetcdfFile netcdfFile = NcHelper.openFile(testDir + "41015.nc");
        try {
            Variable loadVariables[] = NcHelper.findVariables(netcdfFile, new String[]{"time", "BAR"});
            Variable testVariables[] = NcHelper.findVariables(netcdfFile, new String[]{"time"});
            BitSet okRows = NcHelper.testRows(testVariables, testMin, testMax); 
            table.appendNcRows(loadVariables, okRows);
            Test.ensureEqual(okRows.cardinality(), 1, "");
        } finally {
            try {
                netcdfFile.close(); //make sure it is explicitly closed
            } catch (Exception e) {
            }
        }

        Test.ensureEqual(table.nColumns(), 2, "");
        Test.ensureEqual(table.nRows(), 1, "");
        Test.ensureEqual(table.getColumnName(0), "time", "");
        Test.ensureEqual(table.getColumnName(1), "BAR", "");
        Test.ensureEqual(table.getColumn(1).elementType(), PAType.SHORT, ""); //short
        Test.ensureEqual(table.getDoubleData(0, 0), seconds, "");
        Test.ensureEqual(table.getDoubleData(1, 0), 10212, ""); //still packed

    }

    /**
     * This is a test of read4DNc and saveAs4DNc.
     *
     * @throws Exception of trouble
     */
    public static void test4DNc() throws Exception {

        //********** test reading all data 
        String2.log("\n*** Table.test4DNc write and then read all");
        verbose = true;
        reallyVerbose = true;

        //generate some data
        Table table = new Table();
        DoubleArray xCol = new DoubleArray();
        DoubleArray yCol = new DoubleArray();
        DoubleArray zCol = new DoubleArray();
        DoubleArray tCol = new DoubleArray();
        IntArray    data1Col = new IntArray();
        DoubleArray data2Col = new DoubleArray();
        StringArray data3Col = new StringArray();
        table.addColumn("X", xCol);
        table.addColumn("Y", yCol);
        table.addColumn("Z", zCol);
        table.addColumn("T", tCol);
        table.addColumn("data1", data1Col);
        table.addColumn("data2", data2Col);
        table.addColumn("data3", data3Col);
        for (int t = 0; t < 2; t++) {
            for (int z = 0; z < 3; z++) {
                for (int y = 0; y < 3; y++) {
                    for (int x = 0; x < 4; x++) {
                        xCol.add(x+1);
                        yCol.add(y+1);
                        zCol.add(z+1);
                        tCol.add(t+1);
                        int fac = (x+1)*(y+1)*(z+1)*(t+1);
                        data1Col.add(fac);
                        data2Col.add(100+ (x+1)*(y+1)*(z+1)*(t+1));
                        data3Col.add("" + fac);
                    }
                }
            }
        }
        table.ensureValid(); //throws Exception if not
        //String2.log(table.toString("obs", 10));

        //write it to a file
        String fileName = testDir + "temp4DTable.nc";
        Attributes idAttributes = new Attributes();
        idAttributes.set("long_name", "The station's name.");
        idAttributes.set("units", DataHelper.UNITLESS);
        String stringVariableValue = "My Id Value";
        table.saveAs4DNc(fileName, 0,1,2,3, "ID", stringVariableValue, idAttributes);

        //then insert col 4 filled with "My Id Value"
        String sar[] = new String[table.nRows()];
        Arrays.fill(sar, stringVariableValue);
        table.addColumn(4, "ID", new StringArray(sar), idAttributes);

        //get the header
        //String2.log("table=" + String2.log(NcHelper.ncdump(fileName, "-h")));

        //read from file
        Table table2 = new Table();
        table2.read4DNc(fileName, null, 1, "ID", 4); //standarizeWhat=1
        //String2.log("col6=" + table2.getColumn(6));
        //String2.log("\ntable2 after read4DNc: " + table2.toString("obs", 1000000));
         
        //test equality
        Test.ensureTrue(table.equals(table2), "test4DNc tables not equal!");

        File2.delete(fileName);

    }


    /**
     * This is a test of readOpendapSequence.
     * Test cases from Roy:
     * GLOBEC VPT:
     * stn_id=loaddods('https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_vpt?stn_id&unique()');
     * abund=loaddods('-F','https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_vpt?abund_m3&stn_id="NH05"');
     * GLOBEC Bottle:
     * month=loaddods('-F','https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_bottle?month&unique()');
     * [oxy temp]=loaddods('-F','https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_bottle?t0,oxygen&month="5"');
     * GLOBEC MOC1:
     * [abund,lon,lat]=loaddods('-F','https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_MOC1?abund_m3,lat,long');
     * [abund1,lon1,lat1]=loaddods('-F','https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_MOC1?abund_m3,lat,long&program="MESO_1"');
     * I note that loaddods documentation is at https://www.opendap.org/user/mgui-html/mgui_36.html
     * and -F says to convert all strings to floats.
     * "unique()" seems to just return unique values.
     *
     * @throws Exception of trouble
     */
    public static void testOpendapSequence() throws Exception {

        //2013-03-18 I changed from oceanwatch datasets (no longer available) to coastwatch erddap datasets
        String2.log("\n*** Table.testOpendapSequence");
        verbose = true;
        reallyVerbose = true;
        Table table = new Table();
        int nRows;
        String url;
        float lon, lat;
        String results, expected;

        //2016-07-25 test for Kevin's dataset: from remote erddap
        url = "https://ferret.pmel.noaa.gov/pmel/erddap/tabledap/ChukchiSea_454a_037a_fcf4?" +
            "prof,id,cast,cruise,time,longitude,lon360,latitude&time%3E=2012-09-04&time%3C=2012-09-07&distinct()"; 
        table.readOpendapSequence(url, false); //boolean: skipDapSpacerRows
        results = table.toString(3);
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 2 ;\n" +
"\tid_strlen = 10 ;\n" +
"\tcast_strlen = 3 ;\n" +
"\tcruise_strlen = 6 ;\n" +
"variables:\n" +
"\tdouble prof(row) ;\n" +
"\t\tprof:actual_range = 1.0, 1.0 ;\n" +
"\t\tprof:axis = \"E\" ;\n" +
"\t\tprof:long_name = \"Prof\" ;\n" +
"\t\tprof:point_spacing = \"even\" ;\n" +
"\tchar id(row, id_strlen) ;\n" +
"\t\tid:cf_role = \"profile_id\" ;\n" +
"\t\tid:long_name = \"profile id\" ;\n" +
"\tchar cast(row, cast_strlen) ;\n" +
"\t\tcast:colorBarMaximum = 100.0 ;\n" +
"\t\tcast:colorBarMinimum = 0.0 ;\n" +
"\t\tcast:long_name = \"cast number\" ;\n" +
"\tchar cruise(row, cruise_strlen) ;\n" +
"\t\tcruise:long_name = \"Cruise name\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:_CoordinateAxisType = \"Time\" ;\n" +
"\t\ttime:actual_range = 1.28368572E9, 1.34697582E9 ;\n" +
"\t\ttime:axis = \"T\" ;\n" +
"\t\ttime:ioos_category = \"Time\" ;\n" +
"\t\ttime:long_name = \"Time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:time_origin = \"01-JAN-1970 00:00:00\" ;\n" +
"\t\ttime:units = \"seconds since 1970-01-01T00:00:00Z\" ;\n" +
"\tfloat longitude(row) ;\n" +
"\t\tlongitude:_CoordinateAxisType = \"Lon\" ;\n" +
"\t\tlongitude:_FillValue = -1.0E34f ;\n" +
"\t\tlongitude:actual_range = -174.6603f, -157.1593f ;\n" +
"\t\tlongitude:axis = \"X\" ;\n" +
"\t\tlongitude:colorBarMaximum = 180.0 ;\n" +
"\t\tlongitude:colorBarMinimum = -180.0 ;\n" +
"\t\tlongitude:ioos_category = \"Location\" ;\n" +
"\t\tlongitude:long_name = \"station longitude\" ;\n" +
"\t\tlongitude:missing_value = -1.0E34f ;\n" +
"\t\tlongitude:standard_name = \"longitude\" ;\n" +
"\t\tlongitude:units = \"degrees_east\" ;\n" +
"\tfloat lon360(row) ;\n" +
"\t\tlon360:_FillValue = -1.0E34f ;\n" +
"\t\tlon360:actual_range = 185.3397f, 202.8407f ;\n" +
"\t\tlon360:colorBarMaximum = 180.0 ;\n" +
"\t\tlon360:colorBarMinimum = -180.0 ;\n" +
"\t\tlon360:long_name = \"station longitude 360\" ;\n" +
"\t\tlon360:missing_value = -1.0E34f ;\n" +
"\t\tlon360:standard_name = \"longitude\" ;\n" +
"\t\tlon360:units = \"degrees_east\" ;\n" +
"\tfloat latitude(row) ;\n" +
"\t\tlatitude:_CoordinateAxisType = \"Lat\" ;\n" +
"\t\tlatitude:_FillValue = -1.0E34f ;\n" +
"\t\tlatitude:actual_range = 54.34184f, 73.11517f ;\n" +
"\t\tlatitude:axis = \"Y\" ;\n" +
"\t\tlatitude:colorBarMaximum = 90.0 ;\n" +
"\t\tlatitude:colorBarMinimum = -90.0 ;\n" +
"\t\tlatitude:history = \"From mb1101c070.nc_copy\" ;\n" +
"\t\tlatitude:ioos_category = \"Location\" ;\n" +
"\t\tlatitude:long_name = \"station latitude\" ;\n" +
"\t\tlatitude:missing_value = -1.0E34f ;\n" +
"\t\tlatitude:standard_name = \"latitude\" ;\n" +
"\t\tlatitude:units = \"degrees_north\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:CAST = \"070\" ;\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"prof, id, cast, cruise, time, longitude, lon360, latitude\" ;\n" +
"\t\t:Conventions = \"CF-1.6, COARDS, ACDD-1.3\" ;\n" +
"\t\t:COORD_SYSTEM = \"GEOGRAPHICAL\" ;\n" +
"\t\t:creation_date = \"14:48 21-JUN-2013\" ;\n" +
"\t\t:creator_email = \"peggy.sullivan@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Phyllis Stabeno, Margaret Sullivan\" ;\n" +
"\t\t:CRUISE = \"Ch2011\" ;\n" +
"\t\t:DATA_CMNT = \"Data from Seasoft File chaoz2011070.cnv\" ;\n" +
"\t\t:DATA_TYPE = \"CTD\" ;\n" +
"\t\t:Easternmost_Easting = -157.1593 ;\n" +
"\t\t:EPIC_FILE_GENERATOR = \"SEASOFT2EPIC_CTD (Version 1.37, 14-Oct-2011)\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 73.11517 ;\n" +
"\t\t:geospatial_lat_min = 54.34184 ;\n" +
"\t\t:geospatial_lat_units = \"degrees_north\" ;\n" +
"\t\t:geospatial_lon_max = -157.1593 ;\n" +
"\t\t:geospatial_lon_min = -174.6603 ;\n" +
"\t\t:geospatial_lon_units = \"degrees_east\" ;\n" +
"\t\t:geospatial_vertical_max = 166.0 ;\n" +
"\t\t:geospatial_vertical_min = 0.0 ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"m\" ;\n" +
"\t\t:history = \"FERRET V7  13-Jun-16\n";
//2016-10-03T22:25:01Z (local files)
//2016-10-03T22:25:01Z 
Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);
  
expected = 
"https://ferret.pmel.noaa.gov/pmel/erddap/tabledap/ChukchiSea_454a_037a_fcf4.das\" ;\n" +
"\t\t:infoUrl = \"www.ecofoci.noaa.gov\" ;\n" +
"\t\t:INST_TYPE = \"Sea-Bird CTD SBE911\" ;\n" +
"\t\t:institution = \"PMEL EcoFOCI\" ;\n" +
"\t\t:keywords = \"2010-2012, active, ammonia, ammonium, bottle, calibration, cast, chemistry, chlorophyll, chukchi, concentration, concentration_of_chlorophyll_in_sea_water, cooperative, cruise, data, density, depth, dissolved, Earth Science > Oceans > Ocean Chemistry > Ammonia, Earth Science > Oceans > Ocean Chemistry > Chlorophyll, Earth Science > Oceans > Ocean Chemistry > Nitrate, Earth Science > Oceans > Ocean Chemistry > Oxygen, Earth Science > Oceans > Ocean Chemistry > Phosphate, Earth Science > Oceans > Ocean Chemistry > Silicate, Earth Science > Oceans > Salinity/Density > Salinity, ecofoci, environmental, factory, fisheries, fisheries-oceanography, flourescence, foci, fraction, fractional, fractional_saturation_of_oxygen_in_sea_water, investigations, laboratory, latitude, lon360, longitude, marine, ml/l, mmoles, mmoles/kg, mole, mole_concentration_of_ammonium_in_sea_water, mole_concentration_of_dissolved_molecular_oxygen_in_sea_water, mole_concentration_of_nitrate_in_sea_water, mole_concentration_of_nitrite_in_sea_water, mole_concentration_of_phosphate_in_sea_water, mole_concentration_of_silicate_in_sea_water, molecular, n02, name, nh4, niskin, nitrate, nitrite, no2, no3, noaa, number, nutrients, O2, ocean, ocean_chlorophyll_a_concentration_factoryCal, ocean_chlorophyll_fluorescence_raw, ocean_dissolved_oxygen_concentration_1_mLperL, ocean_dissolved_oxygen_concentration_1_mMperkg, ocean_dissolved_oxygen_concentration_2_mLperL, ocean_dissolved_oxygen_concentration_2_mMperkg, ocean_oxygen_saturation_1, ocean_practical_salinity_1, ocean_practical_salinity_2, ocean_sigma_t, ocean_temperature_1, ocean_temperature_2, oceanography, oceans, oxygen, pacific, percent, phosphate, photosynthetically, photosynthetically_active_radiation, pmel, po4, practical, prof, profile, pss, pss-78, psu, radiation, raw, salinity, saturation, scale, sea, sea_water_ammonium_concentration, sea_water_nitrate_concentration, sea_water_nitrite_concentration, sea_water_nutrient_bottle_number, sea_water_phosphate_concentration, sea_water_practical_salinity, sea_water_silicate_concentration, seawater, sigma, sigma-t, silicate, station, temperature, time, unit, volume, volume_fraction_of_oxygen_in_sea_water, water\" ;\n" +
"\t\t:keywords_vocabulary = \"GCMD Science Keywords\" ;\n" +
"\t\t:license = \"The data may be used and redistributed for free but is not intended\n" +
"for legal use, since it may contain inaccuracies. Neither the data\n" +
"Contributor, ERD, NOAA, nor the United States Government, nor any\n" +
"of their employees or contractors, makes any warranty, express or\n" +
"implied, including warranties of merchantability and fitness for a\n" +
"particular purpose, or assumes any legal liability for the accuracy,\n" +
"completeness, or usefulness, of this information.\" ;\n" +
"\t\t:Northernmost_Northing = 73.11517 ;\n" +
"\t\t:PROG_CMNT1 = \"cat_ctd v1.36 06Aug2010\" ;\n" +
"\t\t:PROG_CMNT2 = \"Variables Extrapolated from 2 db to 0\" ;\n" +
"\t\t:sourceUrl = \"(local files)\" ;\n" +
"\t\t:Southernmost_Northing = 54.34184 ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v29\" ;\n" +
"\t\t:STATION_NAME = \"Unimak3\" ;\n" +
"\t\t:subsetVariables = \"prof, id, cast, cruise, time, longitude, lon360, latitude\" ;\n" +
"\t\t:summary = \"Pacific Marine Environmental Laboratory (PMEL) Fisheries-Oceanography Cooperative Investigations (FOCI) Chukchi Sea. PMEL EcoFOCI data from a local source.\" ;\n" +
"\t\t:time_coverage_end = \"2012-09-06T23:57:00Z\" ;\n" +
"\t\t:time_coverage_start = \"2010-09-05T11:22:00Z\" ;\n" +
"\t\t:title = \"PMEL EcoFOCI Chukchi Sea profile data, 2010-2012\" ;\n" +
"\t\t:WATER_DEPTH = 0 ;\n" +
"\t\t:WATER_MASS = \"A\" ;\n" +
"\t\t:Westernmost_Easting = -174.6603 ;\n" +
"}\n" +
"prof,id,cast,cruise,time,longitude,lon360,latitude\n" +
"1.0,aq1201c069,069,aq1201,1.34697456E9,-164.0447,195.9553,56.866\n" +
"1.0,aq1201c070,070,aq1201,1.34697582E9,-164.049,195.951,56.864\n";
        int po = results.indexOf(expected.substring(0, 60));
        Test.ensureEqual(results.substring(Math.max(0, po)), expected, "results=\n" + results);

        url = "https://ferret.pmel.noaa.gov/pmel/erddap/tabledap/ChukchiSea_454a_037a_fcf4?" +
            "prof,id,cast,cruise,time,longitude,lon360,latitude&time%3E=2012-09-04&time%3C=2012-09-07"; 
        table.readOpendapSequence(url, false); //boolean: skipDapSpacerRows
        results = table.toString(3);
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 2 ;\n" +
"\tid_strlen = 10 ;\n" +
"\tcast_strlen = 3 ;\n" +
"\tcruise_strlen = 6 ;\n" +
"variables:\n" +
"\tdouble prof(row) ;\n" +
"\t\tprof:actual_range = 1.0, 1.0 ;\n" +
"\t\tprof:axis = \"E\" ;\n" +
"\t\tprof:long_name = \"Prof\" ;\n" +
"\t\tprof:point_spacing = \"even\" ;\n" +
"\tchar id(row, id_strlen) ;\n" +
"\t\tid:cf_role = \"profile_id\" ;\n" +
"\t\tid:long_name = \"profile id\" ;\n" +
"\tchar cast(row, cast_strlen) ;\n" +
"\t\tcast:colorBarMaximum = 100.0 ;\n" +
"\t\tcast:colorBarMinimum = 0.0 ;\n" +
"\t\tcast:long_name = \"cast number\" ;\n" +
"\tchar cruise(row, cruise_strlen) ;\n" +
"\t\tcruise:long_name = \"Cruise name\" ;\n" +
"\tdouble time(row) ;\n" +
"\t\ttime:_CoordinateAxisType = \"Time\" ;\n" +
"\t\ttime:actual_range = 1.28368572E9, 1.34697582E9 ;\n" +
"\t\ttime:axis = \"T\" ;\n" +
"\t\ttime:ioos_category = \"Time\" ;\n" +
"\t\ttime:long_name = \"Time\" ;\n" +
"\t\ttime:standard_name = \"time\" ;\n" +
"\t\ttime:time_origin = \"01-JAN-1970 00:00:00\" ;\n" +
"\t\ttime:units = \"seconds since 1970-01-01T00:00:00Z\" ;\n" +
"\tfloat longitude(row) ;\n" +
"\t\tlongitude:_CoordinateAxisType = \"Lon\" ;\n" +
"\t\tlongitude:_FillValue = -1.0E34f ;\n" +
"\t\tlongitude:actual_range = -174.6603f, -157.1593f ;\n" +
"\t\tlongitude:axis = \"X\" ;\n" +
"\t\tlongitude:colorBarMaximum = 180.0 ;\n" +
"\t\tlongitude:colorBarMinimum = -180.0 ;\n" +
"\t\tlongitude:ioos_category = \"Location\" ;\n" +
"\t\tlongitude:long_name = \"station longitude\" ;\n" +
"\t\tlongitude:missing_value = -1.0E34f ;\n" +
"\t\tlongitude:standard_name = \"longitude\" ;\n" +
"\t\tlongitude:units = \"degrees_east\" ;\n" +
"\tfloat lon360(row) ;\n" +
"\t\tlon360:_FillValue = -1.0E34f ;\n" +
"\t\tlon360:actual_range = 185.3397f, 202.8407f ;\n" +
"\t\tlon360:colorBarMaximum = 180.0 ;\n" +
"\t\tlon360:colorBarMinimum = -180.0 ;\n" +
"\t\tlon360:long_name = \"station longitude 360\" ;\n" +
"\t\tlon360:missing_value = -1.0E34f ;\n" +
"\t\tlon360:standard_name = \"longitude\" ;\n" +
"\t\tlon360:units = \"degrees_east\" ;\n" +
"\tfloat latitude(row) ;\n" +
"\t\tlatitude:_CoordinateAxisType = \"Lat\" ;\n" +
"\t\tlatitude:_FillValue = -1.0E34f ;\n" +
"\t\tlatitude:actual_range = 54.34184f, 73.11517f ;\n" +
"\t\tlatitude:axis = \"Y\" ;\n" +
"\t\tlatitude:colorBarMaximum = 90.0 ;\n" +
"\t\tlatitude:colorBarMinimum = -90.0 ;\n" +
"\t\tlatitude:history = \"From mb1101c070.nc_copy\" ;\n" +
"\t\tlatitude:ioos_category = \"Location\" ;\n" +
"\t\tlatitude:long_name = \"station latitude\" ;\n" +
"\t\tlatitude:missing_value = -1.0E34f ;\n" +
"\t\tlatitude:standard_name = \"latitude\" ;\n" +
"\t\tlatitude:units = \"degrees_north\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:CAST = \"070\" ;\n" +
"\t\t:cdm_data_type = \"Profile\" ;\n" +
"\t\t:cdm_profile_variables = \"prof, id, cast, cruise, time, longitude, lon360, latitude\" ;\n" +
"\t\t:Conventions = \"CF-1.6, COARDS, ACDD-1.3\" ;\n" +
"\t\t:COORD_SYSTEM = \"GEOGRAPHICAL\" ;\n" +
"\t\t:creation_date = \"14:48 21-JUN-2013\" ;\n" +
"\t\t:creator_email = \"peggy.sullivan@noaa.gov\" ;\n" +
"\t\t:creator_name = \"Phyllis Stabeno, Margaret Sullivan\" ;\n" +
"\t\t:CRUISE = \"Ch2011\" ;\n" +
"\t\t:DATA_CMNT = \"Data from Seasoft File chaoz2011070.cnv\" ;\n" +
"\t\t:DATA_TYPE = \"CTD\" ;\n" +
"\t\t:Easternmost_Easting = -157.1593 ;\n" +
"\t\t:EPIC_FILE_GENERATOR = \"SEASOFT2EPIC_CTD (Version 1.37, 14-Oct-2011)\" ;\n" +
"\t\t:featureType = \"Profile\" ;\n" +
"\t\t:geospatial_lat_max = 73.11517 ;\n" +
"\t\t:geospatial_lat_min = 54.34184 ;\n" +
"\t\t:geospatial_lat_units = \"degrees_north\" ;\n" +
"\t\t:geospatial_lon_max = -157.1593 ;\n" +
"\t\t:geospatial_lon_min = -174.6603 ;\n" +
"\t\t:geospatial_lon_units = \"degrees_east\" ;\n" +
"\t\t:geospatial_vertical_max = 166.0 ;\n" +
"\t\t:geospatial_vertical_min = 0.0 ;\n" +
"\t\t:geospatial_vertical_positive = \"down\" ;\n" +
"\t\t:geospatial_vertical_units = \"m\" ;\n" +
"\t\t:history = \"FERRET V7  13-Jun-16\n";
//2016-10-03T22:32:26Z (local files)
//2016-10-03T22:32:26Z 
        Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);


expected = 
"https://ferret.pmel.noaa.gov/pmel/erddap/tabledap/ChukchiSea_454a_037a_fcf4.das\" ;\n" +
"\t\t:infoUrl = \"www.ecofoci.noaa.gov\" ;\n" +
"\t\t:INST_TYPE = \"Sea-Bird CTD SBE911\" ;\n" +
"\t\t:institution = \"PMEL EcoFOCI\" ;\n" +
"\t\t:keywords = \"2010-2012, active, ammonia, ammonium, bottle, calibration, cast, chemistry, chlorophyll, chukchi, concentration, concentration_of_chlorophyll_in_sea_water, cooperative, cruise, data, density, depth, dissolved, Earth Science > Oceans > Ocean Chemistry > Ammonia, Earth Science > Oceans > Ocean Chemistry > Chlorophyll, Earth Science > Oceans > Ocean Chemistry > Nitrate, Earth Science > Oceans > Ocean Chemistry > Oxygen, Earth Science > Oceans > Ocean Chemistry > Phosphate, Earth Science > Oceans > Ocean Chemistry > Silicate, Earth Science > Oceans > Salinity/Density > Salinity, ecofoci, environmental, factory, fisheries, fisheries-oceanography, flourescence, foci, fraction, fractional, fractional_saturation_of_oxygen_in_sea_water, investigations, laboratory, latitude, lon360, longitude, marine, ml/l, mmoles, mmoles/kg, mole, mole_concentration_of_ammonium_in_sea_water, mole_concentration_of_dissolved_molecular_oxygen_in_sea_water, mole_concentration_of_nitrate_in_sea_water, mole_concentration_of_nitrite_in_sea_water, mole_concentration_of_phosphate_in_sea_water, mole_concentration_of_silicate_in_sea_water, molecular, n02, name, nh4, niskin, nitrate, nitrite, no2, no3, noaa, number, nutrients, O2, ocean, ocean_chlorophyll_a_concentration_factoryCal, ocean_chlorophyll_fluorescence_raw, ocean_dissolved_oxygen_concentration_1_mLperL, ocean_dissolved_oxygen_concentration_1_mMperkg, ocean_dissolved_oxygen_concentration_2_mLperL, ocean_dissolved_oxygen_concentration_2_mMperkg, ocean_oxygen_saturation_1, ocean_practical_salinity_1, ocean_practical_salinity_2, ocean_sigma_t, ocean_temperature_1, ocean_temperature_2, oceanography, oceans, oxygen, pacific, percent, phosphate, photosynthetically, photosynthetically_active_radiation, pmel, po4, practical, prof, profile, pss, pss-78, psu, radiation, raw, salinity, saturation, scale, sea, sea_water_ammonium_concentration, sea_water_nitrate_concentration, sea_water_nitrite_concentration, sea_water_nutrient_bottle_number, sea_water_phosphate_concentration, sea_water_practical_salinity, sea_water_silicate_concentration, seawater, sigma, sigma-t, silicate, station, temperature, time, unit, volume, volume_fraction_of_oxygen_in_sea_water, water\" ;\n" +
"\t\t:keywords_vocabulary = \"GCMD Science Keywords\" ;\n" +
"\t\t:license = \"The data may be used and redistributed for free but is not intended\n" +
"for legal use, since it may contain inaccuracies. Neither the data\n" +
"Contributor, ERD, NOAA, nor the United States Government, nor any\n" +
"of their employees or contractors, makes any warranty, express or\n" +
"implied, including warranties of merchantability and fitness for a\n" +
"particular purpose, or assumes any legal liability for the accuracy,\n" +
"completeness, or usefulness, of this information.\" ;\n" +
"\t\t:Northernmost_Northing = 73.11517 ;\n" +
"\t\t:PROG_CMNT1 = \"cat_ctd v1.36 06Aug2010\" ;\n" +
"\t\t:PROG_CMNT2 = \"Variables Extrapolated from 2 db to 0\" ;\n" +
"\t\t:sourceUrl = \"(local files)\" ;\n" +
"\t\t:Southernmost_Northing = 54.34184 ;\n" +
"\t\t:standard_name_vocabulary = \"CF Standard Name Table v29\" ;\n" +
"\t\t:STATION_NAME = \"Unimak3\" ;\n" +
"\t\t:subsetVariables = \"prof, id, cast, cruise, time, longitude, lon360, latitude\" ;\n" +
"\t\t:summary = \"Pacific Marine Environmental Laboratory (PMEL) Fisheries-Oceanography Cooperative Investigations (FOCI) Chukchi Sea. PMEL EcoFOCI data from a local source.\" ;\n" +
"\t\t:time_coverage_end = \"2012-09-06T23:57:00Z\" ;\n" +
"\t\t:time_coverage_start = \"2010-09-05T11:22:00Z\" ;\n" +
"\t\t:title = \"PMEL EcoFOCI Chukchi Sea profile data, 2010-2012\" ;\n" +
"\t\t:WATER_DEPTH = 0 ;\n" +
"\t\t:WATER_MASS = \"A\" ;\n" +
"\t\t:Westernmost_Easting = -174.6603 ;\n" +
"}\n" +
"prof,id,cast,cruise,time,longitude,lon360,latitude\n" +
"1.0,aq1201c069,069,aq1201,1.34697456E9,-164.0447,195.9553,56.866\n" +
"1.0,aq1201c070,070,aq1201,1.34697582E9,-164.049,195.951,56.864\n";
        po = results.indexOf(expected.substring(0, 60));
        Test.ensureEqual(results.substring(Math.max(0, po)), expected, "results=\n" + results);


        //************* SINGLE SEQUENCE *****************************
        //read data from opendap
        table.readOpendapSequence(
            "https://coastwatch.pfeg.noaa.gov/erddap/tabledap/erdGlobecMoc1?abund_m3,latitude,longitude", false);
        results = table.toString(5);
        String2.log(results);

        nRows = 3763; //2013-0620 was 3779;
        Test.ensureEqual(table.nColumns(), 3, "");
        Test.ensureEqual(table.nRows(), nRows, "");

        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 3763 ;\n" +
"variables:\n" +
"\tfloat abund_m3(row) ;\n" +
"\t\tabund_m3:_FillValue = -9999999.0f ;\n" +
"\t\tabund_m3:actual_range = 0.0f, 9852.982f ;\n" +
"\t\tabund_m3:colorBarMaximum = 1000.0 ;\n" +
"\t\tabund_m3:colorBarMinimum = 0.0 ;\n" +
"\t\tabund_m3:comment = \"Density [individuals per m3]\" ;\n" +
"\t\tabund_m3:ioos_category = \"Other\" ;\n" +
"\t\tabund_m3:long_name = \"Abundance\" ;\n" +
"\t\tabund_m3:missing_value = -9999999.0f ;\n" +
"\t\tabund_m3:units = \"count m-3\" ;\n" +
"\tfloat latitude(row) ;\n" +
"\t\tlatitude:_CoordinateAxisType = \"Lat\" ;\n" +
"\t\tlatitude:_FillValue = 214748.36f ;\n" +
"\t\tlatitude:actual_range = 42.4733f, 44.6517f ;\n" +
"\t\tlatitude:axis = \"Y\" ;\n" +
"\t\tlatitude:ioos_category = \"Location\" ;\n" +
"\t\tlatitude:long_name = \"Latitude\" ;\n" +
"\t\tlatitude:missing_value = 214748.36f ;\n" +
"\t\tlatitude:standard_name = \"latitude\" ;\n" +
"\t\tlatitude:units = \"degrees_north\" ;\n" +
"\tfloat longitude(row) ;\n" +
"\t\tlongitude:_CoordinateAxisType = \"Lon\" ;\n" +
"\t\tlongitude:_FillValue = 214748.36f ;\n" +
"\t\tlongitude:actual_range = -125.1167f, -124.175f ;\n" +
"\t\tlongitude:axis = \"X\" ;\n" +
"\t\tlongitude:ioos_category = \"Location\" ;\n" +
"\t\tlongitude:long_name = \"Longitude\" ;\n" +
"\t\tlongitude:missing_value = 214748.36f ;\n" +
"\t\tlongitude:standard_name = \"longitude\" ;\n" +
"\t\tlongitude:units = \"degrees_east\" ;\n" +
"\n" +
"// global attributes:\n" +
"\t\t:cdm_data_type = \"Trajectory\" ;\n" +
"\t\t:cdm_trajectory_variables = \"cruise_id\" ;\n" +
"\t\t:Conventions = \"COARDS, CF-1.6, ACDD-1.3\" ;\n" +
"\t\t:Easternmost_Easting = -124.175 ;\n" +
"\t\t:featureType = \"Trajectory\" ;\n" +
"\t\t:geospatial_lat_max = 44.6517 ;\n" +
"\t\t:geospatial_lat_min = 42.4733 ;\n" +
"\t\t:geospatial_lat_units = \"degrees_north\" ;\n" +
"\t\t:geospatial_lon_max = -124.175 ;\n" +
"\t\t:geospatial_lon_min = -125.1167 ;\n" +
"\t\t:geospatial_lon_units = \"degrees_east\" ;\n";
        Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);

        expected =
"\t\t:time_coverage_end = \"2002-05-30T15:22:00Z\" ;\n" +
"\t\t:time_coverage_start = \"2000-04-12T04:00:00Z\" ;\n" +
"\t\t:title = \"GLOBEC NEP MOCNESS Plankton (MOC1) Data, 2000-2002\" ;\n" +
"\t\t:Westernmost_Easting = -125.1167 ;\n" +
"}\n" +
//"    Row        abund_m3       latitude      longitude\n" +
//"      0     3.698225E-3      44.651699    -124.650002\n" +  2013-06-20 was
//"      1      7.26257E-2      44.651699    -124.650002\n" +
//"      2     1.100231E-3      42.504601    -125.011299\n" +
//"      3     7.889546E-2      42.501801    -124.705803\n" +
//"      4        3.416457        42.5033    -124.845001\n";
"abund_m3,latitude,longitude\n" +
"0.003688676,44.6517,-124.65\n" +
"0.003688676,44.6517,-124.65\n" +
"0.011066027,44.6517,-124.65\n" +
"0.014754703,44.6517,-124.65\n" +
"0.014754703,44.6517,-124.65\n" +
"...\n";
        po = results.indexOf(expected.substring(0, 19));
        Test.ensureEqual(results.substring(Math.max(po, 0)), expected, "results=\n" + results);
/* on oceanwatch, was          
"{\n" +
"dimensions:\n" +
"\trow = 3779 ;\n" +
"variables:\n" +
"\tfloat latitude(row) ;\n" +
"\t\tlat:long_name = \"Latitude\" ;\n" +
"\tfloat long(row) ;\n" +
"\t\tlong:long_name = \"Longitude\" ;\n" +
"\tfloat abund_m3(row) ;\n" +
"\t\tabund_m3:long_name = \"Abundance m3\" ;\n" +
"\n" +
"// global attributes:\n" +
"}\n" +
"    Row             lat           long       abund_m3\n" +
"      0       44.651699    -124.650002     3.69822E-3\n" +
"      1       44.651699    -124.650002     7.26257E-2\n" +
"      2       42.504601    -125.011002     1.10023E-3\n" +
"      3       42.501801    -124.706001     7.88955E-2\n" +
"      4         42.5033    -124.845001        3.41646\n";
*/



        url = "https://coastwatch.pfeg.noaa.gov/erddap/tabledap/erdGlobecVpt?station_id&distinct()"; 
        table.readOpendapSequence(url, false);
        String2.log(table.toString(3));
        //source has no global metadata 
        Test.ensureEqual(table.nColumns(), 1, "");
        Test.ensureEqual(table.nRows(), 77, "");
        Test.ensureEqual(table.getColumnName(0), "station_id", "");
        Test.ensureEqual(table.columnAttributes(0).getString("long_name"), "Station ID", "");
        Test.ensureEqual(table.getStringData(0, 0), "BO01", "");
        Test.ensureEqual(table.getStringData(0, 1), "BO02", "");


        url = "https://coastwatch.pfeg.noaa.gov/erddap/tabledap/erdGlobecVpt?abund_m3&station_id=%22NH05%22"; 
        table.readOpendapSequence(url, false);
        String2.log(table.toString(3));
        //source has no global metadata 
        Test.ensureEqual(table.nColumns(), 1, "");
        Test.ensureEqual(table.nRows(), 2400, "");
        Test.ensureEqual(table.getColumnName(0), "abund_m3", "");
        Test.ensureEqual(table.columnAttributes(0).getString("long_name"), "Abundance", "");
        Test.ensureEqual(table.getFloatData(0, 0), 11.49f, "");
        Test.ensureEqual(table.getFloatData(0, 1), 74.720001f, "");


        url = "https://coastwatch.pfeg.noaa.gov/erddap/tabledap/erdGlobecBottle?cruise_id&distinct()"; 
        table.readOpendapSequence(url, false);
        String2.log(table.toString(1000000));
        //source has no global metadata 
        Test.ensureEqual(table.nColumns(), 1, "");
        Test.ensureEqual(table.nRows(), 2, "");
        Test.ensureEqual(table.getColumnName(0), "cruise_id", "");
        Test.ensureEqual(table.columnAttributes(0).getString("long_name"), "Cruise ID", "");
        Test.ensureEqual(table.getStringData(0, 0), "nh0207", "");
        Test.ensureEqual(table.getStringData(0, 1), "w0205", "");


        url = "https://coastwatch.pfeg.noaa.gov/erddap/tabledap/erdGlobecMoc1?abund_m3,latitude,longitude&program=%22MESO_1%22";
        table.readOpendapSequence(url, false);
        results = table.dataToString();
        String2.log(results);
        expected =
/* oceanwatch was 
...
"    Row             lat           long       abund_m3\n" +
"      0       44.651699    -124.650002        10.7463\n" +
"      1       44.651699    -124.650002     1.40056E-2\n" +
"      2       44.651699    -124.650002       0.252101\n";
*/
"abund_m3,latitude,longitude\n" +
//"10.746269,44.6517,-124.65\n" +  //pre 2013-06-20 was
//"0.014005602,44.6517,-124.65\n" +
//"0.25210083,44.6517,-124.65\n";
"0.003688676,44.6517,-124.65\n" +
"0.003688676,44.6517,-124.65\n" +
"0.011066027,44.6517,-124.65\n";
        Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);

        //test getting all data
        //modified from above so it returns lots of data 
        //nRows=16507 nColumns=28  readTime=5219 ms  processTime=94 ms
        url = "https://coastwatch.pfeg.noaa.gov/erddap/tabledap/erdGlobecVpt";
        table.readOpendapSequence(url, false);
        results = table.dataToString(5);
        //on oceanwatch, was
//    Row        datetime   datetime_utc datetime_utc_e           year        program      cruise_id        cast_no         stn_id
//lat           long        lat1000        lon1000    water_depth      sample_id min_sample_dep max_sample_dep    month_local      day_local
//   time_local       d_n_flag      gear_type   gear_area_m2      gear_mesh       vol_filt     counter_id       comments   perc_counted     lo
//cal_code      nodc_code  genus_species     life_stage       abund_m3
//      0  2001-04-25 21: 2001-04-25 22:      988261731           2001             NH       EL010403              2           NH05      44.650
//002    -124.169998          44650        -124170             60              1              0             55              4             25
//        -9999          -9999            VPT        0.19635          0.202          14.46            WTP          -9999            1.1    611
//8010204#     6118010204 CALANUS_MARSHA        3;_CIII          11.49
        expected = 
"cruise_id,longitude,latitude,time,cast_no,station_id,abund_m3,comments,counter_id,d_n_flag,gear_area,gear_mesh,gear_type,genus_species,life_stage,local_code,max_sample_depth,min_sample_depth,nodc_code,perc_counted,program,sample_id,vol_filt,water_depth\n" +
"EL010403,-124.17,44.65,9.88261731E8,0,NH05,11.49,-9999,WTP,-9999,0.19635,0.202,VPT,CALANUS_MARSHALLAE,3;_CIII,6118010204#,55,0,6118010204,1.1,NH,0,14.46,60\n" +
"EL010403,-124.17,44.65,9.88261731E8,0,NH05,74.72,-9999,WTP,-9999,0.19635,0.202,VPT,BIVALVIA,Veliger,55V,55,0,55,1.1,NH,0,14.46,60\n" +
"EL010403,-124.17,44.65,9.88261731E8,0,NH05,57.48,-9999,WTP,-9999,0.19635,0.202,VPT,POLYCHAETA,Larva,5001LV,55,0,5001,1.1,NH,0,14.46,60\n" +
"EL010403,-124.17,44.65,9.88261731E8,0,NH05,74.72,-9999,WTP,-9999,0.19635,0.202,VPT,GASTROPODA,Veliger,51V,55,0,51,1.1,NH,0,14.46,60\n" +
"EL010403,-124.17,44.65,9.88261731E8,0,NH05,11.49,-9999,WTP,-9999,0.19635,0.202,VPT,CALANUS_MARSHALLAE,1;_CI,6118010204!,55,0,6118010204,1.1,NH,0,14.46,60\n";
        Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);



        //*************
        String2.log("\n*** Table.testOpendapSequence subset data via tests");

        //read data from opendap
        table = new Table();
        table.readOpendapSequence(
            //resulting url (for asc) is: 
            // https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_MOC1.asc?abund_m3,lat,long&abund_m3>=0.248962651&abund_m3<=0.248962653
            //  Opera browser changes > to %3E and < to %3C
            "https://coastwatch.pfeg.noaa.gov/erddap/tabledap/erdGlobecMoc1",
            new String[]{"abund_m3"}, 
            new double[]{0.24896}, //new double[]{0.248962651}, //the last 2 rows only
            new double[]{0.24897}, //new double[]{0.248962653}, 
            new String[]{"abund_m3","latitude","longitude"},
            false); 

        results = table.dataToString();
        expected = 
"abund_m3,latitude,longitude\n" +
"0.24896266,44.6517,-124.65\n" +
"0.24896266,44.6517,-124.65\n";
        Test.ensureEqual(results, expected, "results=\n" + results);



        //************* TWO-LEVEL SEQUENCE *****************************
        /* 2014-08-06 TEST REMOVED BECAUSE dataset is gone


        //note that I was UNABLE to get .asc responses for these dapper urls while poking around.
        //but straight dods request (without ".dods") works.
        //I'm testing Lynn's old ndbc data because I can independently generate test info
        //  from my ndbc files.
        //Starting url from Roy: http://las.pfeg.noaa.gov/dods/
        //See in DChart: http://las.pfeg.noaa.gov/dchart
        //Test info from my cached ndbc file /u00/data/points/ndbcMet2HistoricalTxt/46022h2004.txt
        //YYYY MM DD hh  WD  WSPD GST  WVHT  DPD   APD  MWD  BAR    ATMP  WTMP  DEWP  VIS  TIDE
        //2004 01 01 00 270  2.0  3.1  3.11 16.67  9.80 999 1010.7 999.0 999.0 999.0 99.0 99.00
        //2004 01 01 01 120  5.9  7.3  3.29 16.67 10.12 999 1010.4 999.0 999.0 999.0 99.0 99.00
        //test attributes are from "http://las.pfeg.noaa.gov/dods/ndbc/all_noaa_time_series.cdp.das"
        //http://las.pfeg.noaa.gov/dods/ndbc/all_noaa_time_series.cdp?location.LON,location.LAT,location.DEPTH,location.profile.TIME,location.profile.WSPD1,location.profile.BAR1&location.LON>=235.3&location.LON<=235.5&location.LAT>=40.7&location.LAT<=40.8&location.profile.TIME>=1072915200000&location.profile.TIME<=1072920000000
        lon = 235.460007f; //exact values from just get LON and LAT values available
        lat = 40.779999f;
        long time1 = Calendar2.newGCalendarZulu(2004, 1, 1).getTimeInMillis();
        long time2 = time1 + Calendar2.MILLIS_PER_HOUR;
        //was http://las.pfeg.noaa.gov/dods/ndbc/all_noaa_time_series.cdp 
        //was http://las.pfeg.noaa.gov/dods/ndbcMet/ndbcMet_time_series.cdp?" +
        url = "http://oceanview.pfeg.noaa.gov/dods/ndbcMet/ndbcMet_time_series.cdp?" +
            "location.LON,location.LAT,location.DEPTH,location.profile.TIME,location.profile.WSPD,location.profile.BAR" +
            "&location.LON>=" + (lon - .01f) + "&location.LON<=" + (lon + .01f) + //I couldn't catch lon with "="
            "&location.LAT>=" + (lat - .01f) + "&location.LAT<=" + (lat + .01f) + //I couldn't catch lat with "="
            "&location.profile.TIME>=" + (time1 - 1) + 
            "&location.profile.TIME<=" + (time2 + 1);
        String2.log("url=" + url);
        table.readOpendapSequence(url, false);
        String2.log(table.toString());
        Test.ensureEqual(table.nColumns(), 6, "");
        Test.ensureEqual(table.nRows(), 2, "");
        int latCol = table.findColumnNumber("LAT");
        int lonCol = table.findColumnNumber("LON");
        Test.ensureTrue(latCol >= 0 && latCol < 2, "latCol=" + latCol); 
        Test.ensureTrue(lonCol >= 0 && lonCol < 2, "lonCol=" + lonCol);  
        Test.ensureEqual(table.getColumnName(2), "DEPTH", "");
        Test.ensureEqual(table.getColumnName(3), "TIME", "");
        int barCol = table.findColumnNumber("BAR");
        int wspdCol = table.findColumnNumber("WSPD");
        Test.ensureEqual(table.getColumn(latCol).elementTypeString(), "float", "");
        Test.ensureEqual(table.getColumn(3).elementTypeString(), "double", "");
        Test.ensureEqual(table.getColumn(wspdCol).elementTypeString(), "float", "");
        Test.ensureEqual(table.globalAttributes().getString("Conventions"), "epic-insitu-1.0", "");
        Test.ensureEqual(table.globalAttributes().get("lat_range").toString(), "-27.7000007629395, 70.4000015258789", "");
        Test.ensureEqual(table.getFloatData(latCol, 0), lat, "");
        Test.ensureEqual(table.getFloatData(latCol, 1), lat, "");
        Test.ensureEqual(table.getFloatData(lonCol, 0), lon, ""); 
        Test.ensureEqual(table.getFloatData(lonCol, 1), lon, "");
        //outer attributes...
        Test.ensureEqual(table.columnAttributes(latCol).getString("units"), "degrees_north", ""); 
        Test.ensureEqual(table.columnAttributes(latCol).getString("long_name"), "latitude", "");
        Test.ensureEqual(table.columnAttributes(latCol).getDouble("missing_value"), Double.NaN, "");
        Test.ensureEqual(table.columnAttributes(latCol).getString("axis"), "Y", "");
        Test.ensureEqual(table.getDoubleData(3, 0), time1, "");
        Test.ensureEqual(table.getDoubleData(3, 1), time2, "");
        //inner attributes...
        Test.ensureEqual(table.columnAttributes(3).getString("units"), "msec since 1970-01-01 00:00:00 GMT", "");
        Test.ensureEqual(table.columnAttributes(3).getString("long_name"), "time", "");
        Test.ensureEqual(table.columnAttributes(3).getDouble("missing_value"), Double.NaN, "");
        Test.ensureEqual(table.columnAttributes(3).getString("axis"), "T", "");
        Test.ensureEqual(table.getFloatData(barCol, 0), 1010.7f, ""); //bar
        Test.ensureEqual(table.getFloatData(barCol, 1), 1010.4f, "");
        Test.ensureEqual(table.getFloatData(wspdCol, 0), 2.0f, ""); //wspd
        Test.ensureEqual(table.getFloatData(wspdCol, 1), 5.9f, "");

        */


        /* 2014-08-06 INACTIVE BECAUSE DATASET NO LONGER AVAILABLE
        //This Calcofi test simply verifies that the results now are as they were when
        //  I wrote the test (circular logic).
        //I hope this test is better than ndbc test above,
        //  since hopefully longer lived (since ndbc data may not be around forever).
        //target data
        //    Row            time            lat            lon          depth English_sole_LarvaeCount
        //     10    947320140000      32.341667     241.445007     203.800003        NaN
        //     11    947320140000      32.341667     241.445007            NaN        NaN
        lat = 32.341667f;
        lon = 241.445f;
        long time = 947320140000L;
        //Starting url from roy: http://las.pfeg.noaa.gov/dods/
        //see info via url without query, but plus .dds or .das
        //was las.pfeg.noaa.gov
        url = "http://oceanview.pfeg.noaa.gov/dods/CalCOFI/Biological.cdp?" +
            "location.lon,location.lat,location.time,location.profile.depth,location.profile.Line,location.profile.Disintegrated_fish_larvae_LarvaeCount" +
            "&location.lon>=" + (lon - .01f) + "&location.lon<=" + (lon + .01f) + //I couldn't catch lon with "="
            "&location.lat>=" + (lat - .01f) + "&location.lat<=" + (lat + .01f) + //I couldn't catch lat with "="
            "&location.time>=" + (time - 1);
        table.readOpendapSequence(url, false);

        String2.log(table.toString());
        int latCol = table.findColumnNumber("lat");
        int lonCol = table.findColumnNumber("lon");
        Test.ensureTrue(latCol >= 0, "latCol=" + latCol); 
        Test.ensureTrue(lonCol >= 0, "lonCol=" + lonCol);  
        Test.ensureEqual(table.nColumns(), 6, "");
        Test.ensureEqual(table.nRows(), 31, "");
        Test.ensureEqual(table.getColumnName(0), "time", ""); //not in order I requested!   they are in dataset order
        Test.ensureEqual(table.getColumnName(latCol), "lat", "");  
        Test.ensureEqual(table.getColumnName(lonCol), "lon", "");  
        Test.ensureEqual(table.getColumnName(3), "Line", "");
        Test.ensureEqual(table.getColumnName(4), "Disintegrated_fish_larvae_LarvaeCount", "");
        Test.ensureEqual(table.getColumnName(5), "depth", "");
        Test.ensureEqual(table.getColumn(0).elementTypeString(), "double", "");
        Test.ensureEqual(table.getColumn(latCol).elementTypeString(), "float", "");
        Test.ensureEqual(table.getColumn(lonCol).elementTypeString(), "float", "");
        Test.ensureEqual(table.getColumn(3).elementTypeString(), "float", "");
        Test.ensureEqual(table.getColumn(4).elementTypeString(), "float", "");
        Test.ensureEqual(table.getColumn(5).elementTypeString(), "float", "");
        //global attributes
        Test.ensureEqual(table.globalAttributes().getString("Conventions"), "epic-insitu-1.0", "");
        Test.ensureEqual(table.globalAttributes().getInt("total_profiles_in_dataset"),  6407, "");
        //test of outer attributes
        Test.ensureEqual(table.columnAttributes(0).getString("units"), "msec since 1970-01-01 00:00:00 GMT", "");
        Test.ensureEqual(table.columnAttributes(0).getString("long_name"), "time", "");
        Test.ensureEqual(table.columnAttributes(0).getDouble("missing_value"), Double.NaN, "");
        Test.ensureEqual(table.columnAttributes(0).getString("axis"), "T", "");
        //test of inner attributes
        Test.ensureEqual(table.columnAttributes(4).getString("long_name"), "disintegrated fish larvae larvae count", "");
        Test.ensureEqual(table.columnAttributes(4).getFloat("missing_value"), Float.NaN, "");
        Test.ensureEqual(table.columnAttributes(4).getString("units"), "number of larvae", "");

        //test of results
        //NOTE that data from different inner sequences is always separated by a row of NaNs 
        //  in the ending inner sequence's info.
        //  I believe Dapper is doing this. See more comments below.
        //    Row            time            lat            lon Disintegrated_           Line          depth
        //      0    947320140000      32.341667     241.445007            NaN      93.300003     203.800003
        //      1    947320140000      32.341667     241.445007            NaN            NaN            NaN
        //      2    955184100000      32.348331     241.448334            NaN      93.300003     215.800003
        //     30   1099482480000      32.345001     241.445007            NaN      93.300003     198.899994
         Test.ensureEqual(table.getDoubleData(0, 0), 947320140000L, "");
        Test.ensureEqual(table.getFloatData(latCol, 0), 32.341667f, "");
        Test.ensureEqual(table.getFloatData(lonCol, 0), 241.445007f, "");
        Test.ensureEqual(table.getFloatData(3, 0), 93.300003f, "");
        Test.ensureEqual(table.getFloatData(4, 0), Float.NaN, "");
        Test.ensureEqual(table.getFloatData(5, 0), 203.800003f, "");

        Test.ensureEqual(table.getDoubleData(0, 1), 947320140000L, "");
        Test.ensureEqual(table.getFloatData(latCol, 1), 32.341667f, "");
        Test.ensureEqual(table.getFloatData(lonCol, 1), 241.445007f, "");
        Test.ensureEqual(table.getFloatData(3, 1), Float.NaN, "");
        Test.ensureEqual(table.getFloatData(4, 1), Float.NaN, "");
        Test.ensureEqual(table.getFloatData(5, 1), Float.NaN, "");

        Test.ensureEqual(table.getDoubleData(0, 30), 1099482480000L, "");
        Test.ensureEqual(table.getFloatData(latCol, 30), 32.345001f, "");
        Test.ensureEqual(table.getFloatData(lonCol, 30), 241.445007f, "");
        Test.ensureEqual(table.getFloatData(3, 30), 93.300003f, "");
        Test.ensureEqual(table.getFloatData(4, 30), Float.NaN, "");
        Test.ensureEqual(table.getFloatData(5, 30), 198.899994f, "");


        //*** visual test: is dapper returning the NAN row at the end of every innerSequence (true)
        //  or is that the way it is in the files?  (false)
        lon = 235.460007f; //exact values from just get LON and LAT values available
        lat = 40.779999f;
        long time1 = Calendar2.newGCalendarZulu(2004, 1, 1).getTimeInMillis();
        long time2 = time1 + Calendar2.MILLIS_PER_HOUR;
        //was http://las.pfeg.noaa.gov/dods/ndbc/all_noaa_time_series.cdp
        url = "http://oceanview.pfeg.noaa.gov/dods/ndbcMet/ndbcMet_time_series.cdp?" +
            "location.LON,location.LAT,location.DEPTH,location.profile.TIME,location.profile.WSPD,location.profile.BAR" +
            "&location.LON>=" + (lon - 5f) + "&location.LON<=" + (lon + 5f) + 
            "&location.LAT>=" + (lat - 5f) + "&location.LAT<=" + (lat + 5f) + 
            "&location.profile.TIME>=" + (time1 - 1) + 
            "&location.profile.TIME<=" + (time2 + 1);
        table.readOpendapSequence(url, false);
        String2.log(table.toString());
        */

    /*
        //THIS WORKS, BUT TAKES ~40 SECONDS!!!  so don't do all the time
        //see questions below.
        //This gets all the valid English_sole_LarvaeCount data.
        //UNFORTUNATELY, you can't put constraint on non-axis variable,
        //  so I have to get all data and then filter the results.
        //This test simply verifies that the results now are as they were when
        //  I wrote the test (circular logic).
        //I had hoped this test would be better than ndbc test above,
        //  since hopefully longer lived (since ndbc data may not be around forever).
        //Starting url from roy: http://las.pfeg.noaa.gov/dods/
        url = "http://las.pfeg.noaa.gov/dods/CalCOFI/Biological.cdp?" +
            "location.lon,location.lat,location.time,location.profile.depth,location.profile.English_sole_LarvaeCount";
        table.readOpendapSequence(url);
        String2.log("raw results nRows=" + table.nRows());
        //just keep rows with larvaeCounts >= 0
        table.subset(new int[]{4}, new double[]{0}, new double[]{1e300}); 

        String2.log(table.toString());
        Test.ensureEqual(table.nColumns(), 5, "");
        Test.ensureEqual(table.nRows(), 98, "");
        Test.ensureEqual(table.getColumnName(0), "time", ""); //not in order I requested!   they are in dataset order
        Test.ensureEqual(table.getColumnName(1), "lat", "");  
        Test.ensureEqual(table.getColumnName(2), "lon", "");  
        Test.ensureEqual(table.getColumnName(3), "depth", "");
        Test.ensureEqual(table.getColumnName(4), "English_sole_LarvaeCount", "");
        Test.ensureEqual(table.getColumn(0).elementTypeString(), "double", "");
        Test.ensureEqual(table.getColumn(1).elementTypeString(), "float", "");
        Test.ensureEqual(table.getColumn(2).elementTypeString(), "float", "");
        Test.ensureEqual(table.getColumn(3).elementTypeString(), "float", "");
        Test.ensureEqual(table.getColumn(4).elementTypeString(), "float", "");
        //global attributes
        Test.ensureEqual(table.globalAttributes().getString("Conventions"), "epic-insitu-1.0", "");
        Test.ensureEqual(table.globalAttributes().getInt("total_profiles_in_dataset"),  6407, "");
        //test of outer attributes
        Test.ensureEqual(table.columnAttributes(0).getString("units"), "msec since 1970-01-01 00:00:00 GMT", "");
        Test.ensureEqual(table.columnAttributes(0).getString("long_name"), "time", "");
        Test.ensureEqual(table.columnAttributes(0).getDouble("missing_value"), Double.NaN, "");
        Test.ensureEqual(table.columnAttributes(0).getString("axis"), "T", "");
        //test of inner attributes
        Test.ensureEqual(table.columnAttributes(4).getString("long_name"), "parophrys vetulus larvae count", "");
        Test.ensureEqual(table.columnAttributes(4).getFloat("missing_value"), Float.NaN, "");
        Test.ensureEqual(table.columnAttributes(4).getString("units"), "number of larvae", "");

        //test of results
        Test.ensureEqual(table.getDoubleData(0, 0), 955657380000L, "");
        Test.ensureEqual(table.getFloatData(1, 0), 33.485001f, "");
        Test.ensureEqual(table.getFloatData(2, 0), 242.231659f, "");
        Test.ensureEqual(table.getFloatData(3, 0), 210.800003f, "");
        Test.ensureEqual(table.getFloatData(4, 0), 1, "");

        Test.ensureEqual(table.getDoubleData(0, 1), 955691700000L, "");
        Test.ensureEqual(table.getFloatData(1, 1), 33.825001f, "");
        Test.ensureEqual(table.getFloatData(2, 1), 241.366669f, "");
        Test.ensureEqual(table.getFloatData(3, 1), 208.5f, "");
        Test.ensureEqual(table.getFloatData(4, 1), 6, "");

        Test.ensureEqual(table.getDoubleData(0, 97), 923900040000L, "");
        Test.ensureEqual(table.getFloatData(1, 97), 34.976665f, "");
        Test.ensureEqual(table.getFloatData(2, 97), 237.334991f, "");
        Test.ensureEqual(table.getFloatData(3, 97), 24.1f, "");
        Test.ensureEqual(table.getFloatData(4, 97), 4, "");

/* */
/**
[Bob talked to Lynn about this. Conclusions below.]
1)   If I just get all lon,lat,time,depth, and English_sole_LarvaeCount
          (was http://las.pfeg...)
        url = "http://oceanview.pfeg.noaa.gov/dods/CalCOFI/Biological.cdp?" +
            "location.lon,location.lat,location.time,location.profile.depth,location.profile.English_sole_LarvaeCount";
    it looks like each time,lat,lon combo has a data row and a NaN row.
    ???Is this a real NaN row, or a mistake in my code (e.g., end of sequence beginning of next).
    [I believe it is real and added by Dapper.]
    Note that some sole counts below are non-NaN.

    Row            time            lat            lon          depth English_sole_LarvaeCount
      0    947255160000      32.955002     242.695007           71.5        NaN
      1    947255160000      32.955002     242.695007            NaN        NaN
      2    947264520000      32.913334     242.606659     207.600006        NaN
      3    947264520000      32.913334     242.606659            NaN        NaN
      4    947275680000      32.848335     242.471664     211.699997        NaN
      5    947275680000      32.848335     242.471664            NaN        NaN
      6    947290920000          32.68     242.126663     195.899994        NaN
      7    947290920000          32.68     242.126663            NaN        NaN
      8    947306040000      32.513332     241.790009     208.100006        NaN
      9    947306040000      32.513332     241.790009            NaN        NaN
     10    947320140000      32.341667     241.445007     203.800003        NaN
     11    947320140000      32.341667     241.445007            NaN        NaN
     12    947343360000          32.18     241.110001          209.5        NaN
     13    947343360000          32.18     241.110001            NaN        NaN
     14    947359140000      32.006668     240.764999          215.5        NaN
     15    947359140000      32.006668     240.764999            NaN        NaN
2) do all time,lat,lon combo's just have one depth?
   If so, then why set up this way?  
   Just to match dapper convention (must have z or t outside and t or z inside)?
   [I believe so.]

3) Since it appears that the 150(?) variables were only measured rarely,
   it seems hugely wasteful to allocate space for them.
   And worse, since a query use constraints on non-axis variables,
   one can't simply ask for  ... &English_sole_LarvaeCount>=0
   to find time,lat,lon,depth where there are valid values of English_sole_LarvaeCount.
   And requesting all data rows (so I can then filtering on my end) takes ~40 seconds
   for 98 rows of data.
   [Wasteful, but I believe Roy did it this way to conform to Dapper Conventions so
   data easily served by Dapper/DChart, see http://oceanview.pfeg.noaa.gov/dchart (was http://las.pfeg...).]

4) There are no 0 values for English_sole_LarvaeCount.
   So how can one tell if people looked for English_sole_Larvae but didn't find any?
   Are NaN's to be treated as 0 for this data set?
   [It looks like 0 values are lumped in with NaNs.]

5) Why is number of larvae (units="number of larvae") a float and not an int?
   [Because all variables are floats for simplicity (maybe for matlab or fortran).]

*/
    }

    /** Test the speed of readASCII */
    public static void testReadASCIISpeed() throws Exception {

        try {
            String fileName = "/u00/data/points/ndbcMet2HistoricalTxt/41009h1990.txt"; 
            long time = 0;

            for (int attempt = 0; attempt < 4; attempt++) {
                String2.log("\n*** Table.testReadASCIISpeed attempt #" + attempt + "\n");
                Math2.gcAndWait(); //in a test
                Math2.sleep(5000);
                //time it
                long fileLength = File2.length(fileName); //was 1335204
                Test.ensureTrue(fileLength > 1335000, "fileName=" + fileName + " length=" + fileLength); 
                time = System.currentTimeMillis();
                Table table = new Table();
                table.readASCII(fileName);
                time = System.currentTimeMillis() - time;

                String results = table.dataToString(3);
                String expected =
"YY,MM,DD,hh,WD,WSPD,GST,WVHT,DPD,APD,MWD,BAR,ATMP,WTMP,DEWP,VIS\n" +
"90,01,01,00,161,08.6,10.7,01.50,05.00,04.80,999,1017.2,22.7,22.0,999.0,99.0\n" +
"90,01,01,01,163,09.3,11.3,01.50,05.00,04.90,999,1017.3,22.7,22.0,999.0,99.0\n" +
"90,01,01,01,164,09.2,10.6,01.60,04.80,04.90,999,1017.3,22.7,22.0,999.0,99.0\n" +
"...\n";
                Test.ensureEqual(results, expected, "results=\n" + results);
                Test.ensureEqual(table.nColumns(), 16, "nColumns=" + table.nColumns()); 
                Test.ensureEqual(table.nRows(), 17117, "nRows=" + table.nRows()); 

                String2.log("********** attempt #" + attempt + " Done.\n" +
                    "cells/ms=" + (table.nColumns() * table.nRows()/time) + 
                      " (usual=2560 with StringHolder. With String, was 2711 Java 1.7M4700, was 648)" +
                    "\ntime=" + time + "ms (good=106ms, but slower when computer is busy.\n" +
                    "  (was 101 Java 1.7M4700, was 422, java 1.5 was 719)"); 
                if (time <= 130)
                    break;
            }
            if (time > 130)
                throw new SimpleException("readASCII took too long (but often does when computer is busy).");
        } catch (Exception e) {
            String2.pressEnterToContinue(MustBe.throwableToString(e) +
                "\nUnexpected " + String2.ERROR); 
        }
    }


    /** Test the speed of readJson */
    public static void testReadJsonSpeed() throws Exception {

        //warmup
        String fileName = String2.unitTestDataDir + "cPostDet3.files.json"; 
        long time = 0;
        String msg = "";

        for (int attempt = 0; attempt < 3; attempt++) {
            String2.log("\n*** Table.testReadJsonSpeed attempt#" + attempt + "\n");
            Math2.gcAndWait(); //in a test

            //time it
            time = System.currentTimeMillis();
            long fileLength = File2.length(fileName); //was 10,166KB
            Test.ensureTrue(fileLength > 9000000, "fileName=" + fileName + " length=" + fileLength); 
            Table table=new Table();
            table.readJson(fileName);

            String results = table.dataToString(3);
            String2.log("results=\n" + results);
//row,dirIndex,fileName,lastMod,sortedSpacing,unique_tag_id_min_,unique_tag_id_max_,PI_min_,PI_max_,longitude_min_,longitude_max_,l
//atitude_min_,latitude_max_,time_min_,time_max_,bottom_depth_min_,bottom_depth_max_,common_name_min_,common_name_max_,date_public_min
//_,date_public_max_,line_min_,line_max_,position_on_subarray_min_,position_on_subarray_max_,project_min_,project_max_,riser_height_mi
//n_,riser_height_max_,role_min_,role_max_,scientific_name_min_,scientific_name_max_,serial_number_min_,serial_number_max_,stock_min_,
// stock_max_,surgery_time_min_,surgery_time_max_,surgery_location_min_,surgery_location_max_,tagger_min_,tagger_max_
            Test.ensureTrue(results.indexOf("unique_tag_id_max") > 0, "test 1");
            Test.ensureTrue(results.indexOf("surgery_time_min") > 0,  "test 2");
            Test.ensureTrue(table.nColumns() > 40, "nColumns=" + table.nColumns()); //was 42
            Test.ensureTrue(table.nRows() > 15000, "nRows=" + table.nRows()); //was 15024

            time = System.currentTimeMillis() - time;
            msg = "*** Done. cells/ms=" + 
                (table.nColumns() * table.nRows()/time) + " (usual=2881 Java 1.7M4700, was 747)" +
                "\ntime=" + time + "ms (usual=219 Java 1.7M4700, was 844, java 1.5 was 1687)"; 
            String2.log(msg);
            if (time <= 400)
                break;
        }
        Test.ensureTrue(time < 400, msg + "\nreadJson took too long.");
    }


    /** Test the speed of readNDNc */
    public static void testReadNDNcSpeed() throws Exception {

        String fileName = "c:/u00/data/points/ndbcMet2/historical/NDBC_41004_met.nc"; 
        Table table = new Table();
        long time = 0;
        String2.log(NcHelper.ncdump(fileName, "-h"));

        for (int attempt = 0; attempt < 3; attempt++) {
            String2.log("\n*** Table.testReadNDNcSpeed attempt+" + attempt + "\n");
            Math2.gcAndWait(); //in a test

            //time it
            time = System.currentTimeMillis();
            long fileLength = File2.length(fileName); //was 20580000
            Test.ensureTrue(fileLength > 20570000, "fileName=" + fileName + " length=" + fileLength); 
            table = new Table();
            table.readNDNc(fileName, null, 0, null, 0, 0); //standardizeWhat=0   

            String results = table.dataToString(3);
            String expected =  //before 2011-06-14 was 32.31, -75.35,
"TIME,DEPTH,LAT,LON,WD,WSPD,GST,WVHT,DPD,APD,MWD,BAR,ATMP,WTMP,DEWP,VIS,PTDY,TIDE,WSPU,WSPV,ID\n" +
"2.678004E8,0.0,32.501,-79.099,255,1.3,-9999999.0,-9999999.0,-9999999.0,-9999999.0,32767,1020.5,27.2,27.4,-9999999.0,-9999999.0,-9999999.0,-9999999.0,1.3,0.3,41004\n" +
"2.67804E8,0.0,32.501,-79.099,247,6.6,-9999999.0,-9999999.0,-9999999.0,-9999999.0,32767,1020.6,26.8,27.4,-9999999.0,-9999999.0,-9999999.0,-9999999.0,6.1,2.6,41004\n" +
"2.678076E8,0.0,32.501,-79.099,249,7.0,-9999999.0,-9999999.0,-9999999.0,-9999999.0,32767,1020.4,26.8,27.4,-9999999.0,-9999999.0,-9999999.0,-9999999.0,6.5,2.5,41004\n" +
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);
            Test.ensureEqual(table.nColumns(), 21, "nColumns=" + table.nColumns()); 
            Test.ensureTrue(table.nRows() >= 351509, "nRows=" + table.nRows()); 

            time = System.currentTimeMillis() - time;
            String2.log("********** Done. cells/ms=" + 
                (table.nColumns() * table.nRows()/time) + " (usual=31414 Java 1.7M4700, was 9679)" +
                "\ntime=" + time + "ms (usual=556 Lenovo, was 226 Java 1.7M4700, was 640, java 1.5 was 828, but varies a lot)"); 
            if (time <= 650)
                break;
        }
        if (time > 650)
            throw new SimpleException("readNDNc took too long.");
    }


    /** Test the speed of readOpendapSequence */
    public static void testReadOpendapSequenceSpeed() throws Exception {

        String url = 
            "https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet?" +
            "&time%3E=1999-01-01&time%3C=1999-04-01&station=%2241009%22";
        long time = 0;

        for (int attempt = 0; attempt < 3; attempt++) {
            String2.log("\n*** Table.testReadOpendapSequenceSpeed\n");
            Math2.gcAndWait(); //in a test

            //time it
            time = System.currentTimeMillis();
            Table table = new Table();
            table.readOpendapSequence(url);
            String results = table.dataToString(3);            
            String expected = //before 2011-06-14 was -80.17, 28.5
//"station,longitude,latitude,time,wd,wspd,gst,wvht,dpd,apd,mwd,bar,atmp,wtmp,dewp,vis,ptdy,tide,wspu,wspv\n" +
//"41009,-80.166,28.519,9.151488E8,0,1.9,2.7,1.02,11.11,6.49,32767,1021.0,20.4,24.2,-9999999.0,-9999999.0,-9999999.0,-9999999.0,0.0,-1.9\n" +
//"41009,-80.166,28.519,9.151524E8,53,1.5,2.8,0.99,11.11,6.67,32767,1021.0,20.6,24.5,-9999999.0,-9999999.0,-9999999.0,-9999999.0,-1.2,-0.9\n" +
//"41009,-80.166,28.519,9.15156E8,154,1.0,2.2,1.06,11.11,6.86,32767,1021.2,20.6,24.6,-9999999.0,-9999999.0,-9999999.0,-9999999.0,-0.4,0.9\n" +

//source ASCII file has:  (note 2 rows for ever hour)
//YYYY MM DD hh WD   WSPD GST  WVHT  DPD   APD  MWD  BAR    ATMP  WTMP  DEWP  VIS  [in EditPlus, the first row of data is here, to right of col names -- screwy line endings?!]
//1999 01 01 00 360  1.9  2.7  1.02 11.11  6.49 999 1021.0  20.4  24.2 999.0 99.0
//1999 01 01 00  21  1.4  3.4  1.10 11.11  6.82 999 1020.9  20.4  24.5 999.0 99.0
//1999 01 01 01  53  1.5  2.8   .99 11.11  6.67 999 1021.0  20.6  24.5 999.0 99.0
//1999 01 01 01  53  1.5  2.6  1.10 11.11  6.97 999 1021.1  20.6  24.5 999.0 99.0
//1999 01 01 02 154  1.0  2.2  1.06 11.11  6.86 999 1021.2  20.6  24.6 999.0 99.0
//1999 01 01 02  73  2.5  3.8  1.09 11.11  6.87 999 1021.2  20.7  24.6 999.0 99.0

//2020-03-03 this data changed significantly after big changes to processing system/ dealing with duplicate lines (prefer newer data/later in file)
"station,longitude,latitude,time,wd,wspd,gst,wvht,dpd,apd,mwd,bar,atmp,wtmp,dewp,vis,ptdy,tide,wspu,wspv\n" +
"41009,-80.166,28.519,9.151488E8,21,1.4,3.4,1.1,11.11,6.82,32767,1020.9,20.4,24.5,-9999999.0,-9999999.0,-9999999.0,-9999999.0,-0.5,-1.3\n" + //1999-01-01T00:00
"41009,-80.166,28.519,9.151524E8,53,1.5,2.6,1.1,11.11,6.97,32767,1021.1,20.6,24.5,-9999999.0,-9999999.0,-9999999.0,-9999999.0,-1.2,-0.9\n" + //1999-01-01T01:00
"41009,-80.166,28.519,9.15156E8,73,2.5,3.8,1.09,11.11,6.87,32767,1021.2,20.7,24.6,-9999999.0,-9999999.0,-9999999.0,-9999999.0,-2.4,-0.7\n" + //1999-01-01T02:00
"...\n";
            Test.ensureEqual(results, expected, "results=\n" + results);

            Test.ensureTrue(table.nRows() > 2100, "nRows=" + table.nRows());
            time = System.currentTimeMillis() - time;
            String2.log("********** Done. cells/ms=" + 
                (table.nColumns() * table.nRows()/time) + " (usual(https)=33, was(http) 337 Java 1.7M4700, was 106)" +                
                "\ntime=" + time + "ms (usual(https)=1285, was http=600 since remote, was 128 Java 1.7M4700, was 406, java 1.5 was 562)");  
            if (time <= 1600)
                break;
        }
        if (time > 1600)
            throw new SimpleException("readOpendapSequence took too long.");
    }


    /** Test the speed of saveAs speed */
    public static void testSaveAsSpeed() throws Exception {

        //warmup
        String2.log("\n*** Table.testSaveAsSpeed\n");
        String sourceName = "/u00/data/points/ndbcMet2HistoricalTxt/41009h1990.txt"; 
        String destName = File2.getSystemTempDirectory() + "testSaveAsSpeed";
        Table table = new Table();
        table.readASCII(sourceName);
        Test.ensureEqual(table.nColumns(), 16, "nColumns=" + table.nColumns()); 
        Test.ensureEqual(table.nRows(), 17117, "nRows=" + table.nRows()); 
        table.saveAsCsvASCII(destName + ".csv");
        table.saveAsJson(destName + ".json", table.findColumnNumber("time"), true); //writeUnits
        table.saveAsFlatNc(destName + ".nc", "row");
        long time = 0;

        for (int attempt = 0; attempt < 3; attempt++) {
            //time it
            String2.log("\ntime it\n");

            //saveAsCsvASCII
            time = System.currentTimeMillis();
            table.saveAsCsvASCII(destName + ".csv");
            time = System.currentTimeMillis() - time;
            String2.log("saveAsCsvASCII attempt#" + attempt + 
                " done. cells/ms=" + (table.nColumns() * table.nRows() / time) + //796
                "\ntime=" + time + "ms  (expected=344, was 532 for Java 1.5 Dell)"); 
            File2.delete(destName + ".csv");
            if (time <= 550)
                break;
        }
        if (time > 550)
            throw new SimpleException("saveAsCsvASCII took too long. Expected=~344 for 17117 rows.");

        for (int attempt = 0; attempt < 3; attempt++) {
            //saveAsJson
            time = System.currentTimeMillis();
            table.saveAsJson(destName + ".json", table.findColumnNumber("time"), true); //writeUnits
            time = System.currentTimeMillis() - time;
            String2.log("saveAsJson attempt#" + attempt + 
                " done. cells/ms=" + (table.nColumns() * table.nRows() / time) +   //974
                "\ntime=" + time + "ms  (expect=281, was 515 for Java 1.5 Dell)"); 
            File2.delete(destName + ".json");
            if (time <= 450)
                break;
        }
        if (time >= 450)
            throw new SimpleException("saveAsJson took too long (" + time + "ms). Expected=~281 for 17117 rows.");

        //saveAsFlatNc
        for (int attempt = 0; attempt < 3; attempt++) {
            time = System.currentTimeMillis();
            table.saveAsFlatNc(destName + ".nc", "row");
            time = System.currentTimeMillis() - time;
            String2.log("saveAsFlatNc attempt#" + attempt + 
                " done. cells/ms=" + (table.nColumns() * table.nRows() / time) + //2190
                "\ntime=" + time + "ms  (expected=125, was 172 for Java 1.5 Dell)"); 
            File2.delete(destName + ".nc");
            if (time <= 200)
                break;
        }
        if (time > 200)
            throw new SimpleException("saveAsFlatNc took too long. Expected=~125 for 17117 rows.");
        
    }



    /**
     * This is a test of readOpendap.
     *
     * @throws Exception of trouble
     */
    public static void testOpendap() throws Exception {
        //*************
        String2.log("\n*** Table.testOpendap");
        verbose = true;
        reallyVerbose = true;

        //opendap, even sequence data, can be read via .nc
        //  but constraints are not supported
        Table table = new Table();
        int nRows = 3779;
        table.readFlatNc(
            //read all via ascii: "https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_MOC1.asc?abund_m3,lat,long", null);
            //or                  "https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_MOC1.asc?MOC1.abund_m3,MOC1.lat,MOC1.long", null);
            "https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_MOC1", 
            new String[]{"MOC1.abund_m3", "MOC1.lat", "MOC1.long"},  //but "MOC1." is required here
            0); //standardizeWhat=0
//2018-05-12 was unpack to doubles, so these tests will change
        String2.log(table.toString(5));

        Test.ensureEqual(table.nColumns(), 3, "");
        Test.ensureEqual(table.nRows(), nRows, "");

        Test.ensureEqual(table.getColumnName(0), "abund_m3", "");
        Test.ensureEqual(table.columnAttributes(0).getString("long_name"), "Abundance m3", "");
        Test.ensureEqual(table.getDoubleData(0, 0), 0.242688983, "");
        Test.ensureEqual(table.getDoubleData(0, nRows-1), 0.248962652, "");

        Test.ensureEqual(table.getColumnName(1), "lat", "");
        Test.ensureEqual(table.columnAttributes(1).getString("long_name"), "Latitude", "");
        Test.ensureEqual(table.getDoubleData(1, 0), 44.6517, "");
        Test.ensureEqual(table.getDoubleData(1, nRows-1), 44.6517, "");

        Test.ensureEqual(table.getColumnName(2), "long", "");
        Test.ensureEqual(table.columnAttributes(2).getString("long_name"), "Longitude", "");
        Test.ensureEqual(table.getDoubleData(2, 0), -124.175, "");
        Test.ensureEqual(table.getDoubleData(2, nRows-1), -124.65, "");

        //can it read with list of variables?
        table.readFlatNc(
            "https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_MOC1?abund_m3,lat,long",
            null, //read all variables
            0); //standardizeWhat=0
//2018-05-12 was unpack to doubles, so these tests will change
        String2.log(table.toString(5));
        Test.ensureEqual(table.nColumns(), 3, "");
        Test.ensureEqual(table.nRows(), nRows, "");

        //!!!HEY, the results are an unexpected order!!!
        Test.ensureEqual(table.getColumnName(0), "lat", "");
        Test.ensureEqual(table.columnAttributes(0).getString("long_name"), "Latitude", "");
        Test.ensureEqual(table.getDoubleData(0, 0), 44.6517, "");
        Test.ensureEqual(table.getDoubleData(0, nRows-1), 44.6517, "");

        Test.ensureEqual(table.getColumnName(1), "long", "");
        Test.ensureEqual(table.columnAttributes(1).getString("long_name"), "Longitude", "");
        Test.ensureEqual(table.getDoubleData(1, 0), -124.175, "");
        Test.ensureEqual(table.getDoubleData(1, nRows-1), -124.65, "");
 
        Test.ensureEqual(table.getColumnName(2), "abund_m3", "");
        Test.ensureEqual(table.columnAttributes(2).getString("long_name"), "Abundance m3", "");
        Test.ensureEqual(table.getDoubleData(2, 0), 0.242688983, "");
        Test.ensureEqual(table.getDoubleData(2, nRows-1), 0.248962652, "");

    }

    /**
     * This tests the little methods.
     */
    public static void testLittleMethods() {
        String2.log("\n*** Table.testLittleMethods...");
        verbose = true;
        reallyVerbose = true;

        //isValid   and findColumnNumber   and subset
        Table table = getTestTable(true, true);
        table.ensureValid(); //throws Exception if not
        Test.ensureEqual(table.findColumnNumber("Time"), 0, "");
        Test.ensureEqual(table.findColumnNumber("String Data"), 9, "");
        Test.ensureEqual(table.findColumnNumber("zz"), -1, "");

      
        //toString
        table = getTestTable(true, true);
        String2.log("toString: " + table.toString());

        //ensureEqual
        Table table2 = getTestTable(true, true);
        Test.ensureTrue(table.equals(table2), "test equals a");

        String2.log("intentional error:\n");
        table2.getColumn(2).setDouble(1, 100);
        Test.ensureEqual(table.equals(table2), false, "intentional notEqual b");

        String2.log("intentional error:\n");
        table2 = getTestTable(true, true);
        table2.getColumn(0).setDouble(2, 55);
        Test.ensureEqual(table.equals(table2), false, "intentional notEqual c");

        //getSubset
        /*table = getTestTable();
        table.getSubset(new int[]{table.secondsColumn},
            new double[]{stringToSeconds("2005-08-31T16:01:01")}, 
            new double[]{stringToSeconds("2005-08-31T16:01:03")});
        Test.ensureEqual(table.nRows(), 1, "getSubset a");
        Test.ensureEqual(table.nColumns(), 5, "getSubset b");
        Test.ensureEqual(table.getColumn(table.secondsColumn), new double[]{stringToSeconds("2005-08-31T16:01:02")}, "getSubset c"); 
        Test.ensureEqual(table.getColumn(table.lonColumn),     new double[]{-2}, "getSubset d"); 
        Test.ensureEqual(table.getColumn(table.latColumn),     new double[]{1.5}, "getSubset e"); 
        Test.ensureEqual(table.getColumn(3)[0], 7, "getSubset f"); 
        Test.ensureEqual(table.getColumn(4)[0], 8, "getSubset g"); 

        table = getTestTable();
        table.getSubset(new int[]{table.latColumn},
            new double[]{1.9},
            new double[]{2.1});
        Test.ensureEqual(table.nRows(), 1, "getSubset b");
        Test.ensureEqual(table.getColumn(table.latColumn), new double[]{2}, "getSubset j"); 
        */

        //calculateStats   look at array via constants and as array
        table = getTestTable(true, true);
        Test.ensureEqual(table.getColumnName(1), "Longitude", "columnNames a");
        table.setColumnName(1, "Test");
        Test.ensureEqual(table.getColumnName(1), "Test",      "columnNames b");
        table.setColumnName(1, "Longitude");
        Test.ensureEqual(table.getColumnName(1), "Longitude", "columnNames c");

        double stats[] = table.getColumn(1).calculateStats();
        Test.ensureEqual(stats[PrimitiveArray.STATS_N],    3, "calculateStats n"); 
        Test.ensureEqual(stats[PrimitiveArray.STATS_MIN], -3, "calculateStats min"); 
        Test.ensureEqual(stats[PrimitiveArray.STATS_MAX], -1, "calculateStats max"); 

        //forceLonPM180(boolean pm180)
        table = getTestTable(true, true);
        PrimitiveArray lonAr = table.getColumn(1);
        forceLonPM180(lonAr, false);
        Test.ensureEqual(lonAr.toString(), "357, 358, 359, 2147483647", "forceLonPM180f"); 
        Table.forceLonPM180(lonAr, true);
        Test.ensureEqual(lonAr.toString(), "-3, -2, -1, 2147483647", "forceLonPM180t"); 

        //clear
        table = getTestTable(true, true);
        table.clear();
        Test.ensureEqual(table.nRows(), 0, "clear a");
        Test.ensureEqual(table.nColumns(), 0, "clear b");

        //getXxxAttribute
        table = getTestTable(true, true);
        int col = table.findColumnNumber("Double Data");
        Test.ensureEqual(col, 3, "");
        Test.ensureEqual(table.globalAttributes().getString("global_att1"), "a string", "");
        Test.ensureEqual(table.globalAttributes().getString("test"), null, "");
        table.globalAttributes().set("global_att1", "new");
        Test.ensureEqual(table.globalAttributes().getString("global_att1"), "new", "");
        table.globalAttributes().remove("global_att1");
        Test.ensureEqual(table.globalAttributes().getString("global_att1"), null, "");

        Test.ensureEqual(table.columnAttributes(3).getString("units"), "doubles", "");
        table.columnAttributes(3).set("units", "new");
        Test.ensureEqual(table.columnAttributes(3).getString("units"), "new", "");
        table.columnAttributes(3).remove("units");
        Test.ensureEqual(table.columnAttributes(3).getString("units"), null, "");
        Test.ensureEqual(table.getDoubleData(3,1), 3.123, "");
        Test.ensureEqual(table.getStringData(3,1), "3.123", "");
        table.setColumnName(3, "new3");
        Test.ensureEqual(table.getColumnName(3), "new3", "");

        //sort
        table.sort(new int[]{3}, new boolean[]{false});
        Test.ensureEqual(table.getColumn(2).toString(), "NaN, 2.0, 1.5, 1.0", "");
        Test.ensureEqual(table.getColumn(3).toString(), "NaN, 1.0E300, 3.123, -1.0E300", "");

        //removeColumn
        table.removeColumn(3);
        Test.ensureEqual(table.getColumn(3).toString(), "9223372036854775807, 2000000000000000, 2, -2000000000000000", "");
        Test.ensureEqual(table.getColumnName(3), "Long Data", "");
        Test.ensureEqual(table.columnAttributes(3).getString("units"), "longs", "");

        //addColumn
        table.addColumn(3, "test3", new IntArray(new int[]{10,20,30,Integer.MAX_VALUE}));
        Test.ensureEqual(table.getColumn(3).toString(), "10, 20, 30, 2147483647", "");
        Test.ensureEqual(table.getColumnName(3), "test3", "");        
        Test.ensureEqual(table.getColumn(4).toString(), "9223372036854775807, 2000000000000000, 2, -2000000000000000", "");
        Test.ensureEqual(table.getColumnName(4), "Long Data", "");
        Test.ensureEqual(table.columnAttributes(4).getString("units"), "longs", "");

        //append
        table.append(table);
        Test.ensureEqual(table.getColumn(4).toString(), 
            "9223372036854775807, 2000000000000000, 2, -2000000000000000, 9223372036854775807, 2000000000000000, 2, -2000000000000000", "");
        Test.ensureEqual(table.getColumnName(4), "Long Data", "");
        Test.ensureEqual(table.columnAttributes(4).getString("units"), "longs", "");

        //average
        table = new Table();
        DoubleArray da = new DoubleArray(new double[]{10,20,30,40,50});
        table.addColumn("a", da);
        da = new DoubleArray(new double[]{0,0,1,2,2});
        table.addColumn("b", da);
        table.average(new int[]{1});
        Test.ensureEqual(table.getColumn(0).toString(), "15.0, 30.0, 45.0", "");
        Test.ensureEqual(table.getColumn(1).toString(), "0.0, 1.0, 2.0", "");

    } 

    /** Test join(). **/
    public static void testJoin() {

        //*** testJoin 1
        String2.log("\n*** Table.testJoin 1 column");
        Table table = new Table();
        table.addColumn("zero", PrimitiveArray.csvFactory(PAType.STRING, "a,b,c,d,,e"));
        table.addColumn("one",  PrimitiveArray.csvFactory(PAType.INT, "40,10,12,30,,20"));
        table.addColumn("two",  PrimitiveArray.csvFactory(PAType.STRING, "aa,bb,cc,dd,,ee"));
        table.columnAttributes(0).add("long_name", "hey zero");
        table.columnAttributes(1).add("missing_value", -99999);
        table.columnAttributes(2).add("long_name", "hey two");
        
        Table lut = new Table();
        lut.addColumn("aa", PrimitiveArray.csvFactory(PAType.INT, "10,20,30,40"));
        lut.addColumn("bb", PrimitiveArray.csvFactory(PAType.STRING, "11,22,33,44"));
        lut.addColumn("cc", PrimitiveArray.csvFactory(PAType.LONG, "111,222,333,444"));
        lut.columnAttributes(0).add("missing_value", -99999);
        lut.columnAttributes(1).add("long_name", "hey bb");
        lut.columnAttributes(2).add("missing_value", -9999999L);

        //test lut before join
        String results = lut.toString();
        String expectedLut = 
"{\n" +
"dimensions:\n" +
"\trow = 4 ;\n" +
"\tbb_strlen = 2 ;\n" +
"variables:\n" +
"\tint aa(row) ;\n" +
"\t\taa:missing_value = -99999 ;\n" +
"\tchar bb(row, bb_strlen) ;\n" +
"\t\tbb:long_name = \"hey bb\" ;\n" +
"\tlong cc(row) ;\n" +
"\t\tcc:missing_value = -9999999 ;\n" +
"\n" +
"// global attributes:\n" +
"}\n" +
"aa,bb,cc\n" +
"10,11,111\n" +
"20,22,222\n" +
"30,33,333\n" +
"40,44,444\n";
        Test.ensureEqual(results, expectedLut, "lut results=\n" + results);

        //do the join
        table.join(1, 1, "10", lut);

        results = table.toString();
        String expected = 
"{\n" +
"dimensions:\n" +
"\trow = 6 ;\n" +
"\tzero_strlen = 1 ;\n" +
"\tbb_strlen = 2 ;\n" +
"\ttwo_strlen = 2 ;\n" +
"variables:\n" +
"\tchar zero(row, zero_strlen) ;\n" +
"\t\tzero:long_name = \"hey zero\" ;\n" +
"\tint one(row) ;\n" +
"\t\tone:missing_value = -99999 ;\n" +
"\tchar bb(row, bb_strlen) ;\n" +
"\t\tbb:long_name = \"hey bb\" ;\n" +
"\tlong cc(row) ;\n" +
"\t\tcc:missing_value = -9999999 ;\n" +
"\tchar two(row, two_strlen) ;\n" +
"\t\ttwo:long_name = \"hey two\" ;\n" +
"\n" +
"// global attributes:\n" +
"}\n" +
"zero,one,bb,cc,two\n" +
"a,40,44,444,aa\n" +
"b,10,11,111,bb\n" +
"c,12,,-9999999,cc\n" +
"d,30,33,333,dd\n" +
",,11,111,\n" +
"e,20,22,222,ee\n";
        Test.ensureEqual(results, expected, "join 1 results=\n" + results);

        //ensure lut unchanged
        results = lut.toString();
        Test.ensureEqual(results, expectedLut, "lut 1 results=\n" + results);


        //*** testJoin 2 columns
        String2.log("\n*** Table.testJoin 2 columns");
        table = new Table();
        table.addColumn("zero", PrimitiveArray.csvFactory(PAType.STRING, "a,b,c,d,,e"));
        table.addColumn("one",  PrimitiveArray.csvFactory(PAType.INT, "40,10,12,30,,20"));
        table.addColumn("two",  PrimitiveArray.csvFactory(PAType.STRING, "44,bad,1212,33,,22"));
        table.addColumn("three",PrimitiveArray.csvFactory(PAType.STRING, "aaa,bbb,ccc,ddd,,eee"));
        table.columnAttributes(0).add("long_name", "hey zero");
        table.columnAttributes(1).add("missing_value", -99999);
        table.columnAttributes(2).add("long_name", "hey two");
        table.columnAttributes(3).add("long_name", "hey three");

        //do the join
        table.join(2, 1, "10\t11", lut);

        results = table.toString();
        expected = 
"{\n" +
"dimensions:\n" +
"\trow = 6 ;\n" +
"\tzero_strlen = 1 ;\n" +
"\ttwo_strlen = 4 ;\n" +
"\tthree_strlen = 3 ;\n" +
"variables:\n" +
"\tchar zero(row, zero_strlen) ;\n" +
"\t\tzero:long_name = \"hey zero\" ;\n" +
"\tint one(row) ;\n" +
"\t\tone:missing_value = -99999 ;\n" +
"\tchar two(row, two_strlen) ;\n" +
"\t\ttwo:long_name = \"hey two\" ;\n" +
"\tlong cc(row) ;\n" +
"\t\tcc:missing_value = -9999999 ;\n" +
"\tchar three(row, three_strlen) ;\n" +
"\t\tthree:long_name = \"hey three\" ;\n" +
"\n" +
"// global attributes:\n" +
"}\n" +
"zero,one,two,cc,three\n" +
"a,40,44,444,aaa\n" +
"b,10,bad,-9999999,bbb\n" +
"c,12,1212,-9999999,ccc\n" +
"d,30,33,333,ddd\n" +
",,,111,\n" + 
"e,20,22,222,eee\n";
        Test.ensureEqual(results, expected, "join 2 results=\n" + results);

        //ensure lut unchanged
        results = lut.toString();
        Test.ensureEqual(results, expectedLut, "lut 2 results=\n" + results);
    }

    /** test update() */
    public static void testUpdate() throws Exception {
        Table table = new Table();
        table.addColumn("zero", PrimitiveArray.csvFactory(PAType.STRING, "a,    b,  c,  d,   ,  e"));
        table.addColumn("one",  PrimitiveArray.csvFactory(PAType.INT,    "10,  20, 30, 40,   , 50"));
        table.addColumn("two",  PrimitiveArray.csvFactory(PAType.INT,    "111,222,333,444,-99,555"));
        table.addColumn("three",PrimitiveArray.csvFactory(PAType.DOUBLE, "1.1,2.2,3.3,4.4,4.6,5.5"));
        table.columnAttributes(2).add("missing_value", -99);

        //otherTable rows: matches, matches, partial match, new
        //otherTable cols: keys, matches (but different type), doesn't match
        Table otherTable = new Table(); 
        otherTable.addColumn("one",  PrimitiveArray.csvFactory(PAType.INT,    " 50,   , 11,  5"));
        otherTable.addColumn("zero", PrimitiveArray.csvFactory(PAType.STRING, "  e,   ,  a,  f"));
        otherTable.addColumn("three",PrimitiveArray.csvFactory(PAType.INT,    " 11, 22, 33, 44"));
        otherTable.addColumn("five", PrimitiveArray.csvFactory(PAType.INT,    "  1,  2,  3,  4"));

        int nMatched = table.update(new String[]{"zero", "one"}, otherTable);
        String results = table.dataToString();
        String expected = 
"zero,one,two,three\n" +
"a,10,111,1.1\n" +
"b,20,222,2.2\n" +
"c,30,333,3.3\n" +
"d,40,444,4.4\n" +
",,-99,22.0\n" +  
"e,50,555,11.0\n" +
"a,11,-99,33.0\n" + //-99 is from missing_value
"f,5,-99,44.0\n";   //-99 is from missing_value
        Test.ensureEqual(results, expected, "update results=\n" + results);
        Test.ensureEqual(nMatched, 2, "nMatched");

    }

    public static void testReorderColumns() throws Exception {
        String2.log("\n*** Table.testReorderColumns");
        Table table = new Table();
        table.addColumn("ints", new IntArray());
        table.addColumn("floats", new FloatArray());
        table.addColumn("doubles", new DoubleArray());

        StringArray newOrder = new StringArray(new String[]{
            "hubert", "floats", "doubles", "zztop"});
        table.reorderColumns(newOrder, false);  
        String results = String2.toCSSVString(table.getColumnNames());
        String expected = "floats, doubles, ints";
        Test.ensureEqual(results, expected, "results=" + results);

        newOrder = new StringArray(new String[]{
            "ints", "doubles"});
        table.reorderColumns(newOrder, true);  //discard columns not in list
        results = String2.toCSSVString(table.getColumnNames());
        expected = "ints, doubles";
        Test.ensureEqual(results, expected, "results=" + results);
    }

    public static void testLastRowWithData() throws Exception {
        String2.log("\n*** Table.testLastRowWithData");
        boolean oDebug = debugMode;
        debugMode = true;
        Table table = new Table();
        String results, expected;
        Attributes iAtts = new Attributes(); iAtts.add("missing_value", 99); 
                                             iAtts.add("_FillValue", 999);
        Attributes fAtts = new Attributes(); fAtts.add("_FillValue", -99f);
        Attributes dAtts = new Attributes(); dAtts.add("_FillValue", -99.0);
        Attributes sAtts = new Attributes(); sAtts.add("_FillValue", "99");

        IntArray    ia = (IntArray)new IntArray(  new int[]    {1,   99,  999, Integer.MAX_VALUE}).setMaxIsMV(true);
        FloatArray  fa = new FloatArray(new float[]  {2,   -99, -99, Float.NaN});
        DoubleArray da = new DoubleArray(new double[]{3,   -99, -99, Double.NaN});
        StringArray sa = new StringArray(new String[]{"4", null,"99",""});

        table.clear();
        table.addColumn(0, "i", ia, iAtts);
        Test.ensureEqual(table.lastRowWithData(), 0, "");

        table.clear();
        table.addColumn(0, "f", fa, fAtts);
        Test.ensureEqual(table.lastRowWithData(), 0, "");

        table.clear();
        table.addColumn(0, "d", da, dAtts);
        Test.ensureEqual(table.lastRowWithData(), 0, "");

        table.clear();
        table.addColumn(0, "s", sa, sAtts);
        Test.ensureEqual(table.lastRowWithData(), 0, "");

        table.clear();
        table.addColumn(0, "i", ia, iAtts);
        table.addColumn(1, "f", fa, fAtts);
        table.addColumn(2, "d", da, dAtts);
        table.addColumn(3, "s", sa, sAtts);
        Test.ensureEqual(table.lastRowWithData(), 0, "");

        //***
        String2.log("\n*** Table.testRemoveRowsWithoutData");
        table.clear();
        table.addColumn(0, "i", ia, iAtts);        
        Test.ensureEqual(table.removeRowsWithoutData(), 1, "");

        table.clear();
        table.addColumn(0, "f", fa, fAtts);
        Test.ensureEqual(table.removeRowsWithoutData(), 1, "");

        table.clear();
        table.addColumn(0, "d", da, dAtts);
        Test.ensureEqual(table.removeRowsWithoutData(), 1, "");

        table.clear();
        table.addColumn(0, "s", sa, sAtts);
        Test.ensureEqual(table.removeRowsWithoutData(), 1, "");

        table.clear();
        table.addColumn(0, "i", ia, iAtts);
        table.addColumn(1, "f", fa, fAtts);
        table.addColumn(2, "d", da, dAtts);
        table.addColumn(3, "s", sa, sAtts);
        //good: original row +
        //      hi                                                     5             there
        ia.add(99);   ia.add(999);   ia.add(Integer.MAX_VALUE); ia.add(99);  ia.add(999);
        fa.add(-99);  fa.add(-99);   fa.add(Float.NaN);         fa.add(-99); fa.add(-99);
        da.add(-99);  da.add(-99);   da.add(Double.NaN);        da.add(5);   da.add(-99);
        sa.add("hi"); sa.add("99");  sa.add("");                sa.add("");  sa.add("there");
        table.removeRowsWithoutData();
        results = table.dataToString();
expected = 
"i,f,d,s\n" +
"1,2.0,3.0,4\n" +
"99,-99.0,-99.0,hi\n" +
"99,-99.0,5.0,\n" +
"999,-99.0,-99.0,there\n";
        Test.ensureEqual(results, expected, "results=" + results);

        debugMode = oDebug;

    }

    /** 
     * This tests reading data from a ncCF multidimensional dataset
     * where the dimensions are in the discouraged order (e.g., var[time][station]).
     * Very large test file has discharge[time=758001][station=18]  4vars[station=18],
     *   so when flattened 758001 * 18 * 5vars * 8bytes =~545MB
     * + 2 indexColumns: 758001 * 18 * 2vars * 4bytes =~109MB
     *
     * @param readAsNcCF if true, this reads the file via readNcCF.
     *   If false, this reads the file via readMultidimNc
     */
    public static void testReadNcCFMATimeSeriesReversed(boolean readAsNcCF) throws Exception {
        String2.log("\n*** Table.testReadNcCFMATimeSeriesReversed readAsNcCF=" + readAsNcCF);
        //time is days since 2006-01-01 00:00:00.  file has  2007-10-01T04 through 2013-11-14T17:06
        boolean oDebug = debugMode;
        debugMode = true;
        Table table = new Table();
        String results, expected;
        long time; 
        //was "/data/hunter/USGS_DISCHARGE_STATIONS_SUBSET.nc"
        String fileName = String2.unitTestBigDataDir + "nccf/MATimeSeriesReversedDim.nc"; 
        String2.log(NcHelper.ncdump(fileName, "-h"));

/* */
        //               read all vars  when obs is constrained
        String2.log("\n* read all vars  when obs is constrained");
        time = System.currentTimeMillis();
        if (readAsNcCF)
            table.readNcCF(fileName, 
                null, //all vars
                0,  //standardizeWhat=0
                StringArray.fromCSV("time"), StringArray.fromCSV(">"), StringArray.fromCSV("3426.69"));
        else 
            table.readMultidimNc(fileName, 
                null, null, null, //read default dimensions
                true, 0, true, //getMetadata, standardizeWhat, removeMVRows,
                StringArray.fromCSV("time"), StringArray.fromCSV(">"), StringArray.fromCSV("3426.69"));
        String2.log("time=" + (System.currentTimeMillis() - time) + "ms");
        results = table.dataToString();
        expected = 
//EEK! I don't think they should be different.
//I think readMultidimNc is correct, because the -99999.0 values are from
//rows with earlier time than valid data rows from same station at later time.
//I think readNcCF is too aggressive at removing MV rows.
"discharge,station,time,longitude,latitude\n" +
(readAsNcCF? "" : 
"-99999.0,1327750.0,3426.691666666651,-73.5958333,43.26944444\n") +
"80.98618241999999,1327750.0,3426.6979166667443,-73.5958333,43.26944444\n" + //same station, later time
(readAsNcCF? "" : 
"-99999.0,1357500.0,3426.691666666651,-73.7075,42.78527778\n") +
"181.2278208,1357500.0,3426.6979166667443,-73.7075,42.78527778\n" + //same station, later time
"183.77633703,1357500.0,3426.708333333372,-73.7075,42.78527778\n" +
"-56.06735706,1484085.0,3426.691666666651,-75.3976111,39.05830556\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //               just read station vars (all stations)  no constraints
        String2.log("\n* just read station vars (all stations)  no constraints");
        time = System.currentTimeMillis();
        if (readAsNcCF)
            table.readNcCF(fileName, 
                StringArray.fromCSV("station,latitude,longitude"), 
                0,  //standardizeWhat=0
                null, null, null);
        else
            table.readMultidimNc(fileName, 
                StringArray.fromCSV("station,latitude,longitude"), 
                null, //dimensions
                null, //treatDimensionsAs
                true, 0, true, //getMetadata, standardizeWhat, removeMVRows,
                null, null, null);
        String2.log("time=" + (System.currentTimeMillis() - time) + "ms");
        results = table.dataToString();
        expected = 
"station,latitude,longitude\n" +
"1463500.0,40.22166667,-74.7780556\n" +
"1389500.0,40.8847222,-74.2261111\n" +
"1327750.0,43.26944444,-73.5958333\n" +
"1357500.0,42.78527778,-73.7075\n" +
"1403060.0,40.5511111,-74.5483333\n" +
"1474500.0,39.9678905,-75.1885123\n" +
"1477050.0,39.83677934,-75.36630199\n" +
"1480120.0,39.7362245,-75.540172\n" +
"1481500.0,39.7695,-75.5766944\n" +
"1480065.0,39.71063889,-75.6087222\n" +
"1480015.0,39.71575,-75.6399444\n" +
"1482170.0,39.65680556,-75.562\n" +
"1482800.0,39.5009454,-75.5682589\n" +
"1413038.0,39.3836111,-75.35027778\n" +
"1412150.0,39.23166667,-75.0330556\n" +
"1411435.0,39.16166667,-74.8319444\n" +
"1484085.0,39.05830556,-75.3976111\n" +
"1484080.0,39.01061275,-75.45794828\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //               just read station vars (a few stations because lat is constrained)
        String2.log("\n* just read station vars (a few stations because lat is constrained)");
        time = System.currentTimeMillis();
        if (readAsNcCF)
            table.readNcCF(fileName, 
                StringArray.fromCSV("station,latitude,longitude"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("latitude"), StringArray.fromCSV("<"), StringArray.fromCSV("39.1"));
        else 
            table.readMultidimNc(fileName, 
                StringArray.fromCSV("station,latitude,longitude"), 
                null, null, //dimensions, treatDimensionsAs
                true, 0, true, //getMetadata, standardizeWhat, removeMVRows,
                StringArray.fromCSV("latitude"), StringArray.fromCSV("<"), StringArray.fromCSV("39.1"));
        String2.log("time=" + (System.currentTimeMillis() - time) + "ms");
        results = table.dataToString();
        expected = 
"station,latitude,longitude\n" +
"1484085.0,39.05830556,-75.3976111\n" +
"1484080.0,39.01061275,-75.45794828\n";
        Test.ensureEqual(results, expected, "results=\n" + results);


        //               just read obs vars  (obs is constrained)
        String2.log("\n* just read obs vars  (obs is constrained)");
        time = System.currentTimeMillis();
        if (readAsNcCF)
            table.readNcCF(fileName, 
                StringArray.fromCSV("time,discharge"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("discharge"), StringArray.fromCSV(">"), StringArray.fromCSV("5400"));
        else
            table.readMultidimNc(fileName, 
                StringArray.fromCSV("time,discharge"), 
                null, null, //dimensions, treatDimensionsAs
                true, 0, true, //getMetadata, standardizeWhat, removeMVRows,
                StringArray.fromCSV("discharge"), StringArray.fromCSV(">"), StringArray.fromCSV("5400"));
        String2.log("time=" + (System.currentTimeMillis() - time) + "ms");
        results = table.dataToString();
        expected = 
"time,discharge\n" +
"2076.5,5408.517777\n" +
"2076.510416666628,5465.151471\n" +
"2076.5208333332557,5493.468318\n" +
"2076.53125,5521.785165\n" +
"2076.541666666628,5521.785165\n" +
"2076.5520833332557,5521.785165\n" +
"2076.5625,5521.785165\n" +
"2076.572916666628,5521.785165\n" +
"2076.5833333332557,5493.468318\n" +
"2076.59375,5465.151471\n" +
"2076.604166666628,5436.834624\n" +
"2076.6145833332557,5408.517777\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        
        //               read all vars when station is constrained, 
        String2.log("\n* read all vars when station is constrained");
        time = System.currentTimeMillis();
        if (readAsNcCF)
            table.readNcCF(fileName, 
                StringArray.fromCSV("station,latitude,longitude,time,discharge"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station"), StringArray.fromCSV("="), StringArray.fromCSV("1463500.0"));
        else 
            table.readMultidimNc(fileName, 
                StringArray.fromCSV("station,latitude,longitude,time,discharge"), 
                null, null, //dimensions, treatDimensionsAs
                true, 0, true, //getMetadata, standardizeWhat, removeMVRows,
                StringArray.fromCSV("station"), StringArray.fromCSV("="), StringArray.fromCSV("1463500.0"));
        String2.log("time=" + (System.currentTimeMillis() - time) + "ms");
        results = table.dataToString();
        expected = 
//EEK! Again, readMultidimNc has additional rows with discharge=MV.
//I think readMultidimNc is correct.
"station,latitude,longitude,time,discharge\n" +
"1463500.0,40.22166667,-74.7780556,638.1666666666279,92.02975275\n" +
"1463500.0,40.22166667,-74.7780556,638.1770833332557,92.02975275\n" +
"1463500.0,40.22166667,-74.7780556,638.1875,92.02975275\n" +
"1463500.0,40.22166667,-74.7780556,638.1979166666279,92.87925815999999\n" +
"1463500.0,40.22166667,-74.7780556,638.2083333332557,93.72876357\n" +
(readAsNcCF? "" : 
"1463500.0,40.22166667,-74.7780556,638.2083333333721,-99999.0\n" +
"1463500.0,40.22166667,-74.7780556,638.2125000000233,-99999.0\n" +
"1463500.0,40.22166667,-74.7780556,638.2166666666744,-99999.0\n") +
"1463500.0,40.22166667,-74.7780556,638.21875,93.72876357\n" +
(readAsNcCF? "" : 
"1463500.0,40.22166667,-74.7780556,638.2208333333256,-99999.0\n" +
"1463500.0,40.22166667,-74.7780556,638.2250000000931,-99999.0\n") +
"1463500.0,40.22166667,-74.7780556,638.2291666666279,94.86143745\n" +
(readAsNcCF? "" : 
"1463500.0,40.22166667,-74.7780556,638.2291666667443,-99999.0\n" +
"1463500.0,40.22166667,-74.7780556,638.2333333333954,-99999.0\n" +
"1463500.0,40.22166667,-74.7780556,638.2375000000466,-99999.0\n") +
"1463500.0,40.22166667,-74.7780556,638.2395833332557,95.71094286\n";  //stop there
        results = results.substring(0, expected.length());
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), readAsNcCF? 256610 : 757994, "wrong nRows");

        //               read all data 
        String2.log("\n* read all data");
        time = System.currentTimeMillis();
        if (readAsNcCF)
            table.readNcCF(fileName, 
                null, 0,  //standardizeWhat=0
                null, null, null);
        else
            table.readMultidimNc(fileName, 
                null, null, null, //read all dimensions
                true, 0, true, //getMetadata, standardizeWhat, removeMVRows,
                null, null, null);
        String2.log("time=" + (System.currentTimeMillis() - time) + "ms");
        results = table.dataToString(10);
        expected = 
readAsNcCF?
"discharge,station,time,longitude,latitude\n" +
"92.02975275,1463500.0,638.1666666666279,-74.7780556,40.22166667\n" +
"92.02975275,1463500.0,638.1770833332557,-74.7780556,40.22166667\n" +
"92.02975275,1463500.0,638.1875,-74.7780556,40.22166667\n" +
"92.87925815999999,1463500.0,638.1979166666279,-74.7780556,40.22166667\n" +
"93.72876357,1463500.0,638.2083333332557,-74.7780556,40.22166667\n" +
"93.72876357,1463500.0,638.21875,-74.7780556,40.22166667\n" +
"94.86143745,1463500.0,638.2291666666279,-74.7780556,40.22166667\n" +
"95.71094286,1463500.0,638.2395833332557,-74.7780556,40.22166667\n" +
"95.71094286,1463500.0,638.25,-74.7780556,40.22166667\n" +
"95.71094286,1463500.0,638.2604166666279,-74.7780556,40.22166667\n" +
"...\n" :
"discharge,station,time,longitude,latitude\n" +
"92.02975275,1463500.0,638.1666666666279,-74.7780556,40.22166667\n" +
"92.02975275,1463500.0,638.1770833332557,-74.7780556,40.22166667\n" +
"92.02975275,1463500.0,638.1875,-74.7780556,40.22166667\n" +
"92.87925815999999,1463500.0,638.1979166666279,-74.7780556,40.22166667\n" +
"93.72876357,1463500.0,638.2083333332557,-74.7780556,40.22166667\n" +
"-99999.0,1463500.0,638.2083333333721,-74.7780556,40.22166667\n" +
"-99999.0,1463500.0,638.2125000000233,-74.7780556,40.22166667\n" +
"-99999.0,1463500.0,638.2166666666744,-74.7780556,40.22166667\n" +
"93.72876357,1463500.0,638.21875,-74.7780556,40.22166667\n" +
"-99999.0,1463500.0,638.2208333333256,-74.7780556,40.22166667\n" +
"...\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        Test.ensureEqual(table.nRows(), readAsNcCF? 2315617 : 7539127, "wrong nRows");


        //               read all vars when obs is constrained, 
        String2.log("\n* read all vars when obs is constrained");
        time = System.currentTimeMillis();
        if (readAsNcCF)
            table.readNcCF(fileName, 
                StringArray.fromCSV("station,latitude,longitude,time,discharge"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("discharge"), StringArray.fromCSV(">"), StringArray.fromCSV("5400"));
        else 
            table.readMultidimNc(fileName, 
                StringArray.fromCSV("station,latitude,longitude,time,discharge"), 
                null, null, //dimensions, treatDimensionsAs
                true, 0, true, //getMetadata, standardizeWhat, removeMVRows,
                StringArray.fromCSV("discharge"), StringArray.fromCSV(">"), StringArray.fromCSV("5400"));
        String2.log("time=" + (System.currentTimeMillis() - time) + "ms");
        results = table.dataToString();
        expected = 
"station,latitude,longitude,time,discharge\n" +
"1463500.0,40.22166667,-74.7780556,2076.5,5408.517777\n" +
"1463500.0,40.22166667,-74.7780556,2076.510416666628,5465.151471\n" +
"1463500.0,40.22166667,-74.7780556,2076.5208333332557,5493.468318\n" +
"1463500.0,40.22166667,-74.7780556,2076.53125,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.541666666628,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.5520833332557,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.5625,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.572916666628,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.5833333332557,5493.468318\n" +
"1463500.0,40.22166667,-74.7780556,2076.59375,5465.151471\n" +
"1463500.0,40.22166667,-74.7780556,2076.604166666628,5436.834624\n" +
"1463500.0,40.22166667,-74.7780556,2076.6145833332557,5408.517777\n";
        Test.ensureEqual(results, expected, "results=\n" + results);

        //               read all vars when station and obs are constrained, 
        String2.log("\n* read all vars when station and obs are constrained");
        time = System.currentTimeMillis();
        if (readAsNcCF)
            table.readNcCF(fileName, 
                StringArray.fromCSV("station,latitude,longitude,time,discharge"), 
                0,  //standardizeWhat=0
                StringArray.fromCSV("station,discharge"), StringArray.fromCSV("=,>"), StringArray.fromCSV("1463500.0,5400"));
        else 
            table.readMultidimNc(fileName, 
                StringArray.fromCSV("station,latitude,longitude,time,discharge"), 
                null, null, //dimensions, treatDimensionsAs
                true, 0, true, //getMetadata, standardizeWhat, removeMVRows,
                StringArray.fromCSV("station,discharge"), StringArray.fromCSV("=,>"), StringArray.fromCSV("1463500.0,5400"));
        String2.log("time=" + (System.currentTimeMillis() - time) + "ms");
        results = table.dataToString();
        expected = 
"station,latitude,longitude,time,discharge\n" +
"1463500.0,40.22166667,-74.7780556,2076.5,5408.517777\n" +
"1463500.0,40.22166667,-74.7780556,2076.510416666628,5465.151471\n" +
"1463500.0,40.22166667,-74.7780556,2076.5208333332557,5493.468318\n" +
"1463500.0,40.22166667,-74.7780556,2076.53125,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.541666666628,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.5520833332557,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.5625,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.572916666628,5521.785165\n" +
"1463500.0,40.22166667,-74.7780556,2076.5833333332557,5493.468318\n" +
"1463500.0,40.22166667,-74.7780556,2076.59375,5465.151471\n" +
"1463500.0,40.22166667,-74.7780556,2076.604166666628,5436.834624\n" +
"1463500.0,40.22166667,-74.7780556,2076.6145833332557,5408.517777\n";
        Test.ensureEqual(results, expected, "results=\n" + results);
        debugMode = oDebug;

    }


    /**
     * Parse the orderByCsv string into an array of strings. If the final string begins with a number (eg. 2days)
     * it is appended to the last field eg, time/2days.
     * @param tOrderByCsv from the query
     * @return an array of strings representing the column names.
     */
    public static String[] parseOrderByColumnNamesCsvString(final String errorMessage, final String tOrderByCsv) {
        if ((tOrderByCsv == null || tOrderByCsv.trim().length() == 0))
            throw new SimpleException(QUERY_ERROR + errorMessage +
                " (no csv)");
        String[] cols = String2.split(tOrderByCsv, ',');
        // filter out the blanks.
        cols =  Arrays.stream(cols).filter(value -> value.trim().length() > 0).toArray(size -> new String[size]);
        if (cols.length == 0)
            throw new SimpleException(QUERY_ERROR + errorMessage +
                " (csv.length=0)");

        // support the old format where interval was the last field.
        if (cols.length > 1 && cols[cols.length-1].trim().matches("^\\d")) {
            cols[cols.length - 2] += "/" + cols[cols.length-1];
            cols = Arrays.copyOf(cols, cols.length - 1);
        }
        return cols;
    }

    private static String[] splitColNameForRounders(String colName) {
        String split[] = colName.split("/",2); // split on '/'
        Arrays.stream(split).forEach(s -> s.trim()); // remove outer whitespace
        return Arrays.stream(split).filter( s -> s.length() > 0).toArray(size -> new String[size]); // discard blanks.
    }

    /**
     * Derive the actual column names by removing the rounding part eg time/1day =&gt; time.
     * @param keyColumnNames
     * @return
     */
    public static String[] deriveActualColumnNames(String[] keyColumnNames) {
        final String[] actualKeyColumnNames = new String[keyColumnNames.length];
        for(int i=0;i<keyColumnNames.length;i++) {
            actualKeyColumnNames[i] = deriveActualColumnName(keyColumnNames[i]);
        }
        return actualKeyColumnNames;
    }

    public static String deriveActualColumnName(String colName) {
        return splitColNameForRounders(colName)[0];
    }

    private final static Pattern alphaPattern = Pattern.compile("\\p{Alpha}");

    public static Table.Rounder createRounder(final String responsible, final String param) {
        String[] split = splitColNameForRounders(param);
        if (split.length == 1) {
            return (d)->(d); // nothing to be done.
        }
        String str = split[1];
        try {
            str = str.replaceAll("\\s", "");
            String[] parts = str.split(":",2);
            Matcher alphaMatcher = alphaPattern.matcher(parts[0]);
            if (alphaMatcher.find()) { // eg: 2days.
                if (parts.length == 2) {
                    throw new IllegalArgumentException(Table.QUERY_ERROR + responsible +
                        " could not parse " + param + ". (Offset not allowed with date intervals.)");
                }
                return createTimeRounder(responsible, str, param);
            } else {
                final double numberOfUnits = Double.parseDouble(parts[0]);
                if (parts.length == 2) {
                    final double offset = Double.parseDouble(parts[1]);
                    return (d)->(Math.floor((d-offset)  / numberOfUnits));
                }
                return (d)->(Math.floor(d  / numberOfUnits));
            }
        }catch(IllegalArgumentException e) {
            throw e;
        }catch(Throwable t) {
            throw new IllegalArgumentException(Table.QUERY_ERROR + responsible + 
                " could not parse " + param + ". (Format should be variable[/interval[:offset]] )");
        }
    }


    private static Table.Rounder createTimeRounder(final String responsible, String str, String param) {
        final double[] numberTimeUnits = Calendar2.parseNumberTimeUnits(str); //throws RuntimeException if trouble
        if (numberTimeUnits[0] <= 0 || numberTimeUnits[1] <= 0)
            throw new IllegalArgumentException(Table.QUERY_ERROR + responsible +
                " could not parse " + param + ". (numberTimeUnits values must be positive numbers)");
        final double simpleInterval = numberTimeUnits[0] * numberTimeUnits[1];
        final int field =
            numberTimeUnits[1] ==  30 * Calendar2.SECONDS_PER_DAY? Calendar2.MONTH :
            numberTimeUnits[1] == 360 * Calendar2.SECONDS_PER_DAY? Calendar2.YEAR : //but see getYear below
            Integer.MAX_VALUE;
        final int intNumber = Math2.roundToInt(numberTimeUnits[0]); //used for Month and Year
        if (field != Integer.MAX_VALUE &&
            (intNumber < 1 || intNumber != numberTimeUnits[0]))
            throw new IllegalArgumentException(Table.QUERY_ERROR + responsible +
                " could not parse " + param + ". (The number of months or years must be a positive integer.)");
        if (field == Calendar2.MONTH && (intNumber == 5 || intNumber > 6))
            throw new IllegalArgumentException(Table.QUERY_ERROR + responsible +
                " could not parse " + param + ". (The number of months must be one of 1,2,3,4, or 6.)");

        if (field == Integer.MAX_VALUE) {
            return (d) -> d - d % simpleInterval;
        }else {
            return (d) -> {
                GregorianCalendar gc = Calendar2.epochSecondsToGc(d);
                Calendar2.clearSmallerFields(gc, field);
                while ((field == Calendar2.YEAR? Calendar2.getYear(gc) : gc.get(field)) % intNumber != 0)
                     gc.add(field, -1);
                return Calendar2.gcToEpochSeconds(gc);
            };
        }
    }

    /** 
     * This tests reading a very large TSV file: 764MB before .gz, 52MB after .gz,
     * 33 columns, 3503266 rows.
     * I switched to StringHolder in StringArray after complaints this file took ~10GB to load.
     * I also made several other significant memory saving changes.
     * Now, reading the file into StringArray ~1600MB is the high point.
     * While parsing the lines, it shrinks to ~671MB (lots of small strings).
     * After convert to binary data types: ~420MB.
     * Total time to read and ingest=~33s from gz file  (was ~420s before). 
     */
    public static void testBigAscii() throws Exception {
        PrimitiveArray.reallyVerbose = true;
        Math2.gcAndWait(); Math2.gcAndWait(); 
        String2.log("\n*** Table.testBigAscii(): " + Math2.memoryString());

        Table table = new Table();
        long time = System.currentTimeMillis();
        table.readASCII("/data/biddle/3937_v1_CTD_Profiles.tsv.gz");
        time = System.currentTimeMillis() - time;
        Math2.gcAndWait(); Math2.gcAndWait(); String2.log(" done. " + Math2.memoryString() + "\n" +
            String2.canonicalStatistics());  //in a test
        String results = table.dataToString(4);
        String2.log(results);
        String expected = 
"cruise_name,station,cast,ISO_DateTime,Year,Month,Day,timeutc,lon,lat,depth_max,pres_max,Date,timecode,HOT_summary_file_name,parameters,num_bottles,section,nav_code,depth_hgt,EXPOCODE,Ship,comments,CTDPRS,CTDTMP,CTDSAL,CTDOXY,XMISS,CHLPIG,NUMBER,NITRATE,FLUOR,QUALT1\n" +
"001,2,1,1988-10-30T21:34:00,1988,10,30,2134,-157.9967,22.7483,4750,238,103088,BE,cruise.summaries/hot1.sum,NaN,11,PRS2,GPS,4514,32MW001_1,32MW001/1,NaN,0.0,26.2412,35.2615,183.2,4.99,-0.0126,0,,,666666\n" +
"001,2,1,1988-10-30T21:34:00,1988,10,30,2134,-157.9967,22.7483,4750,238,103088,BE,cruise.summaries/hot1.sum,NaN,11,PRS2,GPS,4514,32MW001_1,32MW001/1,NaN,2.0,26.2412,35.2615,183.2,4.99,-0.0126,36,,,222322\n" +
"001,2,1,1988-10-30T21:34:00,1988,10,30,2134,-157.9967,22.7483,4750,238,103088,BE,cruise.summaries/hot1.sum,NaN,11,PRS2,GPS,4514,32MW001_1,32MW001/1,NaN,4.0,26.2554,35.2530,185.5,4.08,0.0026,72,,,223322\n" +
"001,2,1,1988-10-30T21:34:00,1988,10,30,2134,-157.9967,22.7483,4750,238,103088,BE,cruise.summaries/hot1.sum,NaN,11,PRS2,GPS,4514,32MW001_1,32MW001/1,NaN,6.0,26.2377,35.2455,204.8,3.05,0.0167,108,,,222122\n" +
"...\n";
        try {
        Test.ensureEqual(results, expected, "");        
        } catch (Exception e) {
            String2.pressEnterToContinue(MustBe.throwableToString(e));
        }

        Test.ensureEqual(table.nRows(), 3503266, "");
        Test.ensureEqual(table.nColumns(), 33, "");

        table.removeRows(0, 3503261);
        results = table.saveAsNccsv(false, true, 0, Integer.MAX_VALUE); //catchScalars, writeMetadata, firstDataRow, lastDataRow

        expected = //many vars are scalar because they're constant in last 6 rows
"*GLOBAL*,Conventions,\"COARDS, CF-1.6, ACDD-1.3, NCCSV-1.1\"\n" +
"cruise_name,*DATA_TYPE*,String\n" +
"station,*DATA_TYPE*,byte\n" +
"cast,*DATA_TYPE*,byte\n" +
"ISO_DateTime,*DATA_TYPE*,String\n" +
"Year,*DATA_TYPE*,short\n" +
"Month,*DATA_TYPE*,byte\n" +
"Day,*DATA_TYPE*,String\n" +
"timeutc,*DATA_TYPE*,String\n" +
"lon,*DATA_TYPE*,float\n" +
"lat,*DATA_TYPE*,float\n" +
"depth_max,*DATA_TYPE*,short\n" +
"pres_max,*DATA_TYPE*,short\n" +
"Date,*DATA_TYPE*,String\n" +
"timecode,*DATA_TYPE*,String\n" +
"HOT_summary_file_name,*DATA_TYPE*,String\n" +
"parameters,*DATA_TYPE*,String\n" +
"num_bottles,*DATA_TYPE*,byte\n" +
"section,*DATA_TYPE*,String\n" +
"nav_code,*DATA_TYPE*,String\n" +
"depth_hgt,*DATA_TYPE*,short\n" +
"EXPOCODE,*DATA_TYPE*,String\n" +
"Ship,*DATA_TYPE*,String\n" +
"comments,*DATA_TYPE*,String\n" +
"CTDPRS,*DATA_TYPE*,float\n" +
"CTDTMP,*DATA_TYPE*,float\n" +
"CTDSAL,*DATA_TYPE*,String\n" +
"CTDOXY,*DATA_TYPE*,String\n" +
"XMISS,*DATA_TYPE*,float\n" +
"CHLPIG,*DATA_TYPE*,String\n" +
"NUMBER,*DATA_TYPE*,String\n" +
"NITRATE,*DATA_TYPE*,float\n" +
"FLUOR,*DATA_TYPE*,double\n" +
"QUALT1,*DATA_TYPE*,String\n" +
"\n" +
"*END_METADATA*\n" +
"cruise_name,station,cast,ISO_DateTime,Year,Month,Day,timeutc,lon,lat,depth_max,pres_max,Date,timecode,HOT_summary_file_name,parameters,num_bottles,section,nav_code,depth_hgt,EXPOCODE,Ship,comments,CTDPRS,CTDTMP,CTDSAL,CTDOXY,XMISS,CHLPIG,NUMBER,NITRATE,FLUOR,QUALT1\n" +
"288,50,1,2016-11-28T17:51:00,2016,11,28,1751,-157.9373,22.7703,4705,202,112816,BE,cruise.summaries/hot288.sum,NaN,22,PRS2,GPS,4504,33KB288_1,33KB288/1,Dual T; C sensors,194.0,18.2746,34.9098,203.9,,0.0254,144,,,222192\n" +
"288,50,1,2016-11-28T17:51:00,2016,11,28,1751,-157.9373,22.7703,4705,202,112816,BE,cruise.summaries/hot288.sum,NaN,22,PRS2,GPS,4504,33KB288_1,33KB288/1,Dual T; C sensors,196.0,18.159,34.9027,203.8,,0.0257,108,,,222192\n" +
"288,50,1,2016-11-28T17:51:00,2016,11,28,1751,-157.9373,22.7703,4705,202,112816,BE,cruise.summaries/hot288.sum,NaN,22,PRS2,GPS,4504,33KB288_1,33KB288/1,Dual T; C sensors,198.0,17.9686,34.8727,203.8,,0.0257,156,,,222192\n" +
"288,50,1,2016-11-28T17:51:00,2016,11,28,1751,-157.9373,22.7703,4705,202,112816,BE,cruise.summaries/hot288.sum,NaN,22,PRS2,GPS,4504,33KB288_1,33KB288/1,Dual T; C sensors,200.0,17.8751,34.8506,201.8,,0.0248,108,,,222192\n" +
"288,50,1,2016-11-28T17:51:00,2016,11,28,1751,-157.9373,22.7703,4705,202,112816,BE,cruise.summaries/hot288.sum,NaN,22,PRS2,GPS,4504,33KB288_1,33KB288/1,Dual T; C sensors,202.0,17.7435,34.8246,202.1,,0.0248,60,,,222192\n" +
"*END_DATA*\n";
        Test.ensureEqual(results, expected, "results=\n" + results);        

        Math2.gcAndWait(); 
        String msg = Math2.memoryString() + "\n" + 
            String2.canonicalStatistics() + "\n" +
            "testBigAscii time=" + time + 
            "ms. file read time should be ~45s (but longer when computer is busy) (was 36s before v2.10)";
        String2.log(msg);
        Test.ensureTrue(time < 55000, "Too slow! " + msg); 
    }


    /**
     * This runs all of the interactive or not interactive tests for this class.
     *
     * @param errorSB all caught exceptions are logged to this.
     * @param interactive  If true, this runs all of the interactive tests; 
     *   otherwise, this runs all of the non-interactive tests.
     * @param doSlowTestsToo If true, this runs the slow tests, too.
     * @param firstTest The first test to be run (0...).  Test numbers may change.
     * @param lastTest The last test to be run, inclusive (0..., or -1 for the last test). 
     *   Test numbers may change.
     */
    public static void test(StringBuilder errorSB, boolean interactive, 
        boolean doSlowTestsToo, int firstTest, int lastTest) {
        if (lastTest < 0)
            lastTest = interactive? 2 : 67;
        String msg = "\n^^^ Table.test(" + interactive + ") test=";

        verbose = true;
        reallyVerbose = true;

        ncCFcc = new BitSet();  //turn on test of readNcCF code coverage

        for (int test = firstTest; test <= lastTest; test++) {
            try {
                long time = System.currentTimeMillis();
                String2.log(msg + test);
            
                if (interactive) {
                    if (test ==  0) testNccsvInteractive();
                    if (test ==  1) testInteractiveNcCFMA(false); //pauseAfterEach?
                    if (test ==  2) testReadAudioWriteWaveFiles(0, 1000);

                } else {
                    if (test ==  0) testLittleMethods();
                    if (test ==  1) testReorderColumns();
                    if (test ==  2) testSortColumnsByName();
                    if (test ==  3) testLastRowWithData();
                    if (test ==  4) testEnhancedFlatNcFile();
                    if (test ==  5) testOrderByMinMax(); //tests orderByMin Max MinMax
                    if (test ==  6) testOrderByClosest();
                    if (test ==  7) testOrderByCount();
                    if (test ==  8) testOrderByLimit();
                    if (test ==  9) testGetDapQueryParts();
                    if (test == 10) testParseDapQuery();
                    if (test == 11) testSubsetViaDapQuery();
                    if (test == 12) testAddIndexColumns();
                    
                    //readWrite tests
                    if (test == 20) testASCII();
                    if (test == 21) testReadAsciiCsvFile();
                    if (test == 22) testReadAsciiSsvFile();
                    if (test == 23) testReadColumnarASCIIFile();
                    if (test == 24) testNccsv();
                    if (test == 25) testHtml();
                    if (test == 26) testJson();
                    if (test == 27) testJsonlCSV();
                    if (test == 28) testFlatNc();
                    if (test == 29) test4DNc();
                    if (test == 30) testSaveAsMatlab();
                    if (test == 31) testOpendapSequence(); 
                    if (test == 32) testReadAwsXmlFile();
                    if (test == 33) testReadNDNc();
                    if (test == 34) testReadNDNc2();
                    if (test == 35) testJoin();
                    if (test == 36) testReadStandardTabbedASCII();
                    if (test == 37) testReadMultidimNc();
                    if (test == 38) testHardReadMultidimNc();
                    if (test == 39) testUnpack();

                    if (test == 40 && doSlowTestsToo) testReadInvalidCRA(); //very slow

                    //readNcCF tests
                    if (test == 45) testReadNcCFPoint(false);  //pauseAfterEachTest
                    if (test == 46) testReadNcCF1(false);  //pauseAfterEachTest
                    if (test == 47) testReadNcCF2(false);
                    if (test == 48) testReadNcCFASAProfile(false);
                    if (test == 49) testReadNcCFASATimeSeries(false);
                    if (test == 50) testReadNcCFASATrajectory(false);
                    if (test == 51) testReadNcCFASATimeSeriesProfile(false);
                    if (test == 52) testReadNcCFASATrajectoryProfile(false);
                    if (test == 53) testReadNcCFMATimeSeriesReversed(true); //read as ncCF
                    if (test == 54) testReadNcCFMATimeSeriesReversed(false);  //readMultidimNc 
                    if (test == 55) testReadGocdNcCF();
                    if (test == 56) testReadNcCF7SampleDims();
                    if (test == 57) {
                        ncCFcc.flip(0, 100);  //there are currently 99 code coverage tests
                        Test.ensureEqual(ncCFcc.toString(), "{}", "Table.readNcCF code coverage");
                        ncCFcc = null; //turn off test of readNcCF code coverage
                    }

                    if (test == 60) testReadASCIISpeed();
                    if (test == 61) testBigAscii();
                    if (test == 62) testReadJsonSpeed();
                    if (test == 63) testReadNDNcSpeed();
                    if (test == 64) testReadOpendapSequenceSpeed();
                    if (test == 65) testSaveAsSpeed();
                    if (test == 66) testUpdate();
                    if (test == 67) testXml();

                    //if (test == 1000) testConvert(); //2013-04-03 Needs work. Not active. This test needs to be updated to test a new source DAP server
                    //if (test == 1001) testSql();     //Needs work. Not active.
                    //if (test == 1002) testIobis();   // Needs work. Not active. It needs work to deal with sessions.
                    //if (test == 1003) testOpendap(); //not done yet, see opendapSequence
                }

                String2.log(msg + test + " finished successfully in " + (System.currentTimeMillis() - time) + " ms.");
            } catch (Throwable testThrowable) {
                String eMsg = msg + test + " caught throwable:\n" + 
                    MustBe.throwableToString(testThrowable);
                errorSB.append(eMsg);
                String2.log(eMsg);
                if (interactive) 
                    String2.pressEnterToContinue("");
            }
        }
    }


}
