package gov.noaa.pfel.erddap.dataset;

import com.cohort.array.Attributes;
import com.cohort.array.DoubleArray;
import com.cohort.array.FloatArray;
import com.cohort.array.IntArray;
import com.cohort.array.PAType;
import com.cohort.array.PrimitiveArray;
import com.cohort.array.StringArray;
import com.cohort.util.Calendar2;
import com.cohort.util.File2;
import com.cohort.util.Image2Tests;
import com.cohort.util.Math2;
import com.cohort.util.MustBe;
import com.cohort.util.SimpleException;
import com.cohort.util.String2;
import com.cohort.util.Test;
import gov.noaa.pfel.coastwatch.griddata.NcHelper;
import gov.noaa.pfel.coastwatch.pointdata.Table;
import gov.noaa.pfel.coastwatch.sgt.SgtUtil;
import gov.noaa.pfel.coastwatch.util.FileVisitorDNLS;
import gov.noaa.pfel.coastwatch.util.RegexFilenameFilter;
import gov.noaa.pfel.coastwatch.util.SSR;
import gov.noaa.pfel.erddap.GenerateDatasetsXml;
import gov.noaa.pfel.erddap.util.EDStatic;
import gov.noaa.pfel.erddap.variable.EDV;
import gov.noaa.pfel.erddap.variable.EDVTime;
import java.io.BufferedOutputStream;
import java.io.File;
import java.io.FileOutputStream;
import java.io.Writer;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.BitSet;
import java.util.GregorianCalendar;
import java.util.HashMap;
import java.util.List;
import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
import org.junit.jupiter.api.BeforeAll;
import org.junit.jupiter.api.io.TempDir;
import org.junit.jupiter.params.ParameterizedTest;
import org.junit.jupiter.params.provider.ValueSource;
import tags.TagImageComparison;
import tags.TagIncompleteTest;
import tags.TagLargeFiles;
import tags.TagLocalERDDAP;
import tags.TagMissingDataset;
import tags.TagSlowTests;
import testDataset.EDDTestDataset;
import testDataset.Initialization;
import ucar.ma2.Array;
import ucar.ma2.DataType;
import ucar.nc2.Dimension;
import ucar.nc2.Group;
import ucar.nc2.NetcdfFile;
import ucar.nc2.Variable;
import ucar.nc2.write.NetcdfFormatWriter;

class EDDTableFromNcFilesTests {
  @TempDir private static Path TEMP_DIR;

  @BeforeAll
  static void init() {
    Initialization.edStatic();
  }

  /** testGenerateDatasetsXml */
  @org.junit.jupiter.api.Test
  @TagIncompleteTest
  void testGenerateDatasetsXml() throws Throwable {
    // testVerboseOn();
    int language = 0;

    String2.log("\n*** EDDTableFromNcFiles.testGenerateDatasetsXml");
    String2.pressEnterToContinue(
        "\nDownload NDBC_41004_met.nc from coastwatch\n"
            + "https://coastwatch.pfeg.noaa.gov/erddap/files/cwwcNDBCMet/nrt/ \n"
            + "to /u00/data/points/ndbcMet2/nrt/ .");

    try {
      String results =
          EDDTableFromNcFiles.generateDatasetsXml(
                  "C:/u00/data/points/ndbcMet2",
                  ".*\\.nc",
                  "C:/u00/data/points/ndbcMet2/nrt/NDBC_41004_met.nc",
                  "",
                  -1,
                  "^.{5}",
                  ".{7}$",
                  ".*",
                  "stationID", // just for test purposes; station is
                  // already a column in the
                  // file
                  "TIME",
                  "stationID TIME",
                  "",
                  "",
                  "",
                  "",
                  -1, // defaultStandardizeWhat
                  null,
                  null)
              + "\n";
      results =
          results.replaceAll(
              "<att name=\"actual_range\" type=\"floatList\">.*</att>",
              "<att name=\"actual_range\" type=\"floatList\">... ...</att>");
      results =
          results.replaceAll(
              "<att name=\"actual_range\" type=\"shortList\">.*</att>",
              "<att name=\"actual_range\" type=\"shortList\">... ...</att>");

      // GenerateDatasetsXml
      String gdxResults =
          new GenerateDatasetsXml()
              .doIt(
                  new String[] {
                    "-verbose",
                    "EDDTableFromNcFiles",
                    "C:/u00/data/points/ndbcMet2",
                    ".*\\.nc",
                    "C:/u00/data/points/ndbcMet2/nrt/NDBC_41004_met.nc",
                    "",
                    "-1",
                    "^.{5}",
                    ".{7}$",
                    ".*",
                    "stationID", // just for test purposes; station is
                    // already a column in the
                    // file
                    "TIME",
                    "stationID TIME",
                    "",
                    "",
                    "",
                    "",
                    "-1",
                    ""
                  }, // defaultStandardizeWhat
                  false); // doIt loop?
      gdxResults =
          gdxResults.replaceAll(
              "<att name=\"actual_range\" type=\"floatList\">.*</att>",
              "<att name=\"actual_range\" type=\"floatList\">... ...</att>");
      gdxResults =
          gdxResults.replaceAll(
              "<att name=\"actual_range\" type=\"shortList\">.*</att>",
              "<att name=\"actual_range\" type=\"shortList\">... ...</att>");

      Test.ensureEqual(gdxResults, results, "Unexpected results from GenerateDatasetsXml.doIt.");

      String expected =
          "<dataset type=\"EDDTableFromNcFiles\" datasetID=\"ndbcMet2_73a7_3fce_afec\" active=\"true\">\n"
              + "    <reloadEveryNMinutes>1440</reloadEveryNMinutes>\n"
              + "    <updateEveryNMillis>10000</updateEveryNMillis>\n"
              + "    <fileDir>C:/u00/data/points/ndbcMet2/</fileDir>\n"
              + "    <fileNameRegex>.*\\.nc</fileNameRegex>\n"
              + "    <recursive>true</recursive>\n"
              + "    <pathRegex>.*</pathRegex>\n"
              + "    <metadataFrom>last</metadataFrom>\n"
              + "    <standardizeWhat>0</standardizeWhat>\n"
              + "    <preExtractRegex>^.{5}</preExtractRegex>\n"
              + "    <postExtractRegex>.{7}$</postExtractRegex>\n"
              + "    <extractRegex>.*</extractRegex>\n"
              + "    <columnNameForExtract>stationID</columnNameForExtract>\n"
              + "    <sortedColumnSourceName>TIME</sortedColumnSourceName>\n"
              + "    <sortFilesBySourceNames>stationID TIME</sortFilesBySourceNames>\n"
              + "    <fileTableInMemory>false</fileTableInMemory>\n"
              + "    <!-- sourceAttributes>\n"
              + "        <att name=\"cdm_data_type\">TimeSeries</att>\n"
              + "        <att name=\"cdm_timeseries_variables\">ID, LON, LAT, DEPTH</att>\n"
              + "        <att name=\"contributor_name\">NOAA NDBC</att>\n"
              + "        <att name=\"contributor_role\">Source of data.</att>\n"
              + "        <att name=\"Conventions\">COARDS, CF-1.6, ACDD-1.3</att>\n"
              + "        <att name=\"creator_email\">erd.data@noaa.gov</att>\n"
              + "        <att name=\"creator_name\">NOAA NMFS SWFSC ERD</att>\n"
              + "        <att name=\"creator_type\">institution</att>\n"
              + "        <att name=\"creator_url\">https://www.pfeg.noaa.gov</att>\n"
              + "        <att name=\"date_created\">2022-10-14</att>\n"
              + // changes
              "        <att name=\"date_issued\">2022-10-14</att>\n"
              + // changes and see
              // other changes below
              "        <att name=\"Easternmost_Easting\" type=\"float\">-79.099</att>\n"
              + "        <att name=\"geospatial_lat_max\" type=\"float\">32.501</att>\n"
              + "        <att name=\"geospatial_lat_min\" type=\"float\">32.501</att>\n"
              + "        <att name=\"geospatial_lat_units\">degrees_north</att>\n"
              + "        <att name=\"geospatial_lon_max\" type=\"float\">-79.099</att>\n"
              + "        <att name=\"geospatial_lon_min\" type=\"float\">-79.099</att>\n"
              + "        <att name=\"geospatial_lon_units\">degrees_east</att>\n"
              + "        <att name=\"geospatial_vertical_max\" type=\"float\">0.0</att>\n"
              + "        <att name=\"geospatial_vertical_min\" type=\"float\">0.0</att>\n"
              + "        <att name=\"geospatial_vertical_positive\">down</att>\n"
              + "        <att name=\"geospatial_vertical_units\">m</att>\n"
              + "        <att name=\"history\">Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\n"
              + "Every 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.</att>\n"
              + "        <att name=\"id\">NDBC_41004_met</att>\n"
              + "        <att name=\"infoUrl\">https://www.ndbc.noaa.gov/</att>\n"
              + "        <att name=\"institution\">NOAA NDBC, NOAA NMFS SWFSC ERD</att>\n"
              + "        <att name=\"keywords\">Earth Science &gt; Atmosphere &gt; Air Quality &gt; Visibility,\n"
              + "Earth Science &gt; Atmosphere &gt; Altitude &gt; Planetary Boundary Layer Height,\n"
              + "Earth Science &gt; Atmosphere &gt; Atmospheric Pressure &gt; Atmospheric Pressure Measurements,\n"
              + "Earth Science &gt; Atmosphere &gt; Atmospheric Pressure &gt; Pressure Tendency,\n"
              + "Earth Science &gt; Atmosphere &gt; Atmospheric Pressure &gt; Sea Level Pressure,\n"
              + "Earth Science &gt; Atmosphere &gt; Atmospheric Pressure &gt; Static Pressure,\n"
              + "Earth Science &gt; Atmosphere &gt; Atmospheric Temperature &gt; Air Temperature,\n"
              + "Earth Science &gt; Atmosphere &gt; Atmospheric Temperature &gt; Dew Point Temperature,\n"
              + "Earth Science &gt; Atmosphere &gt; Atmospheric Water Vapor &gt; Dew Point Temperature,\n"
              + "Earth Science &gt; Atmosphere &gt; Atmospheric Winds &gt; Surface Winds,\n"
              + "Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature,\n"
              + "Earth Science &gt; Oceans &gt; Ocean Waves &gt; Significant Wave Height,\n"
              + "Earth Science &gt; Oceans &gt; Ocean Waves &gt; Swells,\n"
              + "Earth Science &gt; Oceans &gt; Ocean Waves &gt; Wave Period,\n"
              + "air, air_pressure_at_sea_level, air_temperature, atmosphere, atmospheric, average, boundary, buoy, coastwatch, data, dew point, dew_point_temperature, direction, dominant, eastward, eastward_wind, from, gust, height, identifier, layer, level, measurements, meridional, meteorological, meteorology, name, ndbc, noaa, northward, northward_wind, ocean, oceans, period, planetary, pressure, quality, sea, sea level, sea_surface_swell_wave_period, sea_surface_swell_wave_significant_height, sea_surface_swell_wave_to_direction, sea_surface_temperature, seawater, significant, speed, sst, standard, static, station, surface, surface waves, surface_altitude, swell, swells, temperature, tendency, tendency_of_air_pressure, time, vapor, visibility, visibility_in_air, water, wave, waves, wcn, wind, wind_from_direction, wind_speed, wind_speed_of_gust, winds, zonal</att>\n"
              + "        <att name=\"keywords_vocabulary\">GCMD Science Keywords</att>\n"
              + "        <att name=\"license\">The data may be used and redistributed for free but is not intended\n"
              + "for legal use, since it may contain inaccuracies. Neither the data\n"
              + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
              + "of their employees or contractors, makes any warranty, express or\n"
              + "implied, including warranties of merchantability and fitness for a\n"
              + "particular purpose, or assumes any legal liability for the accuracy,\n"
              + "completeness, or usefulness, of this information.</att>\n"
              + "        <att name=\"naming_authority\">gov.noaa.pfeg.coastwatch</att>\n"
              + "        <att name=\"Northernmost_Northing\" type=\"float\">32.501</att>\n"
              + "        <att name=\"project\">NOAA NDBC and NOAA NMFS SWFSC ERD</att>\n"
              + "        <att name=\"publisher_email\">erd.data@noaa.gov</att>\n"
              + "        <att name=\"publisher_name\">NOAA NMFS SWFSC ERD</att>\n"
              + "        <att name=\"publisher_type\">institution</att>\n"
              + "        <att name=\"publisher_url\">https://www.pfeg.noaa.gov</att>\n"
              + "        <att name=\"quality\">Automated QC checks with periodic manual QC</att>\n"
              + "        <att name=\"source\">station observation</att>\n"
              + "        <att name=\"sourceUrl\">https://www.ndbc.noaa.gov/</att>\n"
              + "        <att name=\"Southernmost_Northing\" type=\"float\">32.501</att>\n"
              + "        <att name=\"standard_name_vocabulary\">CF Standard Name Table v70</att>\n"
              + "        <att name=\"subsetVariables\">ID, LON, LAT, DEPTH</att>\n"
              + "        <att name=\"summary\">The National Data Buoy Center (NDBC) distributes meteorological data from\n"
              + "moored buoys maintained by NDBC and others. Moored buoys are the weather\n"
              + "sentinels of the sea. They are deployed in the coastal and offshore waters\n"
              + "from the western Atlantic to the Pacific Ocean around Hawaii, and from the\n"
              + "Bering Sea to the South Pacific. NDBC&#39;s moored buoys measure and transmit\n"
              + "barometric pressure; wind direction, speed, and gust; air and sea\n"
              + "temperature; and wave energy spectra from which significant wave height,\n"
              + "dominant wave period, and average wave period are derived. Even the\n"
              + "direction of wave propagation is measured on many moored buoys. See\n"
              + "https://www.ndbc.noaa.gov/measdes.shtml for a description of the measurements.\n"
              + "\n"
              + "The source data from NOAA NDBC has different column names, different units,\n"
              + "and different missing values in different files, and other problems (notably,\n"
              + "lots of rows with duplicate or different values for the same time point).\n"
              + "This dataset is a standardized, reformatted, and lightly edited version of\n"
              + "that source data, created by NOAA NMFS SWFSC ERD (email: erd.data at noaa.gov).\n"
              + "Before 2020-01-29, this dataset only had the data that was closest to a given\n"
              + "hour, rounded to the nearest hour. Now, this dataset has all of the data\n"
              + "available from NDBC with the original time values. If there are multiple\n"
              + "source rows for a given buoy for a given time, only the row with the most\n"
              + "non-NaN data values is kept. If there is a gap in the data, a row of missing\n"
              + "values is inserted (which causes a nice gap when the data is graphed). Also,\n"
              + "some impossible data values are removed, but this data is not perfectly clean.\n"
              + "This dataset is now updated every 5 minutes.\n"
              + "\n"
              + "This dataset has both historical data (quality controlled) and near real time\n"
              + "data (less quality controlled).</att>\n"
              + "        <att name=\"testOutOfDate\">now-25minutes</att>\n"
              + "        <att name=\"time_coverage_end\">2022-10-14T20:30:00Z</att>\n"
              + // changes.
              // Don't
              // regex
              // it
              // -- I
              // want
              // to
              // see
              // it
              // change.
              "        <att name=\"time_coverage_start\">2022-02-01T00:00:00Z</att>\n"
              + // changes
              // since
              // it
              // is
              // from
              // an
              // nrt
              // file
              "        <att name=\"title\">NDBC Standard Meteorological Buoy Data, 1970-present</att>\n"
              + "        <att name=\"Westernmost_Easting\" type=\"float\">-79.099</att>\n"
              + "    </sourceAttributes -->\n"
              + EDDTableFromNcFiles.cdmSuggestion()
              + "    <addAttributes>\n"
              + "        <att name=\"Conventions\">COARDS, CF-1.10, ACDD-1.3</att>\n"
              + "        <att name=\"keywords\">1970-present, air, air_pressure_at_sea_level, air_temperature, altitude, APD, atmosphere, atmospheric, ATMP, average, BAR, boundary, buoy, center, coast, coastwatch, control, data, depth, dew, dew point, dew_point_temperature, DEWP, dewpoint, direction, dominant, DPD, earth, Earth Science &gt; Atmosphere &gt; Air Quality &gt; Visibility, Earth Science &gt; Atmosphere &gt; Altitude &gt; Planetary Boundary Layer Height, Earth Science &gt; Atmosphere &gt; Atmospheric Pressure &gt; Atmospheric Pressure Measurements, Earth Science &gt; Atmosphere &gt; Atmospheric Pressure &gt; Pressure Tendency, Earth Science &gt; Atmosphere &gt; Atmospheric Pressure &gt; Sea Level Pressure, Earth Science &gt; Atmosphere &gt; Atmospheric Pressure &gt; Static Pressure, Earth Science &gt; Atmosphere &gt; Atmospheric Temperature &gt; Air Temperature, Earth Science &gt; Atmosphere &gt; Atmospheric Temperature &gt; Dew Point Temperature, Earth Science &gt; Atmosphere &gt; Atmospheric Temperature &gt; Surface Air Temperature, Earth Science &gt; Atmosphere &gt; Atmospheric Water Vapor &gt; Dew Point Temperature, Earth Science &gt; Atmosphere &gt; Atmospheric Winds &gt; Surface Winds, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Waves &gt; Significant Wave Height, Earth Science &gt; Oceans &gt; Ocean Waves &gt; Swells, Earth Science &gt; Oceans &gt; Ocean Waves &gt; Wave Period, Earth Science &gt; Oceans &gt; Ocean Waves &gt; Wave Speed/Direction, eastward, eastward_wind, erd, fisheries, GST, gust, height, identifier, latitude, layer, level, longitude, marine, measurements, meridional, meteorological, meteorology, MWD, name, national, ndbc, near, nmfs, noaa, node, northward, northward_wind, nrt, ocean, oceans, period, planetary, point, present, pressure, PTDY, quality, real, science, sea, sea level, sea_surface_swell_wave_period, sea_surface_swell_wave_significant_height, sea_surface_swell_wave_to_direction, sea_surface_temperature, sea_surface_wave_significant_height, sea_surface_wave_to_direction, seawater, service, significant, southwest, speed, sst, standard, static, station, surface, surface waves, surface_altitude, swell, swells, swfsc, swh, temperature, tendency, tendency_of_air_pressure, TIDE, time, vapor, VIS, visibility, visibility_in_air, water, wave, waves, wcn, west, wind, wind_from_direction, wind_speed, wind_speed_of_gust, winds, WSPD, WSPU, WSPV, WTMP, WVHT, zonal</att>\n"
              + "        <att name=\"sourceUrl\">(local files)</att>\n"
              + "        <att name=\"summary\">The National Data Buoy Center (NDBC) distributes meteorological data from\n"
              + "moored buoys maintained by NDBC and others. Moored buoys are the weather\n"
              + "sentinels of the sea. They are deployed in the coastal and offshore waters\n"
              + "from the western Atlantic to the Pacific Ocean around Hawaii, and from the\n"
              + "Bering Sea to the South Pacific. NDBC&#39;s moored buoys measure and transmit\n"
              + "barometric pressure; wind direction, speed, and gust; air and sea\n"
              + "temperature; and wave energy spectra from which significant wave height,\n"
              + "dominant wave period, and average wave period are derived. Even the\n"
              + "direction of wave propagation is measured on many moored buoys. See\n"
              + "https://www.ndbc.noaa.gov/measdes.shtml for a description of the measurements.\n"
              + "\n"
              + "The source data from NOAA NDBC has different column names, different units,\n"
              + "and different missing values in different files, and other problems (notably,\n"
              + "lots of rows with duplicate or different values for the same time point).\n"
              + "This dataset is a standardized, reformatted, and lightly edited version of\n"
              + "that source data, created by NOAA National Marine Fisheries Service (NMFS) Southwest Fisheries Science Center (SWFSC) ERD (email: erd.data at noaa.gov).\n"
              + "Before 2020-01-29, this dataset only had the data that was closest to a given\n"
              + "hour, rounded to the nearest hour. Now, this dataset has all of the data\n"
              + "available from NDBC with the original time values. If there are multiple\n"
              + "source rows for a given buoy for a given time, only the row with the most\n"
              + "non-NaN data values is kept. If there is a gap in the data, a row of missing\n"
              + "values is inserted (which causes a nice gap when the data is graphed). Also,\n"
              + "some impossible data values are removed, but this data is not perfectly clean.\n"
              + "This dataset is now updated every 5 minutes.\n"
              + "\n"
              + "This dataset has both historical data (quality controlled) and near real time\n"
              + "data (less quality controlled).</att>\n"
              + "    </addAttributes>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>stationID</sourceName>\n"
              + "        <destinationName>stationID</destinationName>\n"
              + "        <dataType>String</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "            <att name=\"ioos_category\">Identifier</att>\n"
              + "            <att name=\"long_name\">Station ID</att>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>TIME</sourceName>\n"
              + "        <destinationName>time</destinationName>\n"
              + "        <dataType>double</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_CoordinateAxisType\">Time</att>\n"
              + "            <att name=\"actual_range\" type=\"doubleList\">1.6645824E9 1.6657794E9</att>\n"
              + // both
              // change
              "            <att name=\"axis\">T</att>\n"
              + "            <att name=\"ioos_category\">Time</att>\n"
              + "            <att name=\"long_name\">Time</att>\n"
              + "            <att name=\"standard_name\">time</att>\n"
              + "            <att name=\"time_origin\">01-JAN-1970 00:00:00</att>\n"
              + "            <att name=\"units\">seconds since 1970-01-01T00:00:00Z</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "            <att name=\"colorBarMaximum\" type=\"double\">1.666E9</att>\n"
              + // changes
              "            <att name=\"colorBarMinimum\" type=\"double\">1.6645E9</att>\n"
              + // changes
              "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>DEPTH</sourceName>\n"
              + "        <destinationName>depth</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_CoordinateAxisType\">Height</att>\n"
              + "            <att name=\"_CoordinateZisPositive\">down</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + "            <att name=\"axis\">Z</att>\n"
              + "            <att name=\"colorBarMaximum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">The depth of the station, nominally 0 (see station information for details).</att>\n"
              + "            <att name=\"ioos_category\">Location</att>\n"
              + "            <att name=\"long_name\">Depth</att>\n"
              + "            <att name=\"positive\">down</att>\n"
              + "            <att name=\"standard_name\">depth</att>\n"
              + "            <att name=\"units\">m</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">-0.01</att>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>LAT</sourceName>\n"
              + "        <destinationName>latitude</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_CoordinateAxisType\">Lat</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + "            <att name=\"axis\">Y</att>\n"
              + "            <att name=\"colorBarMaximum\" type=\"double\">90.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">-90.0</att>\n"
              + "            <att name=\"comment\">The latitude of the station.</att>\n"
              + "            <att name=\"ioos_category\">Location</att>\n"
              + "            <att name=\"long_name\">Latitude</att>\n"
              + "            <att name=\"standard_name\">latitude</att>\n"
              + "            <att name=\"units\">degrees_north</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>LON</sourceName>\n"
              + "        <destinationName>longitude</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_CoordinateAxisType\">Lon</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + "            <att name=\"axis\">X</att>\n"
              + "            <att name=\"colorBarMaximum\" type=\"double\">180.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">-180.0</att>\n"
              + "            <att name=\"comment\">The longitude of the station.</att>\n"
              + "            <att name=\"ioos_category\">Location</att>\n"
              + "            <att name=\"long_name\">Longitude</att>\n"
              + "            <att name=\"standard_name\">longitude</att>\n"
              + "            <att name=\"units\">degrees_east</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>WD</sourceName>\n"
              + "        <destinationName>WD</destinationName>\n"
              + "        <dataType>short</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"short\">32767</att>\n"
              + "            <att name=\"actual_range\" type=\"shortList\">... ...</att>\n"
              + "            <att name=\"colorBarMaximum\" type=\"double\">360.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Wind direction (the direction the wind is coming from in degrees clockwise from true N) during the same period used for WSPD.</att>\n"
              + "            <att name=\"ioos_category\">Wind</att>\n"
              + "            <att name=\"long_name\">Wind Direction</att>\n"
              + "            <att name=\"missing_value\" type=\"short\">32767</att>\n"
              + "            <att name=\"standard_name\">wind_from_direction</att>\n"
              + "            <att name=\"units\">degrees_true</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>WSPD</sourceName>\n"
              + "        <destinationName>WSPD</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">15.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Average wind speed (m/s).</att>\n"
              + "            <att name=\"ioos_category\">Wind</att>\n"
              + "            <att name=\"long_name\">Wind Speed</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">wind_speed</att>\n"
              + "            <att name=\"units\">m s-1</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>GST</sourceName>\n"
              + "        <destinationName>GST</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">30.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Peak 5 or 8 second gust speed (m/s).</att>\n"
              + "            <att name=\"ioos_category\">Wind</att>\n"
              + "            <att name=\"long_name\">Wind Gust Speed</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">wind_speed_of_gust</att>\n"
              + "            <att name=\"units\">m s-1</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>WVHT</sourceName>\n"
              + "        <destinationName>WVHT</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">10.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Significant wave height (meters) is calculated as the average of the highest one-third of all of the wave heights during the 20-minute sampling period.</att>\n"
              + "            <att name=\"ioos_category\">Surface Waves</att>\n"
              + "            <att name=\"long_name\">Wave Height</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">sea_surface_wave_significant_height</att>\n"
              + "            <att name=\"units\">m</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>DPD</sourceName>\n"
              + "        <destinationName>DPD</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">20.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Dominant wave period (seconds) is the period with the maximum wave energy.</att>\n"
              + "            <att name=\"ioos_category\">Surface Waves</att>\n"
              + "            <att name=\"long_name\">Wave Period, Dominant</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">sea_surface_swell_wave_period</att>\n"
              + "            <att name=\"units\">s</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>APD</sourceName>\n"
              + "        <destinationName>APD</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">20.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Average wave period (seconds) of all waves during the 20-minute period.</att>\n"
              + "            <att name=\"ioos_category\">Surface Waves</att>\n"
              + "            <att name=\"long_name\">Wave Period, Average</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">sea_surface_swell_wave_period</att>\n"
              + "            <att name=\"units\">s</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>MWD</sourceName>\n"
              + "        <destinationName>MWD</destinationName>\n"
              + "        <dataType>short</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"short\">32767</att>\n"
              + "            <att name=\"actual_range\" type=\"shortList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">360.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Mean wave direction corresponding to energy of the dominant period (DOMPD).</att>\n"
              + "            <att name=\"ioos_category\">Surface Waves</att>\n"
              + "            <att name=\"long_name\">Wave Direction</att>\n"
              + "            <att name=\"missing_value\" type=\"short\">32767</att>\n"
              + "            <att name=\"standard_name\">sea_surface_wave_to_direction</att>\n"
              + "            <att name=\"units\">degrees_true</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>BAR</sourceName>\n"
              + "        <destinationName>BAR</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">1050.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">950.0</att>\n"
              + "            <att name=\"comment\">Air pressure (hPa). (&#39;PRES&#39; on some NDBC tables.) For C-MAN sites and Great Lakes buoys, the recorded pressure is reduced to sea level using the method described in NWS Technical Procedures Bulletin 291 (11/14/80).</att>\n"
              + "            <att name=\"ioos_category\">Pressure</att>\n"
              + "            <att name=\"long_name\">Air Pressure</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">air_pressure_at_sea_level</att>\n"
              + "            <att name=\"units\">hPa</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>ATMP</sourceName>\n"
              + "        <destinationName>ATMP</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">40.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">-10.0</att>\n"
              + "            <att name=\"comment\">Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.</att>\n"
              + "            <att name=\"ioos_category\">Temperature</att>\n"
              + "            <att name=\"long_name\">Air Temperature</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">air_temperature</att>\n"
              + "            <att name=\"units\">degree_C</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>WTMP</sourceName>\n"
              + "        <destinationName>WTMP</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">32.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Sea surface temperature (Celsius). For sensor depth, see Hull Description.</att>\n"
              + "            <att name=\"ioos_category\">Temperature</att>\n"
              + "            <att name=\"long_name\">SST</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">sea_surface_temperature</att>\n"
              + "            <att name=\"units\">degree_C</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>DEWP</sourceName>\n"
              + "        <destinationName>DEWP</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">40.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Dewpoint temperature taken at the same height as the air temperature measurement.</att>\n"
              + "            <att name=\"ioos_category\">Temperature</att>\n"
              + "            <att name=\"long_name\">Dewpoint Temperature</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">dew_point_temperature</att>\n"
              + "            <att name=\"units\">degree_C</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>VIS</sourceName>\n"
              + "        <destinationName>VIS</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"colorBarMaximum\" type=\"double\">100.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">0.0</att>\n"
              + "            <att name=\"comment\">Station visibility (km, originally nautical miles in the NDBC .txt files). Note that buoy stations are limited to reports from 0 to 1.6 nmi.</att>\n"
              + "            <att name=\"ioos_category\">Meteorology</att>\n"
              + "            <att name=\"long_name\">Station Visibility</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">visibility_in_air</att>\n"
              + "            <att name=\"units\">km</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>PTDY</sourceName>\n"
              + "        <destinationName>PTDY</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + // changes
              "            <att name=\"colorBarMaximum\" type=\"double\">3.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">-3.0</att>\n"
              + "            <att name=\"comment\">Pressure Tendency is the direction (plus or minus) and the amount of pressure change (hPa) for a three hour period ending at the time of observation.</att>\n"
              + "            <att name=\"ioos_category\">Pressure</att>\n"
              + "            <att name=\"long_name\">Pressure Tendency</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">tendency_of_air_pressure</att>\n"
              + "            <att name=\"units\">hPa</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>TIDE</sourceName>\n"
              + "        <destinationName>TIDE</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"colorBarMaximum\" type=\"double\">5.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">-5.0</att>\n"
              + "            <att name=\"comment\">The water level in meters (originally feet in the NDBC .txt files) above or below Mean Lower Low Water (MLLW).</att>\n"
              + "            <att name=\"ioos_category\">Sea Level</att>\n"
              + "            <att name=\"long_name\">Water Level</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">surface_altitude</att>\n"
              + "            <att name=\"units\">m</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>WSPU</sourceName>\n"
              + "        <destinationName>WSPU</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + "            <att name=\"colorBarMaximum\" type=\"double\">15.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">-15.0</att>\n"
              + "            <att name=\"comment\">The zonal wind speed (m/s) indicates the u component of where the wind is going, derived from Wind Direction and Wind Speed.</att>\n"
              + "            <att name=\"ioos_category\">Wind</att>\n"
              + "            <att name=\"long_name\">Wind Speed, Zonal</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">eastward_wind</att>\n"
              + "            <att name=\"units\">m s-1</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>WSPV</sourceName>\n"
              + "        <destinationName>WSPV</destinationName>\n"
              + "        <dataType>float</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"_FillValue\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"actual_range\" type=\"floatList\">... ...</att>\n"
              + "            <att name=\"colorBarMaximum\" type=\"double\">15.0</att>\n"
              + "            <att name=\"colorBarMinimum\" type=\"double\">-15.0</att>\n"
              + "            <att name=\"comment\">The meridional wind speed (m/s) indicates the v component of where the wind is going, derived from Wind Direction and Wind Speed.</att>\n"
              + "            <att name=\"ioos_category\">Wind</att>\n"
              + "            <att name=\"long_name\">Wind Speed, Meridional</att>\n"
              + "            <att name=\"missing_value\" type=\"float\">-9999999.0</att>\n"
              + "            <att name=\"standard_name\">northward_wind</att>\n"
              + "            <att name=\"units\">m s-1</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "    <dataVariable>\n"
              + "        <sourceName>ID</sourceName>\n"
              + "        <destinationName>ID</destinationName>\n"
              + "        <dataType>String</dataType>\n"
              + "        <!-- sourceAttributes>\n"
              + "            <att name=\"cf_role\">timeseries_id</att>\n"
              + "            <att name=\"comment\">The station identifier.</att>\n"
              + "            <att name=\"ioos_category\">Identifier</att>\n"
              + "            <att name=\"long_name\">Station Identifier</att>\n"
              + "        </sourceAttributes -->\n"
              + "        <addAttributes>\n"
              + "        </addAttributes>\n"
              + "    </dataVariable>\n"
              + "</dataset>\n"
              + "\n\n";

      Test.ensureEqual(results, expected, "results=\n" + results);
      // Test.ensureEqual(results.substring(0, Math.min(results.length(),
      // expected.length())),
      // expected, "");

      // 2 changes to make it a valid dataset:
      String ts;
      ts = "<att name=\"cdm_timeseries_variables\">ID, LON, LAT, DEPTH</att>";
      int po = results.indexOf(ts);
      Test.ensureEqual(results.substring(po, po + ts.length()), ts, results);
      ts = "<att name=\"subsetVariables\">ID, LON, LAT, DEPTH</att>";
      po = results.indexOf(ts);
      Test.ensureEqual(results.substring(po, po + ts.length()), ts, results);
      // but they are in sourceAtts. I need to add them to addAtts:
      // !!! This should be done by code that catches latitude, longitude
      results =
          String2.replaceAll(
              results,
              "<att name=\"sourceUrl\">(local files)</att>",
              "<att name=\"sourceUrl\">(local files)</att>\n"
                  + "        <att name=\"cdm_timeseries_variables\">ID, latitude, longitude, depth</att>\n"
                  + "        <att name=\"subsetVariables\">ID, latitude, longitude, depth</att>");

      ts = "<att name=\"long_name\">Station Identifier</att>";
      Test.ensureTrue(results.indexOf(ts) > 0, results);
      results =
          String2.replaceAll(
              results,
              ts,
              "<att name=\"long_name\">Station Identifier</att>\n"
                  + "             <att name=\"cf_role\">timeseries_id</att>");

      String2.log("results=\n" + results);
      String tDatasetID = "ndbcMet2_73a7_3fce_afec";
      // EDD.deleteCachedDatasetInfo(tDatasetID);
      EDD edd = EDDTableFromNcFiles.oneFromXmlFragment(null, results);
      Test.ensureEqual(edd.datasetID(), tDatasetID, "");
      Test.ensureEqual(edd.title(), "NDBC Standard Meteorological Buoy Data, 1970-present", "");
      Test.ensureEqual(
          String2.toCSSVString(edd.dataVariableDestinationNames()),
          "stationID, time, depth, latitude, longitude, WD, WSPD, GST, WVHT, "
              + "DPD, APD, MWD, BAR, ATMP, WTMP, DEWP, VIS, PTDY, TIDE, WSPU, WSPV, ID",
          "");

    } catch (Throwable t) {
      throw new Exception(MustBe.throwableToString(t) + "\nError using generateDatasetsXml.");
    }
  }

  /** testGenerateDatasetsXml2 */
  @org.junit.jupiter.api.Test
  @TagIncompleteTest
  void testGenerateDatasetsXml2() throws Throwable {
    // testVerboseOn();
    int language = 0;

    String results =
        EDDTableFromNcFiles.generateDatasetsXml(
            "c:/data/ngdcJasonSwath/",
            ".*\\.nc",
            "c:/data/ngdcJasonSwath/JA2_OPN_2PcS088_239_20101201_005323_20101201_025123.nc",
            "time", // not "time, meas_ind"
            EDDTableFromNcFiles.DEFAULT_RELOAD_EVERY_N_MINUTES,
            "",
            "",
            "",
            "",
            "",
            "time",
            "",
            "",
            "",
            "",
            -1,
            null, // defaultStandardizeWhat
            new Attributes());

    String tDatasetID = "ngdcJasonSwath_c70d_5281_4d5c";
    EDD.deleteCachedDatasetInfo(tDatasetID);
    EDD edd = EDDTableFromNcFiles.oneFromXmlFragment(null, results);
    Test.ensureEqual(edd.datasetID(), tDatasetID, "");
    Test.ensureEqual(edd.title(), "OGDR, Standard dataset", "");
    Test.ensureEqual(
        String2.toCSSVString(edd.dataVariableDestinationNames()),
        "time, latitude, longitude, surface_type, alt_echo_type, rad_surf_type, "
            + "qual_alt_1hz_range_ku, qual_alt_1hz_range_c, qual_alt_1hz_swh_ku, qual_alt_1hz_swh_c, "
            + "qual_alt_1hz_sig0_ku, qual_alt_1hz_sig0_c, qual_alt_1hz_off_nadir_angle_wf_ku, "
            + "qual_alt_1hz_off_nadir_angle_pf, qual_inst_corr_1hz_range_ku, qual_inst_corr_1hz_range_c, "
            + "qual_inst_corr_1hz_swh_ku, qual_inst_corr_1hz_swh_c, qual_inst_corr_1hz_sig0_ku, "
            + "qual_inst_corr_1hz_sig0_c, qual_rad_1hz_tb187, qual_rad_1hz_tb238, qual_rad_1hz_tb340, "
            + "alt_state_flag_oper, alt_state_flag_c_band, alt_state_flag_band_seq, "
            + "alt_state_flag_ku_band_status, alt_state_flag_c_band_status, rad_state_flag_oper, "
            + "orb_state_flag_diode, orb_state_flag_rest, ecmwf_meteo_map_avail, rain_flag, ice_flag, "
            + "interp_flag_tb, interp_flag_mean_sea_surface, interp_flag_mdt, "
            + "interp_flag_ocean_tide_sol1, interp_flag_ocean_tide_sol2, interp_flag_meteo, alt, "
            + "orb_alt_rate, range_ku, range_c, range_rms_ku, range_rms_c, range_numval_ku, "
            + "range_numval_c, net_instr_corr_range_ku, net_instr_corr_range_c, model_dry_tropo_corr, "
            + "model_wet_tropo_corr, rad_wet_tropo_corr, iono_corr_alt_ku, iono_corr_gim_ku, "
            + "sea_state_bias_ku, sea_state_bias_c, swh_ku, swh_c, swh_rms_ku, swh_rms_c, "
            + "swh_numval_ku, swh_numval_c, net_instr_corr_swh_ku, net_instr_corr_swh_c, sig0_ku, "
            + "sig0_c, sig0_rms_ku, sig0_rms_c, sig0_numval_ku, sig0_numval_c, agc_ku, agc_c, "
            + "agc_rms_ku, agc_rms_c, agc_numval_ku, agc_numval_c, net_instr_corr_sig0_ku, "
            + "net_instr_corr_sig0_c, atmos_corr_sig0_ku, atmos_corr_sig0_c, off_nadir_angle_wf_ku, "
            + "off_nadir_angle_pf, tb_187, tb_238, tb_340, mean_sea_surface, mean_topography, geoid, "
            + "bathymetry, inv_bar_corr, hf_fluctuations_corr, ocean_tide_sol1, ocean_tide_sol2, "
            + "ocean_tide_equil, ocean_tide_non_equil, load_tide_sol1, load_tide_sol2, "
            + "solid_earth_tide, pole_tide, wind_speed_model_u, wind_speed_model_v, "
            + "wind_speed_alt, wind_speed_rad, rad_water_vapor, rad_liquid_water, ssha",
        "");
  }

  /** testGenerateDatasetsXml ncdump option */
  @org.junit.jupiter.api.Test
  void testGenerateDatasetsXmlNcdump() throws Throwable {
    // String2.log("\n******************
    // EDDTableFromNcFiles.testGenerateDatasetsXmlNcdump() *****************\n");
    // testVerboseOn();

    int language = 0;

    // just header
    String results =
        new GenerateDatasetsXml()
            .doIt(
                new String[] {
                  "ncdump",
                  EDDTableFromNcFilesTests.class
                      .getResource("/data/gocdNcCF/gocd_v3_sadcp.nc")
                      .getPath(),
                  "-h"
                },
                false); // loop?
    String2.log(results);
    String expected =
        "netcdf gocd_v3_sadcp.nc {\n"
            + "  dimensions:\n"
            + "    time = 501;\n"
            + "    z = 70;\n"
            + "  variables:\n"
            + "    float sampling_interval;\n"
            + "      :long_name = \"Sampling Interval\";\n"
            + "      :units = \"minutes\";\n"
            + "      :_FillValue = 9999.9f; // float\n"
            + "\n"
            + "    float seafloor_depth(time=501);\n"
            + "      :long_name = \"Seafloor Depth\";\n"
            + "      :units = \"meters\";\n"
            + "      :postive = \"down\";\n"
            + "      :_FillValue = 9999.9f; // float\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "");

    expected =
        "  :instrument_type = \"Ocean Surveyor OS75\";\n"
            + "  :QC_Manual = \"Contact Principle Investigaror(s)\";\n"
            + // sic
            "  :QC_test_names = \"Contact Principle Investigaror(s)\";\n"
            + "  :QC_test_codes = \"Contact Principle Investigaror(s)\";\n"
            + "  :QC_test_results = \"Contact Principle Investigaror(s)\";\n"
            + "  :QC_indicator = \"Contact Principle Investigaror(s)\";\n"
            + "  :QC_Software = \"Contact Principle Investigaror(s)\";\n"
            + "}\n"
            + "\n";
    Test.ensureEqual(
        results.substring(results.length() - expected.length()), expected, "results=\n" + results);

    // csv list of vars
    results =
        new GenerateDatasetsXml()
            .doIt(
                new String[] {
                  "ncdump",
                  EDDTableFromNcFilesTests.class
                      .getResource("/data/gocdNcCF/gocd_v3_sadcp.nc")
                      .getPath(),
                  "-v sampling_interval;crs"
                },
                false); // loop?

    expected =
        "  :QC_indicator = \"Contact Principle Investigaror(s)\";\n"
            + // sic
            "  :QC_Software = \"Contact Principle Investigaror(s)\";\n"
            + "\n"
            + "  data:\n"
            + "    sampling_interval = 9999.9\n"
            + "    crs = 0\n"
            + "}\n"
            + "\n";
    Test.ensureEqual(
        results.substring(results.length() - expected.length()), expected, "results=\n" + results);
  }

  /**
   * This tests the methods in this class with a 1D dataset.
   *
   * @throws Throwable if trouble
   */
  @ParameterizedTest
  @ValueSource(booleans = {true, false})
  void test1D(boolean deleteCachedDatasetInfo) throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.test1D()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    EDV edv;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    // 11 is enough to check date. Since this takes long enough to run, checking a
    // more specific time leads to flakiness. Even date could cause flakes if run at
    // just the right time of day.
    String today = Calendar2.getCurrentISODateTimeStringZulu().substring(0, 11);

    String id = "erdCinpKfmSFNH";
    if (deleteCachedDatasetInfo) EDDTableFromNcFiles.deleteCachedDatasetInfo(id);

    EDDTable eddTable = (EDDTable) EDDTestDataset.geterdCinpKfmSFNH();

    // *** test getting das for entire dataset
    String2.log(
        "\n****************** EDDTableFromNcFiles 1D test das and dds for entire dataset\n");
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", dir, eddTable.className() + "_Entire", ".das");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "Attributes {\n"
            + " s {\n"
            + "  id {\n"
            + "    String cf_role \"timeseries_id\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Station Identifier\";\n"
            + (EDStatic.useSaxParser ? "    String units \"unitless\";\n" : "")
            + "  }\n"
            + "  longitude {\n"
            + "    String _CoordinateAxisType \"Lon\";\n"
            + "    Float64 actual_range -120.4, -118.4;\n"
            + "    String axis \"X\";\n"
            + "    Float64 colorBarMaximum -118.4;\n"
            + "    Float64 colorBarMinimum -120.4;\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Longitude\";\n"
            + "    String standard_name \"longitude\";\n"
            + "    String units \"degrees_east\";\n"
            + "  }\n"
            + "  latitude {\n"
            + "    String _CoordinateAxisType \"Lat\";\n"
            + "    Float64 actual_range 32.8, 34.05;\n"
            + "    String axis \"Y\";\n"
            + "    Float64 colorBarMaximum 34.5;\n"
            + "    Float64 colorBarMinimum 32.5;\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Latitude\";\n"
            + "    String standard_name \"latitude\";\n"
            + "    String units \"degrees_north\";\n"
            + "  }\n"
            + "  depth {\n"
            + "    String _CoordinateAxisType \"Height\";\n"
            + "    String _CoordinateZisPositive \"down\";\n"
            + "    Float64 actual_range 5.0, 17.0;\n"
            + "    String axis \"Z\";\n"
            + "    Float64 colorBarMaximum 20.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Depth\";\n"
            + "    String positive \"down\";\n"
            + "    String standard_name \"depth\";\n"
            + "    String units \"m\";\n"
            + "  }\n"
            + "  time {\n"
            + "    String _CoordinateAxisType \"Time\";\n"
            + "    Float64 actual_range 4.89024e+8, 1.183248e+9;\n"
            + "    String axis \"T\";\n"
            + "    Float64 colorBarMaximum 1.183248e+9;\n"
            + "    Float64 colorBarMinimum 4.89024e+8;\n"
            + "    String ioos_category \"Time\";\n"
            + "    String long_name \"Time\";\n"
            + "    String standard_name \"time\";\n"
            + "    String time_origin \"01-JAN-1970 00:00:00\";\n"
            + "    String units \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "  }\n"
            + "  common_name {\n"
            + "    String ioos_category \"Taxonomy\";\n"
            + "    String long_name \"Common Name\";\n"
            + (EDStatic.useSaxParser ? "    String units \"unitless\";\n" : "")
            + "  }\n"
            + "  species_name {\n"
            + "    String ioos_category \"Taxonomy\";\n"
            + "    String long_name \"Species Name\";\n"
            + (EDStatic.useSaxParser ? "    String units \"unitless\";\n" : "")
            + "  }\n"
            + "  size {\n"
            + "    Int16 _FillValue 32767;\n"
            + "    Int16 actual_range 1, 385;\n"
            + "    String ioos_category \"Biology\";\n"
            + "    String long_name \"Size\";\n"
            + "    String units \"mm\";\n"
            + "  }\n"
            + " }\n"
            + "  NC_GLOBAL {\n"
            + "    String acknowledgement \"NOAA NESDIS COASTWATCH, NOAA SWFSC ERD, Channel Islands National Park, National Park Service\";\n"
            + "    String cdm_data_type \"TimeSeries\";\n"
            + "    String cdm_timeseries_variables \"id, longitude, latitude\";\n"
            + "    String contributor_email \"David_Kushner@nps.gov\";\n"
            + "    String contributor_name \"Channel Islands National Park, National Park Service\";\n"
            + "    String contributor_role \"Source of data.\";\n"
            + "    String Conventions \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "    String creator_email \"erd.data@noaa.gov\";\n"
            + "    String creator_name \"NOAA NMFS SWFSC ERD\";\n"
            + "    String creator_type \"institution\";\n"
            + "    String creator_url \"https://www.pfeg.noaa.gov\";\n"
            + "    String date_created \""
            + eddTable.sourceGlobalAttributes.getString("date_created")
            + "\";\n"
            + "    String date_issued \""
            + eddTable.sourceGlobalAttributes.getString("date_issued")
            + "\";\n"
            + "    Float64 Easternmost_Easting -118.4;\n"
            + "    String featureType \"TimeSeries\";\n"
            + "    Float64 geospatial_lat_max 34.05;\n"
            + "    Float64 geospatial_lat_min 32.8;\n"
            + "    String geospatial_lat_units \"degrees_north\";\n"
            + "    Float64 geospatial_lon_max -118.4;\n"
            + "    Float64 geospatial_lon_min -120.4;\n"
            + "    String geospatial_lon_units \"degrees_east\";\n"
            + "    Float64 geospatial_vertical_max 17.0;\n"
            + "    Float64 geospatial_vertical_min 5.0;\n"
            + "    String geospatial_vertical_positive \"down\";\n"
            + "    String geospatial_vertical_units \"m\";\n"
            + "    String history \"Channel Islands National Park, National Park Service\n"
            + eddTable.sourceGlobalAttributes.getString("date_created")
            + " NOAA CoastWatch (West Coast Node) and NOAA SFSC ERD\n"
            + // will
            // be
            // SWFSC
            // when
            // reprocessed
            today;
    tResults = results.substring(0, Math.min(results.length(), expected.length()));
    Test.ensureEqual(tResults, expected, "\nresults=\n" + results);

    // + " (local files)\n" +
    // today + " " + EDStatic.erddapUrl + //in tests, always use non-https url
    expected =
        "/tabledap/erdCinpKfmSFNH.das\";\n"
            + (EDStatic.useSaxParser ? "    String id \"KFMSizeFrequencyNaturalHabitat\";\n" : "")
            + "    String infoUrl \"https://www.nps.gov/chis/naturescience/index.htm\";\n"
            + "    String institution \"CINP\";\n"
            + "    String keywords \"aquatic, atmosphere, biology, biosphere, channel, cinp, coastal, common, depth, Earth Science > Biosphere > Aquatic Ecosystems > Coastal Habitat, Earth Science > Biosphere > Aquatic Ecosystems > Marine Habitat, ecosystems, forest, frequency, habitat, height, identifier, islands, kelp, marine, monitoring, name, natural, size, species, station, taxonomy, time\";\n"
            + "    String keywords_vocabulary \"GCMD Science Keywords\";\n"
            + "    String license \"The data may be used and redistributed for free but is not intended for legal use, since it may contain inaccuracies. Neither the data Contributor, CoastWatch, NOAA, nor the United States Government, nor any of their employees or contractors, makes any warranty, express or implied, including warranties of merchantability and fitness for a particular purpose, or assumes any legal liability for the accuracy, completeness, or usefulness, of this information.  National Park Service Disclaimer: The National Park Service shall not be held liable for improper or incorrect use of the data described and/or contained herein. These data and related graphics are not legal documents and are not intended to be used as such. The information contained in these data is dynamic and may change over time. The data are not better than the original sources from which they were derived. It is the responsibility of the data user to use the data appropriately and consistent within the limitation of geospatial data in general and these data in particular. The related graphics are intended to aid the data user in acquiring relevant data; it is not appropriate to use the related graphics as data. The National Park Service gives no warranty, expressed or implied, as to the accuracy, reliability, or completeness of these data. It is strongly recommended that these data are directly acquired from an NPS server and not indirectly through other sources which may have changed the data in some way. Although these data have been processed successfully on computer systems at the National Park Service, no warranty expressed or implied is made regarding the utility of the data on other systems for general or scientific purposes, nor shall the act of distribution constitute any such warranty. This disclaimer applies both to individual use of the data and aggregate use with other data.\";\n"
            + "    String naming_authority \"gov.noaa.pfeg.coastwatch\";\n"
            + "    Float64 Northernmost_Northing 34.05;\n"
            + "    String observationDimension \"row\";\n"
            + // 2012-07-27 this should disappear soon
            "    String project \"NOAA NMFS SWFSC ERD (https://www.pfeg.noaa.gov/)\";\n"
            + "    String references \"Channel Islands National Parks Inventory and Monitoring information: http://nature.nps.gov/im/units/medn . Kelp Forest Monitoring Protocols: http://www.nature.nps.gov/im/units/chis/Reports_PDF/Marine/KFM-HandbookVol1.pdf .\";\n"
            + "    String sourceUrl \"(local files)\";\n"
            + "    Float64 Southernmost_Northing 32.8;\n"
            + "    String standard_name_vocabulary \"CF Standard Name Table v70\";\n"
            + "    String subsetVariables \"id, longitude, latitude, common_name, species_name\";\n"
            + "    String summary \"This dataset has measurements of the size of selected animal species at selected locations in the Channel Islands National Park. Sampling is conducted annually between the months of May-October, so the Time data in this file is July 1 of each year (a nominal value). The size frequency measurements were taken within 10 meters of the transect line at each site.  Depths at the site vary some, but we describe the depth of the site along the transect line where that station's temperature logger is located, a typical depth for the site.\";\n"
            + "    String time_coverage_end \"2007-07-01T00:00:00Z\";\n"
            + "    String time_coverage_start \"1985-07-01T00:00:00Z\";\n"
            + "    String title \"Channel Islands, Kelp Forest Monitoring, Size and Frequency, Natural Habitat, 1985-2007\";\n"
            + "    Float64 Westernmost_Easting -120.4;\n"
            + "  }\n"
            + "}\n";
    int tPo = results.indexOf(expected.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(
        results.substring(tPo, Math.min(results.length(), tPo + expected.length())),
        expected,
        "results=\n" + results);

    // *** test getting dds for entire dataset
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", dir, eddTable.className() + "_Entire", ".dds");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    String id;\n"
            + "    Float64 longitude;\n"
            + "    Float64 latitude;\n"
            + "    Float64 depth;\n"
            + "    Float64 time;\n"
            + "    String common_name;\n"
            + "    String species_name;\n"
            + "    Int16 size;\n"
            + "  } s;\n"
            + "} s;\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // *** test make data files
    String2.log("\n****************** EDDTableFromNcFiles.test 1D make DATA FILES\n");

    // .csv for one lat,lon,time
    userDapQuery = "" + "&longitude=-119.05&latitude=33.46666666666&time=2005-07-01T00:00:00";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_1Station", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "id,longitude,latitude,depth,time,common_name,species_name,size\n"
            + (EDStatic.useSaxParser
                ? "unitless,degrees_east,degrees_north,m,UTC,unitless,unitless,mm\n"
                : ",degrees_east,degrees_north,m,UTC,,,mm\n")
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Bat star,Asterina miniata,57\n"
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Bat star,Asterina miniata,41\n"
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Bat star,Asterina miniata,55\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);
    expected = // last 3 lines
        "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Purple sea urchin,Strongylocentrotus purpuratus,15\n"
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Purple sea urchin,Strongylocentrotus purpuratus,23\n"
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Purple sea urchin,Strongylocentrotus purpuratus,19\n";
    Test.ensureEqual(
        results.substring(results.length() - expected.length()),
        expected,
        "\nresults=\n" + results);

    // .csv for one lat,lon,time via lon > <
    userDapQuery =
        ""
            + "&longitude>-119.06&longitude<=-119.04&latitude=33.46666666666&time=2005-07-01T00:00:00";
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            userDapQuery,
            dir,
            eddTable.className() + "_1StationGTLT",
            ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "id,longitude,latitude,depth,time,common_name,species_name,size\n"
            + (EDStatic.useSaxParser
                ? "unitless,degrees_east,degrees_north,m,UTC,unitless,unitless,mm\n"
                : ",degrees_east,degrees_north,m,UTC,,,mm\n")
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Bat star,Asterina miniata,57\n"
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Bat star,Asterina miniata,41\n"
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Bat star,Asterina miniata,55\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);
    expected = // last 3 lines
        "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Purple sea urchin,Strongylocentrotus purpuratus,15\n"
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Purple sea urchin,Strongylocentrotus purpuratus,23\n"
            + "Santa Barbara (Webster's Arch),-119.05,33.4666666666667,14.0,2005-07-01T00:00:00Z,Purple sea urchin,Strongylocentrotus purpuratus,19\n";
    Test.ensureEqual(
        results.substring(results.length() - expected.length()),
        expected,
        "\nresults=\n" + results);

    // .csv for test requesting all stations, 1 time, 1 species
    userDapQuery = "" + "&time=2005-07-01&common_name=\"Red+abalone\"";
    long time = System.currentTimeMillis();
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_eq", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "id,longitude,latitude,depth,time,common_name,species_name,size\n"
            + (EDStatic.useSaxParser
                ? "unitless,degrees_east,degrees_north,m,UTC,unitless,unitless,mm\n"
                : ",degrees_east,degrees_north,m,UTC,,,mm\n")
            + "San Miguel (Hare Rock),-120.35,34.05,5.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,13\n"
            + "San Miguel (Miracle Mile),-120.4,34.0166666666667,10.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,207\n"
            + "San Miguel (Miracle Mile),-120.4,34.0166666666667,10.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,203\n"
            + "San Miguel (Miracle Mile),-120.4,34.0166666666667,10.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,193\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);
    expected = // last 3 lines
        "Santa Rosa (South Point),-120.116666666667,33.8833333333333,13.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,185\n"
            + "Santa Rosa (Trancion Canyon),-120.15,33.9,9.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,198\n"
            + "Santa Rosa (Trancion Canyon),-120.15,33.9,9.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,85\n";
    Test.ensureEqual(
        results.substring(results.length() - expected.length()),
        expected,
        "\nresults=\n" + results);

    // .csv for test requesting all stations, 1 time, 1 species String !=
    userDapQuery =
        "" + "&time=2005-07-01&id!=\"San+Miguel+(Hare+Rock)\"&common_name=\"Red+abalone\"";
    time = System.currentTimeMillis();
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_NE", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "id,longitude,latitude,depth,time,common_name,species_name,size\n"
            + (EDStatic.useSaxParser
                ? "unitless,degrees_east,degrees_north,m,UTC,unitless,unitless,mm\n"
                : ",degrees_east,degrees_north,m,UTC,,,mm\n")
            + "San Miguel (Miracle Mile),-120.4,34.0166666666667,10.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,207\n"
            + "San Miguel (Miracle Mile),-120.4,34.0166666666667,10.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,203\n"
            + "San Miguel (Miracle Mile),-120.4,34.0166666666667,10.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,193\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);
    expected = // last 3 lines
        "Santa Rosa (South Point),-120.116666666667,33.8833333333333,13.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,185\n"
            + "Santa Rosa (Trancion Canyon),-120.15,33.9,9.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,198\n"
            + "Santa Rosa (Trancion Canyon),-120.15,33.9,9.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,85\n";
    Test.ensureEqual(
        results.substring(results.length() - expected.length()),
        expected,
        "\nresults=\n" + results);

    // .csv for test requesting all stations, 1 time, 1 species String > <
    userDapQuery =
        ""
            + "&time=2005-07-01&id>\"San+Miguel+(G\"&id<=\"San+Miguel+(I\"&common_name=\"Red+abalone\"";
    time = System.currentTimeMillis();
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_gtlt", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "id,longitude,latitude,depth,time,common_name,species_name,size\n"
            + (EDStatic.useSaxParser
                ? "unitless,degrees_east,degrees_north,m,UTC,unitless,unitless,mm\n"
                : ",degrees_east,degrees_north,m,UTC,,,mm\n")
            + "San Miguel (Hare Rock),-120.35,34.05,5.0,2005-07-01T00:00:00Z,Red abalone,Haliotis rufescens,13\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv for test requesting all stations, 1 time, 1 species REGEX
    userDapQuery =
        "longitude,latitude,depth,time,id,species_name,size"
            + // no common_name
            "&time=2005-07-01&id=~\"(zztop|.*Hare+Rock.*)\"&common_name=\"Red+abalone\""; // but
    // common_name
    // here
    time = System.currentTimeMillis();
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_regex", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "longitude,latitude,depth,time,id,species_name,size\n"
            + (EDStatic.useSaxParser
                ? "degrees_east,degrees_north,m,UTC,unitless,unitless,mm\n"
                : "degrees_east,degrees_north,m,UTC,,,mm\n")
            + "-120.35,34.05,5.0,2005-07-01T00:00:00Z,San Miguel (Hare Rock),Haliotis rufescens,13\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /**
   * This tests the methods in this class with a 2D dataset.
   *
   * @throws Throwable if trouble
   */
  @ParameterizedTest
  @ValueSource(booleans = {true, false})
  @TagSlowTests
  void test2D(boolean deleteCachedDatasetInfo) throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.test2D()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    EDV edv;

    // the test files were made with makeTestFiles();
    String id = "testNc2D";
    if (deleteCachedDatasetInfo) EDDTableFromNcFiles.deleteCachedDatasetInfo(id);

    // touch a good and a bad file, so they are checked again
    String dataDir =
        Path.of(EDDTableFromNcFilesTests.class.getResource("/largePoints/nc2d/").toURI()).toString()
            + "/";
    File2.touch(dataDir + "NDBC_32012_met.nc");
    File2.touch(dataDir + "NDBC_4D_met.nc");

    EDDTable eddTable = (EDDTable) EDDTestDataset.gettestNc2d();
    // just comment out when working on datasets below
    /*
     * currently not active
     * Test.ensureTrue(eddTable.sosOfferings().indexOf("41002") >= 0,
     * eddTable.sosOfferings().toString());
     * //Test.ensureEqual(eddTable.sosObservedProperties()[0],
     * //
     * "https://www.coast.noaa.gov/ioos/schema/IOOS-DIF/IOOS/0.6.0/dictionaries/phenomenaDictionary.xml#AverageWavePeriod",
     * // "");
     */
    // *** test getting das for entire dataset
    String2.log("\n****************** EDDTableFromNcFiles 2D test das dds for entire dataset\n");
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", dir, eddTable.className() + "_Entire", ".das");
    results = String2.annotatedString(File2.directReadFrom88591File(dir + tName));
    // String2.log(results);
    expected =
        "  time {[10]\n"
            + "    String _CoordinateAxisType \"Time\";[10]\n"
            + "    Float64 actual_range 8.67456e+7, 1.2075984e+9;[10]\n"
            + "    String axis \"T\";[10]\n"
            + "    String comment \"Time in seconds since 1970-01-01T00:00:00Z. The original times are rounded to the nearest hour.\";[10]\n"
            + "    String ioos_category \"Time\";[10]\n"
            + "    String long_name \"Time\";[10]\n"
            + "    String standard_name \"time\";[10]\n"
            + "    String time_origin \"01-JAN-1970 00:00:00\";[10]\n"
            + "    String units \"seconds since 1970-01-01T00:00:00Z\";[10]\n"
            + "  }[10]\n";
    Test.ensureTrue(results.indexOf(expected) > 0, "\nresults=\n" + results);
    expected = "  wd {[10]\n" + "    Int16 _FillValue 32767;[10]\n";
    Test.ensureTrue(results.indexOf(expected) > 0, "\nresults=\n" + results);
    expected =
        "  wspv {[10]\n"
            + "    Float32 _FillValue -9999999.0;[10]\n"
            + "    Float32 actual_range"; // varies with subset -6.1, 11.0;[10]
    Test.ensureTrue(results.indexOf(expected) > 0, "\nresults=\n" + results);
    expected =
        "    String comment \"The meridional wind speed (m/s) indicates the v component of where the wind is going, derived from Wind Direction and Wind Speed.\";[10]\n"
            + "    String ioos_category \"Wind\";[10]\n"
            + "    String long_name \"Wind Speed, Meridional\";[10]\n"
            + "    Float32 missing_value -9999999.0;[10]\n"
            + "    String standard_name \"northward_wind\";[10]\n"
            + "    String units \"m s-1\";[10]\n"
            + "  }[10]\n";
    Test.ensureTrue(results.indexOf(expected) > 0, "\nresults=\n" + results);

    // *** test getting dds for entire dataset
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", dir, eddTable.className() + "_Entire", ".dds");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    String station;\n"
            + "    Float32 latitude;\n"
            + "    Float64 time;\n"
            + // no altitude or longitude
            "    Int16 wd;\n"
            + "    Float32 wspd;\n"
            + "    Float32 gst;\n"
            + "    Float32 wvht;\n"
            + "    Float32 dpd;\n"
            + "    Float32 apd;\n"
            + "    Int16 mwd;\n"
            + "    Float32 bar;\n"
            + "    Float32 atmp;\n"
            + "    Float32 wtmp;\n"
            + "    Float32 dewp;\n"
            + "    Float32 vis;\n"
            + "    Float32 ptdy;\n"
            + "    Float32 tide;\n"
            + "    Float32 wspu;\n"
            + "    Float32 wspv;\n"
            + "  } s;\n"
            + "} s;\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // *** test make data files
    String2.log("\n****************** EDDTableFromNcFiles.test2D make DATA FILES\n");

    // .csv
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    // double seconds = Calendar2.isoStringToEpochSeconds("2005-04-19T00");
    // int row = table.getColumn(timeIndex).indexOf("" + seconds, 0);
    // Test.ensureEqual(table.getStringData(sosOfferingIndex, row), "31201", "");
    // Test.ensureEqual(table.getFloatData(latIndex, row), -27.7f, "");
    // Test.ensureEqual(table.getFloatData(lonIndex, row), -48.13f, "");

    userDapQuery =
        "latitude,time,station,wvht,dpd,wtmp,dewp" + "&latitude=-27.7&time=2005-04-19T00";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "latitude,time,station,wvht,dpd,wtmp,dewp\n"
            + "degrees_north,UTC,,m,s,degree_C,degree_C\n"
            + "-27.7,2005-04-19T00:00:00Z,31201,1.4,9.0,24.4,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 25 18 00 999 99.0 99.0 3.90 8.00 99.00 999 9999.0 999.0 23.9 999.0
    // 99.0 99.00
    userDapQuery =
        "latitude,time,station,wvht,dpd,wtmp,dewp"
            + "&latitude=-27.7&time>=2005-04-01&time<=2005-04-26";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected = "latitude,time,station,wvht,dpd,wtmp,dewp\n";
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);
    expected = "degrees_north,UTC,,m,s,degree_C,degree_C\n";
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);
    expected = "-27.7,2005-04-19T00:00:00Z,31201,1.4,9.0,24.4,NaN\n"; // time above
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);
    expected = "-27.7,2005-04-25T18:00:00Z,31201,3.9,8.0,23.9,NaN\n"; // this time
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);

    // test requesting a lat area
    userDapQuery =
        "latitude,time,station,wvht,dpd,wtmp,dewp" + "&latitude>35&latitude<39&time=2005-04-01";
    long time = System.currentTimeMillis();
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data3", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "latitude,time,station,wvht,dpd,wtmp,dewp\n"
            + "degrees_north,UTC,,m,s,degree_C,degree_C\n"
            + "35.01,2005-04-01T00:00:00Z,41025,1.34,10.0,9.1,14.9\n"
            + "38.47,2005-04-01T00:00:00Z,44004,2.04,11.43,9.8,4.9\n"
            + "38.46,2005-04-01T00:00:00Z,44009,1.3,10.0,5.0,5.7\n"
            + "36.61,2005-04-01T00:00:00Z,44014,1.67,11.11,6.5,8.6\n"
            + "37.36,2005-04-01T00:00:00Z,46012,2.55,12.5,13.7,NaN\n"
            + "38.23,2005-04-01T00:00:00Z,46013,2.3,12.9,13.9,NaN\n"
            + "37.75,2005-04-01T00:00:00Z,46026,1.96,12.12,14.0,NaN\n"
            + "35.74,2005-04-01T00:00:00Z,46028,2.57,12.9,16.3,NaN\n"
            + "36.75,2005-04-01T00:00:00Z,46042,2.21,17.39,14.5,NaN\n"
            + "37.98,2005-04-01T00:00:00Z,46059,2.51,14.29,12.9,NaN\n"
            + "36.83,2005-04-01T00:00:00Z,46091,NaN,NaN,NaN,NaN\n"
            + "36.75,2005-04-01T00:00:00Z,46092,NaN,NaN,NaN,NaN\n"
            + "36.69,2005-04-01T00:00:00Z,46093,NaN,NaN,14.3,NaN\n"
            + "37.57,2005-04-01T00:00:00Z,46214,2.5,9.0,12.8,NaN\n"
            + "35.21,2005-04-01T00:00:00Z,46215,1.4,10.0,11.4,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test that constraint vars are sent to low level data request
    userDapQuery =
        "latitude,station,wvht,dpd,wtmp,dewp"
            + // no "time" here
            "&latitude>35&latitude<39&time=2005-04-01"; // "time" here
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data4", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "latitude,station,wvht,dpd,wtmp,dewp\n"
            + "degrees_north,,m,s,degree_C,degree_C\n"
            + "35.01,41025,1.34,10.0,9.1,14.9\n"
            + "38.47,44004,2.04,11.43,9.8,4.9\n"
            + "38.46,44009,1.3,10.0,5.0,5.7\n"
            + "36.61,44014,1.67,11.11,6.5,8.6\n"
            + "37.36,46012,2.55,12.5,13.7,NaN\n"
            + "38.23,46013,2.3,12.9,13.9,NaN\n"
            + "37.75,46026,1.96,12.12,14.0,NaN\n"
            + "35.74,46028,2.57,12.9,16.3,NaN\n"
            + "36.75,46042,2.21,17.39,14.5,NaN\n"
            + "37.98,46059,2.51,14.29,12.9,NaN\n"
            + "36.83,46091,NaN,NaN,NaN,NaN\n"
            + "36.75,46092,NaN,NaN,NaN,NaN\n"
            + "36.69,46093,NaN,NaN,14.3,NaN\n"
            + "37.57,46214,2.5,9.0,12.8,NaN\n"
            + "35.21,46215,1.4,10.0,11.4,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test that constraint vars are sent to low level data request
    // and that constraint causing 0rows for a station doesn't cause problems
    userDapQuery = "latitude,wtmp&time>=2008-03-14T18:00:00Z&time<=2008-03-14T18:00:00Z&wtmp>20";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data5", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "latitude,wtmp\n"
            + "degrees_north,degree_C\n"
            + "32.31,23.5\n"
            + "28.5,21.3\n"
            + "28.95,23.7\n"
            + "30.0,20.1\n"
            + "14.53,25.3\n"
            + "20.99,25.7\n"
            + "27.47,23.8\n"
            + "31.9784,22.0\n"
            + "28.4,21.0\n"
            + "27.55,21.8\n"
            + "25.9,24.1\n"
            + "25.17,23.9\n"
            + "26.07,26.1\n"
            + "22.01,24.4\n"
            + "19.87,26.8\n"
            + "15.01,26.4\n"
            + "27.3403,20.2\n"
            + "29.06,21.8\n"
            + "38.47,20.4\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /**
   * This tests the methods in this class with a 3D dataset.
   *
   * @throws Throwable if trouble
   */
  @ParameterizedTest
  @ValueSource(booleans = {true, false})
  @TagSlowTests
  void test3D(boolean deleteCachedDatasetInfo) throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.test3D()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDV edv;
    String id = "testNc3D";

    if (deleteCachedDatasetInfo) EDDTableFromNcFiles.deleteCachedDatasetInfo(id);

    // touch a good and a bad file, so they are checked again
    File2.touch(
        EDDTableFromNcFilesTests.class
            .getResource("/largePoints/nc3d/NDBC_32012_met.nc")
            .getPath());
    File2.touch(
        EDDTableFromNcFilesTests.class.getResource("/largePoints/nc3d/NDBC_4D_met.nc").getPath());

    EDDTable eddTable = (EDDTable) EDDTestDataset.gettestNc3d();
    // just comment out when working on datasets below
    /*
     * currently not active
     * //test sos-server values
     * Test.ensureTrue(eddTable.sosOfferings().indexOf("32012") >= 0,
     * eddTable.sosOfferings().toString());
     * //Test.ensureEqual(eddTable.sosObservedProperties()[0],
     * //
     * "https://www.coast.noaa.gov/ioos/schema/IOOS-DIF/IOOS/0.6.0/dictionaries/phenomenaDictionary.xml#AverageWavePeriod",
     * // "");
     */
    // *** test getting das for entire dataset
    String2.log("\n****************** EDDTableFromNcFiles test3D das dds for entire dataset\n");
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", dir, eddTable.className() + "_Entire", ".das");
    results = String2.annotatedString(File2.directReadFrom88591File(dir + tName));
    // String2.log(results);
    expected =
        "  time {[10]\n"
            + "    String _CoordinateAxisType \"Time\";[10]\n"
            + "    Float64 actual_range 8.67456e+7, 1.2075984e+9;[10]\n"
            + "    String axis \"T\";[10]\n"
            + "    String comment \"Time in seconds since 1970-01-01T00:00:00Z. The original times are rounded to the nearest hour.\";[10]\n"
            + "    String ioos_category \"Time\";[10]\n"
            + "    String long_name \"Time\";[10]\n"
            + "    String standard_name \"time\";[10]\n"
            + "    String time_origin \"01-JAN-1970 00:00:00\";[10]\n"
            + "    String units \"seconds since 1970-01-01T00:00:00Z\";[10]\n"
            + "  }[10]\n";
    Test.ensureTrue(results.indexOf(expected) > 0, "\nresults=\n" + results);
    expected = "  wd {[10]\n" + "    Int16 _FillValue 32767;[10]\n";
    Test.ensureTrue(results.indexOf(expected) > 0, "\nresults=\n" + results);
    expected =
        "  wspv {[10]\n"
            + "    Float32 _FillValue -9999999.0;[10]\n"
            + "    Float32 actual_range"; // varies with subset -6.1, 11.0;[10]
    Test.ensureTrue(results.indexOf(expected) > 0, "\nresults=\n" + results);
    expected =
        "    String comment \"The meridional wind speed (m/s) indicates the v component of where the wind is going, derived from Wind Direction and Wind Speed.\";[10]\n"
            + "    String ioos_category \"Wind\";[10]\n"
            + "    String long_name \"Wind Speed, Meridional\";[10]\n"
            + "    Float32 missing_value -9999999.0;[10]\n"
            + "    String standard_name \"northward_wind\";[10]\n"
            + "    String units \"m s-1\";[10]\n"
            + "  }[10]\n";
    Test.ensureTrue(results.indexOf(expected) > 0, "\nresults=\n" + results);

    // *** test getting dds for entire dataset
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", dir, eddTable.className() + "_Entire", ".dds");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    String station;\n"
            + "    Float32 longitude;\n"
            + "    Float32 latitude;\n"
            + "    Float64 time;\n"
            + // no altitude
            "    Int16 wd;\n"
            + "    Float32 wspd;\n"
            + "    Float32 gst;\n"
            + "    Float32 wvht;\n"
            + "    Float32 dpd;\n"
            + "    Float32 apd;\n"
            + "    Int16 mwd;\n"
            + "    Float32 bar;\n"
            + "    Float32 atmp;\n"
            + "    Float32 wtmp;\n"
            + "    Float32 dewp;\n"
            + "    Float32 vis;\n"
            + "    Float32 ptdy;\n"
            + "    Float32 tide;\n"
            + "    Float32 wspu;\n"
            + "    Float32 wspv;\n"
            + "  } s;\n"
            + "} s;\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // *** test make data files
    String2.log("\n****************** EDDTableFromNcFiles.test3D make DATA FILES\n");

    // .csv
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    // double seconds = Calendar2.isoStringToEpochSeconds("2005-04-19T00");
    // int row = table.getColumn(timeIndex).indexOf("" + seconds, 0);
    // Test.ensureEqual(table.getStringData(sosOfferingIndex, row), "31201", "");
    // Test.ensureEqual(table.getFloatData(latIndex, row), -27.7f, "");
    // Test.ensureEqual(table.getFloatData(lonIndex, row), -48.13f, "");

    userDapQuery =
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp"
            + "&longitude=-48.13&latitude=-27.7&time=2005-04-19T00";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp\n"
            + "degrees_east,degrees_north,UTC,,m,s,degree_C,degree_C\n"
            + "-48.13,-27.7,2005-04-19T00:00:00Z,31201,1.4,9.0,24.4,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 25 18 00 999 99.0 99.0 3.90 8.00 99.00 999 9999.0 999.0 23.9 999.0
    // 99.0 99.00
    userDapQuery =
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp"
            + "&longitude=-48.13&latitude=-27.7&time>=2005-04-01&time<=2005-04-26";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected = "longitude,latitude,time,station,wvht,dpd,wtmp,dewp\n";
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);
    expected = "degrees_east,degrees_north,UTC,,m,s,degree_C,degree_C\n";
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);
    expected = "-48.13,-27.7,2005-04-19T00:00:00Z,31201,1.4,9.0,24.4,NaN\n"; // time above
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);
    expected = "-48.13,-27.7,2005-04-25T18:00:00Z,31201,3.9,8.0,23.9,NaN\n"; // this time
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);

    // test requesting a lat lon area
    userDapQuery =
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp"
            + "&longitude>-125&longitude<-121&latitude>35&latitude<39&time=2005-04-01";
    long time = System.currentTimeMillis();
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data3", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp\n"
            + "degrees_east,degrees_north,UTC,,m,s,degree_C,degree_C\n"
            + "-122.88,37.36,2005-04-01T00:00:00Z,46012,2.55,12.5,13.7,NaN\n"
            + "-123.32,38.23,2005-04-01T00:00:00Z,46013,2.3,12.9,13.9,NaN\n"
            + "-122.82,37.75,2005-04-01T00:00:00Z,46026,1.96,12.12,14.0,NaN\n"
            + "-121.89,35.74,2005-04-01T00:00:00Z,46028,2.57,12.9,16.3,NaN\n"
            + "-122.42,36.75,2005-04-01T00:00:00Z,46042,2.21,17.39,14.5,NaN\n"
            + "-121.9,36.83,2005-04-01T00:00:00Z,46091,NaN,NaN,NaN,NaN\n"
            + "-122.02,36.75,2005-04-01T00:00:00Z,46092,NaN,NaN,NaN,NaN\n"
            + "-122.41,36.69,2005-04-01T00:00:00Z,46093,NaN,NaN,14.3,NaN\n"
            + "-123.28,37.57,2005-04-01T00:00:00Z,46214,2.5,9.0,12.8,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test that constraint vars are sent to low level data request
    userDapQuery =
        "longitude,latitude,station,wvht,dpd,wtmp,dewp"
            + // no "time" here
            "&longitude>-125&longitude<-121&latitude>35&latitude<39&time=2005-04-01"; // "time" here
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data4", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "longitude,latitude,station,wvht,dpd,wtmp,dewp\n"
            + "degrees_east,degrees_north,,m,s,degree_C,degree_C\n"
            + "-122.88,37.36,46012,2.55,12.5,13.7,NaN\n"
            + "-123.32,38.23,46013,2.3,12.9,13.9,NaN\n"
            + "-122.82,37.75,46026,1.96,12.12,14.0,NaN\n"
            + "-121.89,35.74,46028,2.57,12.9,16.3,NaN\n"
            + "-122.42,36.75,46042,2.21,17.39,14.5,NaN\n"
            + "-121.9,36.83,46091,NaN,NaN,NaN,NaN\n"
            + "-122.02,36.75,46092,NaN,NaN,NaN,NaN\n"
            + "-122.41,36.69,46093,NaN,NaN,14.3,NaN\n"
            + "-123.28,37.57,46214,2.5,9.0,12.8,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test that constraint vars are sent to low level data request
    // and that constraint causing 0rows for a station doesn't cause problems
    userDapQuery =
        "longitude,latitude,wtmp&time>=2008-03-14T18:00:00Z&time<=2008-03-14T18:00:00Z&wtmp>20";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data5", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "longitude,latitude,wtmp\n"
            + "degrees_east,degrees_north,degree_C\n"
            + "-75.35,32.31,23.5\n"
            + "-80.17,28.5,21.3\n"
            + "-78.47,28.95,23.7\n"
            + "-80.6,30.0,20.1\n"
            + "-46.0,14.53,25.3\n"
            + "-65.01,20.99,25.7\n"
            + "-71.49,27.47,23.8\n"
            + "-69.649,31.9784,22.0\n"
            + "-80.53,28.4,21.0\n"
            + "-80.22,27.55,21.8\n"
            + "-89.67,25.9,24.1\n"
            + "-94.42,25.17,23.9\n"
            + "-85.94,26.07,26.1\n"
            + "-94.05,22.01,24.4\n"
            + "-85.06,19.87,26.8\n"
            + "-67.5,15.01,26.4\n"
            + "-84.245,27.3403,20.2\n"
            + "-88.09,29.06,21.8\n"
            + "-70.56,38.47,20.4\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /**
   * This tests the methods in this class with a 4D dataset.
   *
   * @throws Throwable if trouble
   */
  @ParameterizedTest
  @ValueSource(booleans = {true, false})
  @TagLargeFiles
  void test4D(boolean deleteCachedDatasetInfo) throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.test4D()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String error = "";
    int po;
    EDV edv;

    String id = "cwwcNDBCMet";
    if (deleteCachedDatasetInfo) EDDTableFromNcFiles.deleteCachedDatasetInfo(id);

    // touch a good and a bad file, so they are checked again
    String dataDir =
        Path.of(EDDTableFromNcFilesTests.class.getResource("/veryLarge/points/ndbcMet/").toURI())
                .toString()
            + "/";
    File2.touch(dataDir + "NDBC_32012_met.nc");
    File2.touch(dataDir + "NDBC_3D_met.nc");

    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();
    // just comment out when working on datasets below
    /*
     * currently not active
     * Test.ensureTrue(eddTable.sosOfferings().indexOf("32012") >= 0,
     * eddTable.sosOfferings().toString());
     * //Test.ensureEqual(eddTable.sosObservedProperties()[0],
     * //
     * "https://www.coast.noaa.gov/ioos/schema/IOOS-DIF/IOOS/0.6.0/dictionaries/phenomenaDictionary.xml#AverageWavePeriod",
     * // "");
     */
    // *** test getting das for entire dataset
    String2.log("\n****************** EDDTableFromNcFiles test4D das dds for entire dataset\n");
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", dir, eddTable.className() + "_Entire", ".das");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);

    expected = "  wd {\n" + "    Int16 _FillValue 32767;\n";
    int tPo = results.indexOf(expected.substring(0, 10));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(
        results.substring(tPo, tPo + expected.length()), expected, "\nresults=\n" + results);

    expected =
        "  wvht {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range 0.0, 92.39;\n"
            + "    Float64 colorBarMaximum 10.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Significant wave height (meters) is calculated as the average of the highest one-third of all of the wave heights during "
            + "the 20-minute sampling period.\";\n"
            + "    String ioos_category \"Surface Waves\";\n"
            + "    String long_name \"Wave Height\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"sea_surface_wave_significant_height\";\n"
            + "    String units \"m\";\n"
            + "  }\n";
    tPo = results.indexOf(expected.substring(0, 10));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(
        results.substring(tPo, tPo + expected.length()), expected, "\nresults=\n" + results);

    expected =
        "  wspv {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range"; // varies with subset -6.1, 11.0;
    tPo = results.indexOf(expected.substring(0, 10));
    if (tPo < 0) String2.log("\ntPo=-1 results=\n" + results);
    Test.ensureEqual(
        results.substring(tPo, tPo + expected.length()), expected, "\nresults=\n" + results);

    expected =
        "The meridional wind speed (m/s) indicates the v component of where the wind is going, derived from Wind Direction and Wind Speed.\";\n"
            + "    String ioos_category \"Wind\";\n"
            + "    String long_name \"Wind Speed, Meridional\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"northward_wind\";\n"
            + "    String units \"m s-1\";\n"
            + "  }\n";
    tPo = results.indexOf(expected.substring(0, 10));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(
        results.substring(tPo, tPo + expected.length()), expected, "\nresults=\n" + results);

    // *** test getting dds for entire dataset
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", dir, eddTable.className() + "_Entire", ".dds");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    String station;\n"
            + "    Float32 longitude;\n"
            + "    Float32 latitude;\n"
            + "    Float64 time;\n"
            + "    Int16 wd;\n"
            + "    Float32 wspd;\n"
            + "    Float32 gst;\n"
            + "    Float32 wvht;\n"
            + "    Float32 dpd;\n"
            + "    Float32 apd;\n"
            + "    Int16 mwd;\n"
            + "    Float32 bar;\n"
            + "    Float32 atmp;\n"
            + "    Float32 wtmp;\n"
            + "    Float32 dewp;\n"
            + "    Float32 vis;\n"
            + "    Float32 ptdy;\n"
            + "    Float32 tide;\n"
            + "    Float32 wspu;\n"
            + "    Float32 wspv;\n"
            + "  } s;\n"
            + "} s;\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // *** test make data files
    String2.log("\n****************** EDDTableFromNcFiles.test4D make DATA FILES\n");

    // .csv
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    // double seconds = Calendar2.isoStringToEpochSeconds("2005-04-19T00");
    // int row = table.getColumn(timeIndex).indexOf("" + seconds, 0);
    // Test.ensureEqual(table.getStringData(sosOfferingIndex, row), "31201", "");
    // Test.ensureEqual(table.getFloatData(latIndex, row), -27.7f, "");
    // Test.ensureEqual(table.getFloatData(lonIndex, row), -48.13f, "");

    // 2011-04-12 was -48.13&latitude=-27.7 now 27.705 S 48.134 W
    userDapQuery =
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp"
            + "&longitude=-48.134&latitude=-27.705&time=2005-04-19T00";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp\n"
            + "degrees_east,degrees_north,UTC,,m,s,degree_C,degree_C\n"
            + "-48.134,-27.705,2005-04-19T00:00:00Z,31201,1.4,9.0,24.4,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 25 18 00 999 99.0 99.0 3.90 8.00 99.00 999 9999.0 999.0 23.9 999.0
    // 99.0 99.00
    userDapQuery =
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp"
            + "&longitude=-48.134&latitude=-27.705&time>=2005-04-01&time<=2005-04-26";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected = "longitude,latitude,time,station,wvht,dpd,wtmp,dewp\n";
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);
    expected = "degrees_east,degrees_north,UTC,,m,s,degree_C,degree_C\n";
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);
    expected = "-48.134,-27.705,2005-04-19T00:00:00Z,31201,1.4,9.0,24.4,NaN\n"; // time above
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);
    expected = "-48.134,-27.705,2005-04-25T18:00:00Z,31201,3.9,8.0,23.9,NaN\n"; // this time
    Test.ensureTrue(results.indexOf(expected) >= 0, "\nresults=\n" + results);

    // test requesting a lat lon area
    userDapQuery =
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp"
            + "&longitude>-125&longitude<-121&latitude>35&latitude<39&time=2005-04-01";
    long time = System.currentTimeMillis();
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data3", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected = // changed 2011-04-12 after reprocessing everything:
        // more precise lat lon: from mostly 2 decimal digits to mostly 3.
        // changed 2020-03-05 after change to precise time.
        // data that was here from time round to hour is now gone
        "longitude,latitude,time,station,wvht,dpd,wtmp,dewp\n"
            + "degrees_east,degrees_north,UTC,,m,s,degree_C,degree_C\n"
            + "-122.881,37.363,2005-04-01T00:00:00Z,46012,2.55,12.5,13.7,NaN\n"
            + "-123.301,38.242,2005-04-01T00:00:00Z,46013,2.3,12.9,13.9,NaN\n"
            + "-122.833,37.759,2005-04-01T00:00:00Z,46026,1.96,12.12,14.0,NaN\n"
            + "-121.884,35.741,2005-04-01T00:00:00Z,46028,2.57,12.9,16.3,NaN\n"
            + "-122.404,36.789,2005-04-01T00:00:00Z,46042,2.21,17.39,14.5,NaN\n"
            + "-122.02,36.75,2005-04-01T00:00:00Z,46092,NaN,NaN,NaN,NaN\n"
            + "-122.41,36.69,2005-04-01T00:00:00Z,46093,NaN,NaN,14.3,NaN\n"
            + "-123.47,37.945,2005-04-01T00:00:00Z,46214,2.5,9.0,12.8,NaN\n"
            + "-122.298,37.772,2005-04-01T00:00:00Z,AAMC1,NaN,NaN,15.5,NaN\n"
            + "-122.465,37.807,2005-04-01T00:00:00Z,FTPC1,NaN,NaN,NaN,NaN\n"
            + "-121.888,36.605,2005-04-01T00:00:00Z,MTYC1,NaN,NaN,15.1,NaN\n"
            + "-123.74,38.955,2005-04-01T00:00:00Z,PTAC1,NaN,NaN,NaN,NaN\n"
            + "-122.21,37.507,2005-04-01T00:00:00Z,RTYC1,NaN,NaN,14.2,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test that constraint vars are sent to low level data request
    userDapQuery =
        "longitude,latitude,station,wvht,dpd,wtmp,dewp"
            + // no "time" here
            "&longitude>-125&longitude<-121&latitude>35&latitude<39&time=2005-04-01"; // "time" here
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data4", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected = // changed 2011-04-12 after reprocessing everything:
        // more precise lat lon: from mostly 2 decimal digits to mostly 3.
        // changed 2020-03-05 after change to precise time.
        // data that was here from time round to hour is now gone
        "longitude,latitude,station,wvht,dpd,wtmp,dewp\n"
            + "degrees_east,degrees_north,,m,s,degree_C,degree_C\n"
            + "-122.881,37.363,46012,2.55,12.5,13.7,NaN\n"
            + "-123.301,38.242,46013,2.3,12.9,13.9,NaN\n"
            + "-122.833,37.759,46026,1.96,12.12,14.0,NaN\n"
            + "-121.884,35.741,46028,2.57,12.9,16.3,NaN\n"
            + "-122.404,36.789,46042,2.21,17.39,14.5,NaN\n"
            + "-122.02,36.75,46092,NaN,NaN,NaN,NaN\n"
            + "-122.41,36.69,46093,NaN,NaN,14.3,NaN\n"
            + "-123.47,37.945,46214,2.5,9.0,12.8,NaN\n"
            + "-122.298,37.772,AAMC1,NaN,NaN,15.5,NaN\n"
            + "-122.465,37.807,FTPC1,NaN,NaN,NaN,NaN\n"
            + "-121.888,36.605,MTYC1,NaN,NaN,15.1,NaN\n"
            + "-123.74,38.955,PTAC1,NaN,NaN,NaN,NaN\n"
            + "-122.21,37.507,RTYC1,NaN,NaN,14.2,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test that constraint vars are sent to low level data request
    // and that constraint causing 0rows for a station doesn't cause problems
    userDapQuery =
        "longitude,latitude,wtmp&time>=2008-03-14T18:00:00Z&time<=2008-03-14T18:00:00Z&wtmp>20";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_Data5", ".csv");
    String2.log("queryTime=" + (System.currentTimeMillis() - time));
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected = // changed 2011-04-12 after reprocessing everything:
        // more precise lat lon: from mostly 2 decimal digits to mostly 3.
        // changed 2020-03-05 after change to precise time.
        // Data that was here from time round to hour is now gone.
        // Data values changed a little: if old system had 2+rows for 1 time,
        // new system may correctly pick a different row now
        "longitude,latitude,wtmp\n"
            + "degrees_east,degrees_north,degree_C\n"
            + "-88.09,29.06,21.7\n"
            + "-90.42,29.789,20.5\n"
            + "-64.92,18.335,27.7\n"
            + "-81.872,26.647,22.4\n"
            + "-80.097,25.59,23.5\n"
            + "-156.472,20.898,25.0\n"
            + "167.737,8.737,27.6\n"
            + "-81.808,24.553,24.0\n"
            + "-80.862,24.843,23.8\n"
            + "-64.753,17.697,26.0\n"
            + "-67.047,17.972,27.2\n"
            + "-80.38,25.01,24.2\n"
            + "-81.807,26.13,23.9\n"
            + "-170.688,-14.28,29.5\n"
            + "-157.867,21.307,25.5\n"
            + "-96.388,28.452,20.1\n"
            + "-82.773,24.693,22.8\n"
            + "-82.627,27.76,21.6\n"
            + "-66.117,18.462,28.2\n"
            + "-177.36,28.212,21.8\n"
            + "-80.593,28.415,22.8\n"
            + "166.618,19.29,27.8\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /**
   * This is run by hand (special setup) to test dealing with the last 24 hours. Before running
   * this, run NDBCMet updateLastNDays, then copy some files to /u00/data/points/ndbcMet so files
   * have very recent data.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagIncompleteTest
  @TagLargeFiles
  void test24Hours() throws Throwable {
    String2.log("\n****************** EDDTableFromNcFiles.test24Hours() *****************\n");
    // testVerboseOn();
    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    EDV edv;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // !!!change time to be ~nowLocal+16 (= nowZulu+8); e.g., T20 for local time 4pm
    userDapQuery = "longitude,latitude,time,station,wd,wtmp&time%3E=2009-03-12T20";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_24hours", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    String2.log(results);

    // in log output, look at end of constructor for "maxTime is within last 24hrs,
    // so setting maxTime to NaN (i.e., Now)."
    // in log output, look for stations saying "file maxTime is within last 24hrs,
    // so ERDDAP is pretending file maxTime is now+4hours."
  }

  /**
   * This test &amp;distinct().
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testDistinct() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testDistinct()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to
    // check min:sec.
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // time constraints force erddap to get actual data, (not just station
    // variables)
    // and order of variables says to sort by lon first
    userDapQuery =
        "longitude,latitude,station&station=~\"5.*\"&time>=2008-03-11&time<2008-03-12&distinct()";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_distincts", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected = // 2011-04-12 changed with reprocessing. Mostly 2 to mostly 3 decimal digits
        "longitude,latitude,station\n"
            + "degrees_east,degrees_north,\n"
            + "-162.279,23.445,51001\n"
            + "-160.66,19.087,51003\n"
            + "-158.116,21.673,51201\n"
            + "-157.808,17.094,51002\n"
            + "-157.668,21.417,51202\n"
            + "-153.913,0.0,51028\n"
            + "-152.382,17.525,51004\n"
            + "144.789,13.354,52200\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // if no time constraint, erddap can use SUBSET_FILENAME
    String2.log("\n* now testing just subset variables");
    userDapQuery = "longitude,latitude,station&station=~\"5.*\"&distinct()";
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            userDapQuery,
            dir,
            eddTable.className() + "_distincts2",
            ".nc"); // nc so test metadata
    results = NcHelper.ncdump(dir + tName, "");
    results = results.replaceAll("\\d{4}-\\d{2}-\\d{2}", "9999-99-99");
    results = results.replaceAll("\\d{2}:\\d{2}:\\d{2}", "99:99:99");

    // String2.log(results);
    expected = // note sorted by lon first (because of &distinct()), not order in subset file
        // 2011-04-12 lots of small changes due to full reprocessing
        // 2014-08-07 small changes
        // 2020-03-10 lots of cmall changes due to cwwcNDBCMet changes
        "netcdf EDDTableFromNcFiles_distincts2.nc {\n"
            + "  dimensions:\n"
            + "    row = 31;\n"
            + "    station_strlen = 5;\n"
            + "  variables:\n"
            + "    float longitude(row=31);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :actual_range = -170.493f, 171.395f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :colorBarMaximum = 180.0; // double\n"
            + "      :colorBarMinimum = -180.0; // double\n"
            + "      :comment = \"The longitude of the station.\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "    float latitude(row=31);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :actual_range = -14.265f, 24.321f; // float\n"
            + "      :axis = \"Y\";\n"
            + "      :colorBarMaximum = 90.0; // double\n"
            + "      :colorBarMinimum = -90.0; // double\n"
            + "      :comment = \"The latitude of the station.\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "\n"
            + "    char station(row=31, station_strlen=5);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"timeseries_id\";\n"
            + "      :comment = \"The station identifier.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station Identifier\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"TimeSeries\";\n"
            + "  :cdm_timeseries_variables = \"station, longitude, latitude\";\n"
            + "  :contributor_name = \"NOAA NDBC\";\n"
            + "  :contributor_role = \"Source of data.\";\n"
            + "  :Conventions = \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "  :creator_email = \"erd.data@noaa.gov\";\n"
            + "  :creator_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :creator_type = \"institution\";\n"
            + "  :creator_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :date_created = \"9999-99-99\";\n"
            + // changes every month
            "  :date_issued = \"9999-99-99\";\n"
            + "  :Easternmost_Easting = 171.395f; // float\n"
            + "  :featureType = \"TimeSeries\";\n"
            + "  :geospatial_lat_max = 24.321f; // float\n"
            + "  :geospatial_lat_min = -14.265f; // float\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = 171.395f; // float\n"
            + "  :geospatial_lon_min = -170.493f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_positive = \"down\";\n"
            + "  :geospatial_vertical_units = \"m\";\n"
            + "  :history = \"Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\n"
            + "Every 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.\n";
    tResults = results.substring(0, Math.min(results.length(), expected.length()));
    Test.ensureEqual(tResults, expected, "\nresults=\n" + results);

    // + " https://www.ndbc.noaa.gov/\n" +
    // today + " http://localhost:8080/...

    expected =
        "http://localhost:8080/erddap/tabledap/cwwcNDBCMet.nc?longitude,latitude,station&station=~\\\"5.*\\\"&distinct()\";\n"
            + "  :id = \"cwwcNDBCMet\";\n"
            + "  :infoUrl = \"https://www.ndbc.noaa.gov/\";\n"
            + "  :institution = \"NOAA NDBC, NOAA NMFS SWFSC ERD\";\n"
            + "  :keywords = \"air, air_pressure_at_sea_level, air_temperature, atmosphere, atmospheric, average, boundary, buoy, coastwatch, data, dew point, dew_point_temperature, direction, dominant, Earth Science > Atmosphere > Air Quality > Visibility, Earth Science > Atmosphere > Altitude > Planetary Boundary Layer Height, Earth Science > Atmosphere > Atmospheric Pressure > Atmospheric Pressure Measurements, Earth Science > Atmosphere > Atmospheric Pressure > Pressure Tendency, Earth Science > Atmosphere > Atmospheric Pressure > Sea Level Pressure, Earth Science > Atmosphere > Atmospheric Pressure > Static Pressure, Earth Science > Atmosphere > Atmospheric Temperature > Air Temperature, Earth Science > Atmosphere > Atmospheric Temperature > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Water Vapor > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Winds > Surface Winds, Earth Science > Oceans > Ocean Temperature > Sea Surface Temperature, Earth Science > Oceans > Ocean Waves > Significant Wave Height, Earth Science > Oceans > Ocean Waves > Swells, Earth Science > Oceans > Ocean Waves > Wave Period, eastward, eastward_wind, from, gust, height, identifier, layer, level, measurements, meridional, meteorological, meteorology, name, ndbc, noaa, northward, northward_wind, ocean, oceans, period, planetary, pressure, quality, sea, sea level, sea_surface_swell_wave_period, sea_surface_swell_wave_significant_height, sea_surface_swell_wave_to_direction, sea_surface_temperature, seawater, significant, speed, sst, standard, static, station, surface, surface waves, surface_altitude, swell, swells, temperature, tendency, tendency_of_air_pressure, time, vapor, visibility, visibility_in_air, water, wave, waves, wcn, wind, wind_from_direction, wind_speed, wind_speed_of_gust, winds, zonal\";\n"
            + "  :keywords_vocabulary = \"GCMD Science Keywords\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "  :naming_authority = \"gov.noaa.pfeg.coastwatch\";\n"
            + "  :Northernmost_Northing = 24.321f; // float\n"
            + "  :project = \"NOAA NDBC and NOAA NMFS SWFSC ERD\";\n"
            + "  :publisher_email = \"erd.data@noaa.gov\";\n"
            + "  :publisher_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :publisher_type = \"institution\";\n"
            + "  :publisher_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :quality = \"Automated QC checks with periodic manual QC\";\n"
            + "  :source = \"station observation\";\n"
            + "  :sourceUrl = \"https://www.ndbc.noaa.gov/\";\n"
            + "  :Southernmost_Northing = -14.265f; // float\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :subsetVariables = \"station, longitude, latitude\";\n"
            + "  :summary = \"The National Data Buoy Center (NDBC) distributes meteorological data from\n"
            + "moored buoys maintained by NDBC and others. Moored buoys are the weather\n"
            + "sentinels of the sea. They are deployed in the coastal and offshore waters\n"
            + "from the western Atlantic to the Pacific Ocean around Hawaii, and from the\n"
            + "Bering Sea to the South Pacific. NDBC's moored buoys measure and transmit\n"
            + "barometric pressure; wind direction, speed, and gust; air and sea\n"
            + "temperature; and wave energy spectra from which significant wave height,\n"
            + "dominant wave period, and average wave period are derived. Even the\n"
            + "direction of wave propagation is measured on many moored buoys. See\n"
            + "https://www.ndbc.noaa.gov/measdes.shtml for a description of the measurements.\n"
            + "\n"
            + "The source data from NOAA NDBC has different column names, different units,\n"
            + "and different missing values in different files, and other problems\n"
            + "(notably, lots of rows with duplicate or different values for the same time\n"
            + "point). This dataset is a standardized, reformatted, and lightly edited\n"
            + "version of that source data, created by NOAA NMFS SWFSC ERD (email:\n"
            + "erd.data at noaa.gov). Before 9999-99-99, this dataset only had the data\n"
            + "that was closest to a given hour, rounded to the nearest hour. Now, this\n"
            + "dataset has all of the data available from NDBC with the original time\n"
            + "values. If there are multiple source rows for a given buoy for a given\n"
            + "time, only the row with the most non-NaN data values is kept. If there is\n"
            + "a gap in the data, a row of missing values is inserted (which causes a nice\n"
            + "gap when the data is graphed). Also, some impossible data values are\n"
            + "removed, but this data is not perfectly clean. This dataset is now updated\n"
            + "every 5 minutes.\n"
            + "\n"
            + "This dataset has both historical data (quality controlled, before\n"
            + "9999-99-99T99:99:99Z) and near real time data (less quality controlled,\n"
            + // changes
            "which may change at any time, from 9999-99-99T99:99:99Z on).\";\n"
            + // changes
            "  :testOutOfDate = \"now-25minutes\";\n"
            + "  :title = \"NDBC Standard Meteorological Buoy Data, 1970-present\";\n"
            + "  :Westernmost_Easting = -170.493f; // float\n"
            + "\n"
            + "  data:\n"
            + "    longitude = \n"
            + "      {-170.493, -162.279, -162.058, -160.66, -159.575, -158.303, -158.149, -158.124, -158.116, -157.959, -157.808, -157.756, -157.753, -157.668, -157.1, -157.01, -157.003, -156.93, -156.427, -156.1, -154.97, -154.056, -153.913, -153.9, -152.382, -144.668, 134.669, 144.789, 144.812, 145.662, 171.395}\n"
            + "    latitude = \n"
            + "      {-14.265, 23.445, 24.321, 19.087, 22.286, 21.096, 21.323, 21.281, 21.673, 21.297, 17.094, 21.477, 21.477, 21.417, 20.4, 20.788, 20.75, 21.35, 21.019, 20.4, 19.78, 23.546, 0.0, 23.558, 17.525, 13.729, 7.629, 13.354, 13.683, 15.267, 7.092}\n"
            + "    station =   \"51209\",   \"51001\",   \"51101\",   \"51003\",   \"51208\",   \"51200\",   \"51212\",   \"51204\",   \"51201\",   \"51211\",   \"51002\",   \"51210\",   \"51207\",   \"51202\",   \"51027\",   \"51203\",   \"51213\",   \"51026\",   \"51205\",   \"51005\",   \"51206\",   \"51000\",   \"51028\",   \"51100\",   \"51004\",   \"52009\",   \"52212\",   \"52200\",   \"52202\",   \"52211\",   \"52201\"\n"
            + "}\n";
    int tPo = results.indexOf(expected.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(
        results.substring(tPo, Math.min(results.length(), tPo + expected.length())),
        expected,
        "results=\n" + results);

    // if just one var, erddap can use DISTINCT_SUBSET_FILENAME
    String2.log("\n* now testing just distinct subset variables");
    userDapQuery = "longitude&longitude>-154&longitude<-153&distinct()";
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            userDapQuery,
            dir,
            eddTable.className() + "_distincts3",
            ".nc"); // nc so test metadata
    results = NcHelper.ncdump(dir + tName, "");
    results = results.replaceAll("\\d{4}-\\d{2}-\\d{2}", "9999-99-99");
    results = results.replaceAll("\\d{2}:\\d{2}:\\d{2}", "99:99:99");

    // String2.log(results);
    expected =
        "netcdf EDDTableFromNcFiles_distincts3.nc {\n"
            + "  dimensions:\n"
            + "    row = 3;\n"
            + "  variables:\n"
            + "    float longitude(row=3);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :actual_range = -153.913f, -153.348f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :colorBarMaximum = 180.0; // double\n"
            + "      :colorBarMinimum = -180.0; // double\n"
            + "      :comment = \"The longitude of the station.\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"TimeSeries\";\n"
            + "  :cdm_timeseries_variables = \"station, longitude, latitude\";\n"
            + "  :contributor_name = \"NOAA NDBC\";\n"
            + "  :contributor_role = \"Source of data.\";\n"
            + "  :Conventions = \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "  :creator_email = \"erd.data@noaa.gov\";\n"
            + "  :creator_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :creator_type = \"institution\";\n"
            + "  :creator_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :date_created = \"9999-99-99\";\n"
            + "  :date_issued = \"9999-99-99\";\n"
            + "  :Easternmost_Easting = -153.348f; // float\n"
            + "  :featureType = \"TimeSeries\";\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = -153.348f; // float\n"
            + "  :geospatial_lon_min = -153.913f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_positive = \"down\";\n"
            + "  :geospatial_vertical_units = \"m\";\n"
            + "  :history = \"Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\n"
            + "Every 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.\n";
    // "2013-05-28T18:14:07Z https://www.ndbc.noaa.gov/
    // 2013-05-28T18:14:07Z
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    expected =
        "http://localhost:8080/erddap/tabledap/cwwcNDBCMet.nc?longitude&longitude>-154&longitude<-153&distinct()\";\n"
            + "  :id = \"cwwcNDBCMet\";\n"
            + "  :infoUrl = \"https://www.ndbc.noaa.gov/\";\n"
            + "  :institution = \"NOAA NDBC, NOAA NMFS SWFSC ERD\";\n"
            + "  :keywords = \"air, air_pressure_at_sea_level, air_temperature, atmosphere, atmospheric, average, boundary, buoy, coastwatch, data, dew point, dew_point_temperature, direction, dominant, Earth Science > Atmosphere > Air Quality > Visibility, Earth Science > Atmosphere > Altitude > Planetary Boundary Layer Height, Earth Science > Atmosphere > Atmospheric Pressure > Atmospheric Pressure Measurements, Earth Science > Atmosphere > Atmospheric Pressure > Pressure Tendency, Earth Science > Atmosphere > Atmospheric Pressure > Sea Level Pressure, Earth Science > Atmosphere > Atmospheric Pressure > Static Pressure, Earth Science > Atmosphere > Atmospheric Temperature > Air Temperature, Earth Science > Atmosphere > Atmospheric Temperature > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Water Vapor > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Winds > Surface Winds, Earth Science > Oceans > Ocean Temperature > Sea Surface Temperature, Earth Science > Oceans > Ocean Waves > Significant Wave Height, Earth Science > Oceans > Ocean Waves > Swells, Earth Science > Oceans > Ocean Waves > Wave Period, eastward, eastward_wind, from, gust, height, identifier, layer, level, measurements, meridional, meteorological, meteorology, name, ndbc, noaa, northward, northward_wind, ocean, oceans, period, planetary, pressure, quality, sea, sea level, sea_surface_swell_wave_period, sea_surface_swell_wave_significant_height, sea_surface_swell_wave_to_direction, sea_surface_temperature, seawater, significant, speed, sst, standard, static, station, surface, surface waves, surface_altitude, swell, swells, temperature, tendency, tendency_of_air_pressure, time, vapor, visibility, visibility_in_air, water, wave, waves, wcn, wind, wind_from_direction, wind_speed, wind_speed_of_gust, winds, zonal\";\n"
            + "  :keywords_vocabulary = \"GCMD Science Keywords\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "  :naming_authority = \"gov.noaa.pfeg.coastwatch\";\n"
            + "  :project = \"NOAA NDBC and NOAA NMFS SWFSC ERD\";\n"
            + "  :publisher_email = \"erd.data@noaa.gov\";\n"
            + "  :publisher_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :publisher_type = \"institution\";\n"
            + "  :publisher_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :quality = \"Automated QC checks with periodic manual QC\";\n"
            + "  :source = \"station observation\";\n"
            + "  :sourceUrl = \"https://www.ndbc.noaa.gov/\";\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :subsetVariables = \"station, longitude, latitude\";\n"
            + "  :summary = \"The National Data Buoy Center (NDBC) distributes meteorological data from\n"
            + "moored buoys maintained by NDBC and others. Moored buoys are the weather\n"
            + "sentinels of the sea. They are deployed in the coastal and offshore waters\n"
            + "from the western Atlantic to the Pacific Ocean around Hawaii, and from the\n"
            + "Bering Sea to the South Pacific. NDBC's moored buoys measure and transmit\n"
            + "barometric pressure; wind direction, speed, and gust; air and sea\n"
            + "temperature; and wave energy spectra from which significant wave height,\n"
            + "dominant wave period, and average wave period are derived. Even the\n"
            + "direction of wave propagation is measured on many moored buoys. See\n"
            + "https://www.ndbc.noaa.gov/measdes.shtml for a description of the measurements.\n"
            + "\n"
            + "The source data from NOAA NDBC has different column names, different units,\n"
            + "and different missing values in different files, and other problems\n"
            + "(notably, lots of rows with duplicate or different values for the same time\n"
            + "point). This dataset is a standardized, reformatted, and lightly edited\n"
            + "version of that source data, created by NOAA NMFS SWFSC ERD (email:\n"
            + "erd.data at noaa.gov). Before 9999-99-99, this dataset only had the data\n"
            + "that was closest to a given hour, rounded to the nearest hour. Now, this\n"
            + "dataset has all of the data available from NDBC with the original time\n"
            + "values. If there are multiple source rows for a given buoy for a given\n"
            + "time, only the row with the most non-NaN data values is kept. If there is\n"
            + "a gap in the data, a row of missing values is inserted (which causes a nice\n"
            + "gap when the data is graphed). Also, some impossible data values are\n"
            + "removed, but this data is not perfectly clean. This dataset is now updated\n"
            + "every 5 minutes.\n"
            + "\n"
            + "This dataset has both historical data (quality controlled, before\n"
            + "9999-99-99T99:99:99Z) and near real time data (less quality controlled,\n"
            + // changes
            "which may change at any time, from 9999-99-99T99:99:99Z on).\";\n"
            + // changes
            "  :testOutOfDate = \"now-25minutes\";\n"
            + "  :title = \"NDBC Standard Meteorological Buoy Data, 1970-present\";\n"
            + "  :Westernmost_Easting = -153.913f; // float\n"
            + "\n"
            + "  data:\n"
            + "    longitude = \n"
            + "      {-153.913, -153.9, -153.348}\n"
            + "}\n";
    tPo = results.indexOf(expected.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(results.substring(tPo), expected, "results=\n" + results);
  }

  /** This test getting just station ids. */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testId() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testId()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    EDV edv;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    userDapQuery = "station&station>\"5\"&station<\"6\"";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_id", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station\n"
            + "\n"
            + "51000\n"
            + "51001\n"
            + "51002\n"
            + "51003\n"
            + "51004\n"
            + "51005\n"
            + "51026\n"
            + "51027\n"
            + "51028\n"
            + "51100\n"
            + "51101\n"
            + "51200\n"
            + "51201\n"
            + "51202\n"
            + "51203\n"
            + "51204\n"
            + "51205\n"
            + // added 2012-03-25
            "51206\n"
            + // added 2012-06-29
            "51207\n"
            + // added 2014-08-07
            "51208\n"
            + // added 2014-08-07
            "51209\n"
            + // added 2015-07-31
            "51210\n"
            + // added 2017-01-08
            "51211\n"
            + // added 2017-01-08
            "51212\n"
            + // added 2018-08-08
            "51213\n"
            + // added 2018-08-08
            "52009\n"
            + "52200\n"
            + "52201\n"
            + "52202\n"
            + // added 2014-08-07
            "52211\n"
            + // added 2014-08-07
            "52212\n"; // added 2017-01-08
    Test.ensureEqual(results, expected, "results=\n" + results);
  }

  /**
   * This tests orderBy and orderByDescending.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testOrderBy() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderBy()
    // *****************\n");

    // testVerboseOn();
    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String error = "";

    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // .csv
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderBy(\"station,time\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_ob", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T21:00:00Z,51001,24.1,23.5\n"
            + "2005-04-19T22:00:00Z,51001,24.2,23.6\n"
            + "2005-04-19T23:00:00Z,51001,24.2,22.1\n"
            + "2005-04-19T21:00:00Z,51002,25.1,25.4\n"
            + "2005-04-19T22:00:00Z,51002,25.2,25.4\n"
            + "2005-04-19T23:00:00Z,51002,25.2,24.8\n"
            + "2005-04-19T21:00:00Z,51003,25.3,23.9\n"
            + "2005-04-19T22:00:00Z,51003,25.4,24.3\n"
            + "2005-04-19T23:00:00Z,51003,25.4,24.7\n"
            + "2005-04-19T21:00:00Z,51004,25.0,24.0\n"
            + "2005-04-19T22:00:00Z,51004,25.0,23.8\n"
            + "2005-04-19T23:00:00Z,51004,25.0,24.3\n"
            + "2005-04-19T21:00:00Z,51028,27.7,27.6\n"
            + "2005-04-19T22:00:00Z,51028,27.8,27.1\n"
            + "2005-04-19T23:00:00Z,51028,27.8,27.5\n"
            + "2005-04-19T21:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T22:00:00Z,51201,24.9,NaN\n"
            + "2005-04-19T23:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T21:00:00Z,51202,24.5,NaN\n"
            + "2005-04-19T22:00:00Z,51202,24.6,NaN\n"
            + "2005-04-19T23:00:00Z,51202,24.5,NaN\n"
            + "2005-04-19T21:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T22:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T23:00:00Z,52200,28.0,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv Descending
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByDescending(\"station,time\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obd", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T23:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T22:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T21:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T23:00:00Z,51202,24.5,NaN\n"
            + "2005-04-19T22:00:00Z,51202,24.6,NaN\n"
            + "2005-04-19T21:00:00Z,51202,24.5,NaN\n"
            + "2005-04-19T23:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T22:00:00Z,51201,24.9,NaN\n"
            + "2005-04-19T21:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T23:00:00Z,51028,27.8,27.5\n"
            + "2005-04-19T22:00:00Z,51028,27.8,27.1\n"
            + "2005-04-19T21:00:00Z,51028,27.7,27.6\n"
            + "2005-04-19T23:00:00Z,51004,25.0,24.3\n"
            + "2005-04-19T22:00:00Z,51004,25.0,23.8\n"
            + "2005-04-19T21:00:00Z,51004,25.0,24.0\n"
            + "2005-04-19T23:00:00Z,51003,25.4,24.7\n"
            + "2005-04-19T22:00:00Z,51003,25.4,24.3\n"
            + "2005-04-19T21:00:00Z,51003,25.3,23.9\n"
            + "2005-04-19T23:00:00Z,51002,25.2,24.8\n"
            + "2005-04-19T22:00:00Z,51002,25.2,25.4\n"
            + "2005-04-19T21:00:00Z,51002,25.1,25.4\n"
            + "2005-04-19T23:00:00Z,51001,24.2,22.1\n"
            + "2005-04-19T22:00:00Z,51001,24.2,23.6\n"
            + "2005-04-19T21:00:00Z,51001,24.1,23.5\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderBy(\"time,station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_ob2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T21:00:00Z,51001,24.1,23.5\n"
            + "2005-04-19T21:00:00Z,51002,25.1,25.4\n"
            + "2005-04-19T21:00:00Z,51003,25.3,23.9\n"
            + "2005-04-19T21:00:00Z,51004,25.0,24.0\n"
            + "2005-04-19T21:00:00Z,51028,27.7,27.6\n"
            + "2005-04-19T21:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T21:00:00Z,51202,24.5,NaN\n"
            + "2005-04-19T21:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T22:00:00Z,51001,24.2,23.6\n"
            + "2005-04-19T22:00:00Z,51002,25.2,25.4\n"
            + "2005-04-19T22:00:00Z,51003,25.4,24.3\n"
            + "2005-04-19T22:00:00Z,51004,25.0,23.8\n"
            + "2005-04-19T22:00:00Z,51028,27.8,27.1\n"
            + "2005-04-19T22:00:00Z,51201,24.9,NaN\n"
            + "2005-04-19T22:00:00Z,51202,24.6,NaN\n"
            + "2005-04-19T22:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T23:00:00Z,51001,24.2,22.1\n"
            + "2005-04-19T23:00:00Z,51002,25.2,24.8\n"
            + "2005-04-19T23:00:00Z,51003,25.4,24.7\n"
            + "2005-04-19T23:00:00Z,51004,25.0,24.3\n"
            + "2005-04-19T23:00:00Z,51028,27.8,27.5\n"
            + "2005-04-19T23:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T23:00:00Z,51202,24.5,NaN\n"
            + "2005-04-19T23:00:00Z,52200,28.0,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv Descending
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByDescending(\"time,station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obd2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T23:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T23:00:00Z,51202,24.5,NaN\n"
            + "2005-04-19T23:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T23:00:00Z,51028,27.8,27.5\n"
            + "2005-04-19T23:00:00Z,51004,25.0,24.3\n"
            + "2005-04-19T23:00:00Z,51003,25.4,24.7\n"
            + "2005-04-19T23:00:00Z,51002,25.2,24.8\n"
            + "2005-04-19T23:00:00Z,51001,24.2,22.1\n"
            + "2005-04-19T22:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T22:00:00Z,51202,24.6,NaN\n"
            + "2005-04-19T22:00:00Z,51201,24.9,NaN\n"
            + "2005-04-19T22:00:00Z,51028,27.8,27.1\n"
            + "2005-04-19T22:00:00Z,51004,25.0,23.8\n"
            + "2005-04-19T22:00:00Z,51003,25.4,24.3\n"
            + "2005-04-19T22:00:00Z,51002,25.2,25.4\n"
            + "2005-04-19T22:00:00Z,51001,24.2,23.6\n"
            + "2005-04-19T21:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T21:00:00Z,51202,24.5,NaN\n"
            + "2005-04-19T21:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T21:00:00Z,51028,27.7,27.6\n"
            + "2005-04-19T21:00:00Z,51004,25.0,24.0\n"
            + "2005-04-19T21:00:00Z,51003,25.3,23.9\n"
            + "2005-04-19T21:00:00Z,51002,25.1,25.4\n"
            + "2005-04-19T21:00:00Z,51001,24.1,23.5\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv test orderBy with 1 orderBy var and with implicit all data vars
    userDapQuery =
        "&station>\"51\"&station<\"512\"" + "&time=2005-04-19T23:00:00Z&orderBy(\"station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_ob3", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,longitude,latitude,time,wd,wspd,gst,wvht,dpd,apd,mwd,bar,atmp,wtmp,dewp,vis,ptdy,tide,wspu,wspv\n"
            + ",degrees_east,degrees_north,UTC,degrees_true,m s-1,m s-1,m,s,s,degrees_true,hPa,degree_C,degree_C,degree_C,km,hPa,m,m s-1,m s-1\n"
            + "51001,-162.279,23.445,2005-04-19T23:00:00Z,89,7.7,10.6,3.16,14.29,8.32,NaN,1021.1,22.1,24.2,NaN,NaN,NaN,NaN,-7.7,-0.1\n"
            + "51002,-157.808,17.094,2005-04-19T23:00:00Z,72,9.5,12.0,3.11,10.0,6.19,NaN,1016.7,24.8,25.2,NaN,NaN,NaN,NaN,-9.0,-2.9\n"
            + "51003,-160.66,19.087,2005-04-19T23:00:00Z,103,6.1,7.5,2.51,14.29,7.28,NaN,1017.7,24.7,25.4,NaN,NaN,NaN,NaN,-5.9,1.4\n"
            + "51004,-152.382,17.525,2005-04-19T23:00:00Z,65,9.9,11.7,NaN,NaN,NaN,NaN,1017.1,24.3,25.0,NaN,NaN,NaN,NaN,-9.0,-4.2\n"
            + "51028,-153.913,0.0,2005-04-19T23:00:00Z,108,5.4,6.4,1.97,10.0,7.72,40,1008.6,27.5,27.8,NaN,NaN,NaN,NaN,-5.1,1.7\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // Descending
    // .csv test orderBy with 1 orderBy var and with implicit all data vars
    userDapQuery =
        "&station>\"51\"&station<\"512\""
            + "&time=2005-04-19T23:00:00Z&orderByDescending(\"station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obd3", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,longitude,latitude,time,wd,wspd,gst,wvht,dpd,apd,mwd,bar,atmp,wtmp,dewp,vis,ptdy,tide,wspu,wspv\n"
            + ",degrees_east,degrees_north,UTC,degrees_true,m s-1,m s-1,m,s,s,degrees_true,hPa,degree_C,degree_C,degree_C,km,hPa,m,m s-1,m s-1\n"
            + "51028,-153.913,0.0,2005-04-19T23:00:00Z,108,5.4,6.4,1.97,10.0,7.72,40,1008.6,27.5,27.8,NaN,NaN,NaN,NaN,-5.1,1.7\n"
            + "51004,-152.382,17.525,2005-04-19T23:00:00Z,65,9.9,11.7,NaN,NaN,NaN,NaN,1017.1,24.3,25.0,NaN,NaN,NaN,NaN,-9.0,-4.2\n"
            + "51003,-160.66,19.087,2005-04-19T23:00:00Z,103,6.1,7.5,2.51,14.29,7.28,NaN,1017.7,24.7,25.4,NaN,NaN,NaN,NaN,-5.9,1.4\n"
            + "51002,-157.808,17.094,2005-04-19T23:00:00Z,72,9.5,12.0,3.11,10.0,6.19,NaN,1016.7,24.8,25.2,NaN,NaN,NaN,NaN,-9.0,-2.9\n"
            + "51001,-162.279,23.445,2005-04-19T23:00:00Z,89,7.7,10.6,3.16,14.29,8.32,NaN,1021.1,22.1,24.2,NaN,NaN,NaN,NaN,-7.7,-0.1\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderBy with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T12&orderBy(\"time\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_ob4", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T00:50:00Z,41004,252,19.4,20.1\n"
            + "2012-01-01T01:50:00Z,41004,264,19.3,20.2\n"
            + "2012-01-01T02:50:00Z,41004,271,19.3,20.3\n"
            + "2012-01-01T03:50:00Z,41004,NaN,NaN,NaN\n"
            + "2012-01-01T04:50:00Z,41004,272,19.5,20.4\n"
            + "2012-01-01T05:50:00Z,41004,273,19.3,20.4\n"
            + "2012-01-01T06:50:00Z,41004,289,19.2,20.3\n"
            + "2012-01-01T07:50:00Z,41004,288,19.0,20.2\n"
            + "2012-01-01T08:50:00Z,41004,270,18.8,20.2\n"
            + "2012-01-01T09:50:00Z,41004,262,18.6,20.3\n"
            + "2012-01-01T10:50:00Z,41004,249,18.5,20.4\n"
            + "2012-01-01T11:50:00Z,41004,246,18.5,20.4\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByDescending with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T12&orderByDescending(\"time\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obd4", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T11:50:00Z,41004,246,18.5,20.4\n"
            + "2012-01-01T10:50:00Z,41004,249,18.5,20.4\n"
            + "2012-01-01T09:50:00Z,41004,262,18.6,20.3\n"
            + "2012-01-01T08:50:00Z,41004,270,18.8,20.2\n"
            + "2012-01-01T07:50:00Z,41004,288,19.0,20.2\n"
            + "2012-01-01T06:50:00Z,41004,289,19.2,20.3\n"
            + "2012-01-01T05:50:00Z,41004,273,19.3,20.4\n"
            + "2012-01-01T04:50:00Z,41004,272,19.5,20.4\n"
            + "2012-01-01T03:50:00Z,41004,NaN,NaN,NaN\n"
            + "2012-01-01T02:50:00Z,41004,271,19.3,20.3\n"
            + "2012-01-01T01:50:00Z,41004,264,19.3,20.2\n"
            + "2012-01-01T00:50:00Z,41004,252,19.4,20.1\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // quick reject -> orderBy var not in results vars
    // orderBy()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderBy(\"station,latitude\")",
              dir,
              eddTable.className() + "_qr1",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: orderBy "
              + "variable=latitude isn't in the list of results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> orderBy var not in results vars
    // orderByDescending()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByDescending(\"station,latitude\")",
              dir,
              eddTable.className() + "_qrd1",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: orderBy "
              + // not orderByDescending,
              // but that's
              // okay
              "variable=latitude isn't in the list of results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> / not allowed
    // orderBy()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderBy(\"station,latitude/15\")",
              dir,
              eddTable.className() + "_qr1b",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: 'orderBy' doesn't support '/' (latitude/15).";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> / not allowed
    // orderByDescending()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByDescending(\"station,latitude/15\")",
              dir,
              eddTable.className() + "_qrd1b",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: 'orderByDescending' doesn't support '/' (latitude/15).";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> no orderBy vars
    // orderBy()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderBy(\"\")",
              dir,
              eddTable.className() + "_qr2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: "
              + "No column names were specified for 'orderBy'.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> no orderBy vars
    // orderByDescending()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByDescending(\"\")",
              dir,
              eddTable.className() + "_qrd2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: "
              + "No column names were specified for 'orderByDescending'.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // distinct() + orderBy is not an error
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            "station,wtmp&station>\"51\"&station<\"512\""
                + "&time=2005-04-19T23:00:00Z&orderBy(\"station\")&distinct()",
            dir,
            eddTable.className() + "_qr3",
            ".csv");

    // distinct() + orderByDescending is not an error
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            "station,wtmp&station>\"51\"&station<\"512\""
                + "&time=2005-04-19T23:00:00Z&orderBy(\"station\")&distinct()",
            dir,
            eddTable.className() + "_qrd3",
            ".csv");
  }

  /**
   * This tests orderByCount.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testOrderByCount() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderByCount()
    // *****************\n");

    // testVerboseOn();
    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String error = "";

    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // .csv
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "station,time,wd,wtmp,atmp&station<\"42003\""
            + "&time>=2000-01-01&time<2000-01-02&orderByCount(\"station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,wtmp,atmp\n"
            + ",count,count,count,count\n"
            + "41002,24,24,24,24\n"
            + "41004,24,24,24,24\n"
            + "41008,24,24,24,24\n"
            + "41009,24,24,24,24\n"
            + "41010,24,24,24,24\n"
            + "42001,24,24,24,24\n"
            + "42002,24,23,23,23\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv station,time
    userDapQuery =
        "station,time,wd,wtmp,atmp&station<=\"41009\""
            + "&time>=2000-01-01&time<2000-01-01T04&orderByCount(\"station,time\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,wtmp,atmp\n"
            + ",UTC,count,count,count\n"
            + "41002,2000-01-01T00:00:00Z,1,1,1\n"
            + "41002,2000-01-01T01:00:00Z,1,1,1\n"
            + "41002,2000-01-01T02:00:00Z,1,1,1\n"
            + "41002,2000-01-01T03:00:00Z,1,1,1\n"
            + "41004,2000-01-01T00:00:00Z,1,1,1\n"
            + "41004,2000-01-01T01:00:00Z,1,1,1\n"
            + "41004,2000-01-01T02:00:00Z,1,1,1\n"
            + "41004,2000-01-01T03:00:00Z,1,1,1\n"
            + "41008,2000-01-01T00:00:00Z,1,1,1\n"
            + "41008,2000-01-01T01:00:00Z,1,1,1\n"
            + "41008,2000-01-01T02:00:00Z,1,1,1\n"
            + "41008,2000-01-01T03:00:00Z,1,1,1\n"
            + "41009,2000-01-01T00:00:00Z,1,1,1\n"
            + "41009,2000-01-01T01:00:00Z,1,1,1\n"
            + "41009,2000-01-01T02:00:00Z,1,1,1\n"
            + "41009,2000-01-01T03:00:00Z,1,1,1\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv station,time/6hours
    userDapQuery =
        "station,time,wd,wtmp,atmp&station<=\"41009\""
            + "&time>=2000-01-01&time<2000-01-02&orderByCount(\"station,time/6hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc3", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,wtmp,atmp\n"
            + ",UTC,count,count,count\n"
            + "41002,2000-01-01T00:00:00Z,6,6,6\n"
            + "41002,2000-01-01T06:00:00Z,6,6,6\n"
            + "41002,2000-01-01T12:00:00Z,6,6,6\n"
            + "41002,2000-01-01T18:00:00Z,6,6,6\n"
            + "41004,2000-01-01T00:00:00Z,6,6,6\n"
            + "41004,2000-01-01T06:00:00Z,6,6,6\n"
            + "41004,2000-01-01T12:00:00Z,6,6,6\n"
            + "41004,2000-01-01T18:00:00Z,6,6,6\n"
            + "41008,2000-01-01T00:00:00Z,6,6,6\n"
            + "41008,2000-01-01T06:00:00Z,6,6,6\n"
            + "41008,2000-01-01T12:00:00Z,6,6,6\n"
            + "41008,2000-01-01T18:00:00Z,6,6,6\n"
            + "41009,2000-01-01T00:00:00Z,6,6,6\n"
            + "41009,2000-01-01T06:00:00Z,6,6,6\n"
            + "41009,2000-01-01T12:00:00Z,6,6,6\n"
            + "41009,2000-01-01T18:00:00Z,6,6,6\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv orderByCount can have 0 column names (1 station)
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,wd,wtmp,atmp&station=\"31201\""
            + "&time>=2005-04-19&time<2005-04-20&orderByCount(\"\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc4", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected = "time,wd,wtmp,atmp\n" + "count,count,count,count\n" + "24,0,24,0\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv orderByCount can have 0 column names (all stations)
    userDapQuery =
        "station,time,wd,wtmp,atmp" + "&time>=2000-01-01&time<2000-01-02&orderByCount(\"\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc5", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,wtmp,atmp\n"
            + "count,count,count,count,count\n"
            + "2578,2578,2467,1578,2491\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByCount with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T12&orderByCount(\"time/6hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc6", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,count,count,count,count\n"
            + "2012-01-01T00:00:00Z,6,5,5,5\n"
            + "2012-01-01T06:00:00Z,6,6,6,6\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByCount as .nccsv with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T12&orderByCount(\"time/6hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc6", ".nccsv");
    results = File2.directReadFrom88591File(dir + tName);
    // neuter dates that vary
    results = results.replaceAll("\\d{4}-\\d{2}-\\d{2}", "9999-99-99"); // regex replaceAll
    results = results.replaceAll("\\d{2}:\\d{2}:\\d{2}Z", "99:99:99Z"); // regex replaceAll

    expected =
        "*GLOBAL*,Conventions,\"COARDS, CF-1.6, ACDD-1.3, NCCSV-1.2\"\n"
            + "*GLOBAL*,cdm_data_type,TimeSeries\n"
            + "*GLOBAL*,cdm_timeseries_variables,\"station, longitude, latitude\"\n"
            + "*GLOBAL*,contributor_name,NOAA NDBC\n"
            + "*GLOBAL*,contributor_role,Source of data.\n"
            + "*GLOBAL*,creator_email,erd.data@noaa.gov\n"
            + "*GLOBAL*,creator_name,NOAA NMFS SWFSC ERD\n"
            + "*GLOBAL*,creator_type,institution\n"
            + "*GLOBAL*,creator_url,https://www.pfeg.noaa.gov\n"
            + "*GLOBAL*,date_created,\"9999-99-99\"\n"
            + "*GLOBAL*,date_issued,\"9999-99-99\"\n"
            + "*GLOBAL*,Easternmost_Easting,179.001d\n"
            + "*GLOBAL*,featureType,TimeSeries\n"
            + "*GLOBAL*,geospatial_lat_max,71.758d\n"
            + "*GLOBAL*,geospatial_lat_min,-55.0d\n"
            + "*GLOBAL*,geospatial_lat_units,degrees_north\n"
            + "*GLOBAL*,geospatial_lon_max,179.001d\n"
            + "*GLOBAL*,geospatial_lon_min,-177.75d\n"
            + "*GLOBAL*,geospatial_lon_units,degrees_east\n"
            + "*GLOBAL*,geospatial_vertical_positive,down\n"
            + "*GLOBAL*,geospatial_vertical_units,m\n"
            + "*GLOBAL*,history,\"Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\\nEvery 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.\\n9999-99-99T99:99:99Z https://www.ndbc.noaa.gov/\\n9999-99-99T99:99:99Z http://localhost:8080/erddap/tabledap/cwwcNDBCMet.nccsv?time,station,wd,atmp,wtmp&station=\"\"41004\"\"&time>=9999-99-99&time<9999-99-99T12&orderByCount(\"\"time/6hours\"\")\"\n"
            + "*GLOBAL*,id,cwwcNDBCMet\n"
            + "*GLOBAL*,infoUrl,https://www.ndbc.noaa.gov/\n"
            + "*GLOBAL*,institution,\"NOAA NDBC, NOAA NMFS SWFSC ERD\"\n"
            + "*GLOBAL*,keywords,\"air, air_pressure_at_sea_level, air_temperature, atmosphere, atmospheric, average, boundary, buoy, coastwatch, data, dew point, dew_point_temperature, direction, dominant, Earth Science > Atmosphere > Air Quality > Visibility, Earth Science > Atmosphere > Altitude > Planetary Boundary Layer Height, Earth Science > Atmosphere > Atmospheric Pressure > Atmospheric Pressure Measurements, Earth Science > Atmosphere > Atmospheric Pressure > Pressure Tendency, Earth Science > Atmosphere > Atmospheric Pressure > Sea Level Pressure, Earth Science > Atmosphere > Atmospheric Pressure > Static Pressure, Earth Science > Atmosphere > Atmospheric Temperature > Air Temperature, Earth Science > Atmosphere > Atmospheric Temperature > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Water Vapor > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Winds > Surface Winds, Earth Science > Oceans > Ocean Temperature > Sea Surface Temperature, Earth Science > Oceans > Ocean Waves > Significant Wave Height, Earth Science > Oceans > Ocean Waves > Swells, Earth Science > Oceans > Ocean Waves > Wave Period, eastward, eastward_wind, from, gust, height, identifier, layer, level, measurements, meridional, meteorological, meteorology, name, ndbc, noaa, northward, northward_wind, ocean, oceans, period, planetary, pressure, quality, sea, sea level, sea_surface_swell_wave_period, sea_surface_swell_wave_significant_height, sea_surface_swell_wave_to_direction, sea_surface_temperature, seawater, significant, speed, sst, standard, static, station, surface, surface waves, surface_altitude, swell, swells, temperature, tendency, tendency_of_air_pressure, time, vapor, visibility, visibility_in_air, water, wave, waves, wcn, wind, wind_from_direction, wind_speed, wind_speed_of_gust, winds, zonal\"\n"
            + "*GLOBAL*,keywords_vocabulary,GCMD Science Keywords\n"
            + "*GLOBAL*,license,\"The data may be used and redistributed for free but is not intended\\nfor legal use, since it may contain inaccuracies. Neither the data\\nContributor, ERD, NOAA, nor the United States Government, nor any\\nof their employees or contractors, makes any warranty, express or\\nimplied, including warranties of merchantability and fitness for a\\nparticular purpose, or assumes any legal liability for the accuracy,\\ncompleteness, or usefulness, of this information.\"\n"
            + "*GLOBAL*,naming_authority,gov.noaa.pfeg.coastwatch\n"
            + "*GLOBAL*,Northernmost_Northing,71.758d\n"
            + "*GLOBAL*,project,NOAA NDBC and NOAA NMFS SWFSC ERD\n"
            + "*GLOBAL*,publisher_email,erd.data@noaa.gov\n"
            + "*GLOBAL*,publisher_name,NOAA NMFS SWFSC ERD\n"
            + "*GLOBAL*,publisher_type,institution\n"
            + "*GLOBAL*,publisher_url,https://www.pfeg.noaa.gov\n"
            + "*GLOBAL*,quality,Automated QC checks with periodic manual QC\n"
            + "*GLOBAL*,source,station observation\n"
            + "*GLOBAL*,sourceUrl,https://www.ndbc.noaa.gov/\n"
            + "*GLOBAL*,Southernmost_Northing,-55.0d\n"
            + "*GLOBAL*,standard_name_vocabulary,CF Standard Name Table v70\n"
            + "*GLOBAL*,subsetVariables,\"station, longitude, latitude\"\n"
            + "*GLOBAL*,summary,\"The National Data Buoy Center (NDBC) distributes meteorological data from\\nmoored buoys maintained by NDBC and others. Moored buoys are the weather\\nsentinels of the sea. They are deployed in the coastal and offshore waters\\nfrom the western Atlantic to the Pacific Ocean around Hawaii, and from the\\nBering Sea to the South Pacific. NDBC's moored buoys measure and transmit\\nbarometric pressure; wind direction, speed, and gust; air and sea\\ntemperature; and wave energy spectra from which significant wave height,\\ndominant wave period, and average wave period are derived. Even the\\ndirection of wave propagation is measured on many moored buoys. See\\nhttps://www.ndbc.noaa.gov/measdes.shtml for a description of the measurements.\\n\\nThe source data from NOAA NDBC has different column names, different units,\\nand different missing values in different files, and other problems\\n(notably, lots of rows with duplicate or different values for the same time\\npoint). This dataset is a standardized, reformatted, and lightly edited\\nversion of that source data, created by NOAA NMFS SWFSC ERD (email:\\nerd.data at noaa.gov). Before 9999-99-99, this dataset only had the data\\nthat was closest to a given hour, rounded to the nearest hour. Now, this\\ndataset has all of the data available from NDBC with the original time\\nvalues. If there are multiple source rows for a given buoy for a given\\ntime, only the row with the most non-NaN data values is kept. If there is\\na gap in the data, a row of missing values is inserted (which causes a nice\\ngap when the data is graphed). Also, some impossible data values are\\nremoved, but this data is not perfectly clean. This dataset is now updated\\nevery 5 minutes.\\n\\nThis dataset has both historical data (quality controlled, before\\n9999-99-99T99:99:99Z) and near real time data (less quality controlled,\\nwhich may change at any time, from 9999-99-99T99:99:99Z on).\"\n"
            + "*GLOBAL*,testOutOfDate,now-25minutes\n"
            + "*GLOBAL*,time_coverage_end,9999-99-99T99:99:99Z\n"
            + "*GLOBAL*,time_coverage_start,9999-99-99T99:99:99Z\n"
            + "*GLOBAL*,title,\"NDBC Standard Meteorological Buoy Data, 1970-present\"\n"
            + "*GLOBAL*,Westernmost_Easting,-177.75d\n"
            + "time,*DATA_TYPE*,String\n"
            + "time,_CoordinateAxisType,Time\n"
            + "time,actual_range,9999-99-99T99:99:99Z\\n9999-99-99T99:99:99Z\n"
            + "time,axis,T\n"
            + "time,ioos_category,Time\n"
            + "time,long_name,Time\n"
            + "time,standard_name,time\n"
            + "time,time_origin,01-JAN-1970 00:00:00\n"
            + "time,units,yyyy-MM-dd'T'HH:mm:ssZ\n"
            + "station,*DATA_TYPE*,int\n"
            + "station,_FillValue,2147483647i\n"
            + "station,comment,The station identifier.\n"
            + "station,ioos_category,Identifier\n"
            + "station,long_name,Station Identifier\n"
            + "station,units,count\n"
            + "wd,*DATA_TYPE*,int\n"
            + "wd,_FillValue,2147483647i\n"
            + "wd,comment,Wind direction (the direction the wind is coming from in degrees clockwise from true N) during the same period used for WSPD.\n"
            + "wd,ioos_category,Wind\n"
            + "wd,long_name,Wind Direction\n"
            + "wd,standard_name,wind_from_direction number_of_observations\n"
            + "wd,units,count\n"
            + "atmp,*DATA_TYPE*,int\n"
            + "atmp,_FillValue,2147483647i\n"
            + "atmp,comment,\"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\"\n"
            + "atmp,ioos_category,Temperature\n"
            + "atmp,long_name,Air Temperature\n"
            + "atmp,standard_name,air_temperature number_of_observations\n"
            + "atmp,units,count\n"
            + "wtmp,*DATA_TYPE*,int\n"
            + "wtmp,_FillValue,2147483647i\n"
            + "wtmp,comment,\"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\"\n"
            + "wtmp,ioos_category,Temperature\n"
            + "wtmp,long_name,SST\n"
            + "wtmp,standard_name,sea_surface_temperature number_of_observations\n"
            + "wtmp,units,count\n"
            + "\n"
            + "*END_METADATA*\n"
            + "time,station,wd,atmp,wtmp\n"
            + "9999-99-99T99:99:99Z,6,5,5,5\n"
            + "9999-99-99T99:99:99Z,6,6,6,6\n"
            + "*END_DATA*\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByCount as .nc with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T12&orderByCount(\"time/6hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc6", ".nc");
    Table table = new Table();
    table.readFlatNc(dir + tName, null, 0); // standardizeWhat
    results = table.toString();
    // neuter dates that vary
    results = results.replaceAll("\\d{4}-\\d{2}-\\d{2}", "9999-99-99"); // regex replaceAll
    results = results.replaceAll("\\d{2}:\\d{2}:\\d{2}Z", "99:99:99Z"); // regex replaceAll
    expected =
        "{\n"
            + "dimensions:\n"
            + "\trow = 2 ;\n"
            + "variables:\n"
            + "\tdouble time(row) ;\n"
            + "\t\ttime:_CoordinateAxisType = \"Time\" ;\n"
            + "\t\ttime:actual_range = 1.325376E9, 1.3253976E9 ;\n"
            + "\t\ttime:axis = \"T\" ;\n"
            + "\t\ttime:ioos_category = \"Time\" ;\n"
            + "\t\ttime:long_name = \"Time\" ;\n"
            + "\t\ttime:standard_name = \"time\" ;\n"
            + "\t\ttime:time_origin = \"01-JAN-1970 00:00:00\" ;\n"
            + "\t\ttime:units = \"seconds since 9999-99-99T99:99:99Z\" ;\n"
            + "\tint station(row) ;\n"
            + "\t\tstation:_FillValue = 2147483647 ;\n"
            + "\t\tstation:actual_range = 6, 6 ;\n"
            + "\t\tstation:comment = \"The station identifier.\" ;\n"
            + "\t\tstation:ioos_category = \"Identifier\" ;\n"
            + "\t\tstation:long_name = \"Station Identifier\" ;\n"
            + "\t\tstation:units = \"count\" ;\n"
            + "\tint wd(row) ;\n"
            + "\t\twd:_FillValue = 2147483647 ;\n"
            + "\t\twd:actual_range = 5, 6 ;\n"
            + "\t\twd:comment = \"Wind direction (the direction the wind is coming from in degrees clockwise from true N) during the same period used for WSPD.\" ;\n"
            + "\t\twd:ioos_category = \"Wind\" ;\n"
            + "\t\twd:long_name = \"Wind Direction\" ;\n"
            + "\t\twd:standard_name = \"wind_from_direction number_of_observations\" ;\n"
            + "\t\twd:units = \"count\" ;\n"
            + "\tint atmp(row) ;\n"
            + "\t\tatmp:_FillValue = 2147483647 ;\n"
            + "\t\tatmp:actual_range = 5, 6 ;\n"
            + "\t\tatmp:comment = \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\" ;\n"
            + "\t\tatmp:ioos_category = \"Temperature\" ;\n"
            + "\t\tatmp:long_name = \"Air Temperature\" ;\n"
            + "\t\tatmp:standard_name = \"air_temperature number_of_observations\" ;\n"
            + "\t\tatmp:units = \"count\" ;\n"
            + "\tint wtmp(row) ;\n"
            + "\t\twtmp:_FillValue = 2147483647 ;\n"
            + "\t\twtmp:actual_range = 5, 6 ;\n"
            + "\t\twtmp:comment = \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\" ;\n"
            + "\t\twtmp:ioos_category = \"Temperature\" ;\n"
            + "\t\twtmp:long_name = \"SST\" ;\n"
            + "\t\twtmp:standard_name = \"sea_surface_temperature number_of_observations\" ;\n"
            + "\t\twtmp:units = \"count\" ;\n"
            + "\n"
            + "// global attributes:\n"
            + "\t\t:cdm_data_type = \"TimeSeries\" ;\n"
            + "\t\t:cdm_timeseries_variables = \"station, longitude, latitude\" ;\n"
            + "\t\t:contributor_name = \"NOAA NDBC\" ;\n"
            + "\t\t:contributor_role = \"Source of data.\" ;\n"
            + "\t\t:Conventions = \"COARDS, CF-1.6, ACDD-1.3\" ;\n"
            + "\t\t:creator_email = \"erd.data@noaa.gov\" ;\n"
            + "\t\t:creator_name = \"NOAA NMFS SWFSC ERD\" ;\n"
            + "\t\t:creator_type = \"institution\" ;\n"
            + "\t\t:creator_url = \"https://www.pfeg.noaa.gov\" ;\n"
            + "\t\t:date_created = \"9999-99-99\" ;\n"
            + "\t\t:date_issued = \"9999-99-99\" ;\n"
            + "\t\t:featureType = \"TimeSeries\" ;\n"
            + "\t\t:geospatial_lat_units = \"degrees_north\" ;\n"
            + "\t\t:geospatial_lon_units = \"degrees_east\" ;\n"
            + "\t\t:geospatial_vertical_positive = \"down\" ;\n"
            + "\t\t:geospatial_vertical_units = \"m\" ;\n"
            + "\t\t:history = \"Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\n"
            + "Every 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.\n"
            + "9999-99-99T99:99:99Z https://www.ndbc.noaa.gov/\n"
            + "9999-99-99T99:99:99Z http://localhost:8080/erddap/tabledap/cwwcNDBCMet.nc?time,station,wd,atmp,wtmp&station=\\\"41004\\\"&time>=9999-99-99&time<9999-99-99T12&orderByCount(\\\"time/6hours\\\")\" ;\n"
            + "\t\t:id = \"cwwcNDBCMet\" ;\n"
            + "\t\t:infoUrl = \"https://www.ndbc.noaa.gov/\" ;\n"
            + "\t\t:institution = \"NOAA NDBC, NOAA NMFS SWFSC ERD\" ;\n"
            + "\t\t:keywords = \"air, air_pressure_at_sea_level, air_temperature, atmosphere, atmospheric, average, boundary, buoy, coastwatch, data, dew point, dew_point_temperature, direction, dominant, Earth Science > Atmosphere > Air Quality > Visibility, Earth Science > Atmosphere > Altitude > Planetary Boundary Layer Height, Earth Science > Atmosphere > Atmospheric Pressure > Atmospheric Pressure Measurements, Earth Science > Atmosphere > Atmospheric Pressure > Pressure Tendency, Earth Science > Atmosphere > Atmospheric Pressure > Sea Level Pressure, Earth Science > Atmosphere > Atmospheric Pressure > Static Pressure, Earth Science > Atmosphere > Atmospheric Temperature > Air Temperature, Earth Science > Atmosphere > Atmospheric Temperature > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Water Vapor > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Winds > Surface Winds, Earth Science > Oceans > Ocean Temperature > Sea Surface Temperature, Earth Science > Oceans > Ocean Waves > Significant Wave Height, Earth Science > Oceans > Ocean Waves > Swells, Earth Science > Oceans > Ocean Waves > Wave Period, eastward, eastward_wind, from, gust, height, identifier, layer, level, measurements, meridional, meteorological, meteorology, name, ndbc, noaa, northward, northward_wind, ocean, oceans, period, planetary, pressure, quality, sea, sea level, sea_surface_swell_wave_period, sea_surface_swell_wave_significant_height, sea_surface_swell_wave_to_direction, sea_surface_temperature, seawater, significant, speed, sst, standard, static, station, surface, surface waves, surface_altitude, swell, swells, temperature, tendency, tendency_of_air_pressure, time, vapor, visibility, visibility_in_air, water, wave, waves, wcn, wind, wind_from_direction, wind_speed, wind_speed_of_gust, winds, zonal\" ;\n"
            + "\t\t:keywords_vocabulary = \"GCMD Science Keywords\" ;\n"
            + "\t\t:license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\" ;\n"
            + "\t\t:naming_authority = \"gov.noaa.pfeg.coastwatch\" ;\n"
            + "\t\t:project = \"NOAA NDBC and NOAA NMFS SWFSC ERD\" ;\n"
            + "\t\t:publisher_email = \"erd.data@noaa.gov\" ;\n"
            + "\t\t:publisher_name = \"NOAA NMFS SWFSC ERD\" ;\n"
            + "\t\t:publisher_type = \"institution\" ;\n"
            + "\t\t:publisher_url = \"https://www.pfeg.noaa.gov\" ;\n"
            + "\t\t:quality = \"Automated QC checks with periodic manual QC\" ;\n"
            + "\t\t:source = \"station observation\" ;\n"
            + "\t\t:sourceUrl = \"https://www.ndbc.noaa.gov/\" ;\n"
            + "\t\t:standard_name_vocabulary = \"CF Standard Name Table v70\" ;\n"
            + "\t\t:subsetVariables = \"station, longitude, latitude\" ;\n"
            + "\t\t:summary = \"The National Data Buoy Center (NDBC) distributes meteorological data from\n"
            + "moored buoys maintained by NDBC and others. Moored buoys are the weather\n"
            + "sentinels of the sea. They are deployed in the coastal and offshore waters\n"
            + "from the western Atlantic to the Pacific Ocean around Hawaii, and from the\n"
            + "Bering Sea to the South Pacific. NDBC's moored buoys measure and transmit\n"
            + "barometric pressure; wind direction, speed, and gust; air and sea\n"
            + "temperature; and wave energy spectra from which significant wave height,\n"
            + "dominant wave period, and average wave period are derived. Even the\n"
            + "direction of wave propagation is measured on many moored buoys. See\n"
            + "https://www.ndbc.noaa.gov/measdes.shtml for a description of the measurements.\n"
            + "\n"
            + "The source data from NOAA NDBC has different column names, different units,\n"
            + "and different missing values in different files, and other problems\n"
            + "(notably, lots of rows with duplicate or different values for the same time\n"
            + "point). This dataset is a standardized, reformatted, and lightly edited\n"
            + "version of that source data, created by NOAA NMFS SWFSC ERD (email:\n"
            + "erd.data at noaa.gov). Before 9999-99-99, this dataset only had the data\n"
            + "that was closest to a given hour, rounded to the nearest hour. Now, this\n"
            + "dataset has all of the data available from NDBC with the original time\n"
            + "values. If there are multiple source rows for a given buoy for a given\n"
            + "time, only the row with the most non-NaN data values is kept. If there is\n"
            + "a gap in the data, a row of missing values is inserted (which causes a nice\n"
            + "gap when the data is graphed). Also, some impossible data values are\n"
            + "removed, but this data is not perfectly clean. This dataset is now updated\n"
            + "every 5 minutes.\n"
            + "\n"
            + "This dataset has both historical data (quality controlled, before\n"
            + "9999-99-99T99:99:99Z) and near real time data (less quality controlled,\n"
            + "which may change at any time, from 9999-99-99T99:99:99Z on).\" ;\n"
            + "\t\t:testOutOfDate = \"now-25minutes\" ;\n"
            + "\t\t:time_coverage_end = \"9999-99-99T99:99:99Z\" ;\n"
            + "\t\t:time_coverage_start = \"9999-99-99T99:99:99Z\" ;\n"
            + "\t\t:title = \"NDBC Standard Meteorological Buoy Data, 1970-present\" ;\n"
            + "}\n"
            + "time,station,wd,atmp,wtmp\n"
            + "1.325376E9,6,5,5,5\n"
            + "1.3253976E9,6,6,6,6\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // quick reject -> orderByCount var not in results vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByCount(\"station,atmp\")",
              dir,
              eddTable.className() + "_qr1",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: orderBy "
              + "variable=atmp isn't in the list of results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> station/10 not allowed
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&station<\"32000\"&orderByCount(\"station/10,wtmp\")",
              dir,
              eddTable.className() + "_qr2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: "
              + "orderByCount cannot apply rounding to station/10 because it is not a numeric data type.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }
  }

  /**
   * This tests orderByMean
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testOrderByMean() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderByMean()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // test orderByMean(twoVars)
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wd,wtmp,atmp&station>\"5\"&station<\"51004\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMean(\"station,time/12hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected = // since time in orderByMean"", it is the truncated time
        "time,station,wd,wtmp,atmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2005-04-18T00:00:00Z,51001,97.86183928014171,24.441666666666663,23.816666666666666\n"
            + // Java
            // 8
            // (to
            // 17)
            // had
            // 97.86183928014168
            // (last
            // 2
            // digits
            // changed),
            // and
            // a
            // several
            // similar
            // changes
            // below.
            "2005-04-18T12:00:00Z,51001,94.16803567809627,24.1,23.416666666666664\n"
            + "2005-04-19T00:00:00Z,51001,67.91263458022371,24.425000000000004,23.633333333333333\n"
            + "2005-04-19T12:00:00Z,51001,71.06387582853539,24.15,23.158333333333335\n"
            + "2005-04-18T00:00:00Z,51002,84.1769853744749,25.241666666666667,25.191666666666666\n"
            + "2005-04-18T12:00:00Z,51002,83.91784088447218,25.116666666666667,24.941666666666666\n"
            + "2005-04-19T00:00:00Z,51002,81.5,25.174999999999997,25.158333333333335\n"
            + "2005-04-19T12:00:00Z,51002,76.75426244884592,25.116666666666667,24.78333333333333\n"
            + "2005-04-18T00:00:00Z,51003,91.40518432154903,25.35833333333333,24.65833333333333\n"
            + "2005-04-18T12:00:00Z,51003,82.32152838658655,25.308333333333334,24.491666666666664\n"
            + "2005-04-19T00:00:00Z,51003,75.30158735989092,25.45833333333333,24.533333333333335\n"
            + "2005-04-19T12:00:00Z,51003,77.08087657273535,25.341666666666665,24.333333333333336\n";

    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMean(station)
    userDapQuery =
        "time,station,wd,wtmp,atmp&station>\"5\"&station<\"51004\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMean(\"station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected = // since time isn't in orderByMean"", it is the mean of the time values
        "time,station,wd,wtmp,atmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2005-04-18T23:30:00Z,51001,82.68984571953773,24.27916666666667,23.50625\n"
            + "2005-04-18T23:30:00Z,51002,81.58888862157633,25.162499999999998,25.018749999999997\n"
            + // java
            // 8
            // had
            // 81.58888862157632
            "2005-04-18T23:30:00Z,51003,81.53155106611145,25.366666666666664,24.50416666666667\n"; // java
    // 8
    // had
    // 81.53155106611143
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMean(oneVar)
    userDapQuery =
        "time,station,wd,wtmp,atmp&station=\"51002\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMean(\"time/6hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean3", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,wtmp,atmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2005-04-18T00:00:00Z,51002,82.34275443036394,25.283333333333335,25.73333333333333\n"
            + "2005-04-18T06:00:00Z,51002,85.9998989286213,25.2,24.650000000000002\n"
            + "2005-04-18T12:00:00Z,51002,83.16714540604333,25.1,24.416666666666664\n"
            + "2005-04-18T18:00:00Z,51002,84.66908038147409,25.133333333333333,25.466666666666665\n"
            + "2005-04-19T00:00:00Z,51002,81.66687377762507,25.23333333333333,25.683333333333334\n"
            + "2005-04-19T06:00:00Z,51002,81.33287154965757,25.116666666666667,24.633333333333333\n"
            + "2005-04-19T12:00:00Z,51002,75.83958417390204,25.1,24.349999999999998\n"
            + "2005-04-19T18:00:00Z,51002,77.6665349984058,25.133333333333333,25.216666666666665\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMean( with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T12&orderByMean(\"time/6hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean4", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T00:00:00Z,41004,266.42491026361625,19.36,20.28\n"
            + "2012-01-01T06:00:00Z,41004,267.30712443660354,18.766666666666666,20.3\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMean( with missing value data at 2012-01-01T04
    userDapQuery =
        "station,time,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-07&orderByMean(\"time/2days\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean6", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:00:00Z,258.3003557896057,17.224999999999994,20.63333333333333\n"
            + "41004,2012-01-03T00:00:00Z,305.00601205043847,5.96808510638298,19.58260869565217\n"
            + "41004,2012-01-05T00:00:00Z,258.5502684011244,14.27083333333333,18.948888888888888\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMean( with missing value data at 2012-01-01T04
    userDapQuery =
        "station,time,wd,atmp,wtmp&station>=\"41004\"&station<\"41024\""
            + "&time>=2012-01-01&time<2012-01-07&orderByMean(\"station,time/2days\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean7", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:00:00Z,258.3003557896057,17.224999999999994,20.63333333333333\n"
            + "41004,2012-01-03T00:00:00Z,305.00601205043847,5.96808510638298,19.58260869565217\n"
            + "41004,2012-01-05T00:00:00Z,258.5502684011244,14.27083333333333,18.948888888888888\n"
            + "41008,2012-01-01T00:00:00Z,249.7686962028111,14.765217391304345,16.258695652173916\n"
            + "41008,2012-01-03T00:00:00Z,306.3619051114213,5.192857142857143,15.06341463414634\n"
            + "41008,2012-01-05T00:00:00Z,254.21403357945186,13.03170731707317,14.946341463414635\n"
            + "41009,2012-01-01T00:00:00Z,269.2109644956681,21.23333333333333,23.3774193548387\n"
            + "41009,2012-01-03T00:00:00Z,321.3025236731279,11.41145833333333,21.496874999999996\n"
            + "41009,2012-01-05T00:00:00Z,289.59118887311513,16.469791666666666,21.30104166666666\n"
            + "41010,2012-01-01T00:00:00Z,261.97933085465695,21.780434782608694,23.66304347826087\n"
            + "41010,2012-01-03T00:00:00Z,324.9778634562704,13.541489361702123,23.240425531914894\n"
            + "41010,2012-01-05T00:00:00Z,292.6755186451097,18.502105263157887,23.064210526315783\n"
            + "41012,2012-01-01T00:00:00Z,268.8412847483023,18.68888888888889,23.064444444444447\n"
            + "41012,2012-01-03T00:00:00Z,312.89751647620056,8.904166666666669,22.57021276595745\n"
            + "41012,2012-01-05T00:00:00Z,273.91844710109484,16.110416666666666,21.687234042553186\n"
            + "41013,2012-01-01T00:00:00Z,263.1145225244107,16.269565217391303,18.291304347826088\n"
            + "41013,2012-01-03T00:00:00Z,307.6860309955103,4.056250000000001,15.96666666666666\n"
            + "41013,2012-01-05T00:00:00Z,255.73675729840153,13.558333333333334,16.74583333333333\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMean( with missing value data at 2012-01-01T04
    // first, just print the raw data
    userDapQuery =
        "station,time,wd,atmp,wtmp&station=\"41004\"" + "&time>=2012-01-01&time<=2012-01-01T05";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean8pre", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    String2.log("\nraw results for " + userDapQuery + "\n" + results);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:50:00Z,252,19.4,20.1\n"
            + "41004,2012-01-01T01:50:00Z,264,19.3,20.2\n"
            + "41004,2012-01-01T02:50:00Z,271,19.3,20.3\n"
            + "41004,2012-01-01T03:50:00Z,NaN,NaN,NaN\n"
            + "41004,2012-01-01T04:50:00Z,272,19.5,20.4\n";
    Test.ensureEqual(results, expected, "");

    // test orderByMean( with missing value data at 2012-01-01T04
    userDapQuery += "&orderByMean(\"station,time/2hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean8", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:00:00Z,258.0,19.35,20.15\n"
            + "41004,2012-01-01T02:00:00Z,271.0,19.3,20.3\n"
            + "41004,2012-01-01T04:00:00Z,272.0,19.5,20.4\n"; // third group has 1 value
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMean( with missing value data at 2012-01-01T04 and group size=1
    userDapQuery =
        "station,time,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderByMean(\"station,time/1hour\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean8b", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:00:00Z,252.0,19.4,20.1\n"
            + "41004,2012-01-01T01:00:00Z,264.0,19.3,20.2\n"
            + "41004,2012-01-01T02:00:00Z,271.0,19.3,20.3\n"
            + "41004,2012-01-01T03:00:00Z,NaN,NaN,NaN\n"; // group with no values
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMean( with missing value data at 2012-01-01T04 as .nc file
    userDapQuery =
        "station,time,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderByMean(\"station,time/1hour\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean8bnc", ".nc");
    results = NcHelper.ncdump(dir + tName, "");
    results =
        results.replaceAll(
            "date_created = \"....-..-..\";", "date_created = \"dddd-dd-dd\";"); // changes
    // every
    // month
    results =
        results.replaceAll(
            "date_issued = \"....-..-..\";", "date_issued = \"dddd-dd-dd\";"); // changes
    // every
    // month
    expected =
        "netcdf EDDTableFromNcFiles_obMean8bnc.nc {\n"
            + "  dimensions:\n"
            + "    row = 4;\n"
            + "    station_strlen = 5;\n"
            + "  variables:\n"
            + "    char station(row=4, station_strlen=5);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"timeseries_id\";\n"
            + "      :comment = \"The station identifier.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station Identifier\";\n"
            + "\n"
            + "    double time(row=4);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.325376E9, 1.3253868E9; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    double wd(row=4);\n"
            + "      :_FillValue = NaN; // double\n"
            + "      :actual_range = 252.0, 271.0; // double\n"
            + "      :cell_methods = \"time: mean (interval: 1 hour)\";\n"
            + "      :colorBarMaximum = 360.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Wind direction (the direction the wind is coming from in degrees clockwise from true N) during the same period used for WSPD.\";\n"
            + "      :ioos_category = \"Wind\";\n"
            + "      :long_name = \"Wind Direction\";\n"
            + "      :standard_name = \"wind_from_direction\";\n"
            + "      :units = \"degrees_true\";\n"
            + "\n"
            + "    double atmp(row=4);\n"
            + "      :_FillValue = NaN; // double\n"
            + "      :actual_range = 19.3, 19.4; // double\n"
            + "      :cell_methods = \"time: mean (interval: 1 hour)\";\n"
            + "      :colorBarMaximum = 40.0; // double\n"
            + "      :colorBarMinimum = -10.0; // double\n"
            + "      :comment = \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Air Temperature\";\n"
            + "      :standard_name = \"air_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    double wtmp(row=4);\n"
            + "      :_FillValue = NaN; // double\n"
            + "      :actual_range = 20.1, 20.3; // double\n"
            + "      :cell_methods = \"time: mean (interval: 1 hour)\";\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"SST\";\n"
            + "      :standard_name = \"sea_surface_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"TimeSeries\";\n"
            + "  :cdm_timeseries_variables = \"station, longitude, latitude\";\n"
            + "  :contributor_name = \"NOAA NDBC\";\n"
            + "  :contributor_role = \"Source of data.\";\n"
            + "  :Conventions = \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "  :creator_email = \"erd.data@noaa.gov\";\n"
            + "  :creator_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :creator_type = \"institution\";\n"
            + "  :creator_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :date_created = \"dddd-dd-dd\";\n"
            + "  :date_issued = \"dddd-dd-dd\";\n"
            + "  :featureType = \"TimeSeries\";\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_positive = \"down\";\n"
            + "  :geospatial_vertical_units = \"m\";\n"
            + "  :history = \"Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\n"
            + "Every 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    expected =
        ":time_coverage_end = \"2012-01-01T03:00:00Z\";\n"
            + "  :time_coverage_start = \"2012-01-01T00:00:00Z\";\n"
            + "  :title = \"NDBC Standard Meteorological Buoy Data, 1970-present\";\n"
            + "\n"
            + "  data:\n"
            + "    station =   \"41004\",   \"41004\",   \"41004\",   \"41004\"\n"
            + "    time = \n"
            + "      {1.325376E9, 1.3253796E9, 1.3253832E9, 1.3253868E9}\n"
            + "    wd = \n"
            + "      {252.0, 264.0, 271.0, NaN}\n"
            + "    atmp = \n"
            + "      {19.4, 19.3, 19.3, NaN}\n"
            + "    wtmp = \n"
            + "      {20.1, 20.2, 20.3, NaN}\n"
            + "}\n";
    int po = results.indexOf(expected.substring(0, 20));
    Test.ensureEqual(results.substring(po), expected, "\nresults=\n" + results);
    // String2.pressEnterToContinue();

    // test orderByMean( test that lat and lon means are 180 - 180, but wind
    // (degrees_true) is 0 to 360
    userDapQuery =
        "time,latitude,longitude,wd&latitude<0&longitude<0&time=2014-01-04T12&orderByMean(\"time/1day\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean10", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,latitude,longitude,wd\n"
            + "UTC,degrees_north,degrees_east,degrees_true\n"
            + "2014-01-04T00:00:00Z,-14.28,-170.688,248.0\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMean( test that lat and lon means are 180 - 180, but wind
    // (degrees_true) is 0 to 360
    userDapQuery =
        "time,latitude,longitude,wd&latitude>0&longitude>0&time=2014-01-04T12&orderByMean(\"time/1day\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean11", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,latitude,longitude,wd\n"
            + "UTC,degrees_north,degrees_east,degrees_true\n"
            + "2014-01-04T00:00:00Z,13.784014057024164,155.9907299240343,59.03859101760848\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // quick reject -> orderByMean var not in results vars
    String2.log("\n* Intentional Errors:\n");
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMean(\"station,atmp\")",
              dir,
              eddTable.className() + "_qr1",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For orderByMean, "
              + "you must specify a CSV list of orderBy column names (each of "
              + "which must be in the list of results variables; numeric columns "
              + "may have columnName[/divisor[timeUnits][:offset]]), e.g., \"stationID,time/10minutes\". "
              + "col=atmp is not in results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> station/10 not allowed
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&station<\"32000\"&orderByMean(\"station/10,wtmp\")",
              dir,
              eddTable.className() + "_qr2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For orderByMean, "
              + "you must specify a CSV list of orderBy column names (each of "
              + "which must be in the list of results variables; numeric columns "
              + "may have columnName[/divisor[timeUnits][:offset]]), e.g., \"stationID,time/10minutes\". "
              + "Cannot group numerically for column=station.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> 0 orderByMean vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMean(\"\")",
              dir,
              eddTable.className() + "_qr3",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected = "com.cohort.util.SimpleException: Query error: orderByMean: no csv.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }
    String2.log("End of intentional errors.");
  }

  /**
   * This tests bug fix (reported by Marco Alba 2020-11-11) in orderByMean.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  void testOrderByMean2() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderByMean2()
    // *****************\n");

    // testVerboseOn();
    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getpmelTaoDySst();

    // test orderByMean(twoVars)
    // station%2Clongitude%2Clatitude%2Ctime%2Cdepth%2CT_25%2CQT_5025%2CST_6025&station=%220n10w%22&time%3E=2020-01-01&time%3C2020-01-10&
    userDapQuery =
        "station%2Clongitude%2Clatitude%2Ctime%2Cdepth%2CT_25%2CQT_5025%2CST_6025&station=%220n10w%22&time%3E=2018-07-01&time%3C2018-07-15&orderByMean(%22time/1day%22)";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obMean2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected = // since time in orderByMean"", it is the truncated time
        "station,longitude,latitude,time,depth,T_25,QT_5025,ST_6025\n"
            + ",degrees_east,degrees_north,UTC,m,degree_C,,\n"
            + "0n10w,-10.0,0.0,2018-07-01T00:00:00Z,1.0,24.12,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-02T00:00:00Z,1.0,24.12,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-03T00:00:00Z,1.0,23.92,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-04T00:00:00Z,1.0,23.63,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-05T00:00:00Z,1.0,23.8,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-06T00:00:00Z,1.0,23.72,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-07T00:00:00Z,1.0,23.53,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-08T00:00:00Z,1.0,NaN,0.0,0.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-09T00:00:00Z,1.0,23.41,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-10T00:00:00Z,1.0,NaN,0.0,0.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-11T00:00:00Z,1.0,23.76,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-12T00:00:00Z,1.0,23.73,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-13T00:00:00Z,1.0,24.17,2.0,1.0\n"
            + //
            "0n10w,-10.0,0.0,2018-07-14T00:00:00Z,1.0,24.45,2.0,1.0\n";

    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /**
   * This tests orderBySum -- TODO put the correct value in "expected" variable
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testOrderBySum() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderBySum()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // test orderBySum(twoVars)
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wd,wtmp,atmp&station>\"5\"&station<\"51004\""
            + "&time>=2005-04-18&time<2005-04-20&orderBySum(\"station,time/12hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected = // since time in orderBySum"", it is the truncated time
        "time,station,wd,wtmp,atmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2005-04-18T00:00:00Z,51001,1175.0,293.3,285.8\n"
            + "2005-04-18T12:00:00Z,51001,1130.0,289.2,281.0\n"
            + "2005-04-19T00:00:00Z,51001,815.0,293.09999999999997,283.5999999999999\n"
            + "2005-04-19T12:00:00Z,51001,853.0,289.79999999999995,277.90000000000003\n"
            + "2005-04-18T00:00:00Z,51002,1010.0,302.8999999999999,302.3\n"
            + "2005-04-18T12:00:00Z,51002,1007.0,301.4,299.3\n"
            + "2005-04-19T00:00:00Z,51002,978.0,302.1,301.9\n"
            + "2005-04-19T12:00:00Z,51002,921.0,301.4,297.40000000000003\n"
            + "2005-04-18T00:00:00Z,51003,1097.0,304.30000000000007,295.90000000000003\n"
            + "2005-04-18T12:00:00Z,51003,987.0,303.70000000000005,293.9\n"
            + "2005-04-19T00:00:00Z,51003,904.0,305.5,294.4\n"
            + "2005-04-19T12:00:00Z,51003,925.0,304.1,292.0\n";

    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderBySum(station)
    userDapQuery =
        "time,station,wd,wtmp,atmp&station>\"5\"&station<\"51004\""
            + "&time>=2005-04-18&time<2005-04-20&orderBySum(\"station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected = // since time isn't in orderBySum(), it is the sum of the time values
        "time,station,wd,wtmp,atmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2005-04-18T23:30:00Z,51001,3973.0,1165.4,1128.3000000000002\n"
            + "2005-04-18T23:30:00Z,51002,3916.0,1207.8000000000002,1200.9000000000003\n"
            + "2005-04-18T23:30:00Z,51003,3913.0,1217.6,1176.2\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderBySum(oneVar)
    userDapQuery =
        "time,station,wd,wtmp,atmp&station=\"51002\""
            + "&time>=2005-04-18&time<2005-04-20&orderBySum(\"time/6hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum3", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,wtmp,atmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2005-04-18T00:00:00Z,51002,494.0,151.7,154.4\n"
            + "2005-04-18T06:00:00Z,51002,516.0,151.2,147.9\n"
            + "2005-04-18T12:00:00Z,51002,499.0,150.6,146.5\n"
            + "2005-04-18T18:00:00Z,51002,508.0,150.8,152.8\n"
            + "2005-04-19T00:00:00Z,51002,490.0,151.4,154.1\n"
            + "2005-04-19T06:00:00Z,51002,488.0,150.7,147.8\n"
            + "2005-04-19T12:00:00Z,51002,455.0,150.6,146.1\n"
            + "2005-04-19T18:00:00Z,51002,466.0,150.8,151.3\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderBySum( with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T12&orderBySum(\"time/6hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum4", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T00:00:00Z,41004,1332.0,96.8,101.4\n"
            + "2012-01-01T06:00:00Z,41004,1604.0,112.6,121.80000000000001\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderBySum( with missing value data at 2012-01-01T04
    userDapQuery =
        "station,time,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-07&orderBySum(\"time/2days\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum6", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:00:00Z,11640.0,757.9,866.5999999999998\n"
            + "41004,2012-01-03T00:00:00Z,13902.0,280.5,900.7999999999997\n"
            + "41004,2012-01-05T00:00:00Z,12405.0,685.0000000000001,852.7\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderBySum( with missing value data at 2012-01-01T04
    userDapQuery =
        "station,time,wd,atmp,wtmp&station>=\"41004\"&station<\"41024\""
            + "&time>=2012-01-01&time<2012-01-07&orderBySum(\"station,time/2days\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum7", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:00:00Z,11640.0,757.9,866.5999999999998\n"
            + "41004,2012-01-03T00:00:00Z,13902.0,280.5,900.7999999999997\n"
            + "41004,2012-01-05T00:00:00Z,12405.0,685.0000000000001,852.7\n"
            + "41008,2012-01-01T00:00:00Z,11538.0,679.2,747.9\n"
            + "41008,2012-01-03T00:00:00Z,12997.0,218.09999999999997,617.6\n"
            + "41008,2012-01-05T00:00:00Z,10607.0,534.3000000000001,612.7999999999998\n"
            + "41009,2012-01-01T00:00:00Z,22123.0,1974.7000000000003,2174.0999999999985\n"
            + "41009,2012-01-03T00:00:00Z,30485.0,1095.4999999999998,2063.7\n"
            + "41009,2012-01-05T00:00:00Z,27414.0,1581.0999999999995,2044.8999999999994\n"
            + "41010,2012-01-01T00:00:00Z,23135.0,2003.7999999999997,2176.999999999999\n"
            + "41010,2012-01-03T00:00:00Z,28344.0,1272.9000000000003,2184.599999999999\n"
            + "41010,2012-01-05T00:00:00Z,27432.0,1757.6999999999987,2191.1\n"
            + "41012,2012-01-01T00:00:00Z,12328.0,840.9999999999999,1037.9\n"
            + "41012,2012-01-03T00:00:00Z,14288.0,427.3999999999998,1060.8000000000004\n"
            + "41012,2012-01-05T00:00:00Z,13084.0,773.3,1019.3\n"
            + "41013,2012-01-01T00:00:00Z,11387.0,748.4000000000001,841.4000000000002\n"
            + "41013,2012-01-03T00:00:00Z,14562.0,194.69999999999996,766.4000000000001\n"
            + "41013,2012-01-05T00:00:00Z,12274.0,650.7999999999998,803.8\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderBySum( with missing value data at 2012-01-01T04
    // first, just print the raw data
    userDapQuery =
        "station,time,wd,atmp,wtmp&station=\"41004\"" + "&time>=2012-01-01&time<=2012-01-01T05";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum8pre", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    String2.log("\nraw results for " + userDapQuery + "\n" + results);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:50:00Z,252,19.4,20.1\n"
            + "41004,2012-01-01T01:50:00Z,264,19.3,20.2\n"
            + "41004,2012-01-01T02:50:00Z,271,19.3,20.3\n"
            + "41004,2012-01-01T03:50:00Z,NaN,NaN,NaN\n"
            + "41004,2012-01-01T04:50:00Z,272,19.5,20.4\n";
    Test.ensureEqual(results, expected, "");

    // test orderBySum( with missing value data at 2012-01-01T04
    userDapQuery += "&orderBySum(\"station,time/2hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum8", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:00:00Z,516.0,38.7,40.3\n"
            + "41004,2012-01-01T02:00:00Z,271.0,19.3,20.3\n"
            + "41004,2012-01-01T04:00:00Z,272.0,19.5,20.4\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderBySum( with missing value data at 2012-01-01T04 and group size=1
    userDapQuery =
        "station,time,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderBySum(\"station,time/1hour\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum8b", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,time,wd,atmp,wtmp\n"
            + ",UTC,degrees_true,degree_C,degree_C\n"
            + "41004,2012-01-01T00:00:00Z,252.0,19.4,20.1\n"
            + "41004,2012-01-01T01:00:00Z,264.0,19.3,20.2\n"
            + "41004,2012-01-01T02:00:00Z,271.0,19.3,20.3\n"
            + "41004,2012-01-01T03:00:00Z,NaN,NaN,NaN\n"; // group with no values
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderBySum( with missing value data at 2012-01-01T04 as .nc file
    userDapQuery =
        "station,time,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderBySum(\"station,time/1hour\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obSum8bnc", ".nc");
    results = NcHelper.ncdump(dir + tName, "");
    results =
        results.replaceAll(
            "date_created = \"....-..-..\";", "date_created = \"dddd-dd-dd\";"); // changes
    // every
    // month
    results =
        results.replaceAll(
            "date_issued = \"....-..-..\";", "date_issued = \"dddd-dd-dd\";"); // changes
    // every
    // month
    expected =
        "netcdf EDDTableFromNcFiles_obSum8bnc.nc {\n"
            + "  dimensions:\n"
            + "    row = 4;\n"
            + "    station_strlen = 5;\n"
            + "  variables:\n"
            + "    char station(row=4, station_strlen=5);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"timeseries_id\";\n"
            + "      :comment = \"The station identifier.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station Identifier\";\n"
            + "\n"
            + "    double time(row=4);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.325376E9, 1.3253868E9; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    double wd(row=4);\n"
            + "      :_FillValue = NaN; // double\n"
            + "      :actual_range = 252.0, 271.0; // double\n"
            + "      :cell_methods = \"time: sum (interval: 1 hour)\";\n"
            + "      :colorBarMaximum = 360.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Wind direction (the direction the wind is coming from in degrees clockwise from true N) during the same period used for WSPD.\";\n"
            + "      :ioos_category = \"Wind\";\n"
            + "      :long_name = \"Wind Direction\";\n"
            + "      :standard_name = \"wind_from_direction\";\n"
            + "      :units = \"degrees_true\";\n"
            + "\n"
            + "    double atmp(row=4);\n"
            + "      :_FillValue = NaN; // double\n"
            + "      :actual_range = 19.3, 19.4; // double\n"
            + "      :cell_methods = \"time: sum (interval: 1 hour)\";\n"
            + "      :colorBarMaximum = 40.0; // double\n"
            + "      :colorBarMinimum = -10.0; // double\n"
            + "      :comment = \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Air Temperature\";\n"
            + "      :standard_name = \"air_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    double wtmp(row=4);\n"
            + "      :_FillValue = NaN; // double\n"
            + "      :actual_range = 20.1, 20.3; // double\n"
            + "      :cell_methods = \"time: sum (interval: 1 hour)\";\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"SST\";\n"
            + "      :standard_name = \"sea_surface_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"TimeSeries\";\n"
            + "  :cdm_timeseries_variables = \"station, longitude, latitude\";\n"
            + "  :contributor_name = \"NOAA NDBC\";\n"
            + "  :contributor_role = \"Source of data.\";\n"
            + "  :Conventions = \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "  :creator_email = \"erd.data@noaa.gov\";\n"
            + "  :creator_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :creator_type = \"institution\";\n"
            + "  :creator_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :date_created = \"dddd-dd-dd\";\n"
            + "  :date_issued = \"dddd-dd-dd\";\n"
            + "  :featureType = \"TimeSeries\";\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_positive = \"down\";\n"
            + "  :geospatial_vertical_units = \"m\";\n"
            + "  :history = \"Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\n"
            + "Every 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    expected =
        ":time_coverage_end = \"2012-01-01T03:00:00Z\";\n"
            + "  :time_coverage_start = \"2012-01-01T00:00:00Z\";\n"
            + "  :title = \"NDBC Standard Meteorological Buoy Data, 1970-present\";\n"
            + "\n"
            + "  data:\n"
            + "    station =   \"41004\",   \"41004\",   \"41004\",   \"41004\"\n"
            + "    time = \n"
            + "      {1.325376E9, 1.3253796E9, 1.3253832E9, 1.3253868E9}\n"
            + "    wd = \n"
            + "      {252.0, 264.0, 271.0, NaN}\n"
            + "    atmp = \n"
            + "      {19.4, 19.3, 19.3, NaN}\n"
            + "    wtmp = \n"
            + "      {20.1, 20.2, 20.3, NaN}\n"
            + "}\n";
    int po = results.indexOf(expected.substring(0, 20));
    Test.ensureEqual(results.substring(po), expected, "\nresults=\n" + results);
    // String2.pressEnterToContinue();

    // test orderBySum( test that lat and lon sums are 180 - 180, but wind
    // (degrees_true) is 0 to 360
    // Marco Alba - skip, no special function for lat,lon and wind
    // userDapQuery =
    // "time,latitude,longitude,wd&latitude<0&longitude<0&time=2014-01-04T12&orderBySum(\"time/1day\")";
    // tName = eddTable.makeNewFileForDapQuery(null, null, userDapQuery, dir,
    // eddTable.className() + "_obSum10", ".csv");
    // results = File2.directReadFrom88591File(dir + tName);
    // expected =
    // "time,latitude,longitude,wd\n" +
    // "UTC,degrees_north,degrees_east,degrees_true\n" +
    // "2014-01-04T00:00:00Z,-14.28,-170.688,248.0\n";
    // Test.ensureEqual(results, expected, "\nresults=\n" + results);
    //
    // //test orderBySum( test that lat and lon sums are 180 - 180, but wind
    // (degrees_true) is 0 to 360
    // userDapQuery =
    // "time,latitude,longitude,wd&latitude>0&longitude>0&time=2014-01-04T12&orderBySum(\"time/1day\")";
    // tName = eddTable.makeNewFileForDapQuery(null, null, userDapQuery, dir,
    // eddTable.className() + "_obSum11", ".csv");
    // results = File2.directReadFrom88591File(dir + tName);
    // expected =
    // "time,latitude,longitude,wd\n" +
    // "UTC,degrees_north,degrees_east,degrees_true\n" +
    // "2014-01-04T00:00:00Z,13.784014057024162,155.9907299240343,59.03859101760849\n";
    // Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // quick reject -> orderBySum var not in results vars
    String2.log("\n* Intentional Errors:\n");
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderBySum(\"station,atmp\")",
              dir,
              eddTable.className() + "_qr1",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For orderBySum, "
              + "you must specify a CSV list of orderBy column names (each of "
              + "which must be in the list of results variables; numeric columns "
              + "may have columnName[/divisor[timeUnits][:offset]]), e.g., \"stationID,time/10minutes\". "
              + "col=atmp is not in results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> station/10 not allowed
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&station<\"32000\"&orderBySum(\"station/10,wtmp\")",
              dir,
              eddTable.className() + "_qr2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For orderBySum, "
              + "you must specify a CSV list of orderBy column names (each of "
              + "which must be in the list of results variables; numeric columns "
              + "may have columnName[/divisor[timeUnits][:offset]]), e.g., \"stationID,time/10minutes\". "
              + "Cannot group numerically for column=station.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> 0 orderBySum vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderBySum(\"\")",
              dir,
              eddTable.className() + "_qr3",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected = "com.cohort.util.SimpleException: Query error: orderBySum: no csv.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }
    String2.log("End of intentional errors.");
  }

  /**
   * This tests orderByMax.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testOrderByMax() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderByMax()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // test orderByMax(twoVars)
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMax(\"station,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T23:00:00Z,51001,24.2,22.1\n"
            + "2005-04-19T23:00:00Z,51002,25.2,24.8\n"
            + "2005-04-19T23:00:00Z,51003,25.4,24.7\n"
            + "2005-04-19T23:00:00Z,51004,25.0,24.3\n"
            + "2005-04-19T23:00:00Z,51028,27.8,27.5\n"
            + "2005-04-19T23:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T22:00:00Z,51202,24.6,NaN\n"
            + "2005-04-19T23:00:00Z,52200,28.0,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // check attributes (still original mv fv)
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMax(\"station,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmaxnc", ".nc");
    results = NcHelper.ncdump(dir + tName, "-h");
    expected =
        "netcdf EDDTableFromNcFiles_obmaxnc.nc {\n"
            + "  dimensions:\n"
            + "    row = 8;\n"
            + "    station_strlen = 5;\n"
            + "  variables:\n"
            + "    double time(row=8);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.113948E9, 1.1139516E9; // double\n"
            + // this is range in file,
            // so it won't
            // change
            "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    char station(row=8, station_strlen=5);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"timeseries_id\";\n"
            + "      :comment = \"The station identifier.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station Identifier\";\n"
            + "\n"
            + "    float wtmp(row=8);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 24.2f, 28.0f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"SST\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"sea_surface_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    float atmp(row=8);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 22.1f, 27.5f; // float\n"
            + "      :colorBarMaximum = 40.0; // double\n"
            + "      :colorBarMinimum = -10.0; // double\n"
            + "      :comment = \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Air Temperature\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"air_temperature\";\n"
            + "      :units = \"degree_C\";\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // test orderByMax(station,time/1day,wtmp)
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time/1day,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected = // note that time is the time that max wtmp occurred.
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-18T04:00:00Z,51001,24.6,24.0\n"
            + "2005-04-19T04:00:00Z,51001,24.7,23.9\n"
            + "2005-04-18T04:00:00Z,51002,25.3,25.9\n"
            + "2005-04-19T02:00:00Z,51002,25.3,25.9\n"
            + "2005-04-18T23:00:00Z,51003,25.5,24.7\n"
            + "2005-04-19T03:00:00Z,51003,25.6,24.8\n"
            + "2005-04-18T00:00:00Z,51004,25.1,24.7\n"
            + "2005-04-19T01:00:00Z,51004,25.1,24.6\n"
            + "2005-04-18T01:00:00Z,51028,28.8,27.6\n"
            + "2005-04-19T01:00:00Z,51028,28.5,27.6\n"
            + "2005-04-18T23:00:00Z,51201,24.8,NaN\n"
            + "2005-04-19T23:00:00Z,51201,25.0,NaN\n"
            + "2005-04-18T23:00:00Z,51202,24.6,NaN\n"
            + "2005-04-19T08:00:00Z,51202,24.7,NaN\n"
            + "2005-04-18T06:00:00Z,52200,28.2,NaN\n"
            + "2005-04-19T06:00:00Z,52200,28.1,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test 1day (above) same as day
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time/day,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // same expected
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test 1day (above) same as 86400 (implied seconds)
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time/86400,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // same expected
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test 1.5days orderByMax(station,time/1.5days,wtmp)
    userDapQuery =
        "time,station,wtmp,atmp&station=\"51002\""
            + "&time>=2005-04-01&time<2005-04-20&orderByMax(\"station,time/1.5days,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            userDapQuery,
            dir,
            eddTable.className() + "_obmax1.5days",
            ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected = // note that time is the time that max wtmp occurred.
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-01T08:00:00Z,51002,25.1,24.8\n"
            + "2005-04-02T23:00:00Z,51002,25.0,25.3\n"
            + // base is day 0 since there
            // is a break at -03T00
            "2005-04-03T03:00:00Z,51002,25.0,25.4\n"
            + "2005-04-05T23:00:00Z,51002,24.9,25.3\n"
            + "2005-04-07T07:00:00Z,51002,24.9,24.2\n"
            + "2005-04-08T23:00:00Z,51002,24.9,25.5\n"
            + "2005-04-10T03:00:00Z,51002,25.1,26.0\n"
            + "2005-04-11T23:00:00Z,51002,25.1,25.6\n"
            + "2005-04-12T02:00:00Z,51002,25.3,26.2\n"
            + "2005-04-14T02:00:00Z,51002,25.3,26.1\n"
            + "2005-04-16T04:00:00Z,51002,25.2,25.3\n"
            + "2005-04-17T23:00:00Z,51002,25.2,25.7\n"
            + "2005-04-19T02:00:00Z,51002,25.3,25.9\n"
            + "2005-04-19T23:00:00Z,51002,25.2,24.8\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMax(time/1day,station) last var is a string!
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"time/1day,station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax2s", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected = // note that time is the time that max wtmp occurred.
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-18T23:00:00Z,52200,28.0,NaN\n"
            + // sure enough, it just keep
            // row with max station!
            "2005-04-19T23:00:00Z,52200,28.0,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMax(oneVar)
    userDapQuery =
        "time,station,wtmp,atmp&station=\"51002\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMax(\"wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax3", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T23:00:00Z,51002,25.2,24.8\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMax(one string Var)
    userDapQuery =
        "time,station,wtmp,atmp&station<\"3200\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMax(\"station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax4", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T23:00:00Z,31201,24.2,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test nonTimestamp/nTimeunits
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMax(\"station,wtmp/1msec,time\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax5", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T21:00:00Z,51001,24.1,23.5\n"
            + "2005-04-19T23:00:00Z,51001,24.2,22.1\n"
            + "2005-04-19T21:00:00Z,51002,25.1,25.4\n"
            + "2005-04-19T23:00:00Z,51002,25.2,24.8\n"
            + "2005-04-19T21:00:00Z,51003,25.3,23.9\n"
            + "2005-04-19T23:00:00Z,51003,25.4,24.7\n"
            + "2005-04-19T23:00:00Z,51004,25.0,24.3\n"
            + "2005-04-19T21:00:00Z,51028,27.7,27.6\n"
            + "2005-04-19T23:00:00Z,51028,27.8,27.5\n"
            + "2005-04-19T22:00:00Z,51201,24.9,NaN\n"
            + "2005-04-19T23:00:00Z,51201,25.0,NaN\n"
            + "2005-04-19T23:00:00Z,51202,24.5,NaN\n"
            + "2005-04-19T22:00:00Z,51202,24.6,NaN\n"
            + "2005-04-19T23:00:00Z,52200,28.0,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMax with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderByMax(\"wd\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax6", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T02:50:00Z,41004,271,19.3,20.3\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMax with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderByMax(\"wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmax6", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T02:50:00Z,41004,271,19.3,20.3\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    String2.log("* Expected errors:");
    // quick reject -> var/stringDivisor
    try {
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
              + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time/zztop,wtmp\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, userDapQuery, dir, eddTable.className() + "_qr1a", ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByMax "
              + "could not parse time/zztop. (Format should be variable[/interval[:offset]] )";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> 0 divisor
    try {
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
              + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time/0days,wtmp\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery,
              dir,
              eddTable.className() + "_qr1aZeroDivisor",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByMax "
              + "could not parse time/0days. (numberTimeUnits values must be positive numbers)";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> var:offset (without divisor)
    try {
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
              + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time:3600,wtmp\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, userDapQuery, dir, eddTable.className() + "_qr1bNoDiv", ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: 'orderByMax' "
              + "variable=time:3600 isn't in the dataset.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> unknown timeUnits
    try {
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
              + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time/2zztops,wtmp\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery,
              dir,
              eddTable.className() + "_qr1bUnknown",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByMax "
              + "could not parse time/2zztops. (Format should be variable[/interval[:offset]] )";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> floatingpoint month or year
    try {
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
              + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time/1.5months,wtmp\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery,
              dir,
              eddTable.className() + "_qr1bFloatingTimeunits",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByMax "
              + "could not parse time/1.5months. (The number of months or years must be a positive integer.)";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> var/timeDivisor:offset
    try {
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
              + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time/1day:3600,wtmp\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, userDapQuery, dir, eddTable.className() + "_qr1b", ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByMax "
              + "could not parse time/1day:3600. (Offset not allowed with date intervals.)";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> last orderByMax var has a divisor
    try {
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
              + "&time>=2005-04-18&time<2005-04-20&orderByMax(\"station,time/1day,wtmp/10\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, userDapQuery, dir, eddTable.className() + "_qr1c", ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByMax "
              + "cannot apply rounding to wtmp/10 because it is the last variable in the CSV list.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> orderByMax var not in results vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMax(\"station,atmp\")",
              dir,
              eddTable.className() + "_qr1d",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: orderBy "
              + "variable=atmp isn't in the list of results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> station/10 not allowed
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&station<\"32000\"&orderByMax(\"station/10,wtmp\")",
              dir,
              eddTable.className() + "_qr2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: "
              + "orderByMax cannot apply rounding to station/10 because it is not a numeric data type.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> 0 orderByMax vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMax(\"\")",
              dir,
              eddTable.className() + "_qr3",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: "
              + "No column names were specified for 'orderByMax'.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }
  }

  /**
   * This tests orderByMin.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testOrderByMin() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderByMin()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // test orderByMin(3 Vars)
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMin(\"station,time/1day,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmin1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-18T17:00:00Z,51001,23.9,23.2\n"
            + "2005-04-19T16:00:00Z,51001,24.1,23.0\n"
            + "2005-04-18T12:00:00Z,51002,25.1,24.5\n"
            + "2005-04-19T07:00:00Z,51002,25.1,24.6\n"
            + "2005-04-18T15:00:00Z,51003,25.2,24.3\n"
            + "2005-04-19T07:00:00Z,51003,25.3,24.5\n"
            + "2005-04-18T09:00:00Z,51004,24.9,24.5\n"
            + "2005-04-19T02:00:00Z,51004,25.0,24.6\n"
            + "2005-04-18T17:00:00Z,51028,27.4,26.7\n"
            + "2005-04-19T17:00:00Z,51028,27.5,26.4\n"
            + "2005-04-18T12:00:00Z,51201,24.4,NaN\n"
            + "2005-04-19T15:00:00Z,51201,24.6,NaN\n"
            + "2005-04-18T12:00:00Z,51202,24.4,NaN\n"
            + "2005-04-19T15:00:00Z,51202,24.4,NaN\n"
            + "2005-04-18T17:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T00:00:00Z,52200,28.0,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // check attributes (still original mv fv)
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMin(\"station,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obminnc", ".nc");
    results = NcHelper.ncdump(dir + tName, "-h");
    expected =
        "netcdf EDDTableFromNcFiles_obminnc.nc {\n"
            + "  dimensions:\n"
            + "    row = 8;\n"
            + "    station_strlen = 5;\n"
            + "  variables:\n"
            + "    double time(row=8);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.1139444E9, 1.113948E9; // double\n"
            + // this is range in file,
            // so it won't
            // change
            "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    char station(row=8, station_strlen=5);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"timeseries_id\";\n"
            + "      :comment = \"The station identifier.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station Identifier\";\n"
            + "\n"
            + "    float wtmp(row=8);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 24.1f, 28.0f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"SST\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"sea_surface_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    float atmp(row=8);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 23.5f, 27.6f; // float\n"
            + "      :colorBarMaximum = 40.0; // double\n"
            + "      :colorBarMinimum = -10.0; // double\n"
            + "      :comment = \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Air Temperature\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"air_temperature\";\n"
            + "      :units = \"degree_C\";\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // test orderByMin(twoVars)
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19&time<2005-04-20&orderByMin(\"station,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmin1b", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T16:00:00Z,51001,24.1,23.0\n"
            + "2005-04-19T07:00:00Z,51002,25.1,24.6\n"
            + "2005-04-19T07:00:00Z,51003,25.3,24.5\n"
            + "2005-04-19T02:00:00Z,51004,25.0,24.6\n"
            + "2005-04-19T17:00:00Z,51028,27.5,26.4\n"
            + "2005-04-19T15:00:00Z,51201,24.6,NaN\n"
            + "2005-04-19T15:00:00Z,51202,24.4,NaN\n"
            + "2005-04-19T00:00:00Z,52200,28.0,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMin(time/1day,station) last var is a string!
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMin(\"time/1day,station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmin2a", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        // sure enough, it just keep row with min station!
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-18T00:00:00Z,51001,24.4,23.7\n"
            + "2005-04-19T00:00:00Z,51001,24.5,23.6\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMin(oneVar)
    userDapQuery =
        "time,station,wtmp,atmp&station=\"51002\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMin(\"wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmin2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T21:00:00Z,51002,25.1,25.4\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMin(one string Var)
    userDapQuery =
        "time,station,wtmp,atmp&station<\"3200\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMin(\"station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmin2b", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T21:00:00Z,31201,24.2,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMin(3 Vars -- different order)
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMin(\"time/1day,station,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmin3", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-18T17:00:00Z,51001,23.9,23.2\n"
            + "2005-04-18T12:00:00Z,51002,25.1,24.5\n"
            + "2005-04-18T15:00:00Z,51003,25.2,24.3\n"
            + "2005-04-18T09:00:00Z,51004,24.9,24.5\n"
            + "2005-04-18T17:00:00Z,51028,27.4,26.7\n"
            + "2005-04-18T12:00:00Z,51201,24.4,NaN\n"
            + "2005-04-18T12:00:00Z,51202,24.4,NaN\n"
            + "2005-04-18T17:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T16:00:00Z,51001,24.1,23.0\n"
            + "2005-04-19T07:00:00Z,51002,25.1,24.6\n"
            + "2005-04-19T07:00:00Z,51003,25.3,24.5\n"
            + "2005-04-19T02:00:00Z,51004,25.0,24.6\n"
            + "2005-04-19T17:00:00Z,51028,27.5,26.4\n"
            + "2005-04-19T15:00:00Z,51201,24.6,NaN\n"
            + "2005-04-19T15:00:00Z,51202,24.4,NaN\n"
            + "2005-04-19T00:00:00Z,52200,28.0,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMin(3 Vars -- different order)
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<=\"51004\""
            + "&time>=2005-04-14&time<2005-04-20&orderByMin(\"time/2day,station,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmin3b", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-14T00:00:00Z,51001,23.5,23.0\n"
            + "2005-04-14T05:00:00Z,51002,25.1,24.9\n"
            + "2005-04-14T18:00:00Z,51003,25.1,24.8\n"
            + "2005-04-14T04:00:00Z,51004,24.8,24.4\n"
            + "2005-04-16T12:00:00Z,51001,23.4,22.8\n"
            + "2005-04-15T06:00:00Z,51002,25.1,24.7\n"
            + "2005-04-16T15:00:00Z,51003,25.1,24.6\n"
            + "2005-04-15T08:00:00Z,51004,24.8,24.7\n"
            + "2005-04-17T00:00:00Z,51001,23.9,23.2\n"
            + "2005-04-17T08:00:00Z,51002,25.1,24.4\n"
            + "2005-04-18T15:00:00Z,51003,25.2,24.3\n"
            + "2005-04-17T00:00:00Z,51004,24.9,23.9\n"
            + "2005-04-19T16:00:00Z,51001,24.1,23.0\n"
            + "2005-04-19T07:00:00Z,51002,25.1,24.6\n"
            + "2005-04-19T07:00:00Z,51003,25.3,24.5\n"
            + "2005-04-19T02:00:00Z,51004,25.0,24.6\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMin with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderByMin(\"wd\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmin6", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T00:50:00Z,41004,252,19.4,20.1\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMin with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderByMin(\"wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obmin6", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T00:50:00Z,41004,252,19.4,20.1\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // quick reject -> last orderByMin var has a divisor
    try {
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
              + "&time>=2005-04-18&time<2005-04-20&orderByMin(\"station,time/1day,wtmp/10\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, userDapQuery, dir, eddTable.className() + "_qrMin1a", ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByMin "
              + "cannot apply rounding to wtmp/10 because it is the last variable in the CSV list.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> offset not allowed with date intervals
    try {
      // test orderByMin(3 Vars -- different order) :1day
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<=\"51004\""
              + "&time>=2005-04-14&time<2005-04-20&orderByMin(\"time/2day:1day,station,wtmp\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, userDapQuery, dir, eddTable.className() + "_obmin3c", ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByMin "
              + "could not parse time/2day:1day. (Offset not allowed with date intervals.)";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> orderByMin var not in results vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMin(\"station,latitude\")",
              dir,
              eddTable.className() + "_qr1",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: orderBy "
              + "variable=latitude isn't in the list of results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> stringVar/
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMin(\"station/10,wtmp\")",
              dir,
              eddTable.className() + "_qr1b",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: "
              + "orderByMin cannot apply rounding to station/10 because it is not a numeric data type.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> 0 orderByMin vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMin(\"\")",
              dir,
              eddTable.className() + "_qr2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: "
              + "No column names were specified for 'orderByMin'.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }
  }

  /**
   * This tests orderByMinMax.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testOrderByMinMax() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderByMinMax()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // test orderByMinMax(twoVars)
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<=\"51004\""
            + "&time>=2005-04-19&time<2005-04-20&orderByMinMax(\"station,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obminmax1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T16:00:00Z,51001,24.1,23.0\n"
            + // min
            "2005-04-19T04:00:00Z,51001,24.7,23.9\n"
            + // max
            "2005-04-19T07:00:00Z,51002,25.1,24.6\n"
            + "2005-04-19T02:00:00Z,51002,25.3,25.9\n"
            + "2005-04-19T07:00:00Z,51003,25.3,24.5\n"
            + "2005-04-19T03:00:00Z,51003,25.6,24.8\n"
            + "2005-04-19T02:00:00Z,51004,25.0,24.6\n"
            + "2005-04-19T01:00:00Z,51004,25.1,24.6\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // check attributes (still original mv fv)
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMinMax(\"station,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obminmaxnc", ".nc");
    results = NcHelper.ncdump(dir + tName, "-h");
    expected =
        "netcdf EDDTableFromNcFiles_obminmaxnc.nc {\n"
            + "  dimensions:\n"
            + "    row = 16;\n"
            + "    station_strlen = 5;\n"
            + "  variables:\n"
            + "    double time(row=16);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.1139444E9, 1.1139516E9; // double\n"
            + // this is range in
            // file, so it won't
            // change
            "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    char station(row=16, station_strlen=5);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"timeseries_id\";\n"
            + "      :comment = \"The station identifier.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station Identifier\";\n"
            + "\n"
            + "    float wtmp(row=16);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 24.1f, 28.0f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"SST\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"sea_surface_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    float atmp(row=16);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 22.1f, 27.6f; // float\n"
            + "      :colorBarMaximum = 40.0; // double\n"
            + "      :colorBarMinimum = -10.0; // double\n"
            + "      :comment = \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Air Temperature\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"air_temperature\";\n"
            + "      :units = \"degree_C\";\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // test orderByMinMax(oneVar)
    userDapQuery =
        "time,station,wtmp,atmp&station=\"51002\""
            + "&time>=2005-04-19T21&time<2005-04-20&orderByMinMax(\"wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obminmax2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-19T21:00:00Z,51002,25.1,25.4\n"
            + // min
            "2005-04-19T23:00:00Z,51002,25.2,24.8\n"; // max
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMinMax(3 vars)
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"51003\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMinMax(\"time/1day,station,wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obminmax3", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-18T17:00:00Z,51001,23.9,23.2\n"
            + "2005-04-18T04:00:00Z,51001,24.6,24.0\n"
            + "2005-04-18T12:00:00Z,51002,25.1,24.5\n"
            + "2005-04-18T04:00:00Z,51002,25.3,25.9\n"
            + "2005-04-19T16:00:00Z,51001,24.1,23.0\n"
            + "2005-04-19T04:00:00Z,51001,24.7,23.9\n"
            + "2005-04-19T07:00:00Z,51002,25.1,24.6\n"
            + "2005-04-19T02:00:00Z,51002,25.3,25.9\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMinMax(time/1day,station) last var is a string!
    userDapQuery =
        "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
            + "&time>=2005-04-18&time<2005-04-20&orderByMinMax(\"time/1day,station\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obminmax2a", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        // sure enough, it just keep rows with min+max station!
        "time,station,wtmp,atmp\n"
            + "UTC,,degree_C,degree_C\n"
            + "2005-04-18T00:00:00Z,51001,24.4,23.7\n"
            + "2005-04-18T23:00:00Z,52200,28.0,NaN\n"
            + "2005-04-19T00:00:00Z,51001,24.5,23.6\n"
            + "2005-04-19T23:00:00Z,52200,28.0,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMinMax with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderByMinMax(\"wd\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obminmax3a", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T00:50:00Z,41004,252,19.4,20.1\n"
            + "2012-01-01T02:50:00Z,41004,271,19.3,20.3\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByMinMax with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<=2012-01-01T04&orderByMinMax(\"wtmp\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obminmax3b", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T00:50:00Z,41004,252,19.4,20.1\n"
            + "2012-01-01T02:50:00Z,41004,271,19.3,20.3\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // quick reject -> last orderByMinMax var has a divisor
    try {
      userDapQuery =
          "time,station,wtmp,atmp&station>\"5\"&station<\"6\""
              + "&time>=2005-04-18&time<2005-04-20&orderByMinMax(\"station,time/1day,wtmp/10\")";
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery,
              dir,
              eddTable.className() + "_qrMinMax1a",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByMinMax "
              + "cannot apply rounding to wtmp/10 because it is the last variable in the CSV list.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> orderByMinMax var not in results vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMinMax(\"station,latitude\")",
              dir,
              eddTable.className() + "_qr1",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: orderBy "
              + "variable=latitude isn't in the list of results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> station/10
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMinMax(\"station/10,wtmp\")",
              dir,
              eddTable.className() + "_qr1b",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: "
              + "orderByMinMax cannot apply rounding to station/10 because it is not a numeric data type.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> 0 orderByMinMax vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByMinMax(\"\")",
              dir,
              eddTable.className() + "_qr2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: "
              + "No column names were specified for 'orderByMinMax'.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }
  }

  /**
   * This tests orderByClosest. This is also a good test of regex constraint on string variable
   * (that just has 1 value per file).
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testOrderByClosest() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderByClosest()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // test orderByClosest() old syntax
    userDapQuery =
        "longitude,latitude,time,wtmp,station&station=~%224100.%22"
            + "&time%3E=2006-01-01T00%3A00%3A00Z&time%3C=2006-01-03T00%3A00%3A00Z"
            + "&orderByClosest(%22station,time,1 day%22)";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "longitude,latitude,time,wtmp,station\n"
            + "degrees_east,degrees_north,UTC,degree_C,\n"
            + "-72.698,34.675,2006-01-01T00:00:00Z,20.3,41001\n"
            + "-72.698,34.675,2006-01-02T00:00:00Z,19.8,41001\n"
            + "-72.698,34.675,2006-01-03T00:00:00Z,19.8,41001\n"
            + "-74.921,31.887,2006-01-01T00:00:00Z,21.9,41002\n"
            + // 2020-03-05 before changes, was
            // -75.483,32.309
            // Was it
            // moved?!
            "-74.921,31.887,2006-01-02T00:00:00Z,22.1,41002\n"
            + "-74.921,31.887,2006-01-03T00:00:00Z,22.1,41002\n"
            + "-79.099,32.501,2006-01-01T00:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-02T00:00:00Z,18.7,41004\n"
            + "-79.099,32.501,2006-01-03T00:00:00Z,18.7,41004\n"
            + "-80.869,31.402,2006-01-01T00:00:00Z,13.5,41008\n"
            + "-80.869,31.402,2006-01-02T00:00:00Z,13.7,41008\n"
            + "-80.869,31.402,2006-01-03T00:00:00Z,14.1,41008\n"
            + "-80.166,28.519,2006-01-01T00:00:00Z,21.6,41009\n"
            + "-80.166,28.519,2006-01-02T00:00:00Z,21.9,41009\n"
            + "-80.166,28.519,2006-01-03T00:00:00Z,21.1,41009\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByClosest() old syntax
    userDapQuery =
        "longitude,latitude,time,wtmp,station&station=%2241004%22"
            + "&time%3E=2006-01-01T00%3A00%3A00Z&time%3C=2006-01-03T00%3A00%3A00Z"
            + "&orderByClosest(%22time,1day%22)";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "longitude,latitude,time,wtmp,station\n"
            + "degrees_east,degrees_north,UTC,degree_C,\n"
            + "-79.099,32.501,2006-01-01T00:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-02T00:00:00Z,18.7,41004\n"
            + "-79.099,32.501,2006-01-03T00:00:00Z,18.7,41004\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByClosest() new syntax
    userDapQuery =
        "longitude,latitude,time,wtmp,station&station=%2241004%22"
            + "&time%3E=2006-01-01T00%3A00%3A00Z&time%3C=2006-01-03T00%3A00%3A00Z"
            + "&orderByClosest(%22time/1day%22)";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obc3", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "longitude,latitude,time,wtmp,station\n"
            + "degrees_east,degrees_north,UTC,degree_C,\n"
            + "-79.099,32.501,2006-01-01T00:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-02T00:00:00Z,18.7,41004\n"
            + "-79.099,32.501,2006-01-03T00:00:00Z,18.7,41004\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByClosest() first var has divisor !!! Currently not allowed.
    // Rob said it looked different/harder than the other options,
    // so let's wait for someone to show a use case and request it.
    // userDapQuery = "longitude,latitude,time,wtmp,station&station=~%224100.%22" +
    // "&time%3E=2006-01-01T00%3A00%3A00Z&time%3C=2006-01-03T00%3A00%3A00Z" +
    // "&orderByClosest(%22time/1day,station,wtmp,18%22)";
    // tName = eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery,
    // dir,
    // eddTable.className() + "_obClosest4", ".csv");
    // results = File2.directReadFrom88591File(dir + tName);
    // expected =
    // "zz\n";
    // Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByClosest with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T10&orderByClosest(\"time/4hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obClosest5", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T00:50:00Z,41004,252,19.4,20.1\n"
            + "2012-01-01T03:50:00Z,41004,NaN,NaN,NaN\n"
            + "2012-01-01T07:50:00Z,41004,288,19.0,20.2\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // same test in .nc file to see if mv's are the fake mv's
    // test orderByClosest with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T10&orderByClosest(\"time/4hours\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obClosest5nc", ".nc");
    Table table = new Table();
    results = NcHelper.ncdump(dir + tName, "");
    results =
        results.replaceAll(
            "date_created = \"....-..-..\";", "date_created = \"dddd-dd-dd\";"); // changes
    // every
    // month
    results =
        results.replaceAll(
            "date_issued = \"....-..-..\";", "date_issued = \"dddd-dd-dd\";"); // changes
    // every
    // month

    expected =
        "netcdf EDDTableFromNcFiles_obClosest5nc.nc {\n"
            + "  dimensions:\n"
            + "    row = 3;\n"
            + "    station_strlen = 5;\n"
            + "  variables:\n"
            + "    double time(row=3);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.325379E9, 1.3254042E9; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    char station(row=3, station_strlen=5);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"timeseries_id\";\n"
            + "      :comment = \"The station identifier.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station Identifier\";\n"
            + "\n"
            + "    short wd(row=3);\n"
            + "      :_FillValue = 32767S; // short\n"
            + "      :actual_range = 252S, 288S; // short\n"
            + "      :colorBarMaximum = 360.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Wind direction (the direction the wind is coming from in degrees clockwise from true N) during the same period used for WSPD.\";\n"
            + "      :ioos_category = \"Wind\";\n"
            + "      :long_name = \"Wind Direction\";\n"
            + "      :missing_value = 32767S; // short\n"
            + "      :standard_name = \"wind_from_direction\";\n"
            + "      :units = \"degrees_true\";\n"
            + "\n"
            + "    float atmp(row=3);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 19.0f, 19.4f; // float\n"
            + "      :colorBarMaximum = 40.0; // double\n"
            + "      :colorBarMinimum = -10.0; // double\n"
            + "      :comment = \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Air Temperature\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + // intact
            "      :standard_name = \"air_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    float wtmp(row=3);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 20.1f, 20.2f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"SST\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"sea_surface_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"TimeSeries\";\n"
            + "  :cdm_timeseries_variables = \"station, longitude, latitude\";\n"
            + "  :contributor_name = \"NOAA NDBC\";\n"
            + "  :contributor_role = \"Source of data.\";\n"
            + "  :Conventions = \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "  :creator_email = \"erd.data@noaa.gov\";\n"
            + "  :creator_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :creator_type = \"institution\";\n"
            + "  :creator_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :date_created = \"dddd-dd-dd\";\n"
            + "  :date_issued = \"dddd-dd-dd\";\n"
            + "  :featureType = \"TimeSeries\";\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_positive = \"down\";\n"
            + "  :geospatial_vertical_units = \"m\";\n"
            + "  :history = \"Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\n"
            + "Every 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);
    expected =
        ":time_coverage_end = \"2012-01-01T07:50:00Z\";\n"
            + "  :time_coverage_start = \"2012-01-01T00:50:00Z\";\n"
            + "  :title = \"NDBC Standard Meteorological Buoy Data, 1970-present\";\n"
            + "\n"
            + "  data:\n"
            + "    time = \n"
            + "      {1.325379E9, 1.3253898E9, 1.3254042E9}\n"
            + "    station =   \"41004\",   \"41004\",   \"41004\"\n"
            + "    wd = \n"
            + "      {252, 32767, 288}\n"
            + // a test that missing_values are intact (although these
            // weren't
            // keyColumns, so
            // weren't temporarily converted)
            "    atmp = \n"
            + "      {19.4, -9999999.0, 19.0}\n"
            + // a test that missing_values are intact (although
            // these weren't
            // keyColumns, so weren't temporarily converted)
            "    wtmp = \n"
            + "      {20.1, -9999999.0, 20.2}\n"
            + "}\n";
    int po = results.indexOf(":time_coverage_end");
    Test.ensureEqual(results.substring(po), expected, "\nresults=\n" + results);

    // test orderByClosest with missing value data at 2012-01-01T04
    // crazy request, but see what happens when orderBy last var has missing_value
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T10&orderByClosest(\"wd/90\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obClosest6", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T08:50:00Z,41004,270,18.8,20.2\n"; // note no row for wd=NaN
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // quick reject -> csv is too short (no var specified)
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByClosest(\"2 days\")",
              dir,
              eddTable.className() + "_qr1",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For "
              + "orderByClosest, you must specify a CSV list of 1 or more orderBy "
              + "column names (each of which must be in the list of results "
              + "variables) plus the interval for the last orderBy variable "
              + "(e.g., \"stationID,time,10 minutes\"). CSV.length<2.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> csv is too short (var, but not chunk size)
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,time,wtmp&orderByClosest(\"time\")",
              dir,
              eddTable.className() + "_qr1b",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For "
              + "orderByClosest, you must specify a CSV list of 1 or more orderBy "
              + "column names (each of which must be in the list of results "
              + "variables) plus the interval for the last orderBy variable "
              + "(e.g., \"stationID,time,10 minutes\"). CSV.length<2.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> last orderBy var not numeric
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByClosest(\"station,2 days\")",
              dir,
              eddTable.className() + "_qr2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByClosest: The last orderBy column=station isn't numeric.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> orderBy var not in results vars
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,wtmp&orderByClosest(\"station,time,2 days\")",
              dir,
              eddTable.className() + "_qr3",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For orderByClosest, "
              + "you must specify a CSV list of 1 or more orderBy column names (each of which "
              + "must be in the list of results variables) plus the interval for "
              + "the last orderBy variable (e.g., \"stationID,time,10 minutes\"). "
              + "col=time is not in results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> no divisor, or divisor is var
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,time,wtmp&orderByClosest(\"station,time\")",
              dir,
              eddTable.className() + "_qr4",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.RuntimeException: ERROR in Calendar2.factorToGetSeconds: units=\"time\" is invalid.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> string/10
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,time,wtmp&orderByClosest(\"station,10\")",
              dir,
              eddTable.className() + "_qr5",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "java.lang.IllegalArgumentException: Query error: orderByClosest: The last orderBy column=station isn't numeric.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }
    String2.log("End of intentional errors.");
  }

  /**
   * This tests orderByLimit. This is also a good test of regex constraint on string variable (that
   * just has 1 value per file).
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testOrderByLimit() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testOrderByLimit()
    // *****************\n");
    // testVerboseOn();

    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    int language = 0;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // test orderByLimit()
    userDapQuery =
        "longitude,latitude,time,wtmp,station&station<%2241005%22"
            + "&time%3E=2006-01-01T00%3A00%3A00Z&time%3C2006-01-03"
            + "&orderByLimit(%22station,time/1day,3%22)";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obl1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "longitude,latitude,time,wtmp,station\n"
            + "degrees_east,degrees_north,UTC,degree_C,\n"
            + "-72.698,34.675,2006-01-01T00:00:00Z,20.3,41001\n"
            + "-72.698,34.675,2006-01-01T01:00:00Z,20.3,41001\n"
            + "-72.698,34.675,2006-01-01T02:00:00Z,20.3,41001\n"
            + "-72.698,34.675,2006-01-02T00:00:00Z,19.8,41001\n"
            + "-72.698,34.675,2006-01-02T01:00:00Z,19.8,41001\n"
            + "-72.698,34.675,2006-01-02T02:00:00Z,19.8,41001\n"
            + "-74.921,31.887,2006-01-01T00:00:00Z,21.9,41002\n"
            + "-74.921,31.887,2006-01-01T01:00:00Z,21.9,41002\n"
            + "-74.921,31.887,2006-01-01T02:00:00Z,22.0,41002\n"
            + "-74.921,31.887,2006-01-02T00:00:00Z,22.1,41002\n"
            + "-74.921,31.887,2006-01-02T01:00:00Z,22.1,41002\n"
            + "-74.921,31.887,2006-01-02T02:00:00Z,22.1,41002\n"
            + "-79.099,32.501,2006-01-01T00:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-01T01:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-01T02:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-02T00:00:00Z,18.7,41004\n"
            + "-79.099,32.501,2006-01-02T01:00:00Z,18.7,41004\n"
            + "-79.099,32.501,2006-01-02T02:00:00Z,18.7,41004\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByLimit()
    userDapQuery =
        "longitude,latitude,time,wtmp,station&station<%2241005%22"
            + "&time%3E=2006-01-01T00%3A00%3A00Z&time%3C2006-01-03"
            + "&orderByLimit(%22station,time/1day,1%22)";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obl1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "longitude,latitude,time,wtmp,station\n"
            + "degrees_east,degrees_north,UTC,degree_C,\n"
            + "-72.698,34.675,2006-01-01T00:00:00Z,20.3,41001\n"
            + "-72.698,34.675,2006-01-02T00:00:00Z,19.8,41001\n"
            + "-74.921,31.887,2006-01-01T00:00:00Z,21.9,41002\n"
            + "-74.921,31.887,2006-01-02T00:00:00Z,22.1,41002\n"
            + "-79.099,32.501,2006-01-01T00:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-02T00:00:00Z,18.7,41004\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByLimit()
    userDapQuery =
        "longitude,latitude,time,wtmp,station&station=~%224100.%22"
            + "&time%3E=2006-01-01T00%3A00%3A00Z&time%3C=2006-01-03T00%3A00%3A00Z"
            + "&orderByLimit(%22station,3%22)";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obl1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "longitude,latitude,time,wtmp,station\n"
            + "degrees_east,degrees_north,UTC,degree_C,\n"
            + "-72.698,34.675,2006-01-01T00:00:00Z,20.3,41001\n"
            + "-72.698,34.675,2006-01-01T01:00:00Z,20.3,41001\n"
            + "-72.698,34.675,2006-01-01T02:00:00Z,20.3,41001\n"
            + "-74.921,31.887,2006-01-01T00:00:00Z,21.9,41002\n"
            + "-74.921,31.887,2006-01-01T01:00:00Z,21.9,41002\n"
            + "-74.921,31.887,2006-01-01T02:00:00Z,22.0,41002\n"
            + "-79.099,32.501,2006-01-01T00:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-01T01:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-01T02:00:00Z,18.9,41004\n"
            + "-80.869,31.402,2006-01-01T00:00:00Z,13.5,41008\n"
            + "-80.869,31.402,2006-01-01T01:00:00Z,13.5,41008\n"
            + "-80.869,31.402,2006-01-01T02:00:00Z,13.5,41008\n"
            + "-80.166,28.519,2006-01-01T00:00:00Z,21.6,41009\n"
            + "-80.166,28.519,2006-01-01T00:30:00Z,21.6,41009\n"
            + "-80.166,28.519,2006-01-01T01:00:00Z,21.6,41009\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByLimit("3")
    userDapQuery =
        "longitude,latitude,time,wtmp,station&station=%2241004%22"
            + "&time%3E=2006-01-01T00%3A00%3A00Z&time%3C=2006-01-03T00%3A00%3A00Z"
            + "&orderByLimit(%223%22)"; // 3
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obl2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "longitude,latitude,time,wtmp,station\n"
            + "degrees_east,degrees_north,UTC,degree_C,\n"
            + "-79.099,32.501,2006-01-01T00:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-01T01:00:00Z,18.9,41004\n"
            + "-79.099,32.501,2006-01-01T02:00:00Z,18.9,41004\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test orderByLimit with missing value data at 2012-01-01T04
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-01&time<2012-01-01T12&orderByLimit(\"time/4hours,2\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obl5", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-01T00:50:00Z,41004,252,19.4,20.1\n"
            + "2012-01-01T01:50:00Z,41004,264,19.3,20.2\n"
            + "2012-01-01T04:50:00Z,41004,272,19.5,20.4\n"
            + "2012-01-01T05:50:00Z,41004,273,19.3,20.4\n"
            + "2012-01-01T08:50:00Z,41004,270,18.8,20.2\n"
            + "2012-01-01T09:50:00Z,41004,262,18.6,20.3\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // crazy request, but tests if orderBy keyCol has missing_value
    // the request includes 2 rows with wtmp=NaN
    userDapQuery =
        "time,station,wd,atmp,wtmp&station=\"41004\""
            + "&time>=2012-01-02&time<2012-01-03&orderByLimit(\"wtmp/10,1\")";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_obl6", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "time,station,wd,atmp,wtmp\n"
            + "UTC,,degrees_true,degree_C,degree_C\n"
            + "2012-01-02T06:50:00Z,41004,NaN,NaN,NaN\n"
            + // only 1 row with NaN gets through
            "2012-01-02T00:50:00Z,41004,229,19.9,20.8\n"; // only 1 row ->20 gets through
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // quick reject -> n=0
    // orderBy()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "longitude,latitude,wtmp&orderByLimit(\"0\")",
              dir,
              eddTable.className() + "_L1a",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For orderByLimit, "
              + "you must specify a CSV list of 0 or more orderBy column names "
              + "(each of which must be in the list of results variables; numeric columns "
              + "may have columnName[/divisor[timeUnits][:offset]]) plus the "
              + "maximum number of rows for each group (e.g., \"stationID,time/1day,10\"). limit=0 must be a positive integer.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> n=0
    // orderBy()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "longitude,latitude,wtmp&orderByLimit(\"9999999999999999999\")",
              dir,
              eddTable.className() + "_L1b",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For orderByLimit, "
              + "you must specify a CSV list of 0 or more orderBy column names "
              + "(each of which must be in the list of results variables; numeric columns "
              + "may have columnName[/divisor[timeUnits][:offset]]) plus the "
              + "maximum number of rows for each group (e.g., \"stationID,time/1day,10\"). limit=9999999999999999999 must be a positive integer.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> csv is too short
    // orderBy()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "longitude,latitude,wtmp&orderByLimit(\"\")",
              dir,
              eddTable.className() + "_L1",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For "
              + "orderByLimit, you must specify a CSV list of 0 or more orderBy column "
              + "names (each of which must be in the list of results variables; numeric columns "
              + "may have columnName[/divisor[timeUnits][:offset]]) "
              + "plus the maximum number of rows for each "
              + "group (e.g., \"stationID,time/1day,10\"). No CSV.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> orderBy var not in results vars
    // orderBy()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "longitude,latitude,wtmp&orderByLimit(\"station,3\")",
              dir,
              eddTable.className() + "_L2",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: For "
              + "orderByLimit, you must specify a CSV list of 0 or more orderBy column "
              + "names (each of which must be in the list of results variables; numeric columns "
              + "may have columnName[/divisor[timeUnits][:offset]]) "
              + "plus the maximum number of rows for each "
              + "group (e.g., \"stationID,time/1day,10\"). col=station is not in results variables.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }

    // quick reject -> invalid number
    // orderBy()
    try {
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "longitude,latitude,wtmp&orderByLimit(\"station,zztop\")",
              dir,
              eddTable.className() + "_L3",
              ".csv");
      throw new SimpleException("Shouldn't get here");
    } catch (Throwable t) {
      String2.log(MustBe.throwableToString(t));
      results = t.toString();
      expected =
          "com.cohort.util.SimpleException: Query error: "
              + "For orderByLimit, you must specify a CSV list of 0 or more orderBy column "
              + "names (each of which must be in the list of results variables; numeric columns "
              + "may have columnName[/divisor[timeUnits][:offset]]) "
              + "plus the maximum number of rows for each "
              + "group (e.g., \"stationID,time/1day,10\"). "
              + "limit=zztop must be a positive integer.";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }
  }

  /**
   * This tests station,lon,lat.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testStationLonLat() throws Throwable {
    // String2.log("\n****************** EDDTableFromNcFiles.testStationLonLat()
    // *****************\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // .csv
    // from NdbcMetStation.test31201
    // YYYY MM DD hh mm WD WSPD GST WVHT DPD APD MWD BARO ATMP WTMP DEWP VIS TIDE
    // 2005 04 19 00 00 999 99.0 99.0 1.40 9.00 99.00 999 9999.0 999.0 24.4 999.0
    // 99.0 99.00 first available
    userDapQuery = "station,longitude,latitude&distinct()";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, dir, eddTable.className() + "_sll", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "station,longitude,latitude\n"
            + ",degrees_east,degrees_north\n"
            + "0Y2W3,-87.313,44.794\n"
            + "18CI3,-86.91,41.73\n"
            + "20CM4,-86.49,42.09\n"
            + "23020,38.5,22.162\n"
            + "31201,-48.134,-27.705\n"
            + "32012,-85.384,-19.616\n"
            + "32301,-105.2,-9.9\n"
            + "32302,-85.1,-18.0\n"
            + "32487,-77.737,3.517\n"
            + "32488,-77.511,6.258\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);
  }

  /** This tests converting global metadata into data. */
  @org.junit.jupiter.api.Test
  @TagSlowTests
  void testGlobal() throws Throwable {
    // testVerboseOn();

    int language = 0;
    String name, baseName, tName, results, tResults, expected, userDapQuery, tQuery;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String error = "";
    EDV edv;
    int epo;

    // variant of calcofi Subsurface (has additional ID from global:id)
    EDDTable csub = (EDDTableFromNcFiles) EDDTestDataset.gettestGlobal();
    baseName = csub.className() + "Global";
    String csubDapQuery = "&longitude=-106.11667";

    // min max
    edv = csub.findDataVariableByDestinationName("longitude");
    Test.ensureEqual(edv.destinationMin(), -164.08333, "");
    Test.ensureEqual(edv.destinationMax(), -106.1167, "");

    tName = csub.makeNewFileForDapQuery(language, null, null, csubDapQuery, dir, baseName, ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "ID,line_station,line,station,longitude,latitude,time,depth,chlorophyll,dark,light_percent,NH3,NO2,NO3,oxygen,PO4,pressure,primprod,salinity,silicate,temperature\n"
            + ",,,,degrees_east,degrees_north,UTC,m,mg m-3,mg m-3 experiment-1,mg m-3 experiment-1,ugram-atoms L-1,ugram-atoms L-1,ugram-atoms L-1,mL L-1,ugram-atoms L-1,dbar,mg m-3 experiment-1,PSU,ugram-atoms L-1,degree_C\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,0.0,NaN,NaN,NaN,NaN,NaN,NaN,4.53,NaN,NaN,NaN,34.38,NaN,27.74\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,10.0,NaN,NaN,NaN,NaN,NaN,NaN,4.82,NaN,NaN,NaN,34.39,NaN,27.5\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,29.0,NaN,NaN,NaN,NaN,NaN,NaN,4.16,NaN,NaN,NaN,34.35,NaN,26.11\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,48.0,NaN,NaN,NaN,NaN,NaN,NaN,3.12,NaN,NaN,NaN,34.43,NaN,22.64\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,71.0,NaN,NaN,NaN,NaN,NaN,NaN,0.34,NaN,NaN,NaN,34.63,NaN,17.04\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,94.0,NaN,NaN,NaN,NaN,NaN,NaN,0.2,NaN,NaN,NaN,34.74,NaN,14.89\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,118.0,NaN,NaN,NaN,NaN,NaN,NaN,0.3,NaN,NaN,NaN,34.76,NaN,13.69\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,155.0,NaN,NaN,NaN,NaN,NaN,NaN,0.21,NaN,NaN,NaN,34.79,NaN,12.51\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,193.0,NaN,NaN,NaN,NaN,NaN,NaN,0.24,NaN,NaN,NaN,34.79,NaN,11.98\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,239.0,NaN,NaN,NaN,NaN,NaN,NaN,0.35,NaN,NaN,NaN,34.76,NaN,11.8\n"
            + "171_040,171_040,171.0,40.0,-106.11667,21.05,1956-12-05T21:00:00Z,286.0,NaN,NaN,NaN,NaN,NaN,NaN,0.19,NaN,NaN,NaN,34.76,NaN,11.42\n";
    Test.ensureEqual(results, expected, "results=\n" + results);
  } // end of testGlobal

  @org.junit.jupiter.api.Test
  @TagIncompleteTest
  void testGenerateBreakUpPostDatasetsXml() throws Throwable {
    int language = 0;
    // String tFileDir, String tFileNameRegex, String sampleFileName,
    // int tReloadEveryNMinutes,
    // String tPreExtractRegex, String tPostExtractRegex, String tExtractRegex,
    // String tColumnNameForExtract, String tSortedColumnSourceName,
    // String tSortFilesBySourceNames,
    // String tInfoUrl, String tInstitution, String tSummary, String tTitle,
    // Attributes externalAddGlobalAttributes)
    String2.log(
        EDDTableFromNcFiles.generateDatasetsXml(
            "c:/erddapBPD/copy/tcPostDet3/",
            ".*\\.nc",
            "c:/erddapBPD/copy/tcPostDet3/Barbarax20Block/LAMNAx20DITROPIS/Nx2fA.nc",
            "",
            100000000,
            "",
            "",
            "",
            "",
            "unique_tag_id",
            "PI, scientific_name, stock",
            "",
            "",
            "",
            "",
            -1,
            null, // defaultStandardizeWhat
            new Attributes()));
  }

  /** Test saveAsKml. */
  @org.junit.jupiter.api.Test
  void testKml() throws Throwable {
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String mapDapQuery = "longitude,latitude,NO3,time&latitude>0&altitude>-5&time>=2002-08-03";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    String2.log("\n*** EDDTableFromNcFiles.testKml\n");
    EDDTable globecBottle = (EDDTable) EDDTestDataset.gettestGlobecBottle(); // should work

    // kml
    tName =
        globecBottle.makeNewFileForDapQuery(
            language, null, null, mapDapQuery, dir, globecBottle.className() + "_MapKml", ".kml");
    // String2.log(File2.readFromFile(dir + tName)[1]);
    // Test.displayInBrowser("file://" + dir + tName);
  }

  /** The basic graphics tests of this class (testGlobecBottle). */
  @org.junit.jupiter.api.Test
  @TagImageComparison
  @TagSlowTests
  void testGraphics() throws Throwable {
    boolean doAll = true;

    // testVerboseOn();
    int language = 0;
    String name, tName, baseName, results, tResults, expected, userDapQuery, tQuery;
    String mapDapQuery = "longitude,latitude,NO3,time&latitude>0&altitude>-5&time>=2002-08-03";
    userDapQuery = "longitude,NO3,time,ship&latitude>0&altitude>-5&time>=2002-08-03";
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String obsDir = Image2Tests.urlToAbsolutePath(Image2Tests.OBS_DIR);

    String2.log("\n*** EDDTableFromNcFiles.testGraphics\n");
    EDDTable globecBottle = (EDDTable) EDDTestDataset.gettestGlobecBottle(); // should work

    // kml
    tName =
        globecBottle.makeNewFileForDapQuery(
            language, null, null, mapDapQuery, dir, globecBottle.className() + "_MapKml", ".kml");
    // String2.log(File2.readFromFile(dir + tName)[1]);
    // Test.displayInBrowser("file://" + dir + tName);

    if (doAll) {

      // *** test make graphs
      // there is no .transparentPng for EDDTable

      baseName = globecBottle.className() + "_GraphTiny";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery + "&.size=128|256&.font=.75",
              obsDir,
              baseName,
              ".largePng"); // to show it is irrelevant
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = globecBottle.className() + "_GraphS";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, userDapQuery, obsDir, baseName, ".smallPng");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = globecBottle.className() + "_GraphM";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, userDapQuery, obsDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = globecBottle.className() + "_GraphL";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, userDapQuery, obsDir, baseName, ".largePng");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = globecBottle.className() + "_GraphHuge";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery + "&.size=1700|1800",
              obsDir,
              baseName,
              ".smallPng"); // to show it is irrelevant
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery,
              dir,
              globecBottle.className() + "_GraphPdfSmall2",
              ".smallPdf");
      // Test.displayInBrowser("file://" + dir + tName);

      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery,
              dir,
              globecBottle.className() + "_GraphPdf2",
              ".pdf");
      // Test.displayInBrowser("file://" + dir + tName);

      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery,
              dir,
              globecBottle.className() + "_GraphPdfLarge2",
              ".largePdf");
      // Test.displayInBrowser("file://" + dir + tName);

      // *** test make MAP
      String2.log("\n*** EDDTableFromNcFiles.test make MAP\n");

      baseName = globecBottle.className() + "_MapS";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, mapDapQuery, obsDir, baseName, ".smallPng");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = globecBottle.className() + "_MapM";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, mapDapQuery, obsDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = globecBottle.className() + "_MapL";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, mapDapQuery, obsDir, baseName, ".largePng");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              mapDapQuery,
              dir,
              globecBottle.className() + "_MapS",
              ".smallPdf");
      // Test.displayInBrowser("file://" + dir + tName);

      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, mapDapQuery, dir, globecBottle.className() + "_MapM", ".pdf");
      // Test.displayInBrowser("file://" + dir + tName);

      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              mapDapQuery,
              dir,
              globecBottle.className() + "_MapL",
              ".largePdf");
      // Test.displayInBrowser("file://" + dir + tName);

      // kml
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, mapDapQuery, dir, globecBottle.className() + "_MapKml", ".kml");
      // String2.log(File2.readFromFile(dir + tName)[1]);
      // Test.displayInBrowser("file://" + dir + tName);

      baseName = globecBottle.className() + "_GraphMLegendOff";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              userDapQuery + "&.legend=Off&.trim=10",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = globecBottle.className() + "_GraphSLegendOnly";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, userDapQuery + "&.legend=Only", obsDir, baseName, ".smallPng");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = globecBottle.className() + "_GraphMLegendOnly";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, userDapQuery + "&.legend=Only", obsDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = globecBottle.className() + "_GraphLLegendOnly";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, userDapQuery + "&.legend=Only", obsDir, baseName, ".largePng");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;
    }

    // test of .graphics commands
    if (true) {
      tQuery = "NO3,NH4&altitude>-5&time>=2002-08-03&NO3>=0";
      baseName = globecBottle.className() + "_GraphWithMarkersNoColorBar";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              tQuery
                  +
                  // I specify colorBar, but it isn't used
                  "&.draw=markers&.marker=1|5&.color=0x0000FF&.colorBar=Rainbow|C|Linear",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tQuery = "NO3,NH4,sal00&altitude>-5&time>=2002-08-03&NO3>=0";
      baseName = globecBottle.className() + "_GraphWithLines";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language, null, null, tQuery + "&.draw=lines&.marker=9|7", obsDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tQuery = "NO3,NH4,sal00&altitude>-5&time>=2002-08-03&NO3>=0";
      baseName = globecBottle.className() + "_GraphWithLinesAndMarkers";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              tQuery + "&.draw=linesAndMarkers&.marker=9|7&.colorBar=Rainbow|C|Linear",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tQuery = "NO3,NH4,sal00&altitude>-5&time>=2002-08-03&NO3>=0";
      baseName = globecBottle.className() + "_GraphWithMarkers";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              tQuery
                  +
                  // color and colorBar aren't specified; default is used
                  "&.draw=markers&.marker=9|7",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tQuery = "longitude,latitude,sal00&altitude>-5&time>=2002-08-03";
      baseName = globecBottle.className() + "_MapWithLines";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              tQuery + "&.draw=lines&.color=0xFF8800",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tQuery = "longitude,latitude,sal00&altitude>-5&time>=2002-08-03";
      baseName = globecBottle.className() + "_MapWithLinesAndMarkers";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              tQuery + "&.draw=linesAndMarkers&.marker=5|5&.colorBar=Rainbow|D|Linear",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tQuery = "longitude,latitude,sal00&altitude>-5&time>=2002-08-03";
      baseName = globecBottle.className() + "_MapWithMarkers";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              tQuery + "&.draw=markers&.marker=5|5&.colorBar=Rainbow|D|Linear",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tQuery = "time,sal00,sal11&altitude>-5&time>=2002-08-03&NO3>=0";
      baseName = globecBottle.className() + "_GraphWithSticks";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              tQuery + "&.draw=sticks&.color=0xFF8800",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tQuery = "longitude,latitude,sal00,sal11&altitude>-5&time>=2002-08-03";
      baseName = globecBottle.className() + "_MapWithVectors";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              tQuery + "&.draw=vectors&.color=0xFF0088&.vec=30",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      tQuery = "longitude,latitude,sal00,sal11&altitude>-5&time>=2002-08-03&cast>200";
      baseName = globecBottle.className() + "_MapWithVectorsNoData";
      tName =
          globecBottle.makeNewFileForDapQuery(
              language,
              null,
              null,
              tQuery + "&.draw=vectors&.color=0xFF0088&.vec=30",
              obsDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;
    }
  }

  /**
   * erdGlobecBird flight_dir uses scale_factor=10 add_offset=0, so a good test of scaleAddOffset.
   */
  @org.junit.jupiter.api.Test
  void testGlobecBirds() throws Throwable {
    // testVerboseOn();

    int language = 0;
    String results, query, tName, expected;
    String baseQuery = "&time>=2000-08-07&time<2000-08-08";
    EDDTable tedd = (EDDTable) EDDTestDataset.geterdGlobecBirds();
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // the basicQuery
    // an easy query
    tName =
        tedd.makeNewFileForDapQuery(
            language, null, null, baseQuery, dir, tedd.className() + "_bird1", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "trans_no,trans_id,longitude,latitude,time,area,behav_code,flight_dir,head_c,number,number_adj,species,wspd\n"
            + ",,degrees_east,degrees_north,UTC,km2,,degrees_true,degrees_true,count,count,,knots\n"
            + "22001,8388607,-125.023,43.053,2000-08-07T00:00:00Z,1.3,1,180,240,1,0.448,SHSO,15\n"
            + "22001,8388607,-125.023,43.053,2000-08-07T00:00:00Z,1.3,2,0,240,1,1.0,FUNO,15\n"
            + "22001,8388607,-125.023,43.053,2000-08-07T00:00:00Z,1.3,3,0,240,1,1.0,SKMA,15\n"
            + "22005,8388607,-125.225,43.955,2000-08-07T00:00:00Z,1.3,2,0,240,3,3.0,AKCA,15\n"
            + "22009,8388607,-125.467,43.84,2000-08-07T00:00:00Z,1.3,1,200,240,2,0.928,PHRE,20\n"
            + "22013,8388607,-125.648,43.768,2000-08-07T00:00:00Z,1.3,1,270,240,1,1.104,STLE,20\n"
            + "22015,8388607,-125.745,43.73,2000-08-07T00:00:00Z,1.3,1,180,240,4,1.616,PHRE,20\n"
            + "22018,8388607,-125.922,43.668,2000-08-07T00:00:00Z,1.3,2,0,240,1,1.0,AKCA,20\n"
            + "22019,8388607,-125.935,43.662,2000-08-07T00:00:00Z,1.3,1,270,340,1,0.601,STLE,25\n"
            + "22020,8388607,-125.968,43.693,2000-08-07T00:00:00Z,1.6,1,40,340,1,0.67,STLE,25\n"
            + "22022,8388607,-125.978,43.727,2000-08-07T00:00:00Z,1.3,1,50,150,1,0.469,STLE,25\n"
            + "22023,8388607,-125.953,43.695,2000-08-07T00:00:00Z,1.3,2,0,150,1,1.0,PHRE,25\n"
            + "22025,8388607,-125.903,43.628,2000-08-07T00:00:00Z,1.3,1,50,150,1,0.469,STLE,25\n";
    Test.ensureEqual(results, expected, "results=\n" + results);

    // unscaled flight_dir values are 0..36 so see if >=40 is properly handled
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            baseQuery + "&flight_dir>=40",
            dir,
            tedd.className() + "_bird2",
            ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "trans_no,trans_id,longitude,latitude,time,area,behav_code,flight_dir,head_c,number,number_adj,species,wspd\n"
            + ",,degrees_east,degrees_north,UTC,km2,,degrees_true,degrees_true,count,count,,knots\n"
            + "22001,8388607,-125.023,43.053,2000-08-07T00:00:00Z,1.3,1,180,240,1,0.448,SHSO,15\n"
            + "22009,8388607,-125.467,43.84,2000-08-07T00:00:00Z,1.3,1,200,240,2,0.928,PHRE,20\n"
            + "22013,8388607,-125.648,43.768,2000-08-07T00:00:00Z,1.3,1,270,240,1,1.104,STLE,20\n"
            + "22015,8388607,-125.745,43.73,2000-08-07T00:00:00Z,1.3,1,180,240,4,1.616,PHRE,20\n"
            + "22019,8388607,-125.935,43.662,2000-08-07T00:00:00Z,1.3,1,270,340,1,0.601,STLE,25\n"
            + "22020,8388607,-125.968,43.693,2000-08-07T00:00:00Z,1.6,1,40,340,1,0.67,STLE,25\n"
            + "22022,8388607,-125.978,43.727,2000-08-07T00:00:00Z,1.3,1,50,150,1,0.469,STLE,25\n"
            + "22025,8388607,-125.903,43.628,2000-08-07T00:00:00Z,1.3,1,50,150,1,0.469,STLE,25\n";
    Test.ensureEqual(results, expected, "results=\n" + results);

    try {
      // try getting no data -- exception should be MustBe.THERE_IS_NO_DATA
      tName =
          tedd.makeNewFileForDapQuery(
              language,
              null,
              null,
              baseQuery + "&flight_dir>=4000",
              dir,
              tedd.className() + "_bird2",
              ".csv");
      throw new Exception("Shouldn't have gotten here.");
    } catch (Throwable t) {
      // test that this is the expected exception
      if (t.toString().indexOf(MustBe.THERE_IS_NO_DATA) < 0)
        throw new RuntimeException(
            "Exception should have been MustBe.THERE_IS_NO_DATA=\""
                + MustBe.THERE_IS_NO_DATA
                + "\":\n"
                + MustBe.throwableToString(t));
    }
  }

  /** NEEDS WORK. This tests reading a .pngInfo file. */
  @org.junit.jupiter.api.Test
  void testReadPngInfo() throws Throwable {
    /*
     * needs work
     * String2.log("\n* EDD.testReadPngInfo");
     * Object oa[] = readPngInfo(null,
     * EDStatic.unitTestDataDir + "graphs/testGlobecBottle_2603962601.json");
     * double graphDoubleWESN[] = (double[])oa[0];
     * Test.ensureEqual(graphDoubleWESN,
     * new double[]{-126.30999908447265, -123.45999755859376, 41.9,
     * 44.75000152587891}, "");
     *
     * int graphIntWESN[] = (int[])oa[1];
     * Test.ensureEqual(graphIntWESN,
     * new int[]{29, 331, 323, 20}, "");
     */
  }

  /** This tests lat lon requests. */
  @org.junit.jupiter.api.Test
  void testLatLon() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testLatLon\n");

    // testVerboseOn();
    int language = 0;
    String results, query, tName, expected;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // the basicQuery
    EDDTable edd = (EDDTable) EDDTestDataset.geterdGlobecMoc1();

    // *** test a TableWriter that doesn't convert time to iso format
    query = "cruise_id,station_id,longitude,latitude&latitude=44.6517&distinct()";

    tName =
        edd.makeNewFileForDapQuery(
            language, null, null, query, dir, edd.className() + "_LL", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "cruise_id,station_id,longitude,latitude\n"
            + ",,degrees_east,degrees_north\n"
            + "NH0005,NH15,-124.4117,44.6517\n"
            + "NH0005,NH25,-124.65,44.6517\n"
            + "NH0007,NH05,-124.175,44.6517\n"
            + "NH0007,NH15,-124.4117,44.6517\n"
            + "NH0007,NH25,-124.65,44.6517\n"
            + "W0004B,NH05,-124.175,44.6517\n"
            + "W0004B,NH15,-124.4117,44.6517\n"
            + "W0004B,NH25,-124.65,44.6517\n"
            + "W0004B,NH45,-125.1167,44.6517\n"
            + "W0007A,NH15,-124.4117,44.6517\n"
            + "W0007A,NH25,-124.65,44.6517\n"
            + "W0009A,NH15,-124.4117,44.6517\n"
            + "W0009A,NH25,-124.65,44.6517\n"
            + "W0204A,NH25,-124.65,44.6517\n"
            + "W0205A,NH15,-124.4117,44.6517\n"
            + "W0205A,NH25,-124.65,44.6517\n";
    Test.ensureEqual(results, expected, "results=\n" + results);
  }

  /**
   * This tests an altitude axis variable. This requires testTableWithAltitude dataset in localhost
   * ERDDAP.
   */
  @org.junit.jupiter.api.Test
  void testTableWithAltitude() throws Throwable {
    String2.log("\n*** EDDTableFromNcFiles.testTableWithAltitude");
    int language = 0;
    String results, expected, tName;
    int po;

    // !!! I no longer have a test dataset with real altitude data!

    /*
     * String url =
     * "http://www.marine.csiro.au/dods/nph-dods/dods-data/bl/BRAN2.1/bodas/19921014.bodas_ts.nc";
     * results = generateDatasetsXml(true, url,
     * null, null, null, DEFAULT_RELOAD_EVERY_N_MINUTES, null);
     * po = results.indexOf("<sourceName>z</sourceName>");
     * Test.ensureTrue(po > 0, "results=\n" + results);
     * expected =
     * "<sourceName>z</sourceName>\n" +
     * "        <destinationName>depth</destinationName>\n" +
     * "        <!-- sourceAttributes>\n" +
     * "            <att name=\"cartesian_axis\">Z</att>\n" +
     * "            <att name=\"long_name\">Depth</att>\n" +
     * "            <att name=\"positive\">down</att>\n" +
     * "            <att name=\"units\">m</att>\n" +
     * "        </sourceAttributes -->\n" +
     * "        <addAttributes>\n" +
     * "            <att name=\"ioos_category\">Location</att>\n" +
     * "            <att name=\"standard_name\">depth</att>\n" +
     * "        </addAttributes>\n" +
     * "    </axisVariable>";
     * Test.ensureEqual(results.substring(po, po + expected.length()), expected,
     * "results=\n" + results);
     *
     * //Test that constructor of EDVAlt added proper metadata for altitude
     * variable.
     * EDDTableFromNcFiles tableDataset =
     * (EDDTableFromNcFiles)oneFromDatasetsXml(null, "erdCalcofiBio");
     * tName = tableDataset.makeNewFileForDapQuery(language, null, null, "",
     * dir, tableDataset.className() + "testTableWithAltitude", ".das");
     * results = File2.directReadFrom88591File(dir + tName);
     * po = results.indexOf("depth {");
     * Test.ensureTrue(po > 0, "results=\n" + results);
     * expected =
     * "depth {\n" +
     * "    String _CoordinateAxisType \"Height\";\n" +
     * "    String _CoordinateZisPositive \"down\";\n" +
     * "    Float32 actual_range 6.3, 267.9;\n" +
     * "    String axis \"Z\";\n" +
     * "    String ioos_category \"Location\";\n" +
     * "    String long_name \"Depth at Start of Tow\";\n" +
     * "    String positive \"down\";\n" +
     * "    String standard_name \"depth\";\n" +
     * "    String units \"m\";\n" +
     * "  }";
     * Test.ensureEqual(results.substring(po, po + expected.length()), expected,
     * "results=\n" + results);
     *
     * //FGDC should deal with altitude correctly --
     * //But it isn't like grids. Nothing interesting since not a true axis.
     *
     * //ISO 19115 should deal with altitude correctly
     * tName = tableDataset.makeNewFileForDapQuery(language, null, null, "",
     * dir, tableDataset.className() + "testTableWithAltitude", ".iso19115");
     * results = File2.directReadFromUtf8File(dir + tName);
     *
     * po = results.indexOf(
     * "codeListValue=\"vertical\">");
     * Test.ensureTrue(po > 0, "results=\n" + results);
     * expected =
     * "codeListValue=\"vertical\">vertical</gmd:MD_DimensionNameTypeCode>\n" +
     * "          </gmd:dimensionName>\n" +
     * "          <gmd:dimensionSize gco:nilReason=\"unknown\"/>\n" +
     * "        </gmd:MD_Dimension>\n" +
     * "      </gmd:axisDimensionProperties>\n";
     * Test.ensureEqual(results.substring(po, po + expected.length()), expected,
     * "results=\n" + results);
     *
     * po = results.indexOf(
     * "<gmd:verticalElement>");
     * Test.ensureTrue(po > 0, "results=\n" + results);
     * expected =
     * "<gmd:verticalElement>\n" +
     * "            <gmd:EX_VerticalExtent>\n" +
     * "              <gmd:minimumValue><gco:Real>-267.9</gco:Real></gmd:minimumValue>\n"
     * +
     * "              <gmd:maximumValue><gco:Real>-6.3</gco:Real></gmd:maximumValue>\n"
     * +
     * "              <gmd:verticalCRS gco:nilReason=\"missing\"/>\n" +
     * "            </gmd:EX_VerticalExtent>\n" +
     * "          </gmd:verticalElement>";
     * Test.ensureEqual(results.substring(po, po + expected.length()), expected,
     * "results=\n" + results);
     *
     */

  }

  /** This tests a depth variable. This requires testTableWithDepth dataset in localhost ERDDAP. */
  @org.junit.jupiter.api.Test
  void testTableWithDepth() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testTableWithDepth");

    int language = 0;
    String results, expected, tName;
    int po;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // Test that constructor of EDVDepth added proper metadata for depth variable.
    EDDTableFromNcFiles tableDataset = (EDDTableFromNcFiles) EDDTestDataset.gettestTableWithDepth();
    tName =
        tableDataset.makeNewFileForDapQuery(
            language, null, null, "", dir, tableDataset.className() + "testTableWithDepth", ".das");
    results = File2.directReadFrom88591File(dir + tName);
    results =
        results.replaceAll(
            "Float32 actual_range -?[0-9]+.[0-9]+, -?[0-9]+.[0-9]+;",
            "Float32 actual_range MIN, MAX;");
    po = results.indexOf("depth {");
    Test.ensureTrue(po > 0, "results=\n" + results);
    expected =
        "depth {\n"
            + "    String _CoordinateAxisType \"Height\";\n"
            + "    String _CoordinateZisPositive \"down\";\n"
            + "    Float32 actual_range MIN, MAX;\n"
            + "    String axis \"Z\";\n"
            + "    Int32 epic_code 3;\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Depth\";\n"
            + "    String positive \"down\";\n"
            + "    String standard_name \"depth\";\n"
            + "    String type \"EVEN\";\n"
            + "    String units \"m\";\n"
            + "  }";
    Test.ensureEqual(
        results.substring(po, po + expected.length()), expected, "results=\n" + results);

    // FGDC should deal with altitude correctly --
    // But it isn't like grids. Nothing interesting since not a true axis.

    // ISO 19115 should deal with depth correctly
    String2.log("!!timeIndex=" + tableDataset.timeIndex);
    EDVTime timeEdv = (EDVTime) tableDataset.dataVariables[tableDataset.timeIndex];
    String2.log(
        "!!time destinationMin="
            + timeEdv.destinationMinDouble()
            + "="
            + timeEdv.destinationMinString()
            + " destinationMax="
            + timeEdv.destinationMaxDouble()
            + "="
            + timeEdv.destinationMaxString());
    tName =
        tableDataset.makeNewFileForDapQuery(
            language,
            null,
            null,
            "",
            dir,
            tableDataset.className() + "testTableWithDepth",
            ".iso19115");
    results = File2.directReadFromUtf8File(dir + tName);

    expected =
        "<gmd:EX_Extent>\n"
            + "          <gmd:geographicElement>\n"
            + "            <gmd:EX_GeographicBoundingBox>\n"
            + "              <gmd:extentTypeCode>\n"
            + "                <gco:Boolean>1</gco:Boolean>\n"
            + "              </gmd:extentTypeCode>\n"
            + "              <gmd:westBoundLongitude>\n"
            + "                <gco:Decimal>-180.0</gco:Decimal>\n"
            + "              </gmd:westBoundLongitude>\n"
            + "              <gmd:eastBoundLongitude>\n"
            + "                <gco:Decimal>180.0</gco:Decimal>\n"
            + "              </gmd:eastBoundLongitude>\n"
            + "              <gmd:southBoundLatitude>\n"
            + "                <gco:Decimal>-25.0</gco:Decimal>\n"
            + "              </gmd:southBoundLatitude>\n"
            + "              <gmd:northBoundLatitude>\n"
            + "                <gco:Decimal>21.0</gco:Decimal>\n"
            + "              </gmd:northBoundLatitude>\n"
            + "            </gmd:EX_GeographicBoundingBox>\n"
            + "          </gmd:geographicElement>\n"
            + "          <gmd:temporalElement>\n"
            + "            <gmd:EX_TemporalExtent>\n"
            + "              <gmd:extent>\n"
            + "                <gml:TimePeriod gml:id=\"ED_gmdExtent_timePeriod_id\">\n"
            + "                  <gml:description>seconds</gml:description>\n"
            + "                  <gml:beginPosition>YYYY-MM-DDT12:00:00Z</gml:beginPosition>\n"
            + "                  <gml:endPosition( indeterminatePosition=\"now\" />|>20.{8}T12:00:00Z</gml:endPosition>)\n"
            + // important test
            "                </gml:TimePeriod>\n"
            + "              </gmd:extent>\n"
            + "            </gmd:EX_TemporalExtent>\n"
            + "          </gmd:temporalElement>\n"
            + "          <gmd:verticalElement>\n"
            + "            <gmd:EX_VerticalExtent>\n"
            + "              <gmd:minimumValue><gco:Real>3.0</gco:Real></gmd:minimumValue>\n"
            + "              <gmd:maximumValue><gco:Real>MAX</gco:Real></gmd:maximumValue>\n"
            + "              <gmd:verticalCRS gco:nilReason=\"missing\"/>\n"
            + "            </gmd:EX_VerticalExtent>\n"
            + "          </gmd:verticalElement>\n"
            + "        </gmd:EX_Extent>";
    results =
        results.replaceAll(
            "<gml:beginPosition>....-..-..T12:00:00Z", "<gml:beginPosition>YYYY-MM-DDT12:00:00Z");
    results =
        results.replaceAll(
            "<gmd:maximumValue><gco:Real>[0-9]+.[0-9]+</gco:Real></gmd:maximumValue>",
            "<gmd:maximumValue><gco:Real>MAX</gco:Real></gmd:maximumValue>");
    po = results.indexOf("<gmd:EX_Extent>");
    int po2 = results.indexOf("</gmd:EX_Extent>", po + 10);
    if (po < 0 || po2 < 0) String2.log("po=" + po + " po2=" + po2 + " results=\n" + results);
    Test.ensureLinesMatch(results.substring(po, po2 + 16), expected, "results=\n" + results);

    po = results.indexOf("<gml:TimePeriod gml:id=\"DI_gmdExtent_timePeriod_id\">");
    Test.ensureTrue(po >= 0, results);
    po = results.indexOf("<gml:TimePeriod gml:id=\"ED_gmdExtent_timePeriod_id\">");
    Test.ensureTrue(po >= 0, results);
    po = results.indexOf("<gml:TimePeriod gml:id=\"OD_gmdExtent_timePeriod_id\">");
    Test.ensureTrue(po >= 0, results);
    po = results.indexOf("<gml:TimePeriod gml:id=\"SUB_gmdExtent_timePeriod_id\">");
    Test.ensureTrue(po >= 0, results);
    po = results.indexOf(">OPeNDAP:OPeNDAP<");
    Test.ensureTrue(po >= 0, results);
    po = results.indexOf(">ERDDAP:tabledap<");
    Test.ensureTrue(po >= 0, results);
  }

  @org.junit.jupiter.api.Test
  @TagImageComparison
  @TagSlowTests // If the dataset needs to be downloaded, this is slow.
  void testLegend() throws Throwable {

    int language = 0;
    String time1 = "now-11months";
    double time2 = Calendar2.nowStringToEpochSeconds(time1);
    String time3 = Calendar2.epochSecondsToIsoStringTZ(time2);
    String queries[];
    String dir = Image2Tests.urlToAbsolutePath(Image2Tests.OBS_DIR);
    String tName, baseName, start;
    EDDTable eddTable;

    // lon shouldn't appear
    eddTable = (EDDTable) EDDTestDataset.getfsuNoaaShipWTEPnrt();
    start =
        "longitude,latitude,airPressure&airPressure>900&airPressure!=NaN"
            + "&airPressure=~\"(.*)\"&.marker=1|5&longitude%3E=-180&time%3E=";
    queries = new String[] {time1, "" + time2, time3};
    for (int i = 0; i < queries.length; i++) {
      baseName = "EDDTableFromNcFiles_testLegendA" + i;
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, start + queries[i], dir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
    }

    // time_precision
    eddTable = (EDDTable) EDDTestDataset.getearthCubeKgsBoreTempWV();
    start =
        "longitude,latitude,MeasuredTemperature&longitude%3E=-180&time!=NaN"
            + "&State=\"West Virginia\"&time%3E=";
    queries = new String[] {"2010-03-01T00:00:00", "2010-03", "1267401600"};
    for (int i = 0; i < queries.length; i++) {
      baseName = "EDDTableFromNcFiles_testLegendB" + i;
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, start + queries[i], dir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
    }
  }

  /**
   * This tests saving a big request in a .nc file. (Re Keven O'Brien's email 2013-11-08)
   *
   * @param lastTest Use -1 for max available
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  @TagImageComparison
  void testBigRequest() throws Throwable {
    int firstTest = 0;
    int lastTest = -1;

    // String2.log("\n*** EDDTableFromNcFiles.testBigRequest(" + firstTest + "," +
    // lastTest + ")\n");
    int language = 0;
    // Table.verbose = false;
    // testVerboseOff();
    // boolean oReallyVerbose = reallyVerbose;
    // reallyVerbose = false;

    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String error = "";
    int po;
    long resultLength = -1, expectedLength;

    String id = "cwwcNDBCMet";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();
    String dir = Image2Tests.urlToAbsolutePath(Image2Tests.OBS_DIR);
    String baseName = eddTable.className() + "_BigRequest_";

    String extensions[] =
        new String[] { // .help not available at this level
          // geoJson and .odvTxt require lon, lat (and time) data
          ".asc",
          ".csv",
          ".csvp",
          ".dods",
          ".esriCsv",
          ".geoJson",
          ".htmlTable",
          ".json",
          ".jsonlCSV",
          ".mat",
          ".nc",
          ".nccsv",
          ".ncHeader",
          ".odvTxt",
          ".tsv",
          ".tsvp",
          ".xhtml",
          ".kml",
          ".smallPdf",
          ".pdf",
          ".largePdf",
          ".smallPng", // image file types
          ".png",
          ".largePng"
        };
    int kmli =
        String2.indexOf(extensions, ".kml"); // first image fileType. kmli+1 is first displayable
    // image type
    if (lastTest < 0) lastTest = extensions.length - 1;
    long bytes[] =
        new long[] {
          // 2020-10-02 I revamped this test to make requests smaller and faster
          // because previous request now yielded MUCH LARGER files and MUCH SLOWER than
          // expected
          // (because cwwcNdbcMet is more dense? I don't know)
          82764106,
          161599986,
          161599988,
          92342908,
          171218936,
          1326772815,
          19527920,
          246247712,
          192380925,
          61562192,
          61568964,
          161607148,
          6982,
          378284819,
          161599986,
          161599988,
          315505304,
          162573,
          668848,
          3985435,
          10040671,
          42474,
          108684,
          429717
        };
    // 2015-02-25 Timings vary greatly on different days.
    // I think McAfee AV slows it down a lot. Its settings are not under my control.
    int expectedMs[] =
        new int[] {
          6335, 16300, 15364, 6257, 20926, 45968, 1226, 17262, 17407, 5589, 8233, 15616, 7078,
          34200, 16359, 15677, 18807, 18773, 29706, 18031, 22215, 15509, 13347, 15592
        };

    // warm up
    String2.log("\ndoing warmup (make .nc)");
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "time&station=~\"4....\"&time<2000-01-01", dir, baseName, ".nc");
    File2.delete(dir + tName);

    StringBuilder errors = new StringBuilder();
    for (int test = firstTest; test <= lastTest; test++) {
      if (extensions[test].equals(".ncHeader")) File2.delete(dir + baseName + ".nc");

      long time = 0;
      int nChances = 1; // was 3 when testing time
      String msg = "";
      for (int chance = 0; chance < nChances; chance++) {
        String2.log("\nstart test=" + test + " chance=" + chance);
        Math2.gcAndWait("EDDGridFromNcFiles (between tests)"); // in a test
        time = System.currentTimeMillis();
        tName =
            eddTable.makeNewFileForDapQuery(
                language,
                null,
                null,
                extensions[test].equals(".geoJson") || extensions[test].equals(".odvTxt")
                    ? "longitude,latitude,time,atmp&station=~\"4....\"&time<2000-01-01"
                    : test >= kmli
                        ? "longitude,latitude,wd,time&station=~\"4....\"&time<2000-01-01&.draw=markers"
                        : "time&station=~\"4....\"&time<=2000-01-01",
                dir,
                baseName + extensions[test].substring(1) + chance,
                extensions[test]);
        resultLength = File2.length(dir + tName);
        time = System.currentTimeMillis() - time;

        msg =
            "ext#"
                + test
                + "="
                + extensions[test]
                + " chance#"
                + chance
                + ": length="
                + resultLength
                + " expected="
                + bytes[test]
                + ", "
                + "time="
                + time
                + "ms expected="
                + expectedMs[test]
                + "ms\n";
        String2.log(msg);

        // if not too slow or too fast, break
        if (time > expectedMs[test] / 2 && time < expectedMs[test] * 2) break;
      }

      if (test >= kmli) {
        if (extensions[test].toLowerCase().endsWith("png")) {
          // Test.displayInBrowser("file://" + dir + tName);
          Image2Tests.testImagesIdentical(
              dir + tName,
              baseName + extensions[test].substring(1) + ".png",
              baseName + extensions[test].substring(1) + "_diff.png");
        } else { // kml pdf
          // Test.displayInBrowser("file://" + dir + tName);
          // Google Earth and Acrobat take long time to start up and penalize subsequent
          // tests,
          // so give them time
          Math2.gc("EDDTableFromNcFiles (between tests)", test == kmli ? 60000 : 20000);
        }
      }
      if (resultLength < 0.9 * bytes[test]
          || resultLength > 1.2 * bytes[test]
          || time > expectedMs[test] * 2) {
        msg = "Unexpected length or time: " + msg;
        String2.log(msg);
        errors.append(msg);
      }
    }

    // testVerboseOn();
    // reallyVerbose = oReallyVerbose;
    if (errors.length() > 0)
      throw new RuntimeException(
          "EDDTableFromNcFiles.testBigRequest:\n"
              + errors.toString()
              + "2020-11-25 .geoJson, .pdf, .largePdf (and others) are sometimes very slow (especially during TestAll).\n"
              + "2022-07-01 Java 17 everything super slow in TestAll, but generally okay if run separately. I added some sleep().");
  }

  /** Test pmelTaoAirT against website. */
  @org.junit.jupiter.api.Test
  void testPmelTaoAirt() throws Throwable {

    // String2.log("\n*** EDDTableFromNcFiles.testPmelTaoAirt");

    int language = 0;
    EDDTable tedd =
        (EDDTable) EDDTestDataset.getpmelTaoDyAirt(); // was "pmelTaoDyAirt", but definition
    // matches
    String tName, error, results, tResults, expected;
    int po;
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // *** .das
    tName = tedd.makeNewFileForDapQuery(language, null, null, "", dir, "testAirt", ".das");
    results = File2.directReadFrom88591File(dir + tName);
    results =
        results.replaceAll(
            "Float64 actual_range 2\\.476656e\\+8, .{8,16};",
            "Float64 actual_range 2.476656e+8, [endTime];");
    results =
        results.replaceAll(
            "String time_coverage_end \"2...-..-..T12:00:00Z\";",
            "String time_coverage_end \"[endIsoTime]\";");
    results = results.replaceAll("....-..-.. Bob Simons", "dddd-dd-dd Bob Simons");
    // String2.log(results);
    boolean hasMultipleFillValues = false;
    int fillValueIndex = results.indexOf("Float32 _FillValue 1.0e+35");
    if (fillValueIndex != -1) {
      hasMultipleFillValues =
          results.indexOf("Float32 _FillValue 1.0e+35", fillValueIndex + 1) > -1;
    }
    expected = // 2013-01-04 several changes related to new array and wmo_platform_code
        "Attributes {\n"
            + " s {\n"
            + "  array {\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Array\";\n"
            + "  }\n"
            + "  station {\n"
            + "    String cf_role \"timeseries_id\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Station\";\n"
            + "  }\n"
            + "  wmo_platform_code {\n"
            + "    Int32 actual_range 13001, 56055;\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"WMO Platform Code\";\n"
            + "    Int32 missing_value 2147483647;\n"
            + "  }\n"
            + "  longitude {\n"
            + "    String _CoordinateAxisType \"Lon\";\n"
            + "    Float32 actual_range 0.0, 357.0;\n"
            + "    String axis \"X\";\n"
            + "    Int32 epic_code 502;\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Nominal Longitude\";\n"
            + "    Float32 missing_value 1.0e+35;\n"
            + "    String standard_name \"longitude\";\n"
            + "    String type \"EVEN\";\n"
            + "    String units \"degrees_east\";\n"
            + "  }\n"
            + "  latitude {\n"
            + "    String _CoordinateAxisType \"Lat\";\n"
            + "    Float32 actual_range -25.0, 21.0;\n"
            + // before 2012-09-06 was
            // -19, before 2012-03-20
            // was
            // 38
            "    String axis \"Y\";\n"
            + "    Int32 epic_code 500;\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Nominal Latitude\";\n"
            + "    Float32 missing_value 1.0e+35;\n"
            + "    String standard_name \"latitude\";\n"
            + "    String type \"EVEN\";\n"
            + "    String units \"degrees_north\";\n"
            + "  }\n"
            + "  time {\n"
            + "    String _CoordinateAxisType \"Time\";\n"
            + "    Float64 actual_range 2.476656e+8, [endTime];\n"
            + // 2nd number
            // changes daily
            "    String axis \"T\";\n"
            + "    String ioos_category \"Time\";\n"
            + "    String long_name \"Centered Time\";\n"
            + (results.indexOf("String point_spacing \"even\"") > -1
                ? "    String point_spacing \"even\";\n"
                : "")
            + "    String standard_name \"time\";\n"
            + "    String time_origin \"01-JAN-1970 00:00:00\";\n"
            + "    String type \"EVEN\";\n"
            + "    String units \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "  }\n"
            + "  depth {\n"
            + "    String _CoordinateAxisType \"Height\";\n"
            + "    String _CoordinateZisPositive \"down\";\n"
            + "    Float32 actual_range -8.0, -3.0;\n"
            + "    String axis \"Z\";\n"
            + "    Int32 epic_code 3;\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Depth\";\n"
            + "    Float32 missing_value 1.0e+35;\n"
            + "    String positive \"down\";\n"
            + "    String standard_name \"depth\";\n"
            + "    String type \"EVEN\";\n"
            + "    String units \"m\";\n"
            + "  }\n"
            + "  AT_21 {\n"
            + (hasMultipleFillValues ? "    Float32 _FillValue 1.0e+35;\n" : "")
            + "    Float32 actual_range 16.55, 34.14;\n"
            + // first value changes;
            // 2012-03-20 was 2.59,
            // 41.84;\n" + and bigger
            // sometimes 2016-09-16 was
            // 4.28, etc.
            "    Float64 colorBarMaximum 40.0;\n"
            + "    Float64 colorBarMinimum -10.0;\n"
            + "    Int32 epic_code 21;\n"
            + "    String generic_name \"atemp\";\n"
            + "    String ioos_category \"Temperature\";\n"
            + "    String long_name \"Air Temperature\";\n"
            + "    Float32 missing_value 1.0e+35;\n"
            + "    String name \"AT\";\n"
            + "    String standard_name \"air_temperature\";\n"
            + "    String units \"degree_C\";\n"
            + "  }\n"
            + "  QAT_5021 {\n"
            + (hasMultipleFillValues ? "    Float32 _FillValue 1.0e+35;\n" : "")
            + "    Float32 actual_range 0.0, 5.0;\n"
            + "    String colorBarContinuous \"false\";\n"
            + "    Float64 colorBarMaximum 6.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String description \"Quality: 0=missing data, 1=highest, 2=standard, 3=lower, 4=questionable, 5=bad, -9=contact Dai.C.McClurg@noaa.gov.  To get probably valid data only, request QAT_5021>=1 and QAT_5021<=3.\";\n"
            + "    Int32 epic_code 5021;\n"
            + "    String generic_name \"qat\";\n"
            + "    String ioos_category \"Quality\";\n"
            + "    String long_name \"Air Temperature Quality\";\n"
            + "    Float32 missing_value 1.0e+35;\n"
            + "    String name \"QAT\";\n"
            + "  }\n"
            + "  SAT_6021 {\n"
            + (hasMultipleFillValues ? "    Float32 _FillValue 1.0e+35;\n" : "")
            + "    Float32 actual_range 0.0, 6.0;\n"
            + "    String colorBarContinuous \"false\";\n"
            + "    Float64 colorBarMaximum 8.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String description \"Source Codes:\n"
            + "0 = No Sensor, No Data\n"
            + "1 = Real Time (Telemetered Mode)\n"
            + "2 = Derived from Real Time\n"
            + "3 = Temporally Interpolated from Real Time\n"
            + "4 = Source Code Inactive at Present\n"
            + "5 = Recovered from Instrument RAM (Delayed Mode)\n"
            + "6 = Derived from RAM\n"
            + "7 = Temporally Interpolated from RAM\";\n"
            + "    Int32 epic_code 6021;\n"
            + "    String generic_name \"sat\";\n"
            + "    String ioos_category \"Other\";\n"
            + "    String long_name \"Air Temperature Source\";\n"
            + "    Float32 missing_value 1.0e+35;\n"
            + "    String name \"SAT\";\n"
            + "  }\n"
            + " }\n"
            + "  NC_GLOBAL {\n"
            + (results.indexOf("Float32 _FillValue 1.0e+35") > -1
                ? "    Float32 _FillValue 1.0e+35;\n"
                : "")
            + "    String cdm_data_type \"TimeSeries\";\n"
            + "    String cdm_timeseries_variables \"array, station, wmo_platform_code, longitude, latitude, depth\";\n"
            + "    String Conventions \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "    String CREATION_DATE \"HH:MM  D-MMM-YYYY\";\n"
            + "    String creator_email \"Dai.C.McClurg@noaa.gov\";\n"
            + "    String creator_name \"GTMBA Project Office/NOAA/PMEL\";\n"
            + "    String creator_type \"group\";\n"
            + "    String creator_url \"https://www.pmel.noaa.gov/gtmba/mission\";\n"
            + "    String Data_Source \"Global Tropical Moored Buoy Array Project Office/NOAA/PMEL\";\n"
            + "    String defaultGraphQuery \"longitude,latitude,AT_21&time>=now-7days\";\n"
            + "    Float64 Easternmost_Easting 357.0;\n"
            + "    String featureType \"TimeSeries\";\n"
            + "    String File_info \"Contact: Dai.C.McClurg@noaa.gov\";\n"
            + "    Float64 geospatial_lat_max 21.0;\n"
            + "    Float64 geospatial_lat_min -25.0;\n"
            + "    String geospatial_lat_units \"degrees_north\";\n"
            + "    Float64 geospatial_lon_max 357.0;\n"
            + "    Float64 geospatial_lon_min 0.0;\n"
            + "    String geospatial_lon_units \"degrees_east\";\n"
            + "    Float64 geospatial_vertical_max -3.0;\n"
            + "    Float64 geospatial_vertical_min -8.0;\n"
            + "    String geospatial_vertical_positive \"down\";\n"
            + "    String geospatial_vertical_units \"m\";\n"
            + "    String history \"This dataset has data from the TAO/TRITON, RAMA, and PIRATA projects.\n"
            + "This dataset is a product of the TAO Project Office at NOAA/PMEL.\n"
            + "dddd-dd-dd Bob Simons at NOAA/NMFS/SWFSC/ERD (bob.simons@noaa.gov) fully refreshed ERD's copy of this dataset by downloading all of the .cdf files from the PMEL TAO FTP site.  Since then, the dataset has been partially refreshed everyday by downloading and merging the latest version of the last 25 days worth of data.";
    results =
        results.replaceAll(
            "String CREATION_DATE \\\"..:..  .-...-....\\\"",
            "String CREATION_DATE \"HH:MM  D-MMM-YYYY\"");
    int tPo = results.indexOf("worth of data.");
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(results.substring(0, tPo + 14), expected, "\nresults=\n" + results);

    // + " (local files)\n" +
    // today + " http://127.0.0.1:8080/cwexperimental/
    expected =
        "tabledap/pmelTaoDyAirt.das\";\n"
            + "    String infoUrl \"https://www.pmel.noaa.gov/gtmba/mission\";\n"
            + "    String institution \"NOAA PMEL, TAO/TRITON, RAMA, PIRATA\";\n"
            + "    String keywords \"air, air_temperature, atmosphere, atmospheric, buoys, centered, daily, depth, Earth Science > Atmosphere > Atmospheric Temperature > Air Temperature, Earth Science > Atmosphere > Atmospheric Temperature > Surface Air Temperature, identifier, noaa, pirata, pmel, quality, rama, source, station, surface, tao, temperature, time, triton\";\n"
            + "    String keywords_vocabulary \"GCMD Science Keywords\";\n"
            + "    String license \"Request for Acknowledgement: If you use these data in publications or presentations, please acknowledge the GTMBA Project Office of NOAA/PMEL. Also, we would appreciate receiving a preprint and/or reprint of publications utilizing the data for inclusion in our bibliography. Relevant publications should be sent to: GTMBA Project Office, NOAA/Pacific Marine Environmental Laboratory, 7600 Sand Point Way NE, Seattle, WA 98115\n"
            + "\n"
            + "The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "    Float32 missing_value 1.0e+35;\n"
            + "    Float64 Northernmost_Northing 21.0;\n"
            + "    String platform_code \"CODE\";\n"
            + "    String project \"TAO/TRITON, RAMA, PIRATA\";\n"
            + "    String Request_for_acknowledgement \"If you use these data in publications "
            + "or presentations, please acknowledge the GTMBA Project Office of NOAA/PMEL. "
            + "Also, we would appreciate receiving a preprint and/or reprint of "
            + "publications utilizing the data for inclusion in our bibliography. "
            + "Relevant publications should be sent to: GTMBA Project Office, "
            + "NOAA/Pacific Marine Environmental Laboratory, 7600 Sand Point Way NE, "
            + "Seattle, WA 98115\";\n"
            + "    String sourceUrl \"(local files)\";\n"
            + "    Float64 Southernmost_Northing -25.0;\n"
            + "    String standard_name_vocabulary \"CF Standard Name Table v70\";\n"
            + "    String subsetVariables \"array, station, wmo_platform_code, longitude, latitude, depth\";\n"
            + "    String summary \"This dataset has daily Air Temperature data from the\n"
            + "TAO/TRITON (Pacific Ocean, https://www.pmel.noaa.gov/gtmba/ ),\n"
            + "RAMA (Indian Ocean, https://www.pmel.noaa.gov/gtmba/pmel-theme/indian-ocean-rama ), and\n"
            + "PIRATA (Atlantic Ocean, https://www.pmel.noaa.gov/gtmba/pirata/ )\n"
            + "arrays of moored buoys which transmit oceanographic and meteorological data "
            + "to shore in real-time via the Argos satellite system.  These buoys are "
            + "major components of the CLIVAR climate analysis project and the GOOS, "
            + "GCOS, and GEOSS observing systems.  Daily averages are computed starting "
            + "at 00:00Z and are assigned an observation 'time' of 12:00Z.  For more "
            + "information, see\n"
            + "https://www.pmel.noaa.gov/gtmba/mission .\";\n"
            + "    String testOutOfDate \"now-3days\";\n"
            + "    String time_coverage_end \"[endIsoTime]\";\n"
            + // changes daily
            "    String time_coverage_start \"1977-11-06T12:00:00Z\";\n"
            + // before 2012-03-20 was
            // 1980-03-07T12:00:00
            "    String title \"TAO/TRITON, RAMA, and PIRATA Buoys, Daily, 1977-present, Air Temperature\";\n"
            + "    Float64 Westernmost_Easting 0.0;\n"
            + "  }\n"
            + "}\n";
    results =
        results.replaceAll(
            "String platform_code \"[a-zA-Z0-9]+\"", "String platform_code \"CODE\"");
    tPo = results.indexOf(expected.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(results.substring(tPo), expected, "results=\n" + results);

    // *** .dds
    tName = tedd.makeNewFileForDapQuery(language, null, null, "", dir, "testAirt", ".dds");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    String array;\n"
            + "    String station;\n"
            + "    Int32 wmo_platform_code;\n"
            + "    Float32 longitude;\n"
            + "    Float32 latitude;\n"
            + "    Float64 time;\n"
            + "    Float32 depth;\n"
            + "    Float32 AT_21;\n"
            + "    Float32 QAT_5021;\n"
            + "    Float32 SAT_6021;\n"
            + "  } s;\n"
            + "} s;\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // Are there new stations???
    // Check C:/u00/data/points/tao/daily/airt
    // Currently 139 files: 138 .cdf and 1 update.txt.
    // When new stations appear, need to modify
    // EDDTableFromTao.updateOneTaoDataset and the stations specified by the URLS.
    // (It is unfortunate that this is hard-coded.)
    tName =
        tedd.makeNewFileForDapQuery(
            language, null, null, "station&distinct()", dir, "testAirtStations", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    // good test of salinity values: I hand checked this from 1989427.nc in
    // gtspp_at199505.zip
    expected =
        /*
         * changes noticed 2012-03-20 new stations and stations which disappeared:
         * Dai McClurg says the new stations are old and currently inactive but valid.
         * and the removed stations were temporary and aren't part of their public
         * distribution.
         * So the changes seem good.
         */
        "station\n"
            + "\n"
            + "0.7n110w\n"
            + "0.7s110w\n"
            + "0n0e\n"
            + "0n108w\n"
            + "0n10w\n"
            + "0n110.5w\n"
            + "0n110w\n"
            + "0n125w\n"
            + "0n137e\n"
            + "0n140w\n"
            + "0n143e\n"
            + "0n147e\n"
            + "0n152w\n"
            + "0n154e\n"
            + "0n155w\n"
            + "0n156e\n"
            + "0n158e\n"
            + "0n161e\n"
            + "0n165e\n"
            + "0n170e\n"
            + "0n170w\n"
            + "0n176w\n"
            + "0n180w\n"
            + "0n23w\n"
            + "0n35w\n"
            + "0n3w\n"
            + "0n67e\n"
            + "0n80.5e\n"
            + "0n85w\n"
            + "0n90e\n"
            + "0n95w\n"
            + "1.5n67e\n"
            + // added 2016-10-04
            "1.5n80.5e\n"
            + "1.5n90e\n"
            + "1.5s67e\n"
            + // added 2013-09-05
            "1.5s80.5e\n"
            + "1.5s90e\n"
            + "10n95w\n"
            + "10s10w\n"
            + "12n23w\n"
            + "12n38w\n"
            + "12n90e\n"
            + "12n95w\n"
            + "12s55e\n"
            + "12s67e\n"
            + "12s80.5e\n"
            + "12s93e\n"
            +
            // "13n114e\n" + //removed 2013-09-05
            "14s32w\n"
            + "15n38w\n"
            + "15n65e\n"
            + // added 2018-08-09
            "15n90e\n"
            + "16s55e\n"
            + "16s80.5e\n"
            + "19s34w\n"
            + "1n153w\n"
            + "1n155e\n"
            + "1s153w\n"
            + "1s167e\n"
            +
            // "20n117e\n" + //removed 2013-09-05
            "20n38w\n"
            + "20s10w\n"
            + // added 2020-04-07
            "21n23w\n"
            + "25s100e\n"
            + // added 2012-09-06
            "2n10w\n"
            + "2n110w\n"
            + "2n125w\n"
            + "2n137e\n"
            + "2n140w\n"
            + "2n147e\n"
            + "2n155w\n"
            + "2n156e\n"
            + "2n157w\n"
            + "2n165e\n"
            + "2n170w\n"
            + "2n180w\n"
            + "2n95w\n"
            + "2s10w\n"
            + "2s110w\n"
            + "2s125w\n"
            + "2s140w\n"
            + "2s155w\n"
            + "2s156e\n"
            + "2s165e\n"
            + "2s170w\n"
            + "2s180w\n"
            + "2s95w\n"
            + "3.5n95w\n"
            + "4n23w\n"
            + "4n38w\n"
            + "4n67e\n"
            + // added 2019-11-22, removed 2018-09-15, added 2018-08-09
            "4n90e\n"
            + "4n95w\n"
            + // disappeared 2021-02-26 - re-added 2024
            "4s57e\n"
            + // 2015-12-28 added
            "4s67e\n"
            + "4s80.5e\n"
            + "5n110w\n"
            + "5n125w\n"
            + "5n137e\n"
            + "5n140w\n"
            + "5n147e\n"
            + "5n155w\n"
            + "5n156e\n"
            + "5n165e\n"
            + "5n170w\n"
            + "5n180w\n"
            + "5n95w\n"
            + "5s10w\n"
            + "5s110w\n"
            + "5s125w\n"
            + "5s140w\n"
            + "5s155w\n"
            + "5s156e\n"
            + "5s165e\n"
            + "5s170w\n"
            + "5s180w\n"
            + "5s95e\n"
            + "5s95w\n"
            + "6n150w\n"
            + "6s10w\n"
            + "6s8e\n"
            + "7n132w\n"
            + "7n137e\n"
            + "7n140w\n"
            + "7n147w\n"
            + "7n150w\n"
            + "8n110w\n"
            + "8n125w\n"
            + "8n130e\n"
            + "8n137e\n"
            + "8n150w\n"
            + "8n155w\n"
            + "8n156e\n"
            + "8n165e\n"
            + "8n167e\n"
            + "8n168e\n"
            + "8n170w\n"
            + "8n180w\n"
            + "8n38w\n"
            + "8n67e\n"
            + // added 2018-08-09
            "8n90e\n"
            + "8n95w\n"
            + "8s100e\n"
            + "8s110w\n"
            + "8s125w\n"
            + "8s155w\n"
            + "8s165e\n"
            + "8s170w\n"
            + "8s180w\n"
            + "8s30w\n"
            + "8s55e\n"
            + "8s67e\n"
            + "8s80.5e\n"
            + "8s95e\n"
            + "8s95w\n"
            + "9n140w\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // data for station=2s180w
    // the initial run of this test tests whole file download 2011-07-19 updated on
    // 2011-07-25.
    // Does ERDDAP update match results from website on 2011-07-25?
    // using http://www.pmel.noaa.gov/tao/data_deliv/deliv-nojava.html
    // to generate
    // http://www.pmel.noaa.gov/cgi-tao/cover.cgi?p83=2s180w&P18=137&P19=265&P20=-8&P21=9&P1=deliv&P2=airt&P3=dy&P4=2011&P5=7&P6=10&P7=2011&P8=7&P9=25&P10=buoy&P11=ascii&P12=None&P13=tt&P14=anonymous&P16=anonymous&P15=&NOTHING=&P17=&p22=html&script=disdel%2Fnojava.csh
    // yields
    // Location: 2S 180W 10 Jul 2011 to 24 Jul 2011 ( 15 times, 1 blocks) Gen. Date
    // Jul 25 2011
    // Units: Air Temperature (C), -9.99 = missing
    // Time: 1200 10 Jul 2011 to 1200 24 Jul 2011 (index 1 to 15, 15 times)
    // Depth (M): -3 QUALITY SOURCE
    // YYYYMMDD HHMM AIRT Q S
    // ...
    // 20110714 1200 28.34 2 1
    // 20110715 1200 28.53 2 1
    // 20110716 1200 27.84 2 1
    // 20110717 1200 28.30 2 1
    // 20110718 1200 28.42 2 1
    // 20110719 1200 28.21 2 1
    // 20110720 1200 28.41 2 1
    // 20110721 1200 28.38 2 1
    // 20110722 1200 28.06 2 1
    // 20110723 1200 28.02 2 1
    // 20110724 1200 28.31 2 1
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&station=\"2s180w\"&time>2011-07-14&time<2011-07-25",
            dir,
            "testAirtData",
            ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "array,station,wmo_platform_code,longitude,latitude,time,depth,AT_21,QAT_5021,SAT_6021\n"
            + ",,,degrees_east,degrees_north,UTC,m,degree_C,,\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-14T12:00:00Z,-3.0,28.34,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-15T12:00:00Z,-3.0,28.53,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-16T12:00:00Z,-3.0,27.84,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-17T12:00:00Z,-3.0,28.3,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-18T12:00:00Z,-3.0,28.43,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-19T12:00:00Z,-3.0,28.21,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-20T12:00:00Z,-3.0,28.41,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-21T12:00:00Z,-3.0,28.38,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-22T12:00:00Z,-3.0,28.06,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-23T12:00:00Z,-3.0,28.02,1.0,5.0\n"
            + "TAO/TRITON,2s180w,52312,180.0,-2.0,2011-07-24T12:00:00Z,-3.0,28.31,1.0,5.0\n";

    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);
  }

  /** Test ODV files created by ERDDAP. */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testODV() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testODV");

    int language = 0;
    EDDTable tedd;
    String tName, error, results, tResults, expected;
    int po;
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // * test cdm_data_type=TimeSeries
    tedd = (EDDTable) EDDTestDataset.getcwwcNDBCMet();
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&station=~%22(41004|RCPT2|SANF1)%22&time%3E=2020-01-01&time%3C=2020-01-01T01",
            dir,
            "testOdvTimeSeries",
            ".odvTxt");
    results = String2.annotatedString(File2.directReadFromUtf8File(dir + tName));
    results =
        results.replaceAll(
            "<CreateTime>.*</CreateTime>", "<CreateTime>[CREATION_TIME]</CreateTime>");

    expected =
        "//<Creator>https://www.ndbc.noaa.gov/</Creator>[10]\n"
            + "//<CreateTime>[CREATION_TIME]</CreateTime>[10]\n"
            + "//<Encoding>UTF-8</Encoding>[10]\n"
            + "//<Software>ERDDAP - Version "
            + EDStatic.erddapVersion
            + "</Software>[10]\n"
            + "//<Source>http://localhost:8080/erddap/tabledap/cwwcNDBCMet.html</Source>[10]\n"
            + "//<Version>ODV Spreadsheet V4.6</Version>[10]\n"
            + "//<DataField>GeneralField</DataField>[10]\n"
            + "//<DataType>TimeSeries</DataType>[10]\n"
            + "//<MetaVariable>label=\"Cruise\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Station\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" comment=\"The station identifier.\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Type\" value_type=\"TEXT:2\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"yyyy-mm-ddThh:mm:ss.sss\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Time\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Longitude [degrees_east]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"The longitude of the station.\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Latitude [degrees_north]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"The latitude of the station.\" </MetaVariable>[10]\n"
            + "//<DataVariable>label=\"time_ISO8601\" value_type=\"DOUBLE\" is_primary_variable=\"T\" comment=\"Time\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"wd [degrees_true]\" value_type=\"SHORT\" is_primary_variable=\"F\" comment=\"Wind direction (the direction the wind is coming from in degrees clockwise from true N) during the same period used for WSPD.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"wspd [m s-1]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Average wind speed (m/s).\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"gst [m s-1]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Peak 5 or 8 second gust speed (m/s).\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"wvht [m]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Significant wave height (meters) is calculated as the average of the highest one-third of all of the wave heights during the 20-minute sampling period.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"dpd [s]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Dominant wave period (seconds) is the period with the maximum wave energy.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"apd [s]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Average wave period (seconds) of all waves during the 20-minute period.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"mwd [degrees_true]\" value_type=\"SHORT\" is_primary_variable=\"F\" comment=\"Mean wave direction corresponding to energy of the dominant period (DOMPD).\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"bar [hPa]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Air pressure (hPa). ('PRES' on some NDBC tables.) For C-MAN sites and Great Lakes buoys, the recorded pressure is reduced to sea level using the method described in NWS Technical Procedures Bulletin 291 (11/14/80).\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"atmp [degree_C]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"wtmp [degree_C]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"dewp [degree_C]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Dewpoint temperature taken at the same height as the air temperature measurement.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"vis [km]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Station visibility (km, originally nautical miles in the NDBC .txt files). Note that buoy stations are limited to reports from 0 to 1.6 nmi.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"ptdy [hPa]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Pressure Tendency is the direction (plus or minus) and the amount of pressure change (hPa) for a three hour period ending at the time of observation.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"tide [m]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"The water level in meters (originally feet in the NDBC .txt files) above or below Mean Lower Low Water (MLLW).\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"wspu [m s-1]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"The zonal wind speed (m/s) indicates the u component of where the wind is going, derived from Wind Direction and Wind Speed.\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"wspv [m s-1]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"The meridional wind speed (m/s) indicates the v component of where the wind is going, derived from Wind Direction and Wind Speed.\" </DataVariable>[10]\n"
            + "Cruise[9]Station[9]Type[9]yyyy-mm-ddThh:mm:ss.sss[9]Longitude [degrees_east][9]Latitude [degrees_north][9]time_ISO8601[9]wd [degrees_true][9]wspd [m s-1][9]gst [m s-1][9]wvht [m][9]dpd [s][9]apd [s][9]mwd [degrees_true][9]bar [hPa][9]atmp [degree_C][9]wtmp [degree_C][9]dewp [degree_C][9]vis [km][9]ptdy [hPa][9]tide [m][9]wspu [m s-1][9]wspv [m s-1][10]\n"
            + "[9]41004[9]*[9][9]-79.099[9]32.501[9]2020-01-01T00:00:00.000Z[9][9]10.9[9]13.3[9][9][9][9][9]1013.5[9][9]21.9[9][9][9][9][9][9][10]\n"
            + "[9]41004[9]*[9][9]-79.099[9]32.501[9]2020-01-01T00:10:00.000Z[9][9]11.2[9]13.6[9][9][9][9][9]1013.4[9][9]21.9[9][9][9][9][9][9][10]\n"
            + "[9]41004[9]*[9][9]-79.099[9]32.501[9]2020-01-01T00:20:00.000Z[9][9]11.2[9]14.4[9][9][9][9][9]1013.7[9][9]21.9[9][9][9][9][9][9][10]\n"
            + "[9]41004[9]*[9][9]-79.099[9]32.501[9]2020-01-01T00:30:00.000Z[9][9]11.3[9]13.6[9][9][9][9][9]1013.7[9][9][9][9][9][9][9][9][10]\n"
            + "[9]41004[9]*[9][9]-79.099[9]32.501[9]2020-01-01T00:40:00.000Z[9][9]11.4[9]14.2[9]1.55[9]5.88[9]4.65[9]237[9]1013.7[9][9]21.9[9][9][9][9][9][9][10]\n"
            + "[9]41004[9]*[9][9]-79.099[9]32.501[9]2020-01-01T00:50:00.000Z[9][9]11.4[9]14.1[9][9][9][9][9]1013.8[9][9]21.9[9][9][9][9][9][9][10]\n"
            + "[9]41004[9]*[9][9]-79.099[9]32.501[9]2020-01-01T01:00:00.000Z[9][9]11.3[9]14.2[9][9][9][9][9]1013.7[9][9]21.9[9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:00:00.000Z[9][9][9][9][9][9][9][9]1021.6[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:06:00.000Z[9][9][9][9][9][9][9][9]1021.7[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:12:00.000Z[9][9][9][9][9][9][9][9]1021.9[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:18:00.000Z[9][9][9][9][9][9][9][9]1022.0[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:24:00.000Z[9][9][9][9][9][9][9][9]1021.9[9]13.9[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:30:00.000Z[9][9][9][9][9][9][9][9]1021.5[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:36:00.000Z[9][9][9][9][9][9][9][9]1021.6[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:42:00.000Z[9][9][9][9][9][9][9][9]1021.8[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:48:00.000Z[9][9][9][9][9][9][9][9]1021.7[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T00:54:00.000Z[9][9][9][9][9][9][9][9]1021.5[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]RCPT2[9]*[9][9]-97.047[9]28.022[9]2020-01-01T01:00:00.000Z[9][9][9][9][9][9][9][9]1021.0[9]14.0[9][9][9][9][9][9][9][10]\n"
            + "[9]SANF1[9]*[9][9]-81.88[9]24.46[9]2020-01-01T00:00:00.000Z[9]10[9]6.2[9]6.9[9][9][9][9][9][9]22.7[9][9]21.3[9][9][9][9]-1.1[9]-6.1[10]\n"
            + "[9]SANF1[9]*[9][9]-81.88[9]24.46[9]2020-01-01T00:10:00.000Z[9]6[9]6.0[9]7.3[9][9][9][9][9][9]22.7[9][9]21.4[9][9][9][9]-0.6[9]-6.0[10]\n"
            + "[9]SANF1[9]*[9][9]-81.88[9]24.46[9]2020-01-01T00:20:00.000Z[9]10[9]5.0[9]6.1[9][9][9][9][9][9]22.5[9][9]21.2[9][9][9][9]-0.9[9]-4.9[10]\n"
            + "[9]SANF1[9]*[9][9]-81.88[9]24.46[9]2020-01-01T00:30:00.000Z[9]18[9]5.0[9]6.0[9][9][9][9][9][9]22.4[9][9]21.1[9][9][9][9]-1.5[9]-4.8[10]\n"
            + "[9]SANF1[9]*[9][9]-81.88[9]24.46[9]2020-01-01T00:40:00.000Z[9]25[9]4.3[9]5.2[9][9][9][9][9][9]22.3[9][9]20.9[9][9][9][9]-1.8[9]-3.9[10]\n"
            + "[9]SANF1[9]*[9][9]-81.88[9]24.46[9]2020-01-01T00:50:00.000Z[9]24[9]3.7[9]4.7[9][9][9][9][9][9]22.4[9][9]21.0[9][9][9][9]-1.5[9]-3.4[10]\n"
            + "[9]SANF1[9]*[9][9]-81.88[9]24.46[9]2020-01-01T01:00:00.000Z[9]30[9]3.4[9]4.1[9][9][9][9][9][9]22.4[9][9]20.9[9][9][9][9]-1.7[9]-2.9[10]\n"
            + "[end]";
    String2.log(results + "\nfileName=" + dir + tName);
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // * test cdm_data_type=Trajectory
    tedd = (EDDTable) EDDTestDataset.getfsuNoaaShipWTEP();
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&time%3C=2007-09-01T00:03:00Z&flag=~%22ZZZ.*%22",
            dir,
            "testOdvTrajectory",
            ".odvTxt");
    results = String2.annotatedString(File2.directReadFromUtf8File(dir + tName));
    results =
        results.replaceAll(
            "<CreateTime>.*</CreateTime>", "<CreateTime>[CREATION_TIME]</CreateTime>");
    expected =
        "//<Creator>https://tds.coaps.fsu.edu/thredds/catalog/samos/data/research/WTEP/catalog.xml</Creator>[10]\n"
            + "//<CreateTime>[CREATION_TIME]</CreateTime>[10]\n"
            + "//<Encoding>UTF-8</Encoding>[10]\n"
            + "//<Software>ERDDAP - Version "
            + EDStatic.erddapVersion
            + "</Software>[10]\n"
            + "//<Source>http://localhost:8080/erddap/tabledap/fsuNoaaShipWTEP.html</Source>[10]\n"
            + "//<Version>ODV Spreadsheet V4.6</Version>[10]\n"
            + "//<DataField>GeneralField</DataField>[10]\n"
            + "//<DataType>Trajectories</DataType>[10]\n"
            + "//<MetaVariable>label=\"Cruise\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" comment=\"Call Sign\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Station\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Type\" value_type=\"TEXT:2\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"yyyy-mm-ddThh:mm:ss.sss\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Time\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Longitude [degrees_east]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Longitude\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Latitude [degrees_north]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Latitude\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"site\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" comment=\"Ship Name\" </MetaVariable>[10]\n"
            + "//<DataVariable>label=\"time_ISO8601\" value_type=\"DOUBLE\" is_primary_variable=\"T\" comment=\"Time\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"IMO\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"cruise_id\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"expocode\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"facility\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"platform\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"platform_version\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"airPressure [millibar]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Atmospheric Pressure\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"airTemperature [degree_C]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Air Temperature\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"conductivity [siemens meter-1]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Conductivity\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"relativeHumidity [percent]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Relative Humidity\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"salinity\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Sea Water Practical Salinity\" </DataVariable>[10]\n"
            + // has/doesn't have " [PSU]"
            "//<DataVariable>label=\"seaTemperature [degree_C]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Sea Water Temperature\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"windDirection [degrees (clockwise from true north)]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Earth Relative Wind Direction\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"windSpeed [meter second-1]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Earth Relative Wind Speed\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"platformCourse [degrees_true]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Platform Course\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"platformHeading [degrees_true]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Platform Heading\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"platformSpeed [meter second-1]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Platform Speed Over Ground\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"platformWindDirection [degrees (clockwise from bow)]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Platform Relative Wind Direction\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"platformWindSpeed [meter second-1]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Platform Relative Wind Speed\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"flag\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" comment=\"Quality Control Flags\" </DataVariable>[10]\n"
            + "Cruise[9]Station[9]Type[9]yyyy-mm-ddThh:mm:ss.sss[9]Longitude [degrees_east][9]Latitude [degrees_north][9]site[9]time_ISO8601[9]IMO[9]cruise_id[9]expocode[9]facility[9]platform[9]platform_version[9]airPressure [millibar][9]airTemperature [degree_C][9]conductivity [siemens meter-1][9]relativeHumidity [percent][9]salinity[9]seaTemperature [degree_C][9]windDirection [degrees (clockwise from true north)][9]windSpeed [meter second-1][9]platformCourse [degrees_true][9]platformHeading [degrees_true][9]platformSpeed [meter second-1][9]platformWindDirection [degrees (clockwise from bow)][9]platformWindSpeed [meter second-1][9]flag[10]\n"
            + // has/doesn't have " [PSU]"
            "WTEP[9][9]*[9][9]201.8352[9]55.69271[9]OSCAR DYSON[9]2007-09-01T00:00:00.000Z[9]unknown at this time[9]Cruise_id undefined for now[9]EXPOCODE undefined for now[9]NOAA[9]SCS[9]4.0[9]1008.6[9]16.8[9][9]35.1[9][9]12.12[9]205.31[9]1.640936[9]29.65[9]33.06[9]1.38888[9]152.38[9]0.28292[9]ZZZZZZZZZZZZGZ[10]\n"
            + "WTEP[9][9]*[9][9]201.83586[9]55.69335[9]OSCAR DYSON[9]2007-09-01T00:01:00.000Z[9]unknown at this time[9]Cruise_id undefined for now[9]EXPOCODE undefined for now[9]NOAA[9]SCS[9]4.0[9]1008.58[9]16.3[9][9]33.6[9][9]12.08[9]208.04[9]1.599784[9]29.58[9]31.84[9]1.38888[9]165.08[9]0.236624[9]ZZZZZZZZZZZZGZ[10]\n"
            + "WTEP[9][9]*[9][9]201.83647[9]55.69401[9]OSCAR DYSON[9]2007-09-01T00:02:00.000Z[9]unknown at this time[9]Cruise_id undefined for now[9]EXPOCODE undefined for now[9]NOAA[9]SCS[9]4.0[9]1008.6[9]16.1[9][9]39.5[9][9]12.07[9]207.75[9]1.486616[9]28.12[9]31.63[9]1.38888[9]164.03[9]0.123456[9]ZZZZZZZZZZZZGZ[10]\n"
            + "WTEP[9][9]*[9][9]201.83708[9]55.69469[9]OSCAR DYSON[9]2007-09-01T00:03:00.000Z[9]unknown at this time[9]Cruise_id undefined for now[9]EXPOCODE undefined for now[9]NOAA[9]SCS[9]4.0[9]1008.53[9]16.0[9][9]36.1[9][9]12.08[9]206.9[9]1.404312[9]27.05[9]32.2[9]1.38888[9]162.51[9]0.036008[9]ZZZZZZZZZZZZGZ[10]\n"
            + "[end]";
    String2.log(results + "\nfileName=" + dir + tName);
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // * test cdm_data_type=TrajectoryProfile
    tedd = (EDDTable) EDDTestDataset.geterdGtsppBest();
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&time>=2020-01-01T12&time<=2020-01-02&depth<100&trajectory=~\"(ME_BA_09WX_VNVZ%2020|ME_DB_33TT_51011%2020|ME_DB_33TT_51018%2020)\"&orderBy(\"trajectory,time\")",
            dir,
            "testOdvTrajectoryProfile",
            ".odvTxt");
    results = String2.annotatedString(File2.directReadFromUtf8File(dir + tName));
    results =
        results.replaceAll(
            "<CreateTime>.*</CreateTime>", "<CreateTime>[CREATION_TIME]</CreateTime>");
    expected =
        "//<Creator>https://www.nodc.noaa.gov/GTSPP/</Creator>[10]\n"
            + "//<CreateTime>[CREATION_TIME]</CreateTime>[10]\n"
            + "//<Encoding>UTF-8</Encoding>[10]\n"
            + "//<Software>ERDDAP - Version "
            + EDStatic.erddapVersion
            + "</Software>[10]\n"
            + "//<Source>http://localhost:8080/erddap/tabledap/erdGtsppBest.html</Source>[10]\n"
            + "//<Version>ODV Spreadsheet V4.6</Version>[10]\n"
            + "//<DataField>GeneralField</DataField>[10]\n"
            + "//<DataType>Profiles</DataType>[10]\n"
            + "//<MetaVariable>label=\"Cruise\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" comment=\"Constructed from org_type_platform_cruise\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Station\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Type\" value_type=\"TEXT:2\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"yyyy-mm-ddThh:mm:ss.sss\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Time\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Longitude [degrees_east]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Longitude\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Latitude [degrees_north]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Latitude\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"org\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" comment=\"From the first 2 characters of stream_ident:\\nCode  Meaning\\nAD  Australian Oceanographic Data Centre\\nAF  Argentina Fisheries (Fisheries Research and Development National Institute (INIDEP), Mar del Plata, Argentina\\nAO  Atlantic Oceanographic and Meteorological Lab\\nAP  Asia-Pacific (International Pacific Research Center/ Asia-Pacific Data-Research Center)\\nBI  BIO Bedford institute of Oceanography\\nCF  Canadian Navy\\nCS  CSIRO in Australia\\nDA  Dalhousie University\\nFN  FNOC in Monterey, California\\nFR  Orstom, Brest\\nFW  Fresh Water Institute (Winnipeg)\\nGE  BSH, Germany\\nIC  ICES\\nII  IIP\\nIK  Institut fur Meereskunde, Kiel\\nIM  IML\\nIO  IOS in Pat Bay, BC\\nJA  Japanese Meteorologocal Agency\\nJF  Japan Fisheries Agency\\nME  EDS\\nMO  Moncton\\nMU  Memorial University\\nNA  NAFC\\nNO  NODC (Washington)\\nNW  US National Weather Service\\nOD  Old Dominion Univ, USA\\nRU  Russian Federation\\nSA  St Andrews\\nSI  Scripps Institute of Oceanography\\nSO  Southampton Oceanographic Centre, UK\\nTC  TOGA Subsurface Data Centre (France)\\nTI  Tiberon lab US\\nUB  University of BC\\nUQ  University of Quebec at Rimouski\\nVL  Far Eastern Regional Hydromet. Res. Inst. of V\\nWH  Woods Hole\\n\\nfrom https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref006\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"type\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" comment=\"From the 3rd and 4th characters of stream_ident:\\nCode  Meaning\\nAR  Animal mounted recorder\\nBA  BATHY message\\nBF  Undulating Oceanographic Recorder (e.g. Batfish CTD)\\nBO  Bottle\\nBT  general BT data\\nCD  CTD down trace\\nCT  CTD data, up or down\\nCU  CTD up trace\\nDB  Drifting buoy\\nDD  Delayed mode drifting buoy data\\nDM  Delayed mode version from originator\\nDT  Digital BT\\nIC  Ice core\\nID  Interpolated drifting buoy data\\nIN  Ship intake samples\\nMB  MBT\\nMC  CTD and bottle data are mixed for the station\\nMI  Data from a mixed set of instruments\\nML  Minilog\\nOF  Real-time oxygen and fluorescence\\nPF  Profiling float\\nRM  Radio message\\nRQ  Radio message with scientific QC\\nSC  Sediment core\\nSG  Thermosalinograph data\\nST  STD data\\nSV  Sound velocity probe\\nTE  TESAC message\\nTG  Thermograph data\\nTK  TRACKOB message\\nTO  Towed CTD\\nTR  Thermistor chain\\nXB  XBT\\nXC  Expendable CTD\\n\\nfrom https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref082\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"platform\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" comment=\"See the list of platform codes (sorted in various ways) at https://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"cruise\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" comment=\"Radio callsign + year for real time data, or NODC reference number for delayed mode data.  See\\nhttps://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html .\\n'X' indicates a missing value.\\nTwo or more adjacent spaces in the original cruise names have been compacted to 1 space.\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"station_id\" value_type=\"INTEGER\" is_primary_variable=\"F\" comment=\"Identification number of the station (profile) in the GTSPP Continuously Managed Database\" </MetaVariable>[10]\n"
            + "//<DataVariable>label=\"depth [m]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Depth of the Observations\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"temperature [degree_C]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Sea Water Temperature\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"salinity [PSU]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Practical Salinity\" </DataVariable>[10]\n"
            + "Cruise[9]Station[9]Type[9]yyyy-mm-ddThh:mm:ss.sss[9]Longitude [degrees_east][9]Latitude [degrees_north][9]org[9]type[9]platform[9]cruise[9]station_id[9]depth [m][9]temperature [degree_C][9]salinity [PSU][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T14:18:00.000Z[9]130.882[9]17.959[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606065[9]4.0[9]27.8[9][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T14:18:00.000Z[9]130.882[9]17.959[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606065[9]80.0[9]27.8[9][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T14:18:00.000Z[9]130.882[9]17.959[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606065[9]87.0[9]26.2[9][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T18:29:00.000Z[9]130.458[9]16.82[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606064[9]4.0[9]28.3[9][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T18:29:00.000Z[9]130.458[9]16.82[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606064[9]80.0[9]28.2[9][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T18:29:00.000Z[9]130.458[9]16.82[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606064[9]85.0[9]27.2[9][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T18:29:00.000Z[9]130.458[9]16.82[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606064[9]94.0[9]26.5[9][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T21:37:00.000Z[9]130.218[9]15.966[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606063[9]4.0[9]28.5[9][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T21:37:00.000Z[9]130.218[9]15.966[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606063[9]87.0[9]28.5[9][10]\n"
            + "ME_BA_09WX_VNVZ 20[9][9]*[9]2020-01-01T21:37:00.000Z[9]130.218[9]15.966[9]ME[9]BA[9]09WX[9]VNVZ 20[9]37606063[9]94.0[9]26.9[9][10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T12:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626023[9]1.0[9]26.16[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T12:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626023[9]5.0[9]26.17[9]34.37[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T13:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626024[9]1.0[9]26.16[9]34.35[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T13:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626024[9]5.0[9]26.17[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T14:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626025[9]1.0[9]26.15[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T14:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626025[9]5.0[9]26.16[9]34.37[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T15:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626026[9]1.0[9]26.16[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T15:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626026[9]5.0[9]26.16[9]34.37[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T16:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626027[9]1.0[9]26.16[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T16:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626027[9]5.0[9]26.17[9]34.37[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T17:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626028[9]1.0[9]26.18[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T17:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626028[9]5.0[9]26.18[9]34.37[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T18:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626029[9]1.0[9]26.26[9]34.35[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T18:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626029[9]5.0[9]26.22[9]34.37[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T19:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626030[9]1.0[9]26.38[9]34.35[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T19:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626030[9]5.0[9]26.26[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T20:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626031[9]1.0[9]26.51[9]34.35[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T20:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626031[9]5.0[9]26.33[9]34.35[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T21:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626032[9]1.0[9]26.65[9]34.35[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T21:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626032[9]5.0[9]26.34[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T22:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626033[9]1.0[9]26.66[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T22:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626033[9]5.0[9]26.51[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T23:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626034[9]1.0[9]26.65[9]34.35[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-01T23:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626034[9]5.0[9]26.47[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-02T00:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626035[9]1.0[9]26.68[9]34.36[10]\n"
            + "ME_DB_33TT_51011 20[9][9]*[9]2020-01-02T00:00:00.000Z[9]-124.4[9]-0.2[9]ME[9]DB[9]33TT[9]51011 20[9]37626035[9]5.0[9]26.52[9]34.36[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T12:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625879[9]1.0[9]25.77[9]34.89[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T13:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625880[9]1.0[9]25.77[9]34.89[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T14:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625881[9]1.0[9]25.74[9]34.9[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T15:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625882[9]1.0[9]25.74[9]34.89[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T16:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625883[9]1.0[9]25.75[9]34.89[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T17:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625884[9]1.0[9]25.77[9]34.89[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T18:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625885[9]1.0[9]25.83[9]34.89[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T19:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625886[9]1.0[9]25.91[9]34.89[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T20:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625887[9]1.0[9]25.96[9]34.91[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T21:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625888[9]1.0[9]26.04[9]34.9[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T22:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625889[9]1.0[9]26.11[9]34.9[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-01T23:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625890[9]1.0[9]26.12[9]34.89[10]\n"
            + "ME_DB_33TT_51018 20[9][9]*[9]2020-01-02T00:00:00.000Z[9]-124.9[9]-5.0[9]ME[9]DB[9]33TT[9]51018 20[9]37625891[9]1.0[9]26.16[9]34.89[10]\n"
            + "[end]";
    String2.log(results + "\nfileName=" + dir + tName);
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // * test cdm_data_type=Point
    tedd = (EDDTable) EDDTestDataset.geterdNph();
    tName =
        tedd.makeNewFileForDapQuery(
            language, null, null, "&year=1985", dir, "testOdvPoint", ".odvTxt");
    results = String2.annotatedString(File2.directReadFromUtf8File(dir + tName));
    results =
        results.replaceAll(
            "<CreateTime>.*</CreateTime>", "<CreateTime>[CREATION_TIME]</CreateTime>");
    expected =
        "//<Creator>https://onlinelibrary.wiley.com/doi/10.1002/grl.50100/abstract</Creator>[10]\n"
            + "//<CreateTime>[CREATION_TIME]</CreateTime>[10]\n"
            + "//<Encoding>UTF-8</Encoding>[10]\n"
            + "//<Software>ERDDAP - Version "
            + EDStatic.erddapVersion
            + "</Software>[10]\n"
            + "//<Source>http://localhost:8080/erddap/tabledap/erdNph.html</Source>[10]\n"
            + "//<Version>ODV Spreadsheet V4.6</Version>[10]\n"
            + "//<DataField>GeneralField</DataField>[10]\n"
            + "//<DataType>GeneralType</DataType>[10]\n"
            + "//<MetaVariable>label=\"Cruise\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Station\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Type\" value_type=\"TEXT:2\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"yyyy-mm-ddThh:mm:ss.sss\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Time\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Longitude [degrees_east]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Longitude of the Center of the NPH\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Latitude [degrees_north]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Latitude of the Center of the NPH\" </MetaVariable>[10]\n"
            + "//<DataVariable>label=\"time_ISO8601\" value_type=\"DOUBLE\" is_primary_variable=\"T\" comment=\"Centered Time\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"year\" value_type=\"SHORT\" is_primary_variable=\"F\" comment=\"Year\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"month\" value_type=\"SIGNED_BYTE\" is_primary_variable=\"F\" comment=\"Month (1 - 12)\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"area [km2]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Areal Extent of the 1020 hPa Contour\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"maxSLP [hPa]\" value_type=\"FLOAT\" is_primary_variable=\"F\" comment=\"Maximum Sea Level Pressure\" </DataVariable>[10]\n"
            + "Cruise[9]Station[9]Type[9]yyyy-mm-ddThh:mm:ss.sss[9]Longitude [degrees_east][9]Latitude [degrees_north][9]time_ISO8601[9]year[9]month[9]area [km2][9]maxSLP [hPa][10]\n"
            + "[9][9]*[9][9]229.9[9]35.5[9]1985-01-16T00:00:00.000Z[9]1985[9]1[9]1150500.0[9]1022.7[10]\n"
            + "[9][9]*[9][9]221.3[9]34.1[9]1985-02-16T00:00:00.000Z[9]1985[9]2[9]4989400.0[9]1028.2[10]\n"
            + "[9][9]*[9][9]216.7[9]33.5[9]1985-03-16T00:00:00.000Z[9]1985[9]3[9]6584200.0[9]1031.2[10]\n"
            + "[9][9]*[9][9]217.1[9]34.5[9]1985-04-16T00:00:00.000Z[9]1985[9]4[9]5692500.0[9]1024.5[10]\n"
            + "[9][9]*[9][9]215.5[9]34.5[9]1985-05-16T00:00:00.000Z[9]1985[9]5[9]5334700.0[9]1025.7[10]\n"
            + "[9][9]*[9][9]215.7[9]35.9[9]1985-06-16T00:00:00.000Z[9]1985[9]6[9]4161100.0[9]1022.9[10]\n"
            + "[9][9]*[9][9]214.5[9]35.7[9]1985-07-16T00:00:00.000Z[9]1985[9]7[9]4588300.0[9]1025.3[10]\n"
            + "[9][9]*[9][9]214.7[9]35.9[9]1985-08-16T00:00:00.000Z[9]1985[9]8[9]4456900.0[9]1029.3[10]\n"
            + "[9][9]*[9][9]214.1[9]37.5[9]1985-09-16T00:00:00.000Z[9]1985[9]9[9]3262900.0[9]1028.6[10]\n"
            + "[9][9]*[9][9]214.7[9]36.3[9]1985-10-16T00:00:00.000Z[9]1985[9]10[9]3887100.0[9]1024.7[10]\n"
            + "[9][9]*[9][9]225.7[9]37.7[9]1985-11-16T00:00:00.000Z[9]1985[9]11[9]845770.0[9]1021.0[10]\n"
            + "[9][9]*[9][9]231.1[9]34.5[9]1985-12-16T00:00:00.000Z[9]1985[9]12[9]817010.0[9]1021.9[10]\n"
            + "[end]";
    String2.log(results + "\nfileName=" + dir + tName);
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /** */
  @org.junit.jupiter.api.Test
  @TagMissingDataset
  void testNow() throws Throwable {

    String2.log("\n*** EDDTableFromNcFiles.testNow");
    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.getndbcSosWaves(); // has very recent data

    // these query tests need a dataset that has recent data (or request is
    // rejected)
    // these tests moved here 2014-01-23
    GregorianCalendar gc = Calendar2.newGCalendarZulu();
    gc.set(Calendar2.MILLISECOND, 0);
    gc.add(Calendar2.SECOND, 1); // now it is "now"
    long nowMillis = gc.getTimeInMillis();
    String s;
    StringArray rv = new StringArray();
    StringArray cv = new StringArray();
    StringArray co = new StringArray();
    StringArray cv2 = new StringArray();

    gc = Calendar2.newGCalendarZulu(nowMillis);
    String2.log("now          = " + Calendar2.formatAsISODateTimeT3Z(gc));
    // non-regex EDVTimeStamp conValues will be ""+epochSeconds
    tedd.parseUserDapQuery(language, "time&time=now", rv, cv, co, cv2, false);
    Test.ensureEqual(rv.toString(), "time", "");
    Test.ensureEqual(cv.toString(), "time", "");
    Test.ensureEqual(co.toString(), "=", "");
    Test.ensureEqual(cv2.toString(), "" + Calendar2.gcToEpochSeconds(gc), "");

    gc = Calendar2.newGCalendarZulu(nowMillis);
    gc.add(Calendar2.SECOND, -1);
    String2.log("now-1second  = " + Calendar2.formatAsISODateTimeT3Z(gc));
    // non-regex EDVTimeStamp conValues will be ""+epochSeconds
    tedd.parseUserDapQuery(language, "time&time=now-1second", rv, cv, co, cv2, false);
    Test.ensureEqual(rv.toString(), "time", "");
    Test.ensureEqual(cv.toString(), "time", "");
    Test.ensureEqual(co.toString(), "=", "");
    Test.ensureEqual(cv2.toString(), "" + Calendar2.gcToEpochSeconds(gc), "");

    gc = Calendar2.newGCalendarZulu(nowMillis);
    gc.add(Calendar2.SECOND, 2);
    String2.log("now+2seconds = " + Calendar2.formatAsISODateTimeT3Z(gc));
    // non-regex EDVTimeStamp conValues will be ""+epochSeconds
    tedd.parseUserDapQuery(language, "time&time=now%2B2seconds", rv, cv, co, cv2, false);
    Test.ensureEqual(cv2.toString(), "" + Calendar2.gcToEpochSeconds(gc), "");

    // non-%encoded '+' will be decoded as ' ', so treat ' ' as equal to '+'
    gc = Calendar2.newGCalendarZulu(nowMillis);
    gc.add(Calendar2.SECOND, 2);
    String2.log("now 2seconds = " + Calendar2.formatAsISODateTimeT3Z(gc));
    // non-regex EDVTimeStamp conValues will be ""+epochSeconds
    tedd.parseUserDapQuery(language, "time&time=now 2seconds", rv, cv, co, cv2, false);
    Test.ensureEqual(cv2.toString(), "" + Calendar2.gcToEpochSeconds(gc), "");

    gc = Calendar2.newGCalendarZulu(nowMillis);
    gc.add(Calendar2.MINUTE, -3);
    String2.log("now-3minutes = " + Calendar2.formatAsISODateTimeT3Z(gc));
    // non-regex EDVTimeStamp conValues will be ""+epochSeconds
    tedd.parseUserDapQuery(language, "time&time=now-3minutes", rv, cv, co, cv2, false);
    Test.ensureEqual(cv2.toString(), "" + Calendar2.gcToEpochSeconds(gc), "");

    gc = Calendar2.newGCalendarZulu(nowMillis);
    gc.add(Calendar2.HOUR_OF_DAY, -4);
    String2.log("now-4hours   = " + Calendar2.formatAsISODateTimeT3Z(gc));
    // non-regex EDVTimeStamp conValues will be ""+epochSeconds
    tedd.parseUserDapQuery(language, "time&time=now-4hours", rv, cv, co, cv2, false);
    Test.ensureEqual(cv2.toString(), "" + Calendar2.gcToEpochSeconds(gc), "");

    gc = Calendar2.newGCalendarZulu(nowMillis);
    gc.add(Calendar2.DATE, -5);
    String2.log("now-5days    = " + Calendar2.formatAsISODateTimeT3Z(gc));
    // non-regex EDVTimeStamp conValues will be ""+epochSeconds
    tedd.parseUserDapQuery(language, "time&time=now-5days", rv, cv, co, cv2, false);
    Test.ensureEqual(cv2.toString(), "" + Calendar2.gcToEpochSeconds(gc), "");

    gc = Calendar2.newGCalendarZulu(nowMillis);
    gc.add(Calendar2.MONTH, -6);
    String2.log("now-6months  = " + Calendar2.formatAsISODateTimeT3Z(gc));
    // non-regex EDVTimeStamp conValues will be ""+epochSeconds
    tedd.parseUserDapQuery(language, "time&time=now-6months", rv, cv, co, cv2, false);
    Test.ensureEqual(cv2.toString(), "" + Calendar2.gcToEpochSeconds(gc), "");

    gc = Calendar2.newGCalendarZulu(nowMillis);
    gc.add(Calendar2.YEAR, -2);
    String2.log("now-7years   = " + Calendar2.formatAsISODateTimeT3Z(gc));
    // non-regex EDVTimeStamp conValues will be ""+epochSeconds
    tedd.parseUserDapQuery(language, "time&time=now-2years", rv, cv, co, cv2, false);
    Test.ensureEqual(cv2.toString(), "" + Calendar2.gcToEpochSeconds(gc), "");
    // if (true) throw new RuntimeException("stop here");
  }

  /** */
  @org.junit.jupiter.api.Test
  void testMinMaxConstraints() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testMinMaxConstraints");

    int language = 0;
    // dataset is fromFiles (so min,max are known) and no recent data (so stable)
    EDDTable tedd = (EDDTable) EDDTestDataset.getLiquidR_HBG3_2015_weather();

    String s;
    StringArray rv = new StringArray();
    StringArray cv = new StringArray();
    StringArray co = new StringArray();
    StringArray cv2 = new StringArray();
    EDV pVar = tedd.findDataVariableByDestinationName("pressure");
    Test.ensureEqual(pVar.destinationMin(), 912.4, ""); // test exactly (it's a float)
    Test.ensureEqual(pVar.destinationMax(), 2759, "");
    float minP = (float) pVar.destinationMinDouble(); // work with it as float below
    float maxP = (float) pVar.destinationMaxDouble();
    EDV timeVar = tedd.findDataVariableByDestinationName("time");
    double minT = timeVar.destinationMinDouble();
    double maxT = timeVar.destinationMaxDouble();
    Test.ensureEqual(minT, 1432151400, ""); // 2015-05-20T19:50:00Z
    Test.ensureEqual(maxT, 1446664200, ""); // 2015-11-04T19:10:00Z

    tedd.parseUserDapQuery(
        language,
        "pressure"
            + "&pressure<max(pressure)&pressure<max(pressure)-1.5"
            + "&pressure>min(pressure)&pressure>min(pressure)+2.5"
            + "&time<max(time)&time<max(time)-1.5&time<max(time)-2minutes"
            + "&time>min(time)&time>min(time)+2.5&time>min(time) 3millis",
        rv,
        cv,
        co,
        cv2,
        false); // repair?
    Test.ensureEqual(
        EDDTable.formatAsDapQuery(rv, cv, co, cv2),
        "pressure"
            + "&pressure<"
            + maxP
            + "&pressure<"
            + (maxP - 1.5f)
            + "&pressure>"
            + minP
            + "&pressure>"
            + (minP + 2.5f)
            + "&time<"
            + maxT
            + "&time<"
            + (maxT - 1.5)
            + "&time<"
            + (maxT - 120)
            + "&time>"
            + minT
            + "&time>"
            + (minT + 2.5)
            + "&time>"
            + (minT + 0.003),
        "");

    // test repair (invalid constraints are discarded)
    tedd.parseUserDapQuery(
        language,
        "pressure"
            + "&pressure<max(pressure)&pressure<max(p&pressure<max(p)&pressure<max(pressure)-2minutes"
            + "&pressure>min(pressure)&pressure>min(pressure)2.5a&pressure>min(pressure)+2.5a"
            + "&time<max(time)&time<max(t&time<max(t)&time<max(t)2"
            + "&time>min(time)&time>min(time)+2.5milli&time>min(time)+3millia",
        rv,
        cv,
        co,
        cv2,
        true); // repair?
    Test.ensureEqual(
        EDDTable.formatAsDapQuery(rv, cv, co, cv2),
        "pressure" + "&pressure<" + maxP + "&pressure>" + minP + "&time<" + maxT + "&time>" + minT,
        "");

    // test early error
    try {
      tedd.parseUserDapQuery(
          language, "pressure&pressure<max(p)", rv, cv, co, cv2, false); // repair?
      throw new SimpleException("shouldn't get here");
    } catch (Throwable t) {
      Test.ensureEqual(
          t.toString(),
          "com.cohort.util.SimpleException: Error: destinationVariableName=p wasn't found in datasetID=LiquidR_HBG3_2015_weather.",
          "");
    }

    // test late time error
    try {
      tedd.parseUserDapQuery(
          language, "pressure&pressure<max(time)-2.5seconds", rv, cv, co, cv2, false); // repair?
      throw new SimpleException("shouldn't get here");
    } catch (Throwable t) {
      Test.ensureEqual(
          t.toString(),
          "com.cohort.util.SimpleException: Query error: Invalid \"max()\" constraint: \"max(time)-2.5seconds\". "
              + "Timestamp constraints with \"max()\" must be in the form "
              + "\"max(varName)[+|-positiveInteger[millis|seconds|minutes|hours|days|months|years]]\" (or singular units).",
          "");
    }

    // test late non-time error
    try {
      tedd.parseUserDapQuery(
          language, "pressure&pressure<max(pressure)-2.5a", rv, cv, co, cv2, false); // repair?
      throw new SimpleException("shouldn't get here");
    } catch (Throwable t) {
      Test.ensureEqual(
          t.toString(),
          "com.cohort.util.SimpleException: Query error: Invalid \"max()\" constraint: \"max(pressure)-2.5a\". "
              + "Non-timestamp constraints with \"max()\" must be in the form \"max(varName)[+|-positiveNumber]\".",
          "");
    }
  }

  /**
   * This tests sub-second time_precision in all output file types.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  void testTimePrecisionMillis() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testTimePrecisionMillis()\n");

    int language = 0;
    EDDTable eddTable = (EDDTable) EDDTestDataset.gettestTimePrecisionMillisTable();
    String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String userDapQuery =
        "time,ECEF_X,IB_time"
            + "&time>1984-02-01T12:00:59.001Z"
            + // value is .001, so this just barely fails
            "&time<=1984-02-01T12:00:59.401Z"; // value is .401, so this just barely succeeds
    String fName = "testTimePrecisionMillis";
    String tName, results, ts, expected;
    int po;

    // .asc
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".asc");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    Float64 time;\n"
            + "    Float32 ECEF_X;\n"
            + "    Float64 IB_time;\n"
            + "  } s;\n"
            + "} s;\n"
            + "---------------------------------------------\n"
            + "s.time, s.ECEF_X, s.IB_time\n"
            + "4.44484859101E8, 9.96921E36, 7.600176591E8\n"
            + "4.44484859201E8, 9.96921E36, 7.600176592E8\n"
            + "4.44484859301E8, 9.96921E36, 7.600176593E8\n"
            + "4.4448485940099996E8, 9.96921E36, 7.600176594E8\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "time,ECEF_X,IB_time\n"
            + "UTC,m,UTC\n"
            + "1984-02-01T12:00:59.101Z,9.96921E36,1994-01-31T12:00:59.100Z\n"
            + "1984-02-01T12:00:59.201Z,9.96921E36,1994-01-31T12:00:59.200Z\n"
            + "1984-02-01T12:00:59.301Z,9.96921E36,1994-01-31T12:00:59.300Z\n"
            + "1984-02-01T12:00:59.401Z,9.96921E36,1994-01-31T12:00:59.400Z\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .dods doesn't write strings

    // .htmlTable
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, tDir, fName, ".htmlTable");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "<table class=\"erd commonBGColor nowrap\">\n"
            + "<tr>\n"
            + "<th>time\n"
            + "<th>ECEF_X\n"
            + "<th>IB_time\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<th>UTC\n"
            + "<th>m\n"
            + "<th>UTC\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1984-02-01T12:00:59.101Z\n"
            + "<td class=\"R\">9.96921E36\n"
            + "<td>1994-01-31T12:00:59.100Z\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1984-02-01T12:00:59.201Z\n"
            + "<td class=\"R\">9.96921E36\n"
            + "<td>1994-01-31T12:00:59.200Z\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1984-02-01T12:00:59.301Z\n"
            + "<td class=\"R\">9.96921E36\n"
            + "<td>1994-01-31T12:00:59.300Z\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1984-02-01T12:00:59.401Z\n"
            + "<td class=\"R\">9.96921E36\n"
            + "<td>1994-01-31T12:00:59.400Z\n"
            + "</tr>\n"
            + "</table>\n";
    po = results.indexOf("<table class=\"erd");
    ts = results.substring(Math.max(0, po), Math.min(results.length(), po + expected.length()));
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);

    // .json
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".json");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "{\n"
            + "  \"table\": {\n"
            + "    \"columnNames\": [\"time\", \"ECEF_X\", \"IB_time\"],\n"
            + "    \"columnTypes\": [\"String\", \"float\", \"String\"],\n"
            + "    \"columnUnits\": [\"UTC\", \"m\", \"UTC\"],\n"
            + "    \"rows\": [\n"
            + "      [\"1984-02-01T12:00:59.101Z\", 9.96921E36, \"1994-01-31T12:00:59.100Z\"],\n"
            + "      [\"1984-02-01T12:00:59.201Z\", 9.96921E36, \"1994-01-31T12:00:59.200Z\"],\n"
            + "      [\"1984-02-01T12:00:59.301Z\", 9.96921E36, \"1994-01-31T12:00:59.300Z\"],\n"
            + "      [\"1984-02-01T12:00:59.401Z\", 9.96921E36, \"1994-01-31T12:00:59.400Z\"]\n"
            + "    ]\n"
            + "  }\n"
            + "}\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .mat doesn't write strings
    // !!! but need to test to ensure not rounding to the nearest second

    // .nc
    tName = eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".nc");
    results = NcHelper.ncdump(tDir + tName, "");
    expected =
        "netcdf testTimePrecisionMillis.nc {\n"
            + "  dimensions:\n"
            + "    row = 4;\n"
            + "  variables:\n"
            + "    double time(row=4);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 4.44484859101E8, 4.4448485940099996E8; // double\n"
            + // important
            // full
            // precision
            "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"L1a Outboard intermediate timestamp. Seconds since the J2K epoch\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :time_precision = \"1970-01-01T00:00:00.000Z\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    float ECEF_X(row=4);\n"
            + "      :actual_range = 9.96921E36f, 9.96921E36f; // float\n"
            + "      :ioos_category = \"Other\";\n"
            + "      :long_name = \"Spacecraft ECEF position X value\";\n"
            + "      :units = \"m\";\n"
            + "\n"
            + "    double IB_time(row=4);\n"
            + "      :actual_range = 7.600176591E8, 7.600176594E8; // double\n"
            + // important full
            // precision
            "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"L1a Inboard intermediate timestamp. Seconds since the J2K epoch\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :time_precision = \"1970-01-01T00:00:00.000Z\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :algorithm_date = \"2014-06-18\";\n"
            + "  :algorithm_version = \"OR_ALG_MAG_L1b_GEOF_v01r01.tgz\";\n"
            + "  :cdm_data_type = \"Other\";\n"
            + "  :dataset_name = \"IT_MAG-L1b-GEOF_G16_s2044065031446_e2044065031546_c2014064151446.nc\";\n";
    ts = results.substring(0, expected.length());
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);

    expected =
        "  :time_coverage_end = \"1984-02-01T12:00:59.401Z\";\n"
            + "  :time_coverage_start = \"1984-02-01T12:00:59.101Z\";\n"
            + "  :title = \"L1b Magnetometer (MAG) Geomagnetic Field Product\";\n"
            + "\n"
            + "  data:\n"
            + "    time = \n"
            + "      {4.44484859101E8, 4.44484859201E8, 4.44484859301E8, 4.4448485940099996E8}\n"
            + "    ECEF_X = \n"
            + "      {9.96921E36, 9.96921E36, 9.96921E36, 9.96921E36}\n"
            + "    IB_time = \n"
            + "      {7.600176591E8, 7.600176592E8, 7.600176593E8, 7.600176594E8}\n"
            + "}\n";
    po = results.indexOf("  :time_coverage_end");
    ts = results.substring(Math.max(0, po), Math.min(results.length(), po + expected.length()));
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);

    // .odvTxt
    /*
     * can't test because it needs lon lat values
     * tName = eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery,
     * tDir,
     * fName, ".odvTxt");
     * results = File2.directReadFrom88591File(tDir + tName);
     * expected =
     * "zztop\n";
     * Test.ensureEqual(results, expected, "\nresults=\n" + results);
     */

    // .xhtml
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".xhtml");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "<table class=\"erd commonBGColor nowrap\">\n"
            + "<tr>\n"
            + "<th>time</th>\n"
            + "<th>ECEF_X</th>\n"
            + "<th>IB_time</th>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<th>UTC</th>\n"
            + "<th>m</th>\n"
            + "<th>UTC</th>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1984-02-01T12:00:59.101Z</td>\n"
            + "<td class=\"R\">9.96921E36</td>\n"
            + "<td>1994-01-31T12:00:59.100Z</td>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1984-02-01T12:00:59.201Z</td>\n"
            + "<td class=\"R\">9.96921E36</td>\n"
            + "<td>1994-01-31T12:00:59.200Z</td>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1984-02-01T12:00:59.301Z</td>\n"
            + "<td class=\"R\">9.96921E36</td>\n"
            + "<td>1994-01-31T12:00:59.300Z</td>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1984-02-01T12:00:59.401Z</td>\n"
            + "<td class=\"R\">9.96921E36</td>\n"
            + "<td>1994-01-31T12:00:59.400Z</td>\n"
            + "</tr>\n"
            + "</table>\n";
    po = results.indexOf("<table ");
    ts = results.substring(Math.max(0, po), Math.min(results.length(), po + expected.length()));
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);
  }

  /**
   * This tests timestamps and other things.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  void testSimpleTestNcTable() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testSimpleTestNcTable()\n");

    int language = 0;
    EDDTable eddTable = (EDDTable) EDDTestDataset.gettestSimpleTestNcTable();
    String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String userDapQuery =
        "time,hours,minutes,seconds,millis,latitude,"
            + "longitude,ints,floats,doubles,Strings"
            + "&time>=1970-01-02T00:00:00Z"
            + // should just barely succeed, 86400
            "&time<1970-01-05T00:00:00Z"; // should just barely fail, 345600
    String fName = "testSimpleTestNcTable";
    String tName, results, ts, expected;
    int po;

    // String2.log(NcHelper.ncdump(EDStatic.unitTestDataDir + "simpleTest.nc", ""));

    // all
    tName = eddTable.makeNewFileForDapQuery(language, null, null, "", tDir, fName, ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "time,hours,minutes,seconds,millis,latitude,longitude,ints,floats,doubles,Strings\n"
            + "UTC,UTC,UTC,UTC,UTC,degrees_north,degrees_east,,,,\n"
            + "1970-01-02T00:00:00Z,1980-01-01T05:00:00Z,1990-01-01T00:09:00Z,2000-01-01T00:00:20Z,2010-01-01T00:00:00.030Z,40,10000,1000000,0.0,1.0E12,0\n"
            + "1970-01-03T00:00:00Z,1980-01-01T06:00:00Z,1990-01-01T00:10:00Z,2000-01-01T00:00:21Z,2010-01-01T00:00:00.031Z,41,10001,1000001,1.1,1.0000000000001E12,10\n"
            + "1970-01-04T00:00:00Z,1980-01-01T07:00:00Z,1990-01-01T00:11:00Z,2000-01-01T00:00:22Z,2010-01-01T00:00:00.032Z,42,10002,1000002,2.2,1.0000000000002E12,20\n"
            + "1970-01-05T00:00:00Z,1980-01-01T08:00:00Z,1990-01-01T00:12:00Z,2000-01-01T00:00:23Z,2010-01-01T00:00:00.033Z,43,10004,1000004,4.4,1.0000000000003E12,30\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .asc
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".asc");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    Float64 time;\n"
            + "    Float64 hours;\n"
            + "    Float64 minutes;\n"
            + "    Float64 seconds;\n"
            + "    Float64 millis;\n"
            + "    Byte latitude;\n"
            + "    Int16 longitude;\n"
            + "    Int32 ints;\n"
            + "    Float32 floats;\n"
            + "    Float64 doubles;\n"
            + "    String Strings;\n"
            + "  } s;\n"
            + "} s;\n"
            + "---------------------------------------------\n"
            + "s.time, s.hours, s.minutes, s.seconds, s.millis, s.latitude, s.longitude, s.ints, s.floats, s.doubles, s.Strings\n"
            + "86400.0, 3.155508E8, 6.3115254E8, 9.4668482E8, 1.26230400003E9, 40, 10000, 1000000, 0.0, 1.0E12, \"0\"\n"
            + "172800.0, 3.155544E8, 6.311526E8, 9.46684821E8, 1.262304000031E9, 41, 10001, 1000001, 1.1, 1.0000000000001E12, \"10\"\n"
            + "259200.0, 3.15558E8, 6.3115266E8, 9.46684822E8, 1.262304000032E9, 42, 10002, 1000002, 2.2, 1.0000000000002E12, \"20\"\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "time,hours,minutes,seconds,millis,latitude,longitude,ints,floats,doubles,Strings\n"
            + "UTC,UTC,UTC,UTC,UTC,degrees_north,degrees_east,,,,\n"
            + "1970-01-02T00:00:00Z,1980-01-01T05:00:00Z,1990-01-01T00:09:00Z,2000-01-01T00:00:20Z,2010-01-01T00:00:00.030Z,40,10000,1000000,0.0,1.0E12,0\n"
            + "1970-01-03T00:00:00Z,1980-01-01T06:00:00Z,1990-01-01T00:10:00Z,2000-01-01T00:00:21Z,2010-01-01T00:00:00.031Z,41,10001,1000001,1.1,1.0000000000001E12,10\n"
            + "1970-01-04T00:00:00Z,1980-01-01T07:00:00Z,1990-01-01T00:11:00Z,2000-01-01T00:00:22Z,2010-01-01T00:00:00.032Z,42,10002,1000002,2.2,1.0000000000002E12,20\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .dods hard to test

    // .geoJson
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, tDir, fName, ".geoJson");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "{\n"
            + "  \"type\": \"FeatureCollection\",\n"
            + "  \"propertyNames\": [\"time\", \"hours\", \"minutes\", \"seconds\", \"millis\", \"ints\", \"floats\", \"doubles\", \"Strings\"],\n"
            + "  \"propertyUnits\": [\"UTC\", \"UTC\", \"UTC\", \"UTC\", \"UTC\", null, null, null, null],\n"
            + "  \"features\": [\n"
            + "{\"type\": \"Feature\",\n"
            + "  \"geometry\": {\n"
            + "    \"type\": \"Point\",\n"
            + "    \"coordinates\": [10000.0, 40.0] },\n"
            + "  \"properties\": {\n"
            + "    \"time\": \"1970-01-02T00:00:00Z\",\n"
            + "    \"hours\": \"1980-01-01T05:00:00Z\",\n"
            + "    \"minutes\": \"1990-01-01T00:09:00Z\",\n"
            + "    \"seconds\": \"2000-01-01T00:00:20Z\",\n"
            + "    \"millis\": \"2010-01-01T00:00:00.030Z\",\n"
            + "    \"ints\": 1000000,\n"
            + "    \"floats\": 0.0,\n"
            + "    \"doubles\": 1.0E12,\n"
            + "    \"Strings\": \"0\" }\n"
            + "},\n"
            + "{\"type\": \"Feature\",\n"
            + "  \"geometry\": {\n"
            + "    \"type\": \"Point\",\n"
            + "    \"coordinates\": [10001.0, 41.0] },\n"
            + "  \"properties\": {\n"
            + "    \"time\": \"1970-01-03T00:00:00Z\",\n"
            + "    \"hours\": \"1980-01-01T06:00:00Z\",\n"
            + "    \"minutes\": \"1990-01-01T00:10:00Z\",\n"
            + "    \"seconds\": \"2000-01-01T00:00:21Z\",\n"
            + "    \"millis\": \"2010-01-01T00:00:00.031Z\",\n"
            + "    \"ints\": 1000001,\n"
            + "    \"floats\": 1.1,\n"
            + "    \"doubles\": 1.0000000000001E12,\n"
            + "    \"Strings\": \"10\" }\n"
            + "},\n"
            + "{\"type\": \"Feature\",\n"
            + "  \"geometry\": {\n"
            + "    \"type\": \"Point\",\n"
            + "    \"coordinates\": [10002.0, 42.0] },\n"
            + "  \"properties\": {\n"
            + "    \"time\": \"1970-01-04T00:00:00Z\",\n"
            + "    \"hours\": \"1980-01-01T07:00:00Z\",\n"
            + "    \"minutes\": \"1990-01-01T00:11:00Z\",\n"
            + "    \"seconds\": \"2000-01-01T00:00:22Z\",\n"
            + "    \"millis\": \"2010-01-01T00:00:00.032Z\",\n"
            + "    \"ints\": 1000002,\n"
            + "    \"floats\": 2.2,\n"
            + "    \"doubles\": 1.0000000000002E12,\n"
            + "    \"Strings\": \"20\" }\n"
            + "}\n"
            + "  ],\n"
            + "  \"bbox\": [10000.0, 40.0, 10002.0, 42.0]\n"
            + "}\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .htmlTable
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, tDir, fName, ".htmlTable");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "<table class=\"erd commonBGColor nowrap\">\n"
            + "<tr>\n"
            + "<th>time\n"
            + "<th>hours\n"
            + "<th>minutes\n"
            + "<th>seconds\n"
            + "<th>millis\n"
            + "<th>latitude\n"
            + "<th>longitude\n"
            + "<th>ints\n"
            + "<th>floats\n"
            + "<th>doubles\n"
            + "<th>Strings\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<th>UTC\n"
            + "<th>UTC\n"
            + "<th>UTC\n"
            + "<th>UTC\n"
            + "<th>UTC\n"
            + "<th>degrees_north\n"
            + "<th>degrees_east\n"
            + "<th>\n"
            + "<th>\n"
            + "<th>\n"
            + "<th>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-02\n"
            + "<td>1980-01-01T05Z\n"
            + "<td>1990-01-01T00:09Z\n"
            + "<td>2000-01-01T00:00:20Z\n"
            + "<td>2010-01-01T00:00:00.030Z\n"
            + "<td class=\"R\">40\n"
            + "<td class=\"R\">10000\n"
            + "<td class=\"R\">1000000\n"
            + "<td class=\"R\">0.0\n"
            + "<td class=\"R\">1.0E12\n"
            + "<td>0\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-03\n"
            + "<td>1980-01-01T06Z\n"
            + "<td>1990-01-01T00:10Z\n"
            + "<td>2000-01-01T00:00:21Z\n"
            + "<td>2010-01-01T00:00:00.031Z\n"
            + "<td class=\"R\">41\n"
            + "<td class=\"R\">10001\n"
            + "<td class=\"R\">1000001\n"
            + "<td class=\"R\">1.1\n"
            + "<td class=\"R\">1.0000000000001E12\n"
            + "<td>10\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-04\n"
            + "<td>1980-01-01T07Z\n"
            + "<td>1990-01-01T00:11Z\n"
            + "<td>2000-01-01T00:00:22Z\n"
            + "<td>2010-01-01T00:00:00.032Z\n"
            + "<td class=\"R\">42\n"
            + "<td class=\"R\">10002\n"
            + "<td class=\"R\">1000002\n"
            + "<td class=\"R\">2.2\n"
            + "<td class=\"R\">1.0000000000002E12\n"
            + "<td>20\n"
            + "</tr>\n"
            + "</table>\n";
    po = results.indexOf("<table class=\"erd");
    ts = results.substring(Math.max(0, po), Math.min(results.length(), po + expected.length()));
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);

    // .json
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".json");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "{\n"
            + "  \"table\": {\n"
            + "    \"columnNames\": [\"time\", \"hours\", \"minutes\", \"seconds\", \"millis\", \"latitude\", \"longitude\", \"ints\", \"floats\", \"doubles\", \"Strings\"],\n"
            + "    \"columnTypes\": [\"String\", \"String\", \"String\", \"String\", \"String\", \"byte\", \"short\", \"int\", \"float\", \"double\", \"String\"],\n"
            + "    \"columnUnits\": [\"UTC\", \"UTC\", \"UTC\", \"UTC\", \"UTC\", \"degrees_north\", \"degrees_east\", null, null, null, null],\n"
            + "    \"rows\": [\n"
            + "      [\"1970-01-02T00:00:00Z\", \"1980-01-01T05:00:00Z\", \"1990-01-01T00:09:00Z\", \"2000-01-01T00:00:20Z\", \"2010-01-01T00:00:00.030Z\", 40, 10000, 1000000, 0, 1.0E12, \"0\"],\n"
            + "      [\"1970-01-03T00:00:00Z\", \"1980-01-01T06:00:00Z\", \"1990-01-01T00:10:00Z\", \"2000-01-01T00:00:21Z\", \"2010-01-01T00:00:00.031Z\", 41, 10001, 1000001, 1.1, 1.0000000000001E12, \"10\"],\n"
            + "      [\"1970-01-04T00:00:00Z\", \"1980-01-01T07:00:00Z\", \"1990-01-01T00:11:00Z\", \"2000-01-01T00:00:22Z\", \"2010-01-01T00:00:00.032Z\", 42, 10002, 1000002, 2.2, 1.0000000000002E12, \"20\"]\n"
            + "    ]\n"
            + "  }\n"
            + "}\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .kml
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".kml");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n"
            + "<kml xmlns=\"http://www.opengis.net/kml/2.2\">\n"
            + "<Document>\n"
            + "  <name>My Title</name>\n"
            + "  <description><![CDATA[Data courtesy of NOAA NMFS SWFSC ERD\n"
            + "<br />My summary.\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;html&#x3f;time&#x2c;hours&#x2c;minutes&#x2c;seconds&#x2c;millis&#x2c;latitude&#x2c;l"
            + "ongitude&#x2c;ints&#x2c;floats&#x2c;doubles&#x2c;Strings&#x26;time&#x3e;&#x3d;1970&#x2d;01&#x2d;02T00&#x3a;00&#"
            + "x3a;00Z&#x26;time&#x3c;1970&#x2d;01&#x2d;05T00&#x3a;00&#x3a;00Z\">View/download more data from this dataset.</a>\n"
            + "    ]]></description>\n"
            + "  <open>1</open>\n"
            + "  <Style id=\"BUOY ON\">\n"
            + "    <IconStyle>\n"
            + "      <color>ff0099ff</color>\n"
            + "      <scale>1.2000000000000002</scale>\n"
            + "      <Icon>\n"
            + "        <href>https://maps.google.com/mapfiles/kml/shapes/placemark_circle.png</href>\n"
            + "      </Icon>\n"
            + "    </IconStyle>\n"
            + "  </Style>\n"
            + "  <Style id=\"BUOY OUT\">\n"
            + "    <IconStyle>\n"
            + "      <color>ff0099ff</color>\n"
            + "      <scale>0.8</scale>\n"
            + "      <Icon>\n"
            + "        <href>https://maps.google.com/mapfiles/kml/shapes/placemark_circle.png</href>\n"
            + "      </Icon>\n"
            + "    </IconStyle>\n"
            + "    <LabelStyle><scale>0</scale></LabelStyle>\n"
            + "  </Style>\n"
            + "  <StyleMap id=\"BUOY\">\n"
            + "    <Pair><key>normal</key><styleUrl>#BUOY OUT</styleUrl></Pair>\n"
            + "    <Pair><key>highlight</key><styleUrl>#BUOY ON</styleUrl></Pair>\n"
            + "  </StyleMap>\n"
            + "  <Placemark>\n"
            + "    <name>Lat=40, Lon=-80</name>\n"
            + "    <description><![CDATA[My Title\n"
            + "<br />Data courtesy of NOAA NMFS SWFSC ERD\n"
            + "<br />time = 1970-01-02\n"
            + "<br />hours = 1980-01-01T05Z\n"
            + "<br />minutes = 1990-01-01T00:09Z\n"
            + "<br />seconds = 2000-01-01T00:00:20Z\n"
            + "<br />millis = 2010-01-01T00:00:00.030Z\n"
            + "<br />latitude = 40 degrees_north\n"
            + "<br />longitude = 10000 degrees_east\n"
            + "<br />ints = 1000000\n"
            + "<br />floats = 0.0\n"
            + "<br />doubles = 1.0E12\n"
            + "<br />Strings = 0\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;htmlTable&#x3f;&#x26;time&#x25;3E&#x3d;1969&#x2d;12&#x2d;28&#x26;time&#x25;3C&#x3d;1"
            + "970&#x2d;01&#x2d;04&#x26;longitude&#x25;3E9999&#x2e;99&#x26;longitude&#x25;3C10000&#x2e;01&#x26;latitude&#x25;3"
            + "E39&#x2e;99&#x26;latitude&#x25;3C40&#x2e;01\">View tabular data for this location.</a>\n"
            + "\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;html&#x3f;time&#x2c;hours&#x2c;minutes&#x2c;seconds&#x2c;millis&#x2c;latitude&#x2c;l"
            + "ongitude&#x2c;ints&#x2c;floats&#x2c;doubles&#x2c;Strings&#x26;time&#x3e;&#x3d;1970&#x2d;01&#x2d;02T00&#x3a;00&#"
            + "x3a;00Z&#x26;time&#x3c;1970&#x2d;01&#x2d;05T00&#x3a;00&#x3a;00Z\">View/download more data from this dataset.</a>\n"
            + "]]></description>\n"
            + "    <styleUrl>#BUOY</styleUrl>\n"
            + "    <Point>\n"
            + "      <coordinates>-80.0,40.0</coordinates>\n"
            + "    </Point>\n"
            + "  </Placemark>\n"
            + "  <Placemark>\n"
            + "    <name>Lat=41, Lon=-79</name>\n"
            + "    <description><![CDATA[My Title\n"
            + "<br />Data courtesy of NOAA NMFS SWFSC ERD\n"
            + "<br />time = 1970-01-03\n"
            + "<br />hours = 1980-01-01T06Z\n"
            + "<br />minutes = 1990-01-01T00:10Z\n"
            + "<br />seconds = 2000-01-01T00:00:21Z\n"
            + "<br />millis = 2010-01-01T00:00:00.031Z\n"
            + "<br />latitude = 41 degrees_north\n"
            + "<br />longitude = 10001 degrees_east\n"
            + "<br />ints = 1000001\n"
            + "<br />floats = 1.1\n"
            + "<br />doubles = 1.0000000000001E12\n"
            + "<br />Strings = 10\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;htmlTable&#x3f;&#x26;time&#x25;3E&#x3d;1969&#x2d;12&#x2d;28&#x26;time&#x25;3C&#x3d;1"
            + "970&#x2d;01&#x2d;04&#x26;longitude&#x25;3E10000&#x2e;99&#x26;longitude&#x25;3C10001&#x2e;01&#x26;latitude&#x25;"
            + "3E40&#x2e;99&#x26;latitude&#x25;3C41&#x2e;01\">View tabular data for this location.</a>\n"
            + "\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;html&#x3f;time&#x2c;hours&#x2c;minutes&#x2c;seconds&#x2c;millis&#x2c;latitude&#x2c;l"
            + "ongitude&#x2c;ints&#x2c;floats&#x2c;doubles&#x2c;Strings&#x26;time&#x3e;&#x3d;1970&#x2d;01&#x2d;02T00&#x3a;00&#"
            + "x3a;00Z&#x26;time&#x3c;1970&#x2d;01&#x2d;05T00&#x3a;00&#x3a;00Z\">View/download more data from this dataset.</a>\n"
            + "]]></description>\n"
            + "    <styleUrl>#BUOY</styleUrl>\n"
            + "    <Point>\n"
            + "      <coordinates>-79.0,41.0</coordinates>\n"
            + "    </Point>\n"
            + "  </Placemark>\n"
            + "  <Placemark>\n"
            + "    <name>Lat=42, Lon=-78</name>\n"
            + "    <description><![CDATA[My Title\n"
            + "<br />Data courtesy of NOAA NMFS SWFSC ERD\n"
            + "<br />time = 1970-01-04\n"
            + "<br />hours = 1980-01-01T07Z\n"
            + "<br />minutes = 1990-01-01T00:11Z\n"
            + "<br />seconds = 2000-01-01T00:00:22Z\n"
            + "<br />millis = 2010-01-01T00:00:00.032Z\n"
            + "<br />latitude = 42 degrees_north\n"
            + "<br />longitude = 10002 degrees_east\n"
            + "<br />ints = 1000002\n"
            + "<br />floats = 2.2\n"
            + "<br />doubles = 1.0000000000002E12\n"
            + "<br />Strings = 20\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;htmlTable&#x3f;&#x26;time&#x25;3E&#x3d;1969&#x2d;12&#x2d;28&#x26;time&#x25;3C&#x3d;1"
            + "970&#x2d;01&#x2d;04&#x26;longitude&#x25;3E10001&#x2e;99&#x26;longitude&#x25;3C10002&#x2e;01&#x26;latitude&#x25;"
            + "3E41&#x2e;99&#x26;latitude&#x25;3C42&#x2e;01\">View tabular data for this location.</a>\n"
            + "\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;html&#x3f;time&#x2c;hours&#x2c;minutes&#x2c;seconds&#x2c;millis&#x2c;latitude&#x2c;l"
            + "ongitude&#x2c;ints&#x2c;floats&#x2c;doubles&#x2c;Strings&#x26;time&#x3e;&#x3d;1970&#x2d;01&#x2d;02T00&#x3a;00&#"
            + "x3a;00Z&#x26;time&#x3c;1970&#x2d;01&#x2d;05T00&#x3a;00&#x3a;00Z\">View/download more data from this dataset.</a>\n"
            + "]]></description>\n"
            + "    <styleUrl>#BUOY</styleUrl>\n"
            + "    <Point>\n"
            + "      <coordinates>-78.0,42.0</coordinates>\n"
            + "    </Point>\n"
            + "  </Placemark>\n"
            + "  <LookAt>\n"
            + "    <longitude>-79.0</longitude>\n"
            + "    <latitude>41.0</latitude>\n"
            + "    <range>466666.6666666667</range>\n"
            + "  </LookAt>\n"
            + "  <ScreenOverlay id=\"Logo\">\n"
            + "    <description>http://localhost:8080/erddap</description>\n"
            + "    <name>Logo</name>\n"
            + "    <Icon><href>http://localhost:8080/erddap/images/nlogo.gif</href></Icon>\n"
            + "    <overlayXY x=\"0.005\" y=\".04\" xunits=\"fraction\" yunits=\"fraction\"/>\n"
            + "    <screenXY x=\"0.005\" y=\".04\" xunits=\"fraction\" yunits=\"fraction\"/>\n"
            + "    <size x=\"0\" y=\"0\" xunits=\"pixels\" yunits=\"pixels\"/>\n"
            + "  </ScreenOverlay>\n"
            + "  </Document>\n"
            + "</kml>\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .mat is hard to test
    // !!! but need to test to ensure not rounding to the nearest second

    // .nc
    tName = eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".nc");
    results = NcHelper.ncdump(tDir + tName, "");
    expected =
        "netcdf testSimpleTestNcTable.nc {\n"
            + "  dimensions:\n"
            + "    row = 3;\n"
            + "    Strings_strlen = 2;\n"
            + "  variables:\n"
            + "    double time(row=3);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 86400.0, 259200.0; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :time_precision = \"1970-01-01\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    double hours(row=3);\n"
            + "      :actual_range = 3.155508E8, 3.15558E8; // double\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Hours\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :time_precision = \"1970-01-01T00Z\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    double minutes(row=3);\n"
            + "      :actual_range = 6.3115254E8, 6.3115266E8; // double\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Minutes\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :time_precision = \"1970-01-01T00:00Z\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    double seconds(row=3);\n"
            + "      :actual_range = 9.4668482E8, 9.46684822E8; // double\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Seconds\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :time_precision = \"not valid\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    double millis(row=3);\n"
            + "      :actual_range = 1.26230400003E9, 1.262304000032E9; // double\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Millis\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :time_precision = \"1970-01-01T00:00:00.000Z\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    byte latitude(row=3);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :actual_range = 40B, 42B; // byte\n"
            + "      :axis = \"Y\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "\n"
            + "    short longitude(row=3);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :actual_range = 10000S, 10002S; // short\n"
            + "      :axis = \"X\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "    int ints(row=3);\n"
            + "      :actual_range = 1000000, 1000002; // int\n"
            + "      :ioos_category = \"Unknown\";\n"
            + "\n"
            + "    float floats(row=3);\n"
            + "      :actual_range = 0.0f, 2.2f; // float\n"
            + "      :ioos_category = \"Unknown\";\n"
            + "\n"
            + "    double doubles(row=3);\n"
            + "      :actual_range = 1.0E12, 1.0000000000002E12; // double\n"
            + "      :ioos_category = \"Unknown\";\n"
            + "\n"
            + "    char Strings(row=3, Strings_strlen=2);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :ioos_category = \"Unknown\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"Point\";\n"
            + "  :Conventions = \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "  :Easternmost_Easting = 10002.0; // double\n"
            + "  :featureType = \"Point\";\n"
            + "  :geospatial_lat_max = 42.0; // double\n"
            + "  :geospatial_lat_min = 40.0; // double\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = 10002.0; // double\n"
            + "  :geospatial_lon_min = 10000.0; // double\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :history = \""; // 2014-10-22T16:16:21Z (local files)\n";
    ts = results.substring(0, expected.length());
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);

    expected =
        // "2014-10-22T16:16:21Z http://127.0.0.1:8080/cwexperimental
        "/tabledap/testSimpleTestNcTable.nc?time,hours,minutes,seconds,millis,latitude,longitude,ints,floats,doubles,Strings&time>=1970-01-02T00:00:00Z&time<1970-01-05T00:00:00Z\";\n"
            + "  :id = \"simpleTest\";\n"
            + "  :infoUrl = \"???\";\n"
            + "  :institution = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :keywords = \"data, local, longs, source, strings\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "  :Northernmost_Northing = 42.0; // double\n"
            + "  :sourceUrl = \"(local files)\";\n"
            + "  :Southernmost_Northing = 40.0; // double\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :summary = \"My summary.\";\n"
            + "  :time_coverage_end = \"1970-01-04\";\n"
            + "  :time_coverage_start = \"1970-01-02\";\n"
            + "  :title = \"My Title\";\n"
            + "  :Westernmost_Easting = 10000.0; // double\n"
            + "\n"
            + "  data:\n"
            + "    time = \n"
            + "      {86400.0, 172800.0, 259200.0}\n"
            + "    hours = \n"
            + "      {3.155508E8, 3.155544E8, 3.15558E8}\n"
            + "    minutes = \n"
            + "      {6.3115254E8, 6.311526E8, 6.3115266E8}\n"
            + "    seconds = \n"
            + "      {9.4668482E8, 9.46684821E8, 9.46684822E8}\n"
            + "    millis = \n"
            + "      {1.26230400003E9, 1.262304000031E9, 1.262304000032E9}\n"
            + "    latitude = \n"
            + "      {40, 41, 42}\n"
            + "    longitude = \n"
            + "      {10000, 10001, 10002}\n"
            + "    ints = \n"
            + "      {1000000, 1000001, 1000002}\n"
            + "    floats = \n"
            + "      {0.0, 1.1, 2.2}\n"
            + "    doubles = \n"
            + "      {1.0E12, 1.0000000000001E12, 1.0000000000002E12}\n"
            + "    Strings =   \"0\",   \"10\",   \"20\"\n"
            + "}\n";
    po = results.indexOf("/tabledap/testSimpleTestNcTable.nc?");
    ts = results.substring(Math.max(0, po), Math.min(results.length(), po + expected.length()));
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);

    // .odvTxt
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".odvTxt");
    results = String2.annotatedString(File2.directReadFromUtf8File(tDir + tName));
    results =
        results.replaceAll(
            "<CreateTime>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}",
            "<CreateTime>9999-99-99T99:99:99");
    expected =
        "//<Creator>???</Creator>[10]\n"
            + "//<CreateTime>9999-99-99T99:99:99</CreateTime>[10]\n"
            + "//<Encoding>UTF-8</Encoding>[10]\n"
            + "//<Software>ERDDAP - Version "
            + EDStatic.erddapVersion
            + "</Software>[10]\n"
            + "//<Source>http://localhost:8080/erddap/tabledap/testSimpleTestNcTable.html</Source>[10]\n"
            + "//<Version>ODV Spreadsheet V4.6</Version>[10]\n"
            + "//<DataField>GeneralField</DataField>[10]\n"
            + "//<DataType>GeneralType</DataType>[10]\n"
            + "//<MetaVariable>label=\"Cruise\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Station\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Type\" value_type=\"TEXT:2\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"yyyy-mm-ddThh:mm:ss.sss\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Time\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Longitude [degrees_east]\" value_type=\"SHORT\" is_primary_variable=\"F\" comment=\"Longitude\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Latitude [degrees_north]\" value_type=\"SIGNED_BYTE\" is_primary_variable=\"F\" comment=\"Latitude\" </MetaVariable>[10]\n"
            + "//<DataVariable>label=\"time_ISO8601\" value_type=\"DOUBLE\" is_primary_variable=\"T\" comment=\"Time\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"hours [seconds since 1970-01-01T00:00:00Z]\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Hours\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"minutes [seconds since 1970-01-01T00:00:00Z]\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Minutes\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"seconds [seconds since 1970-01-01T00:00:00Z]\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Seconds\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"millis [seconds since 1970-01-01T00:00:00Z]\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Millis\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"ints\" value_type=\"INTEGER\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"floats\" value_type=\"FLOAT\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"doubles\" value_type=\"DOUBLE\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"Strings\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "Cruise[9]Station[9]Type[9]yyyy-mm-ddThh:mm:ss.sss[9]Longitude [degrees_east][9]Latitude [degrees_north][9]time_ISO8601[9]hours [seconds since 1970-01-01T00:00:00Z][9]minutes [seconds since 1970-01-01T00:00:00Z][9]seconds [seconds since 1970-01-01T00:00:00Z][9]millis [seconds since 1970-01-01T00:00:00Z][9]ints[9]floats[9]doubles[9]Strings[10]\n"
            + "[9][9]*[9][9]10000[9]40[9]1970-01-02T00:00:00.000Z[9]3.155508E8[9]6.3115254E8[9]9.4668482E8[9]1.26230400003E9[9]1000000[9]0.0[9]1.0E12[9]0[10]\n"
            + "[9][9]*[9][9]10001[9]41[9]1970-01-03T00:00:00.000Z[9]3.155544E8[9]6.311526E8[9]9.46684821E8[9]1.262304000031E9[9]1000001[9]1.1[9]1.0000000000001E12[9]10[10]\n"
            + "[9][9]*[9][9]10002[9]42[9]1970-01-04T00:00:00.000Z[9]3.15558E8[9]6.3115266E8[9]9.46684822E8[9]1.262304000032E9[9]1000002[9]2.2[9]1.0000000000002E12[9]20[10]\n"
            + "[end]";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
    // String2.pressEnterToContinue("ODV file is " + tDir + tName);

    // .xhtml
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".xhtml");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n"
            + "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n"
            + "  \"https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n"
            + "<html xmlns=\"https://www.w3.org/1999/xhtml\">\n"
            + "<head>\n"
            + "  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\" />\n"
            + "  <title>testSimpleTestNcTable</title>\n"
            + "  <link rel=\"stylesheet\" type=\"text/css\" href=\"http://localhost:8080/erddap/images/erddap2.css\" />\n"
            + "</head>\n"
            + "<body>\n"
            + "\n"
            + "&nbsp;\n"
            + "<table class=\"erd commonBGColor nowrap\">\n"
            + "<tr>\n"
            + "<th>time</th>\n"
            + "<th>hours</th>\n"
            + "<th>minutes</th>\n"
            + "<th>seconds</th>\n"
            + "<th>millis</th>\n"
            + "<th>latitude</th>\n"
            + "<th>longitude</th>\n"
            + "<th>ints</th>\n"
            + "<th>floats</th>\n"
            + "<th>doubles</th>\n"
            + "<th>Strings</th>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<th>UTC</th>\n"
            + "<th>UTC</th>\n"
            + "<th>UTC</th>\n"
            + "<th>UTC</th>\n"
            + "<th>UTC</th>\n"
            + "<th>degrees_north</th>\n"
            + "<th>degrees_east</th>\n"
            + "<th></th>\n"
            + "<th></th>\n"
            + "<th></th>\n"
            + "<th></th>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-02T00:00:00Z</td>\n"
            + "<td>1980-01-01T05:00:00Z</td>\n"
            + "<td>1990-01-01T00:09:00Z</td>\n"
            + "<td>2000-01-01T00:00:20Z</td>\n"
            + "<td>2010-01-01T00:00:00.030Z</td>\n"
            + "<td class=\"R\">40</td>\n"
            + "<td class=\"R\">10000</td>\n"
            + "<td class=\"R\">1000000</td>\n"
            + "<td class=\"R\">0.0</td>\n"
            + "<td class=\"R\">1.0E12</td>\n"
            + "<td>0</td>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-03T00:00:00Z</td>\n"
            + "<td>1980-01-01T06:00:00Z</td>\n"
            + "<td>1990-01-01T00:10:00Z</td>\n"
            + "<td>2000-01-01T00:00:21Z</td>\n"
            + "<td>2010-01-01T00:00:00.031Z</td>\n"
            + "<td class=\"R\">41</td>\n"
            + "<td class=\"R\">10001</td>\n"
            + "<td class=\"R\">1000001</td>\n"
            + "<td class=\"R\">1.1</td>\n"
            + "<td class=\"R\">1.0000000000001E12</td>\n"
            + "<td>10</td>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-04T00:00:00Z</td>\n"
            + "<td>1980-01-01T07:00:00Z</td>\n"
            + "<td>1990-01-01T00:11:00Z</td>\n"
            + "<td>2000-01-01T00:00:22Z</td>\n"
            + "<td>2010-01-01T00:00:00.032Z</td>\n"
            + "<td class=\"R\">42</td>\n"
            + "<td class=\"R\">10002</td>\n"
            + "<td class=\"R\">1000002</td>\n"
            + "<td class=\"R\">2.2</td>\n"
            + "<td class=\"R\">1.0000000000002E12</td>\n"
            + "<td>20</td>\n"
            + "</tr>\n"
            + "</table>\n"
            + "</body>\n"
            + "</html>\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /**
   * This tests timestamps and other things.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  void testSimpleTestNc2Table() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testSimpleTestNc2Table()\n");

    int language = 0;
    EDDTable eddTable = (EDDTable) EDDTestDataset.gettestSimpleTestNcTable();
    String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String userDapQuery =
        "time,millis,latitude,longitude,doubles,Strings"
            + "&millis>2010-01-01T00:00:00.030Z"
            + // should reject .030 and accept 0.031
            "&millis<=2010-01-01T00:00:00.032Z"; // should accept 0.032, but reject 0.033
    String fName = "testSimpleTestNc2Table";
    String tName, results, ts, expected;
    int po;

    // String2.log(NcHelper.ncdump(EDStatic.unitTestDataDir + "simpleTest.nc", ""));

    // .asc
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".asc");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    Float64 time;\n"
            + "    Float64 millis;\n"
            + "    Byte latitude;\n"
            + "    Int16 longitude;\n"
            + "    Float64 doubles;\n"
            + "    String Strings;\n"
            + "  } s;\n"
            + "} s;\n"
            + "---------------------------------------------\n"
            + "s.time, s.millis, s.latitude, s.longitude, s.doubles, s.Strings\n"
            + "172800.0, 1.262304000031E9, 41, 10001, 1.0000000000001E12, \"10\"\n"
            + "259200.0, 1.262304000032E9, 42, 10002, 1.0000000000002E12, \"20\"\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .csv
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "time,millis,latitude,longitude,doubles,Strings\n"
            + "UTC,UTC,degrees_north,degrees_east,,\n"
            + "1970-01-03T00:00:00Z,2010-01-01T00:00:00.031Z,41,10001,1.0000000000001E12,10\n"
            + "1970-01-04T00:00:00Z,2010-01-01T00:00:00.032Z,42,10002,1.0000000000002E12,20\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .dods hard to test

    // .geoJson
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, tDir, fName, ".geoJson");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "{\n"
            + "  \"type\": \"FeatureCollection\",\n"
            + "  \"propertyNames\": [\"time\", \"millis\", \"doubles\", \"Strings\"],\n"
            + "  \"propertyUnits\": [\"UTC\", \"UTC\", null, null],\n"
            + "  \"features\": [\n"
            + "{\"type\": \"Feature\",\n"
            + "  \"geometry\": {\n"
            + "    \"type\": \"Point\",\n"
            + "    \"coordinates\": [10001.0, 41.0] },\n"
            + "  \"properties\": {\n"
            + "    \"time\": \"1970-01-03T00:00:00Z\",\n"
            + "    \"millis\": \"2010-01-01T00:00:00.031Z\",\n"
            + "    \"doubles\": 1.0000000000001E12,\n"
            + "    \"Strings\": \"10\" }\n"
            + "},\n"
            + "{\"type\": \"Feature\",\n"
            + "  \"geometry\": {\n"
            + "    \"type\": \"Point\",\n"
            + "    \"coordinates\": [10002.0, 42.0] },\n"
            + "  \"properties\": {\n"
            + "    \"time\": \"1970-01-04T00:00:00Z\",\n"
            + "    \"millis\": \"2010-01-01T00:00:00.032Z\",\n"
            + "    \"doubles\": 1.0000000000002E12,\n"
            + "    \"Strings\": \"20\" }\n"
            + "}\n"
            + "  ],\n"
            + "  \"bbox\": [10001.0, 41.0, 10002.0, 42.0]\n"
            + "}\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .htmlTable
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, userDapQuery, tDir, fName, ".htmlTable");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "<table class=\"erd commonBGColor nowrap\">\n"
            + "<tr>\n"
            + "<th>time\n"
            + "<th>millis\n"
            + "<th>latitude\n"
            + "<th>longitude\n"
            + "<th>doubles\n"
            + "<th>Strings\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<th>UTC\n"
            + "<th>UTC\n"
            + "<th>degrees_north\n"
            + "<th>degrees_east\n"
            + "<th>\n"
            + "<th>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-03\n"
            + "<td>2010-01-01T00:00:00.031Z\n"
            + "<td class=\"R\">41\n"
            + "<td class=\"R\">10001\n"
            + "<td class=\"R\">1.0000000000001E12\n"
            + "<td>10\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-04\n"
            + "<td>2010-01-01T00:00:00.032Z\n"
            + "<td class=\"R\">42\n"
            + "<td class=\"R\">10002\n"
            + "<td class=\"R\">1.0000000000002E12\n"
            + "<td>20\n"
            + "</tr>\n"
            + "</table>\n";
    po = results.indexOf("<table class=\"erd");
    ts = results.substring(Math.max(0, po), Math.min(results.length(), po + expected.length()));
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);

    // .json
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".json");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "{\n"
            + "  \"table\": {\n"
            + "    \"columnNames\": [\"time\", \"millis\", \"latitude\", \"longitude\", \"doubles\", \"Strings\"],\n"
            + "    \"columnTypes\": [\"String\", \"String\", \"byte\", \"short\", \"double\", \"String\"],\n"
            + "    \"columnUnits\": [\"UTC\", \"UTC\", \"degrees_north\", \"degrees_east\", null, null],\n"
            + "    \"rows\": [\n"
            + "      [\"1970-01-03T00:00:00Z\", \"2010-01-01T00:00:00.031Z\", 41, 10001, 1.0000000000001E12, \"10\"],\n"
            + "      [\"1970-01-04T00:00:00Z\", \"2010-01-01T00:00:00.032Z\", 42, 10002, 1.0000000000002E12, \"20\"]\n"
            + "    ]\n"
            + "  }\n"
            + "}\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .kml
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".kml");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n"
            + "<kml xmlns=\"http://www.opengis.net/kml/2.2\">\n"
            + "<Document>\n"
            + "  <name>My Title</name>\n"
            + "  <description><![CDATA[Data courtesy of NOAA NMFS SWFSC ERD\n"
            + "<br />My summary.\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;html&#x3f;time&#x2c;millis&#x2c;latitude&#x2c;longitude&#x2c;doubles&#x2c;Strings&#x"
            + "26;millis&#x3e;2010&#x2d;01&#x2d;01T00&#x3a;00&#x3a;00&#x2e;030Z&#x26;millis&#x3c;&#x3d;2010&#x2d;01&#x2d;01T00"
            + "&#x3a;00&#x3a;00&#x2e;032Z\">View/download more data from this dataset.</a>\n"
            + "    ]]></description>\n"
            + "  <open>1</open>\n"
            + "  <Style id=\"BUOY ON\">\n"
            + "    <IconStyle>\n"
            + "      <color>ff0099ff</color>\n"
            + "      <scale>1.2000000000000002</scale>\n"
            + "      <Icon>\n"
            + "        <href>https://maps.google.com/mapfiles/kml/shapes/placemark_circle.png</href>\n"
            + "      </Icon>\n"
            + "    </IconStyle>\n"
            + "  </Style>\n"
            + "  <Style id=\"BUOY OUT\">\n"
            + "    <IconStyle>\n"
            + "      <color>ff0099ff</color>\n"
            + "      <scale>0.8</scale>\n"
            + "      <Icon>\n"
            + "        <href>https://maps.google.com/mapfiles/kml/shapes/placemark_circle.png</href>\n"
            + "      </Icon>\n"
            + "    </IconStyle>\n"
            + "    <LabelStyle><scale>0</scale></LabelStyle>\n"
            + "  </Style>\n"
            + "  <StyleMap id=\"BUOY\">\n"
            + "    <Pair><key>normal</key><styleUrl>#BUOY OUT</styleUrl></Pair>\n"
            + "    <Pair><key>highlight</key><styleUrl>#BUOY ON</styleUrl></Pair>\n"
            + "  </StyleMap>\n"
            + "  <Placemark>\n"
            + "    <name>Lat=41, Lon=-79</name>\n"
            + "    <description><![CDATA[My Title\n"
            + "<br />Data courtesy of NOAA NMFS SWFSC ERD\n"
            + "<br />time = 1970-01-03\n"
            + "<br />millis = 2010-01-01T00:00:00.031Z\n"
            + "<br />latitude = 41 degrees_north\n"
            + "<br />longitude = 10001 degrees_east\n"
            + "<br />doubles = 1.0000000000001E12\n"
            + "<br />Strings = 10\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;htmlTable&#x3f;&#x26;time&#x25;3E&#x3d;1969&#x2d;12&#x2d;28&#x26;time&#x25;3C&#x3d;1"
            + "970&#x2d;01&#x2d;04&#x26;longitude&#x25;3E10000&#x2e;99&#x26;longitude&#x25;3C10001&#x2e;01&#x26;latitude&#x25;"
            + "3E40&#x2e;99&#x26;latitude&#x25;3C41&#x2e;01\">View tabular data for this location.</a>\n"
            + "\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;html&#x3f;time&#x2c;millis&#x2c;latitude&#x2c;longitude&#x2c;doubles&#x2c;Strings&#x"
            + "26;millis&#x3e;2010&#x2d;01&#x2d;01T00&#x3a;00&#x3a;00&#x2e;030Z&#x26;millis&#x3c;&#x3d;2010&#x2d;01&#x2d;01T00"
            + "&#x3a;00&#x3a;00&#x2e;032Z\">View/download more data from this dataset.</a>\n"
            + "]]></description>\n"
            + "    <styleUrl>#BUOY</styleUrl>\n"
            + "    <Point>\n"
            + "      <coordinates>-79.0,41.0</coordinates>\n"
            + "    </Point>\n"
            + "  </Placemark>\n"
            + "  <Placemark>\n"
            + "    <name>Lat=42, Lon=-78</name>\n"
            + "    <description><![CDATA[My Title\n"
            + "<br />Data courtesy of NOAA NMFS SWFSC ERD\n"
            + "<br />time = 1970-01-04\n"
            + "<br />millis = 2010-01-01T00:00:00.032Z\n"
            + "<br />latitude = 42 degrees_north\n"
            + "<br />longitude = 10002 degrees_east\n"
            + "<br />doubles = 1.0000000000002E12\n"
            + "<br />Strings = 20\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;htmlTable&#x3f;&#x26;time&#x25;3E&#x3d;1969&#x2d;12&#x2d;28&#x26;time&#x25;3C&#x3d;1"
            + "970&#x2d;01&#x2d;04&#x26;longitude&#x25;3E10001&#x2e;99&#x26;longitude&#x25;3C10002&#x2e;01&#x26;latitude&#x25;"
            + "3E41&#x2e;99&#x26;latitude&#x25;3C42&#x2e;01\">View tabular data for this location.</a>\n"
            + "\n"
            + "<br /><a href=\"http&#x3a;&#x2f;&#x2f;localhost&#x3a;8080&#x2f;erddap&#x2f;tabledap&#x2f;"
            + "testSimpleTestNcTable&#x2e;html&#x3f;time&#x2c;millis&#x2c;latitude&#x2c;longitude&#x2c;doubles&#x2c;Strings&#x"
            + "26;millis&#x3e;2010&#x2d;01&#x2d;01T00&#x3a;00&#x3a;00&#x2e;030Z&#x26;millis&#x3c;&#x3d;2010&#x2d;01&#x2d;01T00"
            + "&#x3a;00&#x3a;00&#x2e;032Z\">View/download more data from this dataset.</a>\n"
            + "]]></description>\n"
            + "    <styleUrl>#BUOY</styleUrl>\n"
            + "    <Point>\n"
            + "      <coordinates>-78.0,42.0</coordinates>\n"
            + "    </Point>\n"
            + "  </Placemark>\n"
            + "  <LookAt>\n"
            + "    <longitude>-78.5</longitude>\n"
            + "    <latitude>41.5</latitude>\n"
            + "    <range>466666.6666666667</range>\n"
            + "  </LookAt>\n"
            + "  <ScreenOverlay id=\"Logo\">\n"
            + "    <description>http://localhost:8080/erddap</description>\n"
            + "    <name>Logo</name>\n"
            + "    <Icon><href>http://localhost:8080/erddap/images/nlogo.gif</href></Icon>\n"
            + "    <overlayXY x=\"0.005\" y=\".04\" xunits=\"fraction\" yunits=\"fraction\"/>\n"
            + "    <screenXY x=\"0.005\" y=\".04\" xunits=\"fraction\" yunits=\"fraction\"/>\n"
            + "    <size x=\"0\" y=\"0\" xunits=\"pixels\" yunits=\"pixels\"/>\n"
            + "  </ScreenOverlay>\n"
            + "  </Document>\n"
            + "</kml>\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .mat hard to test
    // !!! but need to test to ensure not rounding to the nearest second

    // .nc
    tName = eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".nc");
    results = NcHelper.ncdump(tDir + tName, "");
    expected =
        "netcdf testSimpleTestNc2Table.nc {\n"
            + "  dimensions:\n"
            + "    row = 2;\n"
            + "    Strings_strlen = 2;\n"
            + "  variables:\n"
            + "    double time(row=2);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 172800.0, 259200.0; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :time_precision = \"1970-01-01\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    double millis(row=2);\n"
            + "      :actual_range = 1.262304000031E9, 1.262304000032E9; // double\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Millis\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :time_precision = \"1970-01-01T00:00:00.000Z\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    byte latitude(row=2);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :actual_range = 41B, 42B; // byte\n"
            + "      :axis = \"Y\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "\n"
            + "    short longitude(row=2);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :actual_range = 10001S, 10002S; // short\n"
            + "      :axis = \"X\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "    double doubles(row=2);\n"
            + "      :actual_range = 1.0000000000001E12, 1.0000000000002E12; // double\n"
            + "      :ioos_category = \"Unknown\";\n"
            + "\n"
            + "    char Strings(row=2, Strings_strlen=2);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :ioos_category = \"Unknown\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"Point\";\n"
            + "  :Conventions = \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "  :Easternmost_Easting = 10002.0; // double\n"
            + "  :featureType = \"Point\";\n"
            + "  :geospatial_lat_max = 42.0; // double\n"
            + "  :geospatial_lat_min = 41.0; // double\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = 10002.0; // double\n"
            + "  :geospatial_lon_min = 10001.0; // double\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :history = \""; // 2014-10-22T16:16:21Z (local files)\n";
    ts = results.substring(0, expected.length());
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);

    expected =
        // "2014-10-22T16:16:21Z http://127.0.0.1:8080/cwexperimental
        "/tabledap/testSimpleTestNcTable.nc?time,millis,latitude,longitude,doubles,Strings&millis>2010-01-01T00:00:00.030Z&millis<=2010-01-01T00:00:00.032Z\";\n"
            + "  :id = \"simpleTest\";\n"
            + "  :infoUrl = \"???\";\n"
            + "  :institution = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :keywords = \"data, local, longs, source, strings\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "  :Northernmost_Northing = 42.0; // double\n"
            + "  :sourceUrl = \"(local files)\";\n"
            + "  :Southernmost_Northing = 41.0; // double\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :summary = \"My summary.\";\n"
            + "  :time_coverage_end = \"1970-01-04\";\n"
            + "  :time_coverage_start = \"1970-01-03\";\n"
            + "  :title = \"My Title\";\n"
            + "  :Westernmost_Easting = 10001.0; // double\n"
            + "\n"
            + "  data:\n"
            + "    time = \n"
            + "      {172800.0, 259200.0}\n"
            + "    millis = \n"
            + "      {1.262304000031E9, 1.262304000032E9}\n"
            + "    latitude = \n"
            + "      {41, 42}\n"
            + "    longitude = \n"
            + "      {10001, 10002}\n"
            + "    doubles = \n"
            + "      {1.0000000000001E12, 1.0000000000002E12}\n"
            + "    Strings =   \"10\",   \"20\"\n"
            + "}\n";
    po = results.indexOf("/tabledap/testSimpleTestNcTable.nc?");
    ts = results.substring(Math.max(0, po), Math.min(results.length(), po + expected.length()));
    Test.ensureEqual(ts, expected, "\nresults=\n" + results);

    // .odvTxt
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".odvTxt");
    results = String2.annotatedString(File2.directReadFromUtf8File(tDir + tName));
    results =
        results.replaceAll(
            "<CreateTime>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}",
            "<CreateTime>9999-99-99T99:99:99");
    expected =
        "//<Creator>???</Creator>[10]\n"
            + "//<CreateTime>9999-99-99T99:99:99</CreateTime>[10]\n"
            + "//<Encoding>UTF-8</Encoding>[10]\n"
            + "//<Software>ERDDAP - Version "
            + EDStatic.erddapVersion
            + "</Software>[10]\n"
            + "//<Source>http://localhost:8080/erddap/tabledap/testSimpleTestNcTable.html</Source>[10]\n"
            + "//<Version>ODV Spreadsheet V4.6</Version>[10]\n"
            + "//<DataField>GeneralField</DataField>[10]\n"
            + "//<DataType>GeneralType</DataType>[10]\n"
            + "//<MetaVariable>label=\"Cruise\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Station\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Type\" value_type=\"TEXT:2\" is_primary_variable=\"F\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"yyyy-mm-ddThh:mm:ss.sss\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Time\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Longitude [degrees_east]\" value_type=\"SHORT\" is_primary_variable=\"F\" comment=\"Longitude\" </MetaVariable>[10]\n"
            + "//<MetaVariable>label=\"Latitude [degrees_north]\" value_type=\"SIGNED_BYTE\" is_primary_variable=\"F\" comment=\"Latitude\" </MetaVariable>[10]\n"
            + "//<DataVariable>label=\"time_ISO8601\" value_type=\"DOUBLE\" is_primary_variable=\"T\" comment=\"Time\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"millis [seconds since 1970-01-01T00:00:00Z]\" value_type=\"DOUBLE\" is_primary_variable=\"F\" comment=\"Millis\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"doubles\" value_type=\"DOUBLE\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "//<DataVariable>label=\"Strings\" value_type=\"INDEXED_TEXT\" is_primary_variable=\"F\" </DataVariable>[10]\n"
            + "Cruise[9]Station[9]Type[9]yyyy-mm-ddThh:mm:ss.sss[9]Longitude [degrees_east][9]Latitude [degrees_north][9]time_ISO8601[9]millis [seconds since 1970-01-01T00:00:00Z][9]doubles[9]Strings[10]\n"
            + "[9][9]*[9][9]10001[9]41[9]1970-01-03T00:00:00.000Z[9]1.262304000031E9[9]1.0000000000001E12[9]10[10]\n"
            + "[9][9]*[9][9]10002[9]42[9]1970-01-04T00:00:00.000Z[9]1.262304000032E9[9]1.0000000000002E12[9]20[10]\n"
            + "[end]";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // .xhtml
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, tDir, fName, ".xhtml");
    results = File2.directReadFromUtf8File(tDir + tName);
    expected =
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n"
            + "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n"
            + "  \"https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n"
            + "<html xmlns=\"https://www.w3.org/1999/xhtml\">\n"
            + "<head>\n"
            + "  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\" />\n"
            + "  <title>testSimpleTestNc2Table</title>\n"
            + "  <link rel=\"stylesheet\" type=\"text/css\" href=\"http://localhost:8080/erddap/images/erddap2.css\" />\n"
            + "</head>\n"
            + "<body>\n"
            + "\n"
            + "&nbsp;\n"
            + "<table class=\"erd commonBGColor nowrap\">\n"
            + "<tr>\n"
            + "<th>time</th>\n"
            + "<th>millis</th>\n"
            + "<th>latitude</th>\n"
            + "<th>longitude</th>\n"
            + "<th>doubles</th>\n"
            + "<th>Strings</th>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<th>UTC</th>\n"
            + "<th>UTC</th>\n"
            + "<th>degrees_north</th>\n"
            + "<th>degrees_east</th>\n"
            + "<th></th>\n"
            + "<th></th>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-03T00:00:00Z</td>\n"
            + "<td>2010-01-01T00:00:00.031Z</td>\n"
            + "<td class=\"R\">41</td>\n"
            + "<td class=\"R\">10001</td>\n"
            + "<td class=\"R\">1.0000000000001E12</td>\n"
            + "<td>10</td>\n"
            + "</tr>\n"
            + "<tr>\n"
            + "<td>1970-01-04T00:00:00Z</td>\n"
            + "<td>2010-01-01T00:00:00.032Z</td>\n"
            + "<td class=\"R\">42</td>\n"
            + "<td class=\"R\">10002</td>\n"
            + "<td class=\"R\">1.0000000000002E12</td>\n"
            + "<td>20</td>\n"
            + "</tr>\n"
            + "</table>\n"
            + "</body>\n"
            + "</html>\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /**
   * This tests addVariablesWhere.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  void testAddVariablesWhere() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testAddVariablesWhere()\n");

    int language = 0;
    EDDTableFromNcFiles eddTable = (EDDTableFromNcFiles) EDDTestDataset.getminiNdbc();
    EDV timeEdv = eddTable.dataVariables()[eddTable.timeIndex];
    EDV lonEdv = eddTable.dataVariables()[eddTable.lonIndex];
    String dataDir = eddTable.fileDir;
    String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String tName, results, expected;

    // test incorrect nValues
    try {
      results = "shouldn't happen";
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "time&station=\"41024\"&addVariablesWhere(\"ioos_category\")",
              tDir,
              eddTable.className() + "_avw_1",
              ".csv");
      results = "shouldn't get here";
    } catch (Exception e) {
      results = e.toString();
    }
    expected =
        "com.cohort.util.SimpleException: Query error: &addVariablesWhere() MUST have 2 parameters: attributeName and attributeValue.";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test unknown attributeName -- should be ignored / simply not matched
    results = "shouldn't happen";
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            "time&station=\"41024\"&time>=\"2015-01-23T17:00:00Z\"&addVariablesWhere(\"nonsense\",\"Wind\")",
            tDir,
            eddTable.className() + "_avw_2",
            ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "time\n"
            + "UTC\n"
            + "2015-01-23T17:00:00Z\n"
            + "2015-01-23T18:00:00Z\n"
            + "2015-01-23T19:00:00Z\n"
            + "2015-01-23T20:00:00Z\n"
            + "2015-01-23T21:00:00Z\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test unknown attributeValue -- should be ignored / simply not matched
    results = "shouldn't happen";
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            "time&station=\"41024\"&time>=\"2015-01-23T17:00:00Z\"&addVariablesWhere(\"ioos_category\",\"nonsense\")",
            tDir,
            eddTable.className() + "_avw_2",
            ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    // same expected
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test of predefined (doesn't need to be) addVariablesWhere()
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            "time&station=\"41024\"&time>=\"2015-01-23T17:00:00Z\"&addVariablesWhere(\"ioos_category\",\"Wind\")",
            tDir,
            eddTable.className() + "_avw_3",
            ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "time,wd,wspd,gst,wspu,wspv\n"
            + "UTC,degrees_true,m s-1,m s-1,m s-1,m s-1\n"
            + "2015-01-23T17:00:00Z,70,6.0,7.0,-5.6,-2.1\n"
            + "2015-01-23T18:00:00Z,70,9.0,11.0,-8.5,-3.1\n"
            + "2015-01-23T19:00:00Z,50,7.0,9.0,-5.4,-4.5\n"
            + "2015-01-23T20:00:00Z,50,6.0,7.0,-4.6,-3.9\n"
            + "2015-01-23T21:00:00Z,50,7.0,8.0,-5.4,-4.5\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // test of other addVariablesWhere() and test of 2 &addVariablesWhere
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            "time&station=\"41024\"&time>=\"2015-01-23T17:00:00Z\""
                + "&addVariablesWhere(\"long_name\",\"Latitude\")"
                + "&addVariablesWhere(\"long_name\",\"Longitude\")",
            tDir,
            eddTable.className() + "_avw_4",
            ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    expected =
        "time,latitude,longitude\n"
            + "UTC,degrees_north,degrees_east\n"
            + "2015-01-23T17:00:00Z,33.848,-78.489\n"
            + "2015-01-23T18:00:00Z,33.848,-78.489\n"
            + "2015-01-23T19:00:00Z,33.848,-78.489\n"
            + "2015-01-23T20:00:00Z,33.848,-78.489\n"
            + "2015-01-23T21:00:00Z,33.848,-78.489\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /**
   * This tests the EDDTableFromFiles.update(). This tests with a variable from the file name, a
   * fixed value variable, and 2 global: variables.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagSlowTests
  void testUpdate() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testUpdate()\n");

    int language = 0;
    EDDTableFromNcFiles eddTable = (EDDTableFromNcFiles) EDDTestDataset.getminiNdbc();
    EDV timeEdv = eddTable.dataVariables()[eddTable.timeIndex];
    EDV lonEdv = eddTable.dataVariables()[eddTable.lonIndex];
    String dataDir = eddTable.fileDir;
    String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String subsetQuery = "station,longitude,latitude&distinct()&orderBy(\"station\")";
    String dataQuery =
        "station,longitude,latitude,geolon,geolat,luckySeven,time,atmp&time=\"2014-12-01T00:00:00\"&orderBy(\"station\")";
    String tName, results, expected;

    // fix trouble if left in bad state previously
    if (!File2.isFile(dataDir + "NDBC_41025_met.nc")
        && File2.isFile(dataDir + "NDBC_41025_met.nc2")) {
      File2.rename(dataDir, "NDBC_41025_met.nc2", "NDBC_41025_met.nc");
      for (int i = 0; i < 3; i++) { // Windows is slow, give it a few tries
        Math2.sleep(1000);
        String2.log(
            "a) after rename .nc2 to .nc, call update() i=" + i + ": " + eddTable.update(language));
      }
    }

    String originalExpectedSubset =
        "station,longitude,latitude\n"
            + ",degrees_east,degrees_north\n"
            + "41024,-78.489,33.848\n"
            + "41025,-75.402,35.006\n"
            + // this has max lon and min and max time
            "41029,-79.63,32.81\n"
            + "41033,-80.41,32.28\n";

    String originalExpectedData =
        "station,longitude,latitude,geolon,geolat,luckySeven,time,atmp\n"
            + ",degrees_east,degrees_north,degrees_north,degrees_north,m,UTC,degree_C\n"
            + "41024,-78.489,33.848,-78.489,33.848,7.0,2014-12-01T00:00:00Z,14.2\n"
            + "41025,-75.402,35.006,-75.402,35.006,7.0,2014-12-01T00:00:00Z,19.5\n"
            + "41029,-79.63,32.81,-79.63,32.81,7.0,2014-12-01T00:00:00Z,14.5\n"
            + "41033,-80.41,32.28,-80.41,32.28,7.0,2014-12-01T00:00:00Z,NaN\n";

    String oldMinTime = "2003-03-28T19:00:00Z";
    String oldMinMillis = "1.048878E9";
    String newMinTime = "2005-02-23T15:00:00Z"; // after renaming a file to make it invalid
    String newMinMillis = "1.1091708E9";
    String oldMaxTime = "2015-01-23T22:00:00Z";
    String oldMaxMillis = "1.4220504E9";
    String newMaxTime = "2015-01-23T21:00:00Z";
    String newMaxMillis = "1.4220468E9";

    String oldMinLon = "-80.41";
    String oldMaxLon = "-75.402";
    String newMaxLon = "-78.489";

    // subsetVariables
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, subsetQuery, tDir, eddTable.className() + "_update_0sub", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalExpectedSubset, "\nresults=\n" + results);

    // time min/max
    Test.ensureEqual(timeEdv.destinationMinString(), oldMinTime, "edvTime.destinationMin");
    Test.ensureEqual(timeEdv.destinationMaxString(), oldMaxTime, "edvTime.destinationMax");
    Test.ensureEqual(
        timeEdv.combinedAttributes().get("actual_range").toString(),
        oldMinMillis + ", " + oldMaxMillis,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_start"),
        oldMinTime,
        "time_coverage_start");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_end"),
        oldMaxTime,
        "time_coverage_end");

    // lon min/max
    Test.ensureEqual(lonEdv.destinationMinString(), oldMinLon, "edvLon.destinationMin");
    Test.ensureEqual(lonEdv.destinationMaxString(), oldMaxLon, "edvLon.destinationMax");
    Test.ensureEqual(
        lonEdv.combinedAttributes().get("actual_range").toString(),
        oldMinLon + ", " + oldMaxLon,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_min"),
        oldMinLon,
        "geospatial_lon_min");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_max"),
        oldMaxLon,
        "geospatial_lon_max");

    // *** read the original data
    String2.log("\n*** read original data\n");
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dataQuery, tDir, eddTable.className() + "_update_0d", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalExpectedData, "\nresults=\n" + results);

    // *** rename a data file so it doesn't match regex
    try {
      String2.log("\n*** rename a data file so it doesn't match regex\n");
      File2.rename(dataDir, "NDBC_41025_met.nc", "NDBC_41025_met.nc2");
      for (int i = 0; i < 5; i++) { // Windows is slow, give it a few tries
        Math2.sleep(1000);
        String2.log(
            "b) after rename .nc to .nc2, call update() i=" + i + ": " + eddTable.update(language));
      }

      // subsetVariables should be different
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              subsetQuery,
              tDir,
              eddTable.className() + "_update_1sub",
              ".csv");
      results = File2.directReadFrom88591File(tDir + tName);
      expected =
          "station,longitude,latitude\n"
              + ",degrees_east,degrees_north\n"
              + "41024,-78.489,33.848\n"
              + "41025,-75.402,35.006\n"
              + "41029,-79.63,32.81\n"
              + "41033,-80.41,32.28\n";
      try {
        Test.ensureEqual(results, expected, "\nresults=\n" + results);
      } catch (Throwable t3) {
        Test.knownProblem(
            "update() doesn't update subsetVariables (which is fine most of the time).", "", t3);
      }

      // min and max time should be different
      Test.ensureEqual(timeEdv.destinationMinString(), newMinTime, "edvTime.destinationMin");
      Test.ensureEqual(timeEdv.destinationMaxString(), newMaxTime, "edvTime.destinationMax");
      Test.ensureEqual(
          timeEdv.combinedAttributes().get("actual_range").toString(),
          newMinMillis + ", " + newMaxMillis,
          "actual_range");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("time_coverage_start"),
          newMinTime,
          "time_coverage_start");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("time_coverage_end"),
          newMaxTime,
          "time_coverage_end");

      // max lon should be different
      Test.ensureEqual(lonEdv.destinationMinString(), oldMinLon, "edvLon.destinationMin");
      Test.ensureEqual(lonEdv.destinationMaxString(), newMaxLon, "edvLon.destinationMax");
      Test.ensureEqual(
          lonEdv.combinedAttributes().get("actual_range").toString(),
          oldMinLon + ", " + newMaxLon,
          "actual_range");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("geospatial_lon_min"),
          oldMinLon,
          "geospatial_lon_min");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("geospatial_lon_max"),
          newMaxLon,
          "geospatial_lon_max");

      // data will be different
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, dataQuery, tDir, eddTable.className() + "_update_1d", ".csv");
      results = File2.directReadFrom88591File(tDir + tName);
      expected =
          "station,longitude,latitude,geolon,geolat,luckySeven,time,atmp\n"
              + ",degrees_east,degrees_north,degrees_north,degrees_north,m,UTC,degree_C\n"
              + "41024,-78.489,33.848,-78.489,33.848,7.0,2014-12-01T00:00:00Z,14.2\n"
              +
              // "41025,-75.402,35.006,-75.402,35.006,7.0,2014-12-01T00:00:00Z,19.5\n" +
              "41029,-79.63,32.81,-79.63,32.81,7.0,2014-12-01T00:00:00Z,14.5\n"
              + "41033,-80.41,32.28,-80.41,32.28,7.0,2014-12-01T00:00:00Z,NaN\n";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);

    } finally {
      // rename it back to original
      String2.log("\n*** rename it back to original\n");
      File2.rename(dataDir, "NDBC_41025_met.nc2", "NDBC_41025_met.nc");
      for (int i = 0; i < 5; i++) { // Windows is slow, give it a few tries
        Math2.sleep(1000);
        String2.log(
            "c) after rename .nc2 to .nc, call update() i=" + i + ": " + eddTable.update(language));
      }
    }

    // *** back to original
    String2.log("\n*** after back to original\n");

    // should be original subsetVariables
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, subsetQuery, tDir, eddTable.className() + "_update_2sub", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalExpectedSubset, "\nresults=\n" + results);

    // should be original min/max time
    Test.ensureEqual(timeEdv.destinationMinString(), oldMinTime, "edvTime.destinationMin");
    Test.ensureEqual(timeEdv.destinationMaxString(), oldMaxTime, "edvTime.destinationMax");
    Test.ensureEqual(
        timeEdv.combinedAttributes().get("actual_range").toString(),
        oldMinMillis + ", " + oldMaxMillis,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_start"),
        oldMinTime,
        "time_coverage_start");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_end"),
        oldMaxTime,
        "time_coverage_end");

    // should be original min/max lon
    Test.ensureEqual(lonEdv.destinationMinString(), oldMinLon, "edvLon.destinationMin");
    Test.ensureEqual(lonEdv.destinationMaxString(), oldMaxLon, "edvLon.destinationMax");
    Test.ensureEqual(
        lonEdv.combinedAttributes().get("actual_range").toString(),
        oldMinLon + ", " + oldMaxLon,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_min"),
        oldMinLon,
        "geospatial_lon_min");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_max"),
        oldMaxLon,
        "geospatial_lon_max");

    // should be original data
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dataQuery, tDir, eddTable.className() + "_update_2d", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalExpectedData, "\nresults=\n" + results);

    // *** rename a non-data file so it matches the regex
    try {
      String2.log("\n*** make invalid file and rename to be a valid name\n");
      File2.writeToFileUtf8(dataDir + "image.png", "junk contents");
      File2.rename(dataDir, "image.png", "NDBC_image_met.nc");

      // should be original subsetVariables
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              subsetQuery,
              tDir,
              eddTable.className() + "_update_3sub",
              ".csv");
      results = File2.directReadFrom88591File(tDir + tName);
      Test.ensureEqual(results, originalExpectedSubset, "\nresults=\n" + results);

      // should be original min/max time
      Test.ensureEqual(timeEdv.destinationMinString(), oldMinTime, "edvTime.destinationMin");
      Test.ensureEqual(timeEdv.destinationMaxString(), oldMaxTime, "edvTime.destinationMax");
      Test.ensureEqual(
          timeEdv.combinedAttributes().get("actual_range").toString(),
          oldMinMillis + ", " + oldMaxMillis,
          "actual_range");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("time_coverage_start"),
          oldMinTime,
          "time_coverage_start");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("time_coverage_end"),
          oldMaxTime,
          "time_coverage_end");

      // should be original lon min/max
      Test.ensureEqual(lonEdv.destinationMinString(), oldMinLon, "edvLon.destinationMin");
      Test.ensureEqual(lonEdv.destinationMaxString(), oldMaxLon, "edvLon.destinationMax");
      Test.ensureEqual(
          lonEdv.combinedAttributes().get("actual_range").toString(),
          oldMinLon + ", " + oldMaxLon,
          "actual_range");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("geospatial_lon_min"),
          oldMinLon,
          "geospatial_lon_min");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("geospatial_lon_max"),
          oldMaxLon,
          "geospatial_lon_max");

      // should be original data
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, dataQuery, tDir, eddTable.className() + "_update_3d", ".csv");
      results = File2.directReadFrom88591File(tDir + tName);
      Test.ensureEqual(results, originalExpectedData, "\nresults=\n" + results);

    } finally {
      // rename it back to original
      String2.log("\n*** rename it back to original\n");
      File2.rename(dataDir, "NDBC_image_met.nc", "image.png");
      Math2.sleep(1000);
      String2.log("e) after rename .nc to .notnc, call update():\n" + eddTable.update(language));
    }

    String2.log("\n*** after back to original again\n");

    // should be original subsetVariables
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, subsetQuery, tDir, eddTable.className() + "_update_4sub", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalExpectedSubset, "\nresults=\n" + results);

    // should be original min/max time
    Test.ensureEqual(timeEdv.destinationMinString(), oldMinTime, "edvTime.destinationMin");
    Test.ensureEqual(timeEdv.destinationMaxString(), oldMaxTime, "edvTime.destinationMax");
    Test.ensureEqual(
        timeEdv.combinedAttributes().get("actual_range").toString(),
        oldMinMillis + ", " + oldMaxMillis,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_start"),
        oldMinTime,
        "time_coverage_start");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_end"),
        oldMaxTime,
        "time_coverage_end");

    // should be original lon min/max
    Test.ensureEqual(lonEdv.destinationMinString(), oldMinLon, "edvLon.destinationMin");
    Test.ensureEqual(lonEdv.destinationMaxString(), oldMaxLon, "edvLon.destinationMax");
    Test.ensureEqual(
        lonEdv.combinedAttributes().get("actual_range").toString(),
        oldMinLon + ", " + oldMaxLon,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_min"),
        oldMinLon,
        "geospatial_lon_min");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_max"),
        oldMaxLon,
        "geospatial_lon_max");

    // should be original data
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dataQuery, tDir, eddTable.className() + "_update_4d", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalExpectedData, "\nresults=\n" + results);
  }

  /**
   * This tests the EDDTableFromFiles quickRestart().
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  void testQuickRestart() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testQuickRestart()\n");

    int language = 0;
    EDDTableFromNcFiles eddTable;
    EDV timeEdv, lonEdv;
    String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String subsetQuery = "station,longitude,latitude&distinct()&orderBy(\"station\")";
    String dataQuery =
        "station,longitude,latitude,geolon,geolat,luckySeven,time,atmp&time=\"2014-12-01T00:00:00\"&orderBy(\"station\")";
    String tName, results, expected;
    int po;

    String originalDas1 =
        "Attributes {\n"
            + " s {\n"
            + "  station {\n"
            + "    String cf_role \"timeseries_id\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Station Name\";\n"
            + "  }\n"
            + "  longitude {\n"
            + "    String _CoordinateAxisType \"Lon\";\n"
            + "    Float32 actual_range -80.41, -75.402;\n"
            + "    String axis \"X\";\n"
            + "    String comment \"The longitude of the station.\";\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Longitude\";\n"
            + "    String standard_name \"longitude\";\n"
            + "    String units \"degrees_east\";\n"
            + "  }\n"
            + "  latitude {\n"
            + "    String _CoordinateAxisType \"Lat\";\n"
            + "    Float32 actual_range 32.28, 35.006;\n"
            + "    String axis \"Y\";\n"
            + "    String comment \"The latitude of the station.\";\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Latitude\";\n"
            + "    String standard_name \"latitude\";\n"
            + "    String units \"degrees_north\";\n"
            + "  }\n"
            + "  time {\n"
            + "    String _CoordinateAxisType \"Time\";\n"
            + "    Float64 actual_range 1.048878e+9, 1.4220504e+9;\n"
            + "    String axis \"T\";\n"
            + "    String comment \"Time in seconds since 1970-01-01T00:00:00Z. The original times are rounded to the nearest hour.\";\n"
            + "    String ioos_category \"Time\";\n"
            + "    String long_name \"Time\";\n"
            + "    String standard_name \"time\";\n"
            + "    String time_origin \"01-JAN-1970 00:00:00\";\n"
            + "    String units \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "  }\n"
            + "  luckySeven {\n"
            + "    Float32 actual_range 7.0, 7.0;\n"
            + "    String comment \"fixed value\";\n"
            + "    String ioos_category \"Other\";\n"
            + "    String units \"m\";\n"
            + "  }\n"
            + "  geolon {\n"
            + "    Float32 actual_range -80.41, -75.402;\n"
            + "    String ioos_category \"Location\";\n"
            + "    String units \"degrees_north\";\n"
            + "  }\n"
            + "  geolat {\n"
            + "    Float32 actual_range 32.28, 35.006;\n"
            + "    String ioos_category \"Location\";\n"
            + "    String units \"degrees_north\";\n"
            + "  }\n"
            + "  wd {\n"
            + "    Int16 _FillValue 32767;\n"
            + "    Int16 actual_range 0, 359;\n"
            + "    Float64 colorBarMaximum 360.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Wind direction (the direction the wind is coming from in degrees clockwise from true N) during the same period used for WSPD. See Wind Averaging Methods.\";\n"
            + "    String ioos_category \"Wind\";\n"
            + "    String long_name \"Wind Direction\";\n"
            + "    Int16 missing_value 32767;\n"
            + "    String standard_name \"wind_from_direction\";\n"
            + "    String units \"degrees_true\";\n"
            + "  }\n"
            + "  wspd {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range 0.0, 96.0;\n"
            + "    Float64 colorBarMaximum 15.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Wind speed (m/s) averaged over an eight-minute period for buoys and a two-minute period for land stations. Reported Hourly. See Wind Averaging Methods.\";\n"
            + "    String ioos_category \"Wind\";\n"
            + "    String long_name \"Wind Speed\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"wind_speed\";\n"
            + "    String units \"m s-1\";\n"
            + "  }\n"
            + "  gst {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range 0.0, 60.0;\n"
            + "    Float64 colorBarMaximum 30.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Peak 5 or 8 second gust speed (m/s) measured during the eight-minute or two-minute period. The 5 or 8 second period can be determined by payload, See the Sensor Reporting, Sampling, and Accuracy section.\";\n"
            + "    String ioos_category \"Wind\";\n"
            + "    String long_name \"Wind Gust Speed\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"wind_speed_of_gust\";\n"
            + "    String units \"m s-1\";\n"
            + "  }\n"
            + "  wvht {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range 0.0, 13.63;\n"
            + "    Float64 colorBarMaximum 10.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Significant wave height (meters) is calculated as the average of the highest one-third of all of the wave heights during the 20-minute sampling period. See the Wave Measurements section.\";\n"
            + "    String ioos_category \"Surface Waves\";\n"
            + "    String long_name \"Wave Height\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"sea_surface_wave_significant_height\";\n"
            + "    String units \"m\";\n"
            + "  }\n"
            + "  dpd {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range 0.0, 30.77;\n"
            + "    Float64 colorBarMaximum 20.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Dominant wave period (seconds) is the period with the maximum wave energy. See the Wave Measurements section.\";\n"
            + "    String ioos_category \"Surface Waves\";\n"
            + "    String long_name \"Wave Period, Dominant\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"sea_surface_swell_wave_period\";\n"
            + "    String units \"s\";\n"
            + "  }\n"
            + "  apd {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range 0.0, 14.26;\n"
            + "    Float64 colorBarMaximum 20.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Average wave period (seconds) of all waves during the 20-minute period. See the Wave Measurements section.\";\n"
            + "    String ioos_category \"Surface Waves\";\n"
            + "    String long_name \"Wave Period, Average\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"sea_surface_swell_wave_period\";\n"
            + "    String units \"s\";\n"
            + "  }\n"
            + "  mwd {\n"
            + "    Int16 _FillValue 32767;\n"
            + "    Int16 actual_range 0, 359;\n"
            + "    Float64 colorBarMaximum 360.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Mean wave direction corresponding to energy of the dominant period (DOMPD). The units are degrees from true North just like wind direction. See the Wave Measurements section.\";\n"
            + "    String ioos_category \"Surface Waves\";\n"
            + "    String long_name \"Wave Direction\";\n"
            + "    Int16 missing_value 32767;\n"
            + "    String standard_name \"sea_surface_wave_to_direction\";\n"
            + "    String units \"degrees_true\";\n"
            + "  }\n"
            + "  bar {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range 984.5, 1043.2;\n"
            + "    Float64 colorBarMaximum 1050.0;\n"
            + "    Float64 colorBarMinimum 950.0;\n"
            + "    String comment \"Air pressure (hPa). ('PRES' on some NDBC tables.) For C-MAN sites and Great Lakes buoys, the recorded pressure is reduced to sea level using the method described in NWS Technical Procedures Bulletin 291 (11/14/80).\";\n"
            + "    String ioos_category \"Pressure\";\n"
            + "    String long_name \"Air Pressure\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"air_pressure_at_sea_level\";\n"
            + "    String units \"hPa\";\n"
            + "  }\n"
            + "  atmp {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range -5.9, 35.9;\n"
            + "    Float64 colorBarMaximum 40.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\";\n"
            + "    String ioos_category \"Temperature\";\n"
            + "    String long_name \"Air Temperature\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"air_temperature\";\n"
            + "    String units \"degree_C\";\n"
            + "  }\n"
            + "  wtmp {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range 4.3, 32.6;\n"
            + "    Float64 colorBarMaximum 32.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\";\n"
            + "    String ioos_category \"Temperature\";\n"
            + "    String long_name \"SST\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"sea_surface_temperature\";\n"
            + "    String units \"degree_C\";\n"
            + "  }\n"
            + "  dewp {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range -11.6, 28.2;\n"
            + "    Float64 colorBarMaximum 40.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Dewpoint temperature taken at the same height as the air temperature measurement.\";\n"
            + "    String ioos_category \"Meteorology\";\n"
            + "    String long_name \"Dewpoint Temperature\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"dew_point_temperature\";\n"
            + "    String units \"degree_C\";\n"
            + "  }\n"
            + "  vis {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range 0.0, 10.5;\n"
            + "    Float64 colorBarMaximum 100.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String comment \"Station visibility (km, originally statute miles). Note that buoy stations are limited to reports from 0 to 1.9 miles.\";\n"
            + "    String ioos_category \"Meteorology\";\n"
            + "    String long_name \"Station Visibility\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"visibility_in_air\";\n"
            + "    String units \"km\";\n"
            + "  }\n"
            + "  ptdy {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range -5.5, 4.1;\n"
            + "    Float64 colorBarMaximum 3.0;\n"
            + "    Float64 colorBarMinimum -3.0;\n"
            + "    String comment \"Pressure Tendency is the direction (plus or minus) and the amount of pressure change (hPa) for a three hour period ending at the time of observation.\";\n"
            + "    String ioos_category \"Pressure\";\n"
            + "    String long_name \"Pressure Tendency\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"tendency_of_air_pressure\";\n"
            + "    String units \"hPa\";\n"
            + "  }\n"
            + "  tide {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float64 colorBarMaximum 5.0;\n"
            + "    Float64 colorBarMinimum -5.0;\n"
            + "    String comment \"The water level in meters (originally feet) above or below Mean Lower Low Water (MLLW).\";\n"
            + "    String ioos_category \"Sea Level\";\n"
            + "    String long_name \"Water Level\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"surface_altitude\";\n"
            + "    String units \"m\";\n"
            + "  }\n"
            + "  wspu {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range -27.2, 19.1;\n"
            + "    Float64 colorBarMaximum 15.0;\n"
            + "    Float64 colorBarMinimum -15.0;\n"
            + "    String comment \"The zonal wind speed (m/s) indicates the u component of where the wind is going, derived from Wind Direction and Wind Speed.\";\n"
            + "    String ioos_category \"Wind\";\n"
            + "    String long_name \"Wind Speed, Zonal\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"eastward_wind\";\n"
            + "    String units \"m s-1\";\n"
            + "  }\n"
            + "  wspv {\n"
            + "    Float32 _FillValue -9999999.0;\n"
            + "    Float32 actual_range -26.6, 24.2;\n"
            + "    Float64 colorBarMaximum 15.0;\n"
            + "    Float64 colorBarMinimum -15.0;\n"
            + "    String comment \"The meridional wind speed (m/s) indicates the v component of where the wind is going, derived from Wind Direction and Wind Speed.\";\n"
            + "    String ioos_category \"Wind\";\n"
            + "    String long_name \"Wind Speed, Meridional\";\n"
            + "    Float32 missing_value -9999999.0;\n"
            + "    String standard_name \"northward_wind\";\n"
            + "    String units \"m s-1\";\n"
            + "  }\n"
            + " }\n"
            + "  NC_GLOBAL {\n"
            + "    String acknowledgement \"NOAA NDBC and NOAA CoastWatch (West Coast Node)\";\n"
            + "    String cdm_data_type \"TimeSeries\";\n"
            + "    String cdm_timeseries_variables \"station, longitude, latitude\";\n"
            + "    String contributor_name \"NOAA NDBC and NOAA CoastWatch (West Coast Node)\";\n"
            + "    String contributor_role \"Source of data.\";\n"
            + "    String Conventions \"COARDS, CF-1.6, ACDD-1.3\";\n"
            + "    String creator_email \"dave.foley@noaa.gov\";\n"
            + "    String creator_name \"NOAA CoastWatch, West Coast Node\";\n"
            + "    String creator_url \"https://coastwatch.pfeg.noaa.gov\";\n"
            + "    Float64 Easternmost_Easting -75.402;\n"
            + "    String featureType \"TimeSeries\";\n"
            + "    Float64 geospatial_lat_max 35.006;\n"
            + "    Float64 geospatial_lat_min 32.28;\n"
            + "    String geospatial_lat_units \"degrees_north\";\n"
            + "    Float64 geospatial_lon_max -75.402;\n"
            + "    Float64 geospatial_lon_min -80.41;\n"
            + "    String geospatial_lon_units \"degrees_east\";\n"
            + "    String geospatial_vertical_positive \"down\";\n"
            + "    String geospatial_vertical_units \"m\";\n"
            + "    String history \"NOAA NDBC\n";

    // "2015-09-10T15:31:18Z https://www.ndbc.noaa.gov/\n" +
    // "2015-09-10T15:31:18Z
    String originalDas2 =
        "http://localhost:8080/erddap/tabledap/miniNdbc.das\";\n"
            + "    String infoUrl \"https://www.ndbc.noaa.gov/\";\n"
            + "    String institution \"NOAA NDBC, CoastWatch WCN\";\n"
            + "    String keywords \"air, air_pressure_at_sea_level, air_temperature, atmosphere, atmospheric, average, boundary, buoy, coastwatch, data, dew point, dew_point_temperature, direction, dominant, Earth Science > Atmosphere > Air Quality > Visibility, Earth Science > Atmosphere > Altitude > Planetary Boundary Layer Height, Earth Science > Atmosphere > Atmospheric Pressure > Atmospheric Pressure Measurements, Earth Science > Atmosphere > Atmospheric Pressure > Pressure Tendency, Earth Science > Atmosphere > Atmospheric Pressure > Sea Level Pressure, Earth Science > Atmosphere > Atmospheric Pressure > Static Pressure, Earth Science > Atmosphere > Atmospheric Temperature > Air Temperature, Earth Science > Atmosphere > Atmospheric Temperature > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Water Vapor > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Winds > Surface Winds, Earth Science > Oceans > Ocean Temperature > Sea Surface Temperature, Earth Science > Oceans > Ocean Waves > Significant Wave Height, Earth Science > Oceans > Ocean Waves > Swells, Earth Science > Oceans > Ocean Waves > Wave Period, eastward, eastward_wind, from, gust, height, identifier, layer, level, measurements, meridional, meteorological, meteorology, name, ndbc, noaa, northward, northward_wind, ocean, oceans, period, planetary, pressure, quality, sea, sea level, sea_surface_swell_wave_period, sea_surface_swell_wave_significant_height, sea_surface_swell_wave_to_direction, sea_surface_temperature, seawater, significant, speed, sst, standard, static, station, surface, surface waves, surface_altitude, swell, swells, temperature, tendency, tendency_of_air_pressure, time, vapor, visibility, visibility_in_air, water, wave, waves, wcn, wind, wind_from_direction, wind_speed, wind_speed_of_gust, winds, zonal\";\n"
            + "    String keywords_vocabulary \"GCMD Science Keywords\";\n"
            + "    String license \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "    String naming_authority \"gov.noaa.pfeg.coastwatch\";\n"
            + "    String NDBCMeasurementDescriptionUrl \"https://www.ndbc.noaa.gov/measdes.shtml\";\n"
            + "    Float64 Northernmost_Northing 35.006;\n"
            + "    String project \"NOAA NDBC and NOAA CoastWatch (West Coast Node)\";\n"
            + "    String quality \"Automated QC checks with periodic manual QC\";\n"
            + "    String source \"station observation\";\n"
            + "    String sourceUrl \"https://www.ndbc.noaa.gov/\";\n"
            + "    Float64 Southernmost_Northing 32.28;\n"
            + "    String standard_name_vocabulary \"CF-12\";\n"
            + "    String subsetVariables \"station, longitude, latitude\";\n"
            + "    String summary \"The National Data Buoy Center (NDBC) distributes meteorological data from\n"
            + "moored buoys maintained by NDBC and others. Moored buoys are the weather\n"
            + "sentinels of the sea. They are deployed in the coastal and offshore waters\n"
            + "from the western Atlantic to the Pacific Ocean around Hawaii, and from the\n"
            + "Bering Sea to the South Pacific. NDBC's moored buoys measure and transmit\n"
            + "barometric pressure; wind direction, speed, and gust; air and sea\n"
            + "temperature; and wave energy spectra from which significant wave height,\n"
            + "dominant wave period, and average wave period are derived. Even the\n"
            + "direction of wave propagation is measured on many moored buoys.\n"
            + "\n"
            + "The data is from NOAA NDBC. It has been reformatted by NOAA Coastwatch,\n"
            + "West Coast Node. This dataset only has the data that is closest to a\n"
            + "given hour. The time values in the dataset are rounded to the nearest hour.\n"
            + "\n"
            + "This dataset has both historical data (quality controlled, before\n"
            + "2015-01-01T00:00:00Z) and near real time data (less quality controlled, from\n"
            + "2015-01-01T00:00:00Z on).\";\n"
            + "    String time_coverage_end \"2015-01-23T22:00:00Z\";\n"
            + "    String time_coverage_resolution \"P1H\";\n"
            + "    String time_coverage_start \"2003-03-28T19:00:00Z\";\n"
            + "    String title \"NDBC Standard Meteorological Buoy Data\";\n"
            + "    Float64 Westernmost_Easting -80.41;\n"
            + "  }\n"
            + "}\n";
    String originalSubsetExpected =
        "station,longitude,latitude\n"
            + ",degrees_east,degrees_north\n"
            + "41024,-78.489,33.848\n"
            + "41025,-75.402,35.006\n"
            + // this has max lon and max time
            "41029,-79.63,32.81\n"
            + "41033,-80.41,32.28\n";

    String oldMinTime = "2003-03-28T19:00:00Z";
    String oldMinMillis = "1.048878E9";
    String newMinTime = "2005-02-23T15:00:00Z"; // after renaming a file to make it invalid
    String newMinMillis = "1.1091708E9";
    String oldMaxTime = "2015-01-23T22:00:00Z";
    String oldMaxMillis = "1.4220504E9";
    String newMaxTime = "2015-01-23T21:00:00Z";
    String newMaxMillis = "1.4220468E9";

    String oldMinLon = "-80.41";
    String oldMaxLon = "-75.402";

    String originalExpectedData =
        "station,longitude,latitude,geolon,geolat,luckySeven,time,atmp\n"
            + ",degrees_east,degrees_north,degrees_north,degrees_north,m,UTC,degree_C\n"
            + "41024,-78.489,33.848,-78.489,33.848,7.0,2014-12-01T00:00:00Z,14.2\n"
            + "41025,-75.402,35.006,-75.402,35.006,7.0,2014-12-01T00:00:00Z,19.5\n"
            + "41029,-79.63,32.81,-79.63,32.81,7.0,2014-12-01T00:00:00Z,14.5\n"
            + "41033,-80.41,32.28,-80.41,32.28,7.0,2014-12-01T00:00:00Z,NaN\n";

    // *** Do tests of original data
    // delete bad files list to ensure all are read
    String tDatasetID = "miniNdbc";
    File2.delete(EDDTableFromNcFiles.badFileMapFileName(tDatasetID));
    eddTable = (EDDTableFromNcFiles) EDDTestDataset.getminiNdbc();
    String dataDir = eddTable.fileDir;
    timeEdv = eddTable.dataVariables()[eddTable.timeIndex];
    lonEdv = eddTable.dataVariables()[eddTable.lonIndex];
    long oCreationTimeMillis = eddTable.creationTimeMillis();

    // das
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", tDir, eddTable.className() + "_qr_0das", ".das");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(
        results.substring(0, originalDas1.length()), originalDas1, "\nresults=\n" + results);

    po = results.indexOf(originalDas2.substring(0, 80));
    Test.ensureEqual(results.substring(po), originalDas2, "\nresults=\n" + results);

    // subsetVariables
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, subsetQuery, tDir, eddTable.className() + "_qr_0sub", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalSubsetExpected, "\nresults=\n" + results);

    // original min/max time
    Test.ensureEqual(timeEdv.destinationMinString(), oldMinTime, "edvTime.destinationMin");
    Test.ensureEqual(timeEdv.destinationMaxString(), oldMaxTime, "edvTime.destinationMax");
    Test.ensureEqual(
        timeEdv.combinedAttributes().get("actual_range").toString(),
        oldMinMillis + ", " + oldMaxMillis,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_start"),
        oldMinTime,
        "time_coverage_start");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_end"),
        oldMaxTime,
        "time_coverage_end");

    // original lon min/max
    Test.ensureEqual(lonEdv.destinationMinString(), oldMinLon, "edvLon.destinationMin");
    Test.ensureEqual(lonEdv.destinationMaxString(), oldMaxLon, "edvLon.destinationMax");
    Test.ensureEqual(
        lonEdv.combinedAttributes().get("actual_range").toString(),
        oldMinLon + ", " + oldMaxLon,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_min"),
        oldMinLon,
        "geospatial_lon_min");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_max"),
        oldMaxLon,
        "geospatial_lon_max");

    // read the original data
    String2.log("\n*** read original data\n");
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dataQuery, tDir, eddTable.className() + "_qr_0d", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalExpectedData, "\nresults=\n" + results);

    // *** rename a data file so it doesn't match regex
    try {
      String2.log("\n*** rename a data file so it doesn't match regex\n");
      File2.rename(dataDir, "NDBC_41025_met.nc", "NDBC_41025_met.nc2");
      Math2.sleep(1000);
      EDDTableFromFiles.testQuickRestart = true;
      eddTable = (EDDTableFromNcFiles) EDDTestDataset.getminiNdbc();
      timeEdv = eddTable.dataVariables()[eddTable.timeIndex];
      lonEdv = eddTable.dataVariables()[eddTable.lonIndex];
      Test.ensureEqual(eddTable.creationTimeMillis(), oCreationTimeMillis, "");

      // should be original das
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, "", tDir, eddTable.className() + "_qr_1das", ".das");
      results = File2.directReadFrom88591File(tDir + tName);
      Test.ensureEqual(
          results.substring(0, originalDas1.length()), originalDas1, "\nresults=\n" + results);

      po = results.indexOf(originalDas2.substring(0, 80));
      Test.ensureEqual(results.substring(po), originalDas2, "\nresults=\n" + results);

      // should be original subsetVariables
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, subsetQuery, tDir, eddTable.className() + "_qr_1sub", ".csv");
      results = File2.directReadFrom88591File(tDir + tName);
      Test.ensureEqual(results, originalSubsetExpected, "\nresults=\n" + results);

      // should be original min/max time
      Test.ensureEqual(timeEdv.destinationMinString(), oldMinTime, "edvTime.destinationMin");
      Test.ensureEqual(timeEdv.destinationMaxString(), oldMaxTime, "edvTime.destinationMax");
      Test.ensureEqual(
          timeEdv.combinedAttributes().get("actual_range").toString(),
          oldMinMillis + ", " + oldMaxMillis,
          "actual_range");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("time_coverage_start"),
          oldMinTime,
          "time_coverage_start");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("time_coverage_end"),
          oldMaxTime,
          "time_coverage_end");

      // should be original lon min/max
      Test.ensureEqual(lonEdv.destinationMinString(), oldMinLon, "edvLon.destinationMin");
      Test.ensureEqual(lonEdv.destinationMaxString(), oldMaxLon, "edvLon.destinationMax");
      Test.ensureEqual(
          lonEdv.combinedAttributes().get("actual_range").toString(),
          oldMinLon + ", " + oldMaxLon,
          "actual_range");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("geospatial_lon_min"),
          oldMinLon,
          "geospatial_lon_min");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("geospatial_lon_max"),
          oldMaxLon,
          "geospatial_lon_max");

      // but read the original data will be different
      try {
        tName =
            eddTable.makeNewFileForDapQuery(
                language, null, null, dataQuery, tDir, eddTable.className() + "_qr_1d", ".csv");
        results = "shouldn't happen";
      } catch (Throwable t2) {
        results = t2.getMessage();
      }
      expected =
          "There was a (temporary?) problem.  Wait a minute, then try again.  (In a browser, click the Reload button.)\n"
              + "(Cause: java.io.FileNotFoundException: "
              + dataDir
              + "NDBC_41025_met.nc";
      // Windows has:  (The system cannot find the file specified))
      // Linux has: (No such file or directory))
      // just check the begining of the message.
      Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    } finally {
      // delete badFileMap so bad file will be reconsidered
      File2.delete(EDDTableFromNcFiles.badFileMapFileName(tDatasetID));
      // rename it back to original
      String2.log("\n*** rename it back to original\n");
      File2.rename(dataDir, "NDBC_41025_met.nc2", "NDBC_41025_met.nc");
      // ensure testQuickRestart is set back to false
      EDDTableFromFiles.testQuickRestart = false;
      while (!File2.isFile(dataDir + "NDBC_41025_met.nc")) {
        String2.log("waiting for file to be renamed");
        Math2.sleep(1000);
      }
    }

    // *** back to original
    String2.log("\n*** after back to original\n");
    eddTable = (EDDTableFromNcFiles) EDDTestDataset.getminiNdbc();
    timeEdv = eddTable.dataVariables()[eddTable.timeIndex];
    lonEdv = eddTable.dataVariables()[eddTable.lonIndex];
    // TODO either remove or re-enable this. Does the getOneFromXmlFragment not actually make a new
    // dataset?
    // creationTime should have changed
    // Test.ensureNotEqual(eddTable.creationTimeMillis(), oCreationTimeMillis, "");

    // but everything else should be back to original
    // das
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", tDir, eddTable.className() + "_qr_2das", ".das");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(
        results.substring(0, originalDas1.length()), originalDas1, "\nresults=\n" + results);

    po = results.indexOf(originalDas2.substring(0, 80));
    Test.ensureEqual(results.substring(po), originalDas2, "\nresults=\n" + results);

    // should be original subsetVariables
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, subsetQuery, tDir, eddTable.className() + "_qr_2sub", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalSubsetExpected, "\nresults=\n" + results);

    // should be original min/max time
    Test.ensureEqual(timeEdv.destinationMinString(), oldMinTime, "edvTime.destinationMin");
    Test.ensureEqual(timeEdv.destinationMaxString(), oldMaxTime, "edvTime.destinationMax");
    Test.ensureEqual(
        timeEdv.combinedAttributes().get("actual_range").toString(),
        oldMinMillis + ", " + oldMaxMillis,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_start"),
        oldMinTime,
        "time_coverage_start");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("time_coverage_end"),
        oldMaxTime,
        "time_coverage_end");

    // should be original lon min/max
    Test.ensureEqual(lonEdv.destinationMinString(), oldMinLon, "edvLon.destinationMin");
    Test.ensureEqual(lonEdv.destinationMaxString(), oldMaxLon, "edvLon.destinationMax");
    Test.ensureEqual(
        lonEdv.combinedAttributes().get("actual_range").toString(),
        oldMinLon + ", " + oldMaxLon,
        "actual_range");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_min"),
        oldMinLon,
        "geospatial_lon_min");
    Test.ensureEqual(
        eddTable.combinedGlobalAttributes().getString("geospatial_lon_max"),
        oldMaxLon,
        "geospatial_lon_max");

    // should be original data
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dataQuery, tDir, eddTable.className() + "_qr_2d", ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    Test.ensureEqual(results, originalExpectedData, "\nresults=\n" + results);
  }

  /**
   * This tests the new handling of timestamp destinationMax (2015-02-24): destinationMax is always
   * set (even if recent) and EDDTable.parseUserDapQuery treats timestamp destinationMax as NaN if
   * recent (in last 2 days).
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testNewTime() throws Throwable {

    try {
      int language = 0;
      // String2.pressEnterToContinue(
      // "\n*** EDDTableFromNcFiles.testNewTime()\n" +
      // "Download NDBC_46088_met.nc from coastwatch\n" +
      // "https://coastwatch.pfeg.noaa.gov/erddap/files/cwwcNDBCMet/nrt/ \n" +
      // "to /u00/data/points/ndbcMet/nrt/ .");

      EDDTableFromNcFiles eddTable = (EDDTableFromNcFiles) EDDTestDataset.getcwwcNDBCMet();
      EDV timeEdv = eddTable.dataVariables()[eddTable.timeIndex];
      String dataDir = eddTable.fileDir;
      String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
      String tName, results, expected;

      double destMinD = timeEdv.destinationMinDouble();
      double destMaxD = timeEdv.destinationMaxDouble();
      String destMinS = Calendar2.safeEpochSecondsToIsoStringTZ(destMinD, "");
      String destMaxS = Calendar2.safeEpochSecondsToIsoStringTZ(destMaxD, "");

      Test.ensureTrue(!Double.isNaN(destMinD), "edvTime.destinationMin");
      Test.ensureTrue(!Double.isNaN(destMaxD), "edvTime.destinationMax");
      Test.ensureEqual(
          timeEdv.combinedAttributes().get("actual_range").toString(),
          destMinD + ", " + destMaxD,
          "actual_range");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("time_coverage_start"),
          destMinS,
          "time_coverage_start");
      Test.ensureEqual(
          eddTable.combinedGlobalAttributes().getString("time_coverage_end"),
          destMaxS,
          "time_coverage_end");

      // request data where time>=destMaxD
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "station,time,atmp&time>=" + destMaxD,
              tDir,
              eddTable.className() + "_newTime1",
              ".csv");
      results = File2.directReadFrom88591File(tDir + tName);
      expected =
          "station,time,atmp\n"
              + ",UTC,degree_C\n"
              + "MLSC1,"
              + destMaxS
              + ","; // or 41004 if same time
      Test.ensureEqual(
          results.substring(0, expected.length()),
          expected,
          "\nmaxTime=" + destMaxS + " results=\n" + results);

      String2.log(
          "\nEDDTableFromNcFiles.testNewTime() finished successfully. maxTime=" + destMaxS + "\n");
    } catch (Throwable t) {
      throw new Exception(MustBe.throwableToString(t) + "\nOr 41004 if same max time for both.");
    }
  }

  /**
   * This tests writing Igor Text Files .itx.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testIgor() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testIgor()\n");

    int language = 0;
    // testVerboseOn();
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String error = "";
    int po;
    EDV edv;

    String id = "cwwcNDBCMet";
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    userDapQuery =
        "station,longitude,latitude,time,wd,wspd,vis,wspu,wspv&station=%2246088%22&time>=2016-02-03T04:00:00&time<=2016-02-03T06:00:00";
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, dir, "Igor1", ".itx");
    results = File2.directReadFrom88591File(dir + tName);
    results = String2.replaceAll(results, '\r', '\n');
    // String2.log(results);
    expected =
        "IGOR\n"
            + "WAVES/T station\n"
            + "BEGIN\n"
            + "\"46088\"\n"
            + "\"46088\"\n"
            + "\"46088\"\n"
            + "\"46088\"\n"
            + "END\n"
            + "\n"
            + "WAVES/S longitude\n"
            + "BEGIN\n"
            + "-123.167\n"
            + "-123.167\n"
            + "-123.167\n"
            + "-123.167\n"
            + "END\n"
            + "X SetScale d -123.167,-123.167, \"degrees_east\", longitude\n"
            + "\n"
            + "WAVES/S latitude\n"
            + "BEGIN\n"
            + "48.333\n"
            + "48.333\n"
            + "48.333\n"
            + "48.333\n"
            + "END\n"
            + "X SetScale d 48.333,48.333, \"degrees_north\", latitude\n"
            + "\n"
            + "WAVES/D time2\n"
            + // since time is a reserved keyword
            "BEGIN\n"
            + "3.537318E9\n"
            + "3.5373198E9\n"
            + "3.5373216E9\n"
            + "3.5373234E9\n"
            + "END\n"
            + "X SetScale d 3.537318E9,3.5373234E9, \"dat\", time2\n"
            + "\n"
            + "WAVES/W wd\n"
            + "BEGIN\n"
            + "111\n"
            + "162\n"
            + "147\n"
            + "125\n"
            + "END\n"
            + "X SetScale d 111,162, \"degrees_true\", wd\n"
            + "\n"
            + "WAVES/S wspd\n"
            + "BEGIN\n"
            + "6.9\n"
            + "4.7\n"
            + "2.9\n"
            + "4.1\n"
            + "END\n"
            + "X SetScale d 2.9,6.9, \"m s-1\", wspd\n"
            + "\n"
            + "WAVES/S vis\n"
            + "BEGIN\n"
            + "NaN\n"
            + "NaN\n"
            + "NaN\n"
            + "NaN\n"
            + "END\n"
            + "X SetScale d 0,0, \"km\", vis\n"
            + "\n"
            + "WAVES/S wspu\n"
            + "BEGIN\n"
            + "-6.4\n"
            + "-1.5\n"
            + "-1.6\n"
            + "-3.4\n"
            + "END\n"
            + "X SetScale d -6.4,-1.5, \"m s-1\", wspu\n"
            + "\n"
            + "WAVES/S wspv\n"
            + "BEGIN\n"
            + "2.5\n"
            + "4.5\n"
            + "2.4\n"
            + "2.4\n"
            + "END\n"
            + "X SetScale d 2.4,4.5, \"m s-1\", wspv\n"
            + "\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /**
   * This tests testTablePseudoFileNames.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  void testTablePseudoSourceNames() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testTablePseudoSourceNames()\n");
    // testVerboseOn();

    int language = 0;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String error = "";
    int po;
    EDV edv;

    String id = "testTablePseudoSourceNames";
    EDDTable eddTable = (EDDTable) EDDTestDataset.gettestTablePseudoSourceNames();

    userDapQuery = "&time=2014-01-15T00";
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, dir, "tpfn", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "station,parentDir,longitude,latitude,time,luckySeven,geoLatMin,globalZztop,latActualRangeMin,depthPositive,depthZztop,wd,wspdRange\n"
            + ",,degrees_east,degrees_north,UTC,m,degrees_north,,,,,degrees_true,\n"
            + "41024,miniNdbc,-78.489,33.848,2014-01-15T00:00:00Z,7.0,33.848,NaN,33.848,down,,320,\"0.0, 27.0\"\n"
            + "41025,miniNdbc,-75.402,35.006,2014-01-15T00:00:00Z,7.0,35.006,NaN,35.006,down,,NaN,\"0.0, 27.7\"\n"
            + "41029,miniNdbc,-79.63,32.81,2014-01-15T00:00:00Z,7.0,32.81,NaN,32.81,down,,230,\"0.0, 19.0\"\n"
            + "41033,miniNdbc,-80.41,32.28,2014-01-15T00:00:00Z,7.0,32.28,NaN,32.28,down,,220,\"0.0, 96.0\"\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    userDapQuery = "&time>=2014-01-15T00&time<=2014-01-15T01";
    tName =
        eddTable.makeNewFileForDapQuery(language, null, null, userDapQuery, dir, "tpfn", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "station,parentDir,longitude,latitude,time,luckySeven,geoLatMin,globalZztop,latActualRangeMin,depthPositive,depthZztop,wd,wspdRange\n"
            + ",,degrees_east,degrees_north,UTC,m,degrees_north,,,,,degrees_true,\n"
            + "41024,miniNdbc,-78.489,33.848,2014-01-15T00:00:00Z,7.0,33.848,NaN,33.848,down,,320,\"0.0, 27.0\"\n"
            + "41024,miniNdbc,-78.489,33.848,2014-01-15T01:00:00Z,7.0,33.848,NaN,33.848,down,,330,\"0.0, 27.0\"\n"
            + "41025,miniNdbc,-75.402,35.006,2014-01-15T00:00:00Z,7.0,35.006,NaN,35.006,down,,NaN,\"0.0, 27.7\"\n"
            + "41025,miniNdbc,-75.402,35.006,2014-01-15T01:00:00Z,7.0,35.006,NaN,35.006,down,,NaN,\"0.0, 27.7\"\n"
            + "41029,miniNdbc,-79.63,32.81,2014-01-15T00:00:00Z,7.0,32.81,NaN,32.81,down,,230,\"0.0, 19.0\"\n"
            + "41029,miniNdbc,-79.63,32.81,2014-01-15T01:00:00Z,7.0,32.81,NaN,32.81,down,,310,\"0.0, 19.0\"\n"
            + "41033,miniNdbc,-80.41,32.28,2014-01-15T00:00:00Z,7.0,32.28,NaN,32.28,down,,220,\"0.0, 96.0\"\n"
            + "41033,miniNdbc,-80.41,32.28,2014-01-15T01:00:00Z,7.0,32.28,NaN,32.28,down,,260,\"0.0, 96.0\"\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
  }

  /** This tests hardFlag. */
  @org.junit.jupiter.api.Test
  @TagLocalERDDAP
  void testHardFlag() throws Throwable {
    String2.log(
        "\n*** EDDTableFromNcFiles.testHardFlag()\n"
            + "This test requires testTimeSince19000101 be loaded in the local ERDDAP.");
    int language = 0;

    // set hardFlag
    String startTime = Calendar2.getCurrentISODateTimeStringLocalTZ();
    Math2.sleep(1000);
    File2.writeToFileUtf8(EDStatic.fullHardFlagDirectory + "testTimeSince19000101", "test");
    String2.log(
        "I just set a hardFlag for testTimeSince19000101.\n" + "Now I'm waiting 10 seconds.");
    Math2.sleep(10000);
    // flush the log file
    String tIndex = SSR.getUrlResponseStringUnchanged("http://localhost:8080/erddap/status.html");
    Math2.sleep(5000);
    // read the log file
    String tLog = File2.readFromFileUtf8(EDStatic.fullLogsDirectory + "log.txt")[1];
    String expected = // ***
        "unloading datasetID=testTimeSince19000101\n"
            + "\\*\\*\\* deleting cached dataset info for datasetID=testTimeSince19000101\n"
            + "\n"
            + "\\*\\*\\* RunLoadDatasets is starting a new hardFlag LoadDatasets thread at (..........T..............)\n"
            + "\n"
            + "\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n"
            + "LoadDatasets.run EDStatic.developmentMode=true ..........T..............\n"
            + "  datasetsRegex=\\(testTimeSince19000101\\) inputStream=null majorLoad=false";

    int po = Math.max(0, tLog.lastIndexOf(expected.substring(0, 40)));
    int po2 = Math.min(po + expected.length(), tLog.indexOf("majorLoad=false", po) + 15);
    String tResults = tLog.substring(po, po2);
    String2.log("tResults=\n\"\n" + tResults + "\n\"\n");
    Test.testLinesMatch(tResults, expected, "tResults and expected don't match!");

    // so far so good, tResults matches expected
    int po3 = tResults.indexOf("thread at ");
    String reloadTime = tResults.substring(po3 + 10, po3 + 35);
    String2.log(" startTime=" + startTime + "\n" + "reloadTime=" + reloadTime);
    Test.ensureTrue(startTime.compareTo(reloadTime) < 0, "startTime is after reloadTime?!");

    // test that the dirTable and fileTable weren't found after that
    expected =
        "dir/file table doesn't exist: /erddapBPD/dataset/01/testTimeSince19000101/dirTable.nc\n"
            + "dir/file table doesn't exist: /erddapBPD/dataset/01/testTimeSince19000101/fileTable.nc\n"
            + "creating new dirTable and fileTable (dirTable=null?true fileTable=null?true badFileMap=null?false)";
    int po4 = tLog.indexOf(expected.substring(0, 29), po);
    Test.ensureTrue(
        po4 > 0,
        "\n\n************************************\n\""
            + expected
            + "\" wasn't found after po="
            + po
            + " !\ntLog ending=\n"
            + tLog.substring(po));

    // test that the dataset was successfully constructed after that
    int po5 =
        tLog.indexOf(
            "*** EDDTableFromFiles testTimeSince19000101 constructor finished. TIME=", po4);
    Test.ensureTrue(
        po5 > po4,
        "\n\n>>tLog=" + tLog + "\n[end log]\npo5=" + po5 + " isn't greater than po4=" + po4 + " !");
  }

  /** This tests connecting netcdf-java to localhost hosted .nc file to access via byte ranges. */
  @org.junit.jupiter.api.Test
  @TagLocalERDDAP
  void testByteRange() throws Throwable {
    String2.log(
        "\n*** EDDTableFromNcFiles.testByteRange()\n"
            + "!!! THIS REQURIES cwwcNDBCMet IN THE LOCALHOST ERDDAP!!!\n");
    int language = 0;

    NetcdfFile ncFile =
        NcHelper.openFile(
            "http://localhost:8080/cwexperimental/files/cwwcNDBCMet/NDBC_46088_met.nc");
    try {

      // get a list of variables
      Group rootGroup = ncFile.getRootGroup();
      List rootGroupVariables = rootGroup.getVariables();
      String2.log("rootGroup variables=" + String2.toNewlineString(rootGroupVariables.toArray()));

      /*
       * this fails. It makes 2 requests
       * 1) for entire file (to just read header)
       * but it allows gzip.
       * Erddap log: compression=gzip, fileSize=7319444, Range request=[null]
       *
       * 2) second is 1s later and for a range
       * handled by doTransfer:
       * Erddap log: compression=identity, fileSize=7319444, Range
       * request=bytes=0-1859775[end], set Content-Range=bytes 0-1859775/7319444
       * That throws exception: Exception in thread "main" java.io.IOException:
       * java.io.IOException:
       * File is truncated calculated size= 7319444 actual = 1859776
       */
    } finally {
      try {
        if (ncFile != null) ncFile.close();
      } catch (Exception e9) {
      }
    }
  }

  /**
   * This tests threading.
   *
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testNThreads() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNThreads()\n");

    int language = 0;

    // Table.verbose = false;
    // Table.reallyVerbose = false;
    // EDD.verbose = false;
    // EDD.reallyVerbose = false;
    // EDD.debugMode = false;
    // EDDTableFromFilesCallable.debugMode = true;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String error = "";
    int po;

    StringBuilder bigResults = new StringBuilder("\nbigResults:\n");

    // this dataset and this request are a good test that the results are always in
    // the same order
    String id = "erdGtsppBestNc";
    userDapQuery = "&time>=2017-01-01&time<2017-07-01&depth=200&temperature=10";

    EDDTableFromNcFiles eddTable = (EDDTableFromNcFiles) EDDTestDataset.geterdGtsppBestNc();
    for (int i = 5; i > -5; i--) {
      if (i == 0) continue;
      eddTable.nThreads = Math.abs(i);

      long startTime = System.currentTimeMillis();
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, userDapQuery, dir, "testNThreads" + i, ".csv");

      String msg =
          "nThreads="
              + eddTable.nThreads
              + " time="
              + (System.currentTimeMillis() - startTime)
              + "ms\n";
      String2.log(msg);
      bigResults.append(msg);

      results = File2.directReadFrom88591File(dir + tName);
      // String2.log(results);
      expected = // ensure that order is correct
          /*
           * pre 2020-06-16 was: (I did full gtspp reprocessing 2020-06-13. Same results,
           * but slightly different order.)
           * "trajectory,org,type,platform,cruise,station_id,longitude,latitude,time,depth,temperature,salinity\n"
           * +
           * ",,,,,,degrees_east,degrees_north,UTC,m,degree_C,PSU\n" +
           * "ME_TE_33PF_Q590410717,ME,TE,33PF,Q590410717,28178811,-129.651,31.432,2017-01-28T17:19:00Z,200.0,10.0,33.61\n"
           * +
           * "ME_TE_61PF_Q590250317,ME,TE,61PF,Q590250317,28081602,116.295,-45.927,2017-01-22T16:02:00Z,200.0,10.0,34.75\n"
           * +
           * "ME_TE_33AW_68942 17,ME,TE,33AW,68942 17,28404309,-9.91,56.86,2017-02-28T15:47:00Z,200.0,10.0,35.33\n"
           * +
           * "ME_TE_33PF_Q590480817,ME,TE,33PF,Q590480817,28252348,93.943,-43.403,2017-02-14T06:09:00Z,200.0,10.0,34.67\n"
           * +
           * "ME_TE_09PF_Q590424217,ME,TE,09PF,Q590424217,28252286,122.487,-38.964,2017-02-14T22:50:00Z,200.0,10.0,34.73\n"
           * +
           * "ME_TE_33AW_68944 17,ME,TE,33AW,68944 17,28404467,-11.26,57.37,2017-03-04T20:11:00Z,200.0,10.0,35.31\n"
           * +
           * "ME_DB_33TT_52006 17,ME,DB,33TT,52006 17,28403335,165.1,8.1,2017-03-07T20:00:00Z,200.0,10.0,NaN\n"
           * +
           * "ME_TE_33PF_Q590465217,ME,TE,33PF,Q590465217,28417679,-171.046,-46.9,2017-03-06T18:53:00Z,200.0,10.0,34.71\n"
           * +
           * "ME_TE_33PF_Q490166617,ME,TE,33PF,Q490166617,28613687,-135.913,36.571,2017-04-04T06:54:00Z,200.0,10.0,33.88\n"
           * +
           * "ME_BA_49TK_7JWN 17,ME,BA,49TK,7JWN 17,28918431,137.0,33.761,2017-05-15T16:50:00Z,200.0,10.0,NaN\n"
           * +
           * "ME_TE_35FP_Q390187117,ME,TE,35FP,Q390187117,28935333,-9.61,56.682,2017-05-18T11:52:00Z,200.0,10.0,35.34\n"
           * +
           * "ME_TE_35FP_Q690152417,ME,TE,35FP,Q690152417,28953222,-44.059,50.323,2017-05-22T14:35:00Z,200.0,10.0,35.2\n"
           * +
           * "ME_TE_33AW_68990 17,ME,TE,33AW,68990 17,29162406,-19.3,57.88,2017-05-24T19:44:00Z,200.0,10.0,35.3\n"
           * +
           * "ME_TE_33PF_Q590476517,ME,TE,33PF,Q590476517,28871179,-167.444,-49.142,2017-05-08T00:00:00Z,200.0,10.0,34.7\n"
           * +
           * "ME_TE_33PF_Q590245817,ME,TE,33PF,Q590245817,29011132,148.57,-46.113,2017-05-27T08:43:00Z,200.0,10.0,34.76\n"
           * +
           * "ME_TE_33PF_Q590237417,ME,TE,33PF,Q590237417,28895913,132.582,-45.091,2017-05-12T10:51:00Z,200.0,10.0,34.79\n"
           * +
           * "ME_TE_33AW_68990 17,ME,TE,33AW,68990 17,29162540,-20.14,58.22,2017-06-02T20:09:00Z,200.0,10.0,35.3\n"
           * ;
           */
          "trajectory,org,type,platform,cruise,station_id,longitude,latitude,time,depth,temperature,salinity\n"
              + ",,,,,,degrees_east,degrees_north,UTC,m,degree_C,PSU\n"
              + "ME_TE_33PF_Q590410717,ME,TE,33PF,Q590410717,28178811,-129.651,31.432,2017-01-28T17:19:00Z,200.0,10.0,33.61\n"
              + "ME_TE_61PF_Q590250317,ME,TE,61PF,Q590250317,28081602,116.295,-45.927,2017-01-22T16:02:00Z,200.0,10.0,34.75\n"
              + "ME_TE_33PF_Q590480817,ME,TE,33PF,Q590480817,28252348,93.943,-43.403,2017-02-14T06:09:00Z,200.0,10.0,34.67\n"
              + "ME_TE_09PF_Q590424217,ME,TE,09PF,Q590424217,28252286,122.487,-38.964,2017-02-14T22:50:00Z,200.0,10.0,34.73\n"
              + "ME_TE_33AW_68942 17,ME,TE,33AW,68942 17,28404309,-9.91,56.86,2017-02-28T15:47:00Z,200.0,10.0,35.33\n"
              + "ME_DB_33TT_52006 17,ME,DB,33TT,52006 17,28403335,165.1,8.1,2017-03-07T20:00:00Z,200.0,10.0,NaN\n"
              + "ME_TE_33AW_68944 17,ME,TE,33AW,68944 17,28404467,-11.26,57.37,2017-03-04T20:11:00Z,200.0,10.0,35.31\n"
              + "ME_TE_33PF_Q590465217,ME,TE,33PF,Q590465217,28417679,-171.046,-46.9,2017-03-06T18:53:00Z,200.0,10.0,34.71\n"
              + "ME_TE_33PF_Q490166617,ME,TE,33PF,Q490166617,28613687,-135.913,36.571,2017-04-04T06:54:00Z,200.0,10.0,33.88\n"
              + "ME_BA_49TK_7JWN 17,ME,BA,49TK,7JWN 17,28918431,137.0,33.761,2017-05-15T16:50:00Z,200.0,10.0,NaN\n"
              + "ME_TE_35FP_Q390187117,ME,TE,35FP,Q390187117,28935333,-9.61,56.682,2017-05-18T11:52:00Z,200.0,10.0,35.34\n"
              + "ME_TE_35FP_Q690152417,ME,TE,35FP,Q690152417,28953222,-44.059,50.323,2017-05-22T14:35:00Z,200.0,10.0,35.2\n"
              + "ME_TE_33AW_68990 17,ME,TE,33AW,68990 17,29162406,-19.3,57.88,2017-05-24T19:44:00Z,200.0,10.0,35.3\n"
              + "ME_TE_33PF_Q590476517,ME,TE,33PF,Q590476517,28871179,-167.444,-49.142,2017-05-08T00:00:00Z,200.0,10.0,34.7\n"
              + "ME_TE_33PF_Q590245817,ME,TE,33PF,Q590245817,29011132,148.57,-46.113,2017-05-27T08:43:00Z,200.0,10.0,34.76\n"
              + "ME_TE_33PF_Q590237417,ME,TE,33PF,Q590237417,28895913,132.582,-45.091,2017-05-12T10:51:00Z,200.0,10.0,34.79\n"
              + "ME_TE_33AW_68990 17,ME,TE,33AW,68990 17,29162540,-20.14,58.22,2017-06-02T20:09:00Z,200.0,10.0,35.3\n";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
    }
    // String2.log(bigResults.toString());
    /*
     * 2018-07-27 but times vary greatly
     * bigResults: (truncated to seconds) not much: but these are large data files.
     * nThreads=5 time=65
     * nThreads=4 time=77
     * nThreads=3 time=62
     * nThreads=2 time=66 63
     * nThreads=1 time=67 47 69
     * 2020-06-16
     * nThreads=5 time=26
     * nThreads=4 time=25
     * nThreads=3 time=24
     * nThreads=2 time=33
     * nThreads=1 time=35
     * nThreads=1 time=34
     * nThreads=2 time=33
     * nThreads=3 time=26
     * nThreads=4 time=26
     */

    // Table.verbose = true;
    // Table.reallyVerbose = true;
    // EDD.verbose = true;
    // EDD.reallyVerbose = true;
    // EDD.debugMode = false;
    // EDDTableFromFilesCallable.debugMode = false;
  }

  /**
   * This tests threading.
   *
   * @param tDatasetID cwwcNDBCMet or cwwcNDBCMetSSD
   * @throws Throwable if trouble
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testNThreads2() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNThreads2()\n");

    int language = 0;

    int startNThreads = -3;
    int endNThreads = 3;

    // Table.verbose = false;
    // Table.reallyVerbose = false;
    // EDD.verbose = false;
    // EDD.reallyVerbose = false;
    // EDD.debugMode = false;
    // EDDTableFromFilesCallable.debugMode = true;
    String name, tName, results, tResults, expected, userDapQuery, tQuery;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String error = "";
    int po;

    StringBuilder bigResults = new StringBuilder("\nbigResults:\n");

    // this dataset and this request are a good test that the results are always in
    // the same order
    // For testing by hand:
    // https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.htmlTable?station,latitude,longitude,time,wd,wspd,wtmp&wd=15&wspd=10&station=~"4...."&time<2020-01-01
    String id,
        tDatasetID = "cwwcNDBCMet"; // used to also run for cwwcNDBCMetSSD, does adding that back
    // provide any
    // benefit?
    userDapQuery =
        "station,latitude,longitude,time,wd,wspd,wtmp&wd=15&wspd=10&station=~\"4....\"&time<2020-01-01";

    EDDTableFromNcFiles eddTable = (EDDTableFromNcFiles) EDDTestDataset.getcwwcNDBCMet();
    for (int i = startNThreads; i <= endNThreads; i++) {
      if (i == 0) continue;
      eddTable.nThreads = Math.abs(i);

      long startTime = System.currentTimeMillis();
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, userDapQuery, dir, "testNThreads2_" + i, ".csv");

      String msg =
          "nThreads=" + i + " time=" + (System.currentTimeMillis() - startTime) / 1000 + "s\n";
      String2.log(msg);
      bigResults.append(msg);

      results = File2.directReadFrom88591File(dir + tName);
      // String2.log(results);
      expected = // ensure that order is correct //2019-07-27 results change once in awhile
          "station,latitude,longitude,time,wd,wspd,wtmp\n"
              + ",degrees_north,degrees_east,UTC,degrees_true,m s-1,degree_C\n"
              + "41001,34.675,-72.698,1988-12-12T14:00:00Z,15,10.0,20.4\n"
              + "41001,34.675,-72.698,1990-09-04T19:00:00Z,15,10.0,26.8\n"
              + "41001,34.675,-72.698,2016-02-18T04:20:00Z,15,10.0,20.8\n"
              + "41001,34.675,-72.698,2019-10-09T18:20:00Z,15,10.0,26.1\n"
              + "41002,31.887,-74.921,1994-10-17T02:00:00Z,15,10.0,24.6\n"
              + "41002,31.887,-74.921,1994-10-17T03:00:00Z,15,10.0,24.6\n"
              + "41002,31.887,-74.921,2013-11-08T22:50:00Z,15,10.0,24.6\n"
              + "41004,32.501,-79.099,1994-12-02T15:00:00Z,15,10.0,22.7\n"
              + "41004,32.501,-79.099,1995-01-29T21:00:00Z,15,10.0,18.8\n"
              + "41004,32.501,-79.099,1996-01-22T10:00:00Z,15,10.0,16.8\n"
              + "41004,32.501,-79.099,2015-02-05T16:50:00Z,15,10.0,20.3\n"
              + "41004,32.501,-79.099,2018-11-11T20:10:00Z,15,10.0,23.0\n"
              + "41004,32.501,-79.099,2019-02-04T01:40:00Z,15,10.0,22.5\n"
              + "41004,32.501,-79.099,2019-08-26T02:20:00Z,15,10.0,28.4\n"
              + "41004,32.501,-79.099,2019-10-10T15:00:00Z,15,10.0,26.6\n"
              + "41004,32.501,-79.099,2019-11-09T17:50:00Z,15,10.0,26.0\n"
              + "41006,29.3,-77.4,1990-02-13T00:00:00Z,15,10.0,24.2\n"
              + "41008,31.402,-80.869,1997-10-16T10:00:00Z,15,10.0,25.9\n";
      Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);
    }
    // Table.verbose = true;
    // Table.reallyVerbose = true;
    // EDD.verbose = true;
    // EDD.reallyVerbose = true;
    // EDD.debugMode = false;
    // EDDTableFromFilesCallable.debugMode = false;

    // throw new RuntimeException("\n*** Not necessarily a problem, just logging the
    // results:\n" +
    // bigResults.toString() +
    // "2018-08-14 was for lenovo, ssd: -5,5: 13, 10, 11, 15, 16, 15, 15, 10, 9 s\n"
    // +
    // "2018-08-14 was for lenovo, hdd: -5,5: 80, 111, 114, 38, 16, 15, 15, 10, 9\n"
    // +
    // "2019-10-21 2 core Lenovo, HDD dataset, -5,5 after warmup:
    // 9,8,10,14,14,14,13,9,7,7 truncated s)\n" +
    // "2020-10-01 with revised, denser dataset, hdd, -3,3: 539, 192, 303, 304, 321,
    // 422 s\n" +
    // " clearly, a bigger issue is OS caching of the files\n" +
    // " So slow now, so I revised test to be a much smaller test (just 410..
    // stations)\n" +
    // "2020-10-02 hdd -3,3, now: 75,8, 7, 8, 8, 5\n" +
    // "2022-05-10 after Chris' changes: 116 (can that be reduced?!),6,9,10,6,4\n");
  }

  /**
   * This tests the methods in this class. This requires erdGtsppBest in local ERDDAP and uses the
   * /subset/testEDDTableCacheFiles.json file (a copy of the erdGtsppBest.json file).
   *
   * @param deleteCachedInfo If true, this will have to reload all the files into the cache -- about
   *     40 minutes.
   * @throws Throwable if trouble
   */
  @ParameterizedTest
  @ValueSource(booleans = {true, false})
  @TagLocalERDDAP
  void testCacheFiles(boolean deleteCachedInfo) throws Throwable {
    String2.log(
        "\n****************** testCacheFiles(" + deleteCachedInfo + ") *****************\n");
    int language = 0;
    // testVerboseOn();
    // FileVisitorDNLS.verbose = true;
    // FileVisitorDNLS.reallyVerbose = true;
    // FileVisitorDNLS.debugMode = true;

    String name, tName, results, tResults, expected = null, userDapQuery, tQuery;
    String error = "";
    int po;
    EDV edv;
    long time = System.currentTimeMillis();
    StringBuilder resultsSB = new StringBuilder();

    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.
    String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String id = "testEDDTableCacheFiles";
    if (deleteCachedInfo) EDDTableFromNcFiles.deleteCachedDatasetInfo(id);
    // for test purposes, always empty the cache
    File2.deleteAllFiles(
        EDDTableFromNcFilesTests.class.getResource("/largePoints/testEDDTableCacheFiles").getPath(),
        true,
        true);

    // first attempt will start file downloads (but if deleteCachedInfo, will fail
    // to load)
    EDDTableFromFiles eddTable = (EDDTableFromFiles) EDDTestDataset.gettestEDDTableCacheFiles();

    // *** test getting das for entire dataset
    String2.log("\n****************** EDDTableCopyFiles  das and dds for entire dataset\n");
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", tDir, eddTable.className() + "TestCache_Entire", ".das");
    results = File2.directReadFrom88591File(tDir + tName);
    String2.log(results);
    expected =
        "Attributes {\n"
            + " s {\n"
            + "  trajectory {\n"
            + "    String cf_role \"trajectory_id\";\n"
            + "    String comment \"Constructed from org_type_platform_cruise\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Trajectory ID\";\n"
            + "  }\n"
            + "  org {\n"
            + "    String comment \"From the first 2 characters of stream_ident:\n"
            + "Code  Meaning\n"
            + "AD  Australian Oceanographic Data Centre\n"
            + "AF  Argentina Fisheries (Fisheries Research and Development National Institute (INIDEP), Mar del Plata, Argentina\n"
            + "AO  Atlantic Oceanographic and Meteorological Lab\n"
            + "AP  Asia-Pacific (International Pacific Research Center/ Asia-Pacific Data-Research Center)\n"
            + "BI  BIO Bedford institute of Oceanography\n"
            + "CF  Canadian Navy\n"
            + "CS  CSIRO in Australia\n"
            + "DA  Dalhousie University\n"
            + "FN  FNOC in Monterey, California\n"
            + "FR  Orstom, Brest\n"
            + "FW  Fresh Water Institute (Winnipeg)\n"
            + "GE  BSH, Germany\n"
            + "IC  ICES\n"
            + "II  IIP\n"
            + "IK  Institut fur Meereskunde, Kiel\n"
            + "IM  IML\n"
            + "IO  IOS in Pat Bay, BC\n"
            + "JA  Japanese Meteorologocal Agency\n"
            + "JF  Japan Fisheries Agency\n"
            + "ME  EDS\n"
            + "MO  Moncton\n"
            + "MU  Memorial University\n"
            + "NA  NAFC\n"
            + "NO  NODC (Washington)\n"
            + "NW  US National Weather Service\n"
            + "OD  Old Dominion Univ, USA\n"
            + "RU  Russian Federation\n"
            + "SA  St Andrews\n"
            + "SI  Scripps Institute of Oceanography\n"
            + "SO  Southampton Oceanographic Centre, UK\n"
            + "TC  TOGA Subsurface Data Centre (France)\n"
            + "TI  Tiberon lab US\n"
            + "UB  University of BC\n"
            + "UQ  University of Quebec at Rimouski\n"
            + "VL  Far Eastern Regional Hydromet. Res. Inst. of V\n"
            + "WH  Woods Hole\n"
            + "\n"
            + "from https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref006\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Organization\";\n"
            + "  }\n"
            + "  type {\n"
            + "    String comment \"From the 3rd and 4th characters of stream_ident:\n"
            + "Code  Meaning\n"
            + "AR  Animal mounted recorder\n"
            + "BA  BATHY message\n"
            + "BF  Undulating Oceanographic Recorder (e.g. Batfish CTD)\n"
            + "BO  Bottle\n"
            + "BT  general BT data\n"
            + "CD  CTD down trace\n"
            + "CT  CTD data, up or down\n"
            + "CU  CTD up trace\n"
            + "DB  Drifting buoy\n"
            + "DD  Delayed mode drifting buoy data\n"
            + "DM  Delayed mode version from originator\n"
            + "DT  Digital BT\n"
            + "IC  Ice core\n"
            + "ID  Interpolated drifting buoy data\n"
            + "IN  Ship intake samples\n"
            + "MB  MBT\n"
            + "MC  CTD and bottle data are mixed for the station\n"
            + "MI  Data from a mixed set of instruments\n"
            + "ML  Minilog\n"
            + "OF  Real-time oxygen and fluorescence\n"
            + "PF  Profiling float\n"
            + "RM  Radio message\n"
            + "RQ  Radio message with scientific QC\n"
            + "SC  Sediment core\n"
            + "SG  Thermosalinograph data\n"
            + "ST  STD data\n"
            + "SV  Sound velocity probe\n"
            + "TE  TESAC message\n"
            + "TG  Thermograph data\n"
            + "TK  TRACKOB message\n"
            + "TO  Towed CTD\n"
            + "TR  Thermistor chain\n"
            + "XB  XBT\n"
            + "XC  Expendable CTD\n"
            + "\n"
            + "from https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref082\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Data Type\";\n"
            + "  }\n"
            + "  platform {\n"
            + "    String comment \"See the list of platform codes (sorted in various ways) at https://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"GTSPP Platform Code\";\n"
            + "    String references \"https://www.nodc.noaa.gov/gtspp/document/codetbls/callist.html\";\n"
            + "  }\n"
            + "  cruise {\n"
            + "    String comment \"Radio callsign + year for real time data, or NODC reference number for delayed mode data.  See\n"
            + "https://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html .\n"
            + "'X' indicates a missing value.\n"
            + "Two or more adjacent spaces in the original cruise names have been compacted to 1 space.\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Cruise_ID\";\n"
            + "  }\n"
            + "  station_id {\n"
            + "    Int32 _FillValue 2147483647;\n"
            + "    Int32 actual_range 1, 45282398;\n"
            + // changes
            "    String cf_role \"profile_id\";\n"
            + "    String comment \"Identification number of the station (profile) in the GTSPP Continuously Managed Database\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Station ID Number\";\n"
            + "    Int32 missing_value 2147483647;\n"
            + "  }\n"
            + "  longitude {\n"
            + "    String _CoordinateAxisType \"Lon\";\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range -180.0, 179.999;\n"
            + "    String axis \"X\";\n"
            + "    String C_format \"%9.4f\";\n"
            + "    Float64 colorBarMaximum 180.0;\n"
            + "    Float64 colorBarMinimum -180.0;\n"
            + "    Int32 epic_code 502;\n"
            + "    String FORTRAN_format \"F9.4\";\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Longitude\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String standard_name \"longitude\";\n"
            + "    String units \"degrees_east\";\n"
            + "    Float32 valid_max 180.0;\n"
            + "    Float32 valid_min -180.0;\n"
            + "  }\n"
            + "  latitude {\n"
            + "    String _CoordinateAxisType \"Lat\";\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range -78.579, 90.0;\n"
            + "    String axis \"Y\";\n"
            + "    String C_format \"%8.4f\";\n"
            + "    Float64 colorBarMaximum 90.0;\n"
            + "    Float64 colorBarMinimum -90.0;\n"
            + "    Int32 epic_code 500;\n"
            + "    String FORTRAN_format \"F8.4\";\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Latitude\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String standard_name \"latitude\";\n"
            + "    String units \"degrees_north\";\n"
            + "    Float32 valid_max 90.0;\n"
            + "    Float32 valid_min -90.0;\n"
            + "  }\n"
            + "  time {\n"
            + "    String _CoordinateAxisType \"Time\";\n"
            + "    Float64 actual_range 4.772736e+8, 1.6433712e+9;\n"
            + // changes
            "    String axis \"T\";\n"
            + "    String ioos_category \"Time\";\n"
            + "    String long_name \"Time\";\n"
            + "    String standard_name \"time\";\n"
            + "    String time_origin \"01-JAN-1970 00:00:00\";\n"
            + "    String units \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "  }\n"
            + "  depth {\n"
            + "    String _CoordinateAxisType \"Height\";\n"
            + "    String _CoordinateZisPositive \"down\";\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range -0.4, 9910.0;\n"
            + "    String axis \"Z\";\n"
            + "    String C_format \"%6.2f\";\n"
            + "    Float64 colorBarMaximum 5000.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    Int32 epic_code 3;\n"
            + "    String FORTRAN_format \"F6.2\";\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Depth of the Observations\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String positive \"down\";\n"
            + "    String standard_name \"depth\";\n"
            + "    String units \"m\";\n"
            + "  }\n"
            + "  temperature {\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range -3.91, 40.0;\n"
            + "    String C_format \"%9.4f\";\n"
            + "    String cell_methods \"time: point longitude: point latitude: point depth: point\";\n"
            + "    Float64 colorBarMaximum 32.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String coordinates \"time latitude longitude depth\";\n"
            + "    Int32 epic_code 28;\n"
            + "    String FORTRAN_format \"F9.4\";\n"
            + "    String ioos_category \"Temperature\";\n"
            + "    String long_name \"Sea Water Temperature\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String standard_name \"sea_water_temperature\";\n"
            + "    String units \"degree_C\";\n"
            + "  }\n"
            + "  salinity {\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range 0.0, 41.0;\n"
            + "    String C_format \"%9.4f\";\n"
            + "    String cell_methods \"time: point longitude: point latitude: point depth: point\";\n"
            + "    Float64 colorBarMaximum 37.0;\n"
            + "    Float64 colorBarMinimum 32.0;\n"
            + "    String coordinates \"time latitude longitude depth\";\n"
            + "    Int32 epic_code 41;\n"
            + "    String FORTRAN_format \"F9.4\";\n"
            + "    String ioos_category \"Salinity\";\n"
            + "    String long_name \"Practical Salinity\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String salinity_scale \"PSU\";\n"
            + "    String standard_name \"sea_water_practical_salinity\";\n"
            + "    String units \"PSU\";\n"
            + "  }\n"
            + " }\n"
            + "  NC_GLOBAL {\n"
            + "    String acknowledgment \"These data were acquired from the US NOAA National Oceanographic Data Center (NODC) on "
            + "2022-02-10 from https://www.nodc.noaa.gov/GTSPP/.\";\n"
            + // changes
            "    String cdm_altitude_proxy \"depth\";\n"
            + "    String cdm_data_type \"TrajectoryProfile\";\n"
            + "    String cdm_profile_variables \"station_id, longitude, latitude, time\";\n"
            + "    String cdm_trajectory_variables \"trajectory, org, type, platform, cruise\";\n"
            + "    String Conventions \"COARDS, WOCE, GTSPP, CF-1.6, ACDD-1.3\";\n"
            + "    String creator_email \"nodc.gtspp@noaa.gov\";\n"
            + "    String creator_name \"NOAA NESDIS NODC (IN295)\";\n"
            + "    String creator_url \"https://www.nodc.noaa.gov/GTSPP/\";\n"
            + "    String crs \"EPSG:4326\";\n"
            + "    String defaultGraphQuery \"longitude,latitude,station_id&time%3E=max(time)-7days&time%3C=max(time)&.draw=markers&.marker=10|5\";\n"
            + "    Float64 Easternmost_Easting 179.999;\n"
            + "    String featureType \"TrajectoryProfile\";\n"
            + "    String file_source \"The GTSPP Continuously Managed Data Base\";\n"
            + "    Float64 geospatial_lat_max 90.0;\n"
            + "    Float64 geospatial_lat_min -78.579;\n"
            + "    String geospatial_lat_units \"degrees_north\";\n"
            + "    Float64 geospatial_lon_max 179.999;\n"
            + "    Float64 geospatial_lon_min -180.0;\n"
            + "    String geospatial_lon_units \"degrees_east\";\n"
            + "    Float64 geospatial_vertical_max 9910.0;\n"
            + "    Float64 geospatial_vertical_min -0.4;\n"
            + "    String geospatial_vertical_positive \"down\";\n"
            + "    String geospatial_vertical_units \"m\";\n"
            + "    String gtspp_ConventionVersion \"GTSPP4.0\";\n"
            + "    String gtspp_handbook_version \"GTSPP Data User's Manual 1.0\";\n"
            + "    String gtspp_program \"writeGTSPPnc40.f90\";\n"
            + "    String gtspp_programVersion \"1.8\";\n"
            + "    String history ";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "results=\n" + results);

    // *** test getting dds for entire dataset
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, "", tDir, eddTable.className() + "TestCache_Entire", ".dds");
    results = File2.directReadFrom88591File(tDir + tName);
    // String2.log(results);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    String trajectory;\n"
            + "    String org;\n"
            + "    String type;\n"
            + "    String platform;\n"
            + "    String cruise;\n"
            + "    Int32 station_id;\n"
            + "    Float32 longitude;\n"
            + "    Float32 latitude;\n"
            + "    Float64 time;\n"
            + "    Float32 depth;\n"
            + "    Float32 temperature;\n"
            + "    Float32 salinity;\n"
            + "  } s;\n"
            + "} s;\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // String2.pressEnterToContinue("Turn off Anti Virus software for next test?");
    // //I can't turn it off any more

    // *** test make data files
    String2.log("\n****************** EDDTableCopyFiles make DATA FILES\n");

    // .csv
    Math2.gc("EDDTableFromNcFiles (between tests)", 10000);
    resultsSB.setLength(0);
    for (int thread = 1; thread <= 1; thread++) { // or -3 to 3
      if (thread == 0) continue;
      eddTable.nThreads = Math.abs(thread);
      time = System.currentTimeMillis();
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "&station_id=1254666", // hard, must look in lots of files
              tDir,
              "gtspp1254666",
              ".csv");
      results = File2.directReadFrom88591File(tDir + tName);
      // String2.log(results);
      expected =
          "trajectory,org,type,platform,cruise,station_id,longitude,latitude,time,depth,temperature,salinity\n"
              + ",,,,,,degrees_east,degrees_north,UTC,m,degree_C,PSU\n"
              + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,0.0,20.8,NaN\n"
              + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,50.0,20.7,NaN\n"
              + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,100.0,20.7,NaN\n";
      Test.ensureEqual(results, expected, "\nresults=\n" + results);
      resultsSB.append(
          "finished query #1 nThreads="
              + eddTable.nThreads
              + " time="
              + (System.currentTimeMillis() - time)
              + " ms\n");
      Math2.gc("EDDTableFromNcFiles (between tests)", 10000);
      Math2.gc("EDDTableFromNcFiles (between tests)", 10000);
    }
    // String2.log(resultsSB.toString());
    // With AV software on, Progressively slower! 110 -> 330 s !
    // and when finished it is clear that the disk is still really busy
    // Task Manager shows activity by Antimalware Service Executable
    // With AV software temporarily off, better:
    // finished query #1 nThreads=3 time=253740 ms
    // finished query #1 nThreads=2 time=119059 ms
    // finished query #1 nThreads=1 time=119210 ms
    // finished query #1 nThreads=1 time=119712 ms
    // finished query #1 nThreads=2 time=117873 ms
    // finished query #1 nThreads=3 time=121032 ms
    // disk is quieter sooner with AV off.

    // time range should succeed quickly (except for println statements here)
    // !!! sort order of nc (by time, station_id ?) vs ncCF (by time, lat, lon ?!)
    // is different
    time = System.currentTimeMillis();
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&time>2000-01-01T02:59:59Z&time<2000-01-01T03:00:01Z&orderBy(\"station_id,depth\")",
            tDir,
            "gtsppLL",
            ".csv");
    results = File2.directReadFrom88591File(tDir + tName);
    // String2.log(results);
    expected =
        "trajectory,org,type,platform,cruise,station_id,longitude,latitude,time,depth,temperature,salinity\n"
            + ",,,,,,degrees_east,degrees_north,UTC,m,degree_C,PSU\n"
            + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,0.0,20.8,NaN\n"
            + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,50.0,20.7,NaN\n"
            + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,100.0,20.7,NaN\n"
            + "ME_BA_33TT_21002 00,ME,BA,33TT,21002 00,1254689,134.5333,37.9,2000-01-01T03:00:00Z,0.0,14.7,NaN\n"
            + "ME_BA_33TT_21002 00,ME,BA,33TT,21002 00,1254689,134.5333,37.9,2000-01-01T03:00:00Z,50.0,14.8,NaN\n"
            + "ME_BA_33TT_21002 00,ME,BA,33TT,21002 00,1254689,134.5333,37.9,2000-01-01T03:00:00Z,100.0,14.7,NaN\n"
            + "ME_BA_33TT_22001 00,ME,BA,33TT,22001 00,1254716,126.3,28.1667,2000-01-01T03:00:00Z,0.0,22.3,NaN\n"
            + "ME_BA_33TT_22001 00,ME,BA,33TT,22001 00,1254716,126.3,28.1667,2000-01-01T03:00:00Z,50.0,21.3,NaN\n"
            + "ME_BA_33TT_22001 00,ME,BA,33TT,22001 00,1254716,126.3,28.1667,2000-01-01T03:00:00Z,100.0,19.8,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
    String2.log(
        "finished query #2 time="
            + (System.currentTimeMillis() - time)
            + " ms (expected ~140 ms)\n");

    String2.log("\n*** testCacheFiles() finished successfully.");
    // FileVisitorDNLS.verbose = false;
    // FileVisitorDNLS.reallyVerbose = false;
    // FileVisitorDNLS.debugMode = false;
    /* */
  }

  /**
   * This test that there are files in each of the /data/gtspp/bestNcConsolidated/year/month/
   * directories.
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testGtspp15FilesExist() throws Exception {
    int year1 = 1990;
    int year2 = 2021;

    // String2.log("\n*** testGtspp15FilesExist(" + year1 + ", " + year2 + ")\n" +
    // "This should fail at current calendar month.");
    int language = 0;
    for (int year = year1; year <= year2; year++) {
      for (int month = 1; month <= 12; month++) {
        String dir =
            Path.of(
                    EDDTableFromNcFilesTests.class
                        .getResource(
                            "/veryLarge/gtspp/bestNcConsolidated/"
                                + year
                                + "/"
                                + String2.zeroPad("" + month, 2)
                                + "/")
                        .toURI())
                .toString();
        Table table =
            FileVisitorDNLS.oneStep( // throws IOException if "Too many open files"
                dir, ".*\\.nc", false, // recursive?
                ".*", false); // tDirectoriesToo?
        if (table.nRows() == 0) {
          throw new Exception("No files in " + dir);
        }
      }
    }
  }

  /**
   * This test that there are files in each of the /data/gtspp/bestNcConsolidated/year/month/
   * directories.
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testGtsppabFilesExist() throws Exception {
    int year1 = 1990;
    int year2 = 2021;
    // String2.log("\n*** testGtsppabFilesExist(" + year1 + ", " + year2 + ")\n" +
    // "This should fail at current calendar month.");

    int language = 0;
    String dir =
        Path.of(EDDTableFromNcFilesTests.class.getResource("/veryLarge/points/gtsppNcCf/").toURI())
                .toString()
            + "/";
    for (int year = year1; year <= year2; year++) {
      for (int month = 1; month <= 12; month++) {
        String tName = year + String2.zeroPad("" + month, 2) + "a.nc";
        if (!File2.isFile(dir + tName)) {
          throw new Exception("File not found: " + dir + tName);
        }
        tName = year + String2.zeroPad("" + month, 2) + "b.nc";
        if (!File2.isFile(dir + tName)) {
          throw new Exception("File not found: " + dir + tName);
        }
      }
    }
  }

  /**
   * This makes a series of graphs which test log axes.
   *
   * @param whichChunk -1 (all) or 0 - 4.
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  @TagImageComparison
  void testLogAxis() throws Throwable {
    int whichChunk = -1;
    // String2.log("\n*** EDDTableFromNcFiles.testLogAxis()");

    int language = 0;
    String tDir = Image2Tests.urlToAbsolutePath(Image2Tests.OBS_DIR);
    String tName, baseName, start, query, results, expected;
    EDDTable eddTable;

    // test default=linear
    eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    if (whichChunk < 0 || whichChunk == 0) {
      start = "testTableLogAxis_TimeGust_";
      query = "time,gst&time>=2014-01-20&time<=2014-02-01&station=\"41029\"&.draw=lines";
      baseName = start + "XLogIsIgnoredSinceTimeAxis";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.xRange=|||Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;
    }

    if (whichChunk < 0 || whichChunk == 1) {
      start = "testTableLogAxis_TimeGust_";
      query = "time,gst&time>=2014-01-20&time<=2014-02-01&station=\"41029\"&.draw=lines";
      /* */
      baseName = start + "DefaultIsLinear";
      tName = eddTable.makeNewFileForDapQuery(language, null, null, query, tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "0.1_100DefaultIsAscendingLinear";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=0.1|100||", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "AscendingLinear";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=0.1|100|true|Linear", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "AscendingLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=0.1|100|true|log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "DescendingLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=0.1|100|false|Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "WideRangeLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=1e-5|1e5||Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "Wide5RangeLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=5e-6|5e5||Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "HardIntraDecadeLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              query + "&.yRange=15|35||Log", // hard
              // intra-decade,
              // no
              // power
              // of
              // 10
              // in
              // range,
              // 2
              // small
              // tics
              // visible
              tDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "SuperHardIntraDecadeLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              query + "&.yRange=10.2|19||Log", // super
              // hard
              // intra-decade,
              // no
              // power
              // of
              // 10
              // in
              // range
              tDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;
      /* */
    }

    if (whichChunk < 0 || whichChunk == 2) {

      // swap x and y axes
      start = "tableTestLogAxis_GustTime_";
      query = "gst,time&time>=2014-01-20&time<=2014-02-01&station=\"41029\"&.draw=lines";
      /* */

      baseName = start + "DefaultIsLinear";
      tName = eddTable.makeNewFileForDapQuery(language, null, null, query, tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "0.1_100DefaultIsAscendingLinear";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.xRange=0.1|100||", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "AscendingLinear";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.xRange=0.1|100|true|Linear", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "AscendingLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.xRange=0.1|100|true|log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "DescendingLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.xRange=0.1|100|false|Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "WideRangeLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.xRange=1e-5|1e5||Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "Wide5RangeLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.xRange=5e-6|5e5||Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "HardIntraDecadeLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              query + "&.xRange=15|35||Log", // hard
              // intra-decade,
              // no
              // power
              // of
              // 10
              // in
              // range,
              // 2
              // small
              // tics
              // visible
              tDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "SuperHardIntraDecadeLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              query + "&.xRange=10.2|19||Log", // super
              // hard
              // intra-decade,
              // no
              // power
              // of
              // 10
              // in
              // range
              tDir,
              baseName,
              ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;
      /* */
    }

    // test default=Log
    eddTable = (EDDTable) EDDTestDataset.gettestGlobecBottle();

    if (whichChunk < 0 || whichChunk == 3) {
      start = "tableTestLogAxis_TimeChla_";
      query = "time,chl_a_total&time<=\"2002-06-18\"&.draw=lines";

      baseName = start + "DefaultIsLogButNegValues";
      tName = eddTable.makeNewFileForDapQuery(language, null, null, query, tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "DefaultIsAscendingLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=0.05|50||", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "AscendingLinear";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=0.05|50|true|Linear", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "AscendingLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=0.05|50|true|Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "DescendingLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=0.05|50|false|Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "WideRangeLog";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=1e-5|1e5||Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;

      baseName = start + "WideRangeLog5";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, query + "&.yRange=5e-6|5e5||Log", tDir, baseName, ".png");
      Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      ;
      /* */
    }
  }

  /** Test DAP errors. */
  @org.junit.jupiter.api.Test
  @TagLocalERDDAP
  void testDapErrors() throws Throwable {
    int language = 0;
    String baseRequest = "http://localhost:8080/cwexperimental/tabledap/";
    String results, expected;

    String2.log("\n*** EDDTableFromNcFiles.testDapErrors()");
    String comment = "\n!!! These tests require cwwcNDBCMet and noaaOSPv1 in localhost ERDDAP.";

    /*
     * 400 Bad Request - for request syntax errors
     * 401 Unauthorized - for when the user isn't authorized to access a given
     * dataset
     * 403 Forbidden - when the user is on the blacklist
     * 404 Not Found - for dataset not found or
     * "Your query produced no matching results."
     * 408 Timeout - for dataset not found or
     * "Your query produced no matching results."
     * 413 Payload Too Large
     * 416 Range Not Satisfiable - for invalid byte range requests
     * 500 Internal Server Error - for errors while responding to the request and
     * unexpected errors
     */

    // test of 400 Bad Request: syntax error
    try {
      results =
          SSR.getUrlResponseStringNewline(
              baseRequest + "cwwcNDBCMet.csv?time&time==2002-07-06"); // ==
    } catch (Throwable t) {
      results = t.toString();
    }
    Test.ensureEqual(
        results,
        "java.io.IOException: HTTP status code=400 for URL: http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMet.csv?time&time==2002-07-06\n"
            + "(Error {\n"
            + "    code=400;\n"
            + "    message=\"Bad Request: Query error: Use '=' instead of '==' in constraints.\";\n"
            + "})",
        "results=\n" + results + comment);

    // test of 400 Bad Request: Tomcat rejects this (doesn't show in ERDDAP log.txt)
    // because of unencoded >, so no dap formatted error and no details.
    try {
      results =
          SSR.getUrlResponseStringNewline(
              baseRequest + "cwwcNDBCMet.csv?time&time>2050-01-01&distinct%28%29");
    } catch (Throwable t) {
      results = t.toString();
    }
    expected =
        "java.io.IOException: HTTP status code=400 for URL: "
            + "http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMet.csv?time&time>2050-01-01&distinct%28%29";
    Test.ensureEqual(
        results.substring(0, expected.length()), expected, "results=\n" + results + comment);

    // test of 400 Bad Request: syntax error: two commas
    try {
      results =
          SSR.getUrlResponseStringNewline(
              baseRequest + "cwwcNDBCMet.csv?time,,stationID&time%3E2050-01-01&distinct%28%29");
    } catch (Throwable t) {
      results = t.toString();
    }
    Test.ensureEqual(
        results,
        "java.io.IOException: HTTP status code=400 for URL: http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMet.csv?time,,stationID&time%3E2050-01-01&distinct%28%29\n"
            + "(Error {\n"
            + "    code=400;\n"
            + "    message=\"Bad Request: Query error: Unrecognized variable=\\\"\\\".\";\n"
            + "})",
        "results=\n" + results + comment);

    // test of 400 Bad Request: unsupported file type (vs 404: emphasis here on
    // syntax error, and permanent error)
    try {
      results = SSR.getUrlResponseStringNewline(baseRequest + "cwwcNDBCMet.zztop");
    } catch (Throwable t) {
      results = t.toString();
    }
    Test.ensureEqual(
        results,
        "java.io.IOException: HTTP status code=400 for URL: http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMet.zztop\n"
            + "(Error {\n"
            + "    code=400;\n"
            + "    message=\"Bad Request: Query error: fileType=.zztop isn't supported by this dataset.\";\n"
            + "})",
        "results=\n" + results + comment);

    // test of 401 Unauthorized
    try {
      results = SSR.getUrlResponseStringNewline(baseRequest + "noaaOSPv1.html");
    } catch (Throwable t) {
      results = t.toString();
    }
    Test.ensureEqual(
        results,
        "java.io.IOException: HTTP status code=401 for URL: http://localhost:8080/cwexperimental/tabledap/noaaOSPv1.html\n"
            + "(Error {\n"
            + "    code=401;\n"
            + "    message=\"Unauthorized: loggedInAs=null isn't authorized to access datasetID=noaaOSPv1.\";\n"
            + "})",
        "results=\n" + results + comment);

    // test of 404 not found: unknown datasetID (vs 400: emphasis here on correct
    // syntax, but no such resource (perhaps temporary)
    try {
      results = SSR.getUrlResponseStringNewline(baseRequest + "cwwcNDBCMetzztop.html");
    } catch (Throwable t) {
      results = t.toString();
    }
    Test.ensureEqual(
        results,
        "java.io.IOException: HTTP status code=404 java.io.FileNotFoundException: http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMetzztop.html\n"
            + "(Error {\n"
            + "    code=404;\n"
            + "    message=\"Not Found: Currently unknown datasetID=cwwcNDBCMetzztop\";\n"
            + "})",
        "results=\n" + results + comment);

    // test of 404 not found: No matching results. (request needs to be percent
    // encoded, else tomcat rejects with 400)
    try {
      results =
          SSR.getUrlResponseStringNewline(
              baseRequest + "cwwcNDBCMet.csv?time&time%3E2050-01-01&distinct%28%29");
    } catch (Throwable t) {
      results = t.toString();
    }
    expected =
        "java.io.IOException: HTTP status code=404 java.io.FileNotFoundException: http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMet.csv?time&time%3E2050-01-01&distinct%28%29\n"
            + "(Error {\n"
            + "    code=404;\n"
            + "    message=\"Not Found: Your query produced no matching results. "
            +
            // error message is one of these two (changes periodically):
            // "(No data matches time>2050-01-01T00:00:00Z because the numeric variable's
            // source min=1970-02-26T20:00:00Z, max=202";
            "(time>2050-01-01T00:00:00Z is outside of the variable's actual_range: 1970-02-26T20:00:00Z to 202"; // 2022-01-18T21:00:00Z,
    // and
    // hasNaN=false.)\n";
    // //end
    // date
    // changes
    Test.ensureEqual(
        results.substring(0, expected.length()), expected, "results=\n" + results + comment);

    // test of timeout, but not caught by ERDDAP (caught by tomcat? this java?) so
    // not in desired/testable format
    if (false) {
      String2.log("!!! This next test is very slow (about 5 minutes)!");
      try {
        results =
            SSR.getUrlResponseStringNewline(baseRequest + "cwwcNDBCMet.nc?&station%3C%22a%22");
      } catch (Throwable t) {
        results = t.toString();
      }
      Test.ensureEqual(
          results,
          "java.io.IOException: ERROR from url=http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMet.nc?&station%3C%22a%22 "
              + ": java.net.SocketTimeoutException: Read timed out",
          "results=\n" + results + comment);
    }

    // I DON'T KNOW HOW TO TEST THIS!
    // 413 Payload Too Large: ERDDAP works to comply. Only fails when results it is
    // ready to build .nc.
    if (false) {
      String2.log("!!! This next test is very slow (about ??? minutes)!");
      try {
        results =
            SSR.getUrlResponseStringNewline(baseRequest + "cwwcNDBCMet.nc  HOW TEST???"); // ???
      } catch (Throwable t) {
        results = t.toString();
      }
      Test.ensureEqual(results, "zztop", "results=\n" + results + comment);
    }

    // how test 500 Internal Server Error?
    /*
     * try {
     * results = SSR.getUrlResponseStringNewline(baseRequest + "");
     * } catch (Throwable t) {
     * results = t.toString();
     * }
     * Test.ensureEqual(results,
     * "zztop",
     * "results=\n" + results + comment);
     */

  }

  /** This tests a problem with precision. */
  @org.junit.jupiter.api.Test
  void testPrecision() throws Throwable {

    // String2.log("\n*** EDDTableFromNcFiles.testPrecision()");

    int language = 0;
    String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String dapQuery, tName, start, query, results, expected;
    EDDTable eddTable;
    tName = "/data/pacioos/wqb04_2018_02_01.nc";
    String2.log("\nContents of " + tName + ":\n" + NcHelper.ncdump(tName, "temperature"));

    // test default=linear
    eddTable = (EDDTable) EDDTestDataset.gettestPrecision();
    dapQuery = "&time>max(time)-3days";
    tName =
        eddTable.makeNewFileForDapQuery(
            language,
            null,
            null,
            dapQuery,
            tDir,
            eddTable.className() + "_testPrecision",
            ".htmlTable");
    // Test.displayInBrowser("file://" + tDir + tName);
  }

  /**
   * This tests orderBy graphs in Make A Graph. There were errors in respondToGraphQuery() because
   * it hadn't kept up with changes to orderBy options over the years.
   */
  @org.junit.jupiter.api.Test
  @TagLocalERDDAP
  @TagLargeFiles
  void testMAGOrderByGraphs() throws Throwable {

    String2.log(
        "\n*** EDDTableFromNcFiles.testMAGOrderByGraphs()\n"
            + "This REQUIRES cwwcNDBCMet in localhost ERDDAP.");
    int language = 0;
    String tDir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String dapQuery, tName, start, query, results, expected;
    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();

    // these test very minimal (but common) orderBy requests
    dapQuery =
        "http://localhost:8080/erddap/tabledap/cwwcNDBCMet.graph?"
            + "time,atmp&time%3E=2021-01-01T00%3A00%3A00Z&time%3C=2021-01-08T00%3A00%3A00Z"
            + "&station=%2246088%22&.draw=lines&.color=0x000000&.bgColor=0xffccccff";

    Test.displayInBrowser(
        dapQuery + "&orderBy(%22atmp%22)"); // goofy request (draw in ascending order of
    // atmp, not
    // time), but ERDDAP does what it was asked

    Test.displayInBrowser(
        dapQuery + "&orderByClosest(%22time/1day%22)"); // value each day which is closest
    // to
    // midnight

    Test.displayInBrowser(
        dapQuery + "&orderByCount(%22time/1day%22)"); // !!!y axis units should be 'count'

    Test.displayInBrowser(
        dapQuery + "&orderByLimit(%22time/1day,4%22)"); // first 4 values from each day

    Test.displayInBrowser(
        dapQuery + "&orderByMax(%22time/1day,atmp%22)"); // the max atmp each day (at the
    // time it
    // occurred)

    Test.displayInBrowser(
        dapQuery + "&orderByMin(%22time/1day,atmp%22)"); // the max atmp each day (at the
    // time it
    // occurred)

    Test.displayInBrowser(
        dapQuery + "&orderByMinMax(%22time/1day,atmp%22)"); // the min and max atmp each
    // day (at
    // the time they occurred).
    // Better if
    // markers.

    Test.displayInBrowser(dapQuery + "&orderByMean(%22time/1day%22)"); // the mean atmp each day

    Test.displayInBrowser(
        dapQuery + "&orderBySum(%22time/1day%22)"); // goofy request, but ERDDAP does what
    // it was
    // asked

  }

  /**
   * This tests making a too-big request from localhost ERDDAP to ensure it throws error and doesn't
   * crash.
   */
  @org.junit.jupiter.api.Test
  @TagLocalERDDAP
  void testTooBigLocalhostRequest() throws Exception {
    String toName = File2.getSystemTempDirectory() + "testTooBigLocalhostRequest";
    String2.log(
        "\n* EDDTableFromNcFiles.testTooBigLocalhostRequest()\n"
            + "!!!This requires cwwcNDBCMet and pmelTaoDySst in localhost ERDDAP.\n"
            + "tempFileBaseName="
            + toName);
    String result;
    long time = System.currentTimeMillis();
    String queries[] = { // < " " ,
      "http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMet.csv?&station%3c%22a%22&distinct()",
      "http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMet.csv?&station%3c%22a%22&orderBy(%22station,time%22)",
    };

    for (int i = 0; i < queries.length; i++) {
      result = "shouldn't happen";
      try {
        SSR.downloadFile(queries[i], toName, true); // tryToUseCompression
        String2.log("fileLength=" + File2.length(toName) / Math2.BytesPerGB + "GB");
        result =
            // This is what I see in a browser:
            "Error {\n"
                + "    code=413;\n"
                + "    message=\"Payload Too Large: Your query produced too much data.  Try to request less data. [memory]  The request needs more memory (233 MB) than is currently available in this Java setup (-110 MB). (gathering data in TableWriterAll)\n"
                + "}";
      } catch (Exception e) {
        String2.log("caught exception"); // this is what should happen
        result = e.toString();
      }
      File2.delete(toName);
      long seconds = (System.currentTimeMillis() - time) / 1000;
      String2.log("test #" + i + " finished in " + seconds + "s"); // 611s for query 0
      Test.ensureEqual(
          result,
          // from e.toString. SSR.downloadFile just returns a generic error message.
          "java.io.IOException: ERROR in downloadFile while downloading from " + queries[i],
          "test #" + i);
      Test.ensureTrue(seconds > 500, "test #" + i + " that time=" + seconds + " > 500s");
    }
  }

  /** This test making transparentPngs. */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  @TagImageComparison
  void testTransparentPng() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testTransparentPng");

    // testVerboseOn();
    int language = 0;
    // reallyVerbose = false;
    String dir = Image2Tests.urlToAbsolutePath(Image2Tests.OBS_DIR);
    String name, tName, baseName, userDapQuery, results, expected, error;
    String dapQuery;

    EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();
    /*  */
    // markers on a map
    dapQuery =
        "longitude,latitude,wtmp&time=2010-01-02T00:00:00Z"
            + "&longitude>=-140&longitude<=-110&latitude>=20&latitude<=50"
            + "&.draw=markers&.marker=5|5&.color=0xff0000&.colorBar=|||||";
    baseName = eddTable.className() + "_markersMap";
    tName = eddTable.makeNewFileForDapQuery(language, null, null, dapQuery, dir, baseName, ".png");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPmarkersMap";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery, dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPmarkersMap500400";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery + "&.size=500|400", dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    // vector map
    dapQuery =
        "longitude,latitude,wspu,wspv&time=2010-01-02T00:00:00Z"
            + "&longitude>=-140&longitude<=-110&latitude>=20&latitude<=50"
            + "&.draw=vectors&.color=0xff0000";
    baseName = eddTable.className() + "_vectors";
    tName = eddTable.makeNewFileForDapQuery(language, null, null, dapQuery, dir, baseName, ".png");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPvectors";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery, dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPvectors360150";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery + "&.size=360|150", dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    // lines on a graph
    dapQuery =
        "time,wtmp"
            + "&station=\"41009\"&time>=2000-01-01T00:00:00Z&time<=2000-01-02T00:00:00Z"
            + "&.draw=lines&.color=0xff0000&.colorBar=|||||";
    baseName = eddTable.className() + "_lines";
    tName = eddTable.makeNewFileForDapQuery(language, null, null, dapQuery, dir, baseName, ".png");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPlines";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery, dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPlines500400";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery + "&.size=500|400", dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    // markers on a graph
    dapQuery =
        "time,wtmp"
            + "&station=\"41009\"&time>=2000-01-01T00:00:00Z&time<=2000-01-02T00:00:00Z"
            + "&.draw=markers&.marker=5|5&.color=0xff0000&.colorBar=|||||";
    baseName = eddTable.className() + "_markers";
    tName = eddTable.makeNewFileForDapQuery(language, null, null, dapQuery, dir, baseName, ".png");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPmarkers";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery, dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPmarkers500400";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery + "&.size=500|400", dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    // sticks on a graph
    dapQuery =
        "time,wspu,wspv"
            + "&station=\"41009\"&time>=2000-01-01T00:00:00Z&time<=2000-01-02T00:00:00Z"
            + "&.draw=sticks&.color=0xff0000";
    baseName = eddTable.className() + "_sticks";
    tName = eddTable.makeNewFileForDapQuery(language, null, null, dapQuery, dir, baseName, ".png");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPsticks";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery, dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");

    baseName = eddTable.className() + "_TPsticks500400";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery + "&.size=500|400", dir, baseName, ".transparentPng");
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
    /* */
  }

  /** This tests a long time graph. */
  @org.junit.jupiter.api.Test
  @TagImageComparison
  @TagSlowTests
  void testTimeAxis() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testTimeAxis");

    int language = 0;
    // testVerboseOn();
    // reallyVerbose = true;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String name, tName, baseName, userDapQuery, results, expected, error;
    String dapQuery;

    String id = "testTimeAxis";
    EDDTableFromNcFiles.deleteCachedDatasetInfo(id);
    EDDTable eddTable = (EDDTable) EDDTestDataset.gettestTimeAxis();

    // test reject based on time>lastTime
    // Note that dataset's last time value is exactly 2011-07-01
    try {
      dapQuery = "time,irradiance&time>=2012-01-09T01:02:03.123Z";
      tName =
          eddTable.makeNewFileForDapQuery(
              language, null, null, dapQuery, dir, eddTable.className() + "_afterMaxTime", ".csv");
      results = "shouldn't get here";
    } catch (Throwable t) {
      results = MustBe.throwableToString(t);
    }
    expected =
        "SimpleException: Your query produced no matching results. "
            +
            // request is .123, but it has fudge applied in EDDTable.getSourceQuery...
            // String2.genEFormat10(
            "(time>=2012-01-09T01:02:03.123Z is outside of the variable's actual_range: "
            + "1610-07-01T00:00:00.000Z to 2011-07-01T00:00:00.000Z)";
    Test.ensureEqual(
        results.substring(0, Math.min(results.length(), expected.length())),
        expected,
        "results=" + results);

    // test the interesting time axis cases and the extremes of each sub-axis type
    String time[] = {
      "0000-01-01",
      "0100-01-01",
      "0500-01-01",
      "1000-01-01",
      "1300-01-01", // century
      "1400-01-01",
      "1900-01-01",
      "1940-01-01", // decade
      "1950-01-01",
      "1990-01-01",
      "2009-01-01", // year
      "2010-01-01",
      "2011-01-01",
      "2011-04-09", // month
      "2011-04-10",
      "2011-06-01",
      "2011-06-28T06", // date
      "2011-06-29T12",
      "2011-06-30",
      "2011-06-30T20", // hours
      "2011-06-30T21",
      "2011-06-30T23:00",
      "2011-06-30T23:56:15", // minutes
      "2011-06-30T23:56:30",
      "2011-06-30T23:58:30",
      "2011-06-30T23:59:56", // seconds
      "2011-06-30T23:59:57",
      "2011-06-30T23:59:58",
      "2011-06-30T23:59:59", // millis
      "2011-06-30T23:59:59.7",
      "2011-06-30T23:59:59.97",
      "2011-06-30T23:59:59.997", // millis
      "2011-07-01"
    }; // min=max
    for (int i = 0; i < time.length; i++) {
      // for (int i = 0; i < 3; i++) {

      for (int lowToHigh = 0; lowToHigh < 2; lowToHigh++) {
        dapQuery = "time,irradiance&time>=" + time[i] + "&.xRange=||" + (lowToHigh == 0);
        baseName = "EDDTableFromNcFiles_TimeAxis" + i + "_" + lowToHigh;
        tName =
            eddTable.makeNewFileForDapQuery(
                language,
                null,
                null,
                dapQuery,
                Image2Tests.urlToAbsolutePath(Image2Tests.OBS_DIR),
                baseName,
                ".png");
        Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
      }
    }
  }

  /**
   * This tests modifying the time axis with add_offset (so source times are fractional years) and
   * units="years since 0000-07-01" (to again make the times all at July 1).
   */
  @org.junit.jupiter.api.Test
  void testModTime() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testModTime");

    int language = 0;
    // testVerboseOn();
    // reallyVerbose = true;
    // boolean oDebugMode = debugMode;
    // debugMode = true;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String name, tName, userDapQuery, results, expected, error;
    String dapQuery;

    String id = "testModTime";
    EDDTableFromNcFiles.deleteCachedDatasetInfo(id);
    EDDTable eddTable = (EDDTable) EDDTestDataset.gettestTimeAxis();

    expected = "time,irradiance\n" + "UTC,W/m^2\n" + "2011-07-01T00:00:00.000Z,1361.3473\n";

    dapQuery = "time,irradiance&time=\"2011-07-01\"";
    tName =
        eddTable.makeNewFileForDapQuery(
            language, null, null, dapQuery, dir, eddTable.className() + "_ModTime2", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    Test.ensureEqual(results, expected, "results=\n" + results);

    // debugMode = oDebugMode;
  }

  /**
   * This test the speed of all types of responses. This test is in this class because the source
   * data is in a file, so it has reliable access speed. This gets a pretty big chunk of data.
   *
   * @param firstTest 0..
   * @param lastTest (inclusive) Any number greater than last available is interpreted as last
   *     available.
   */
  @org.junit.jupiter.api.Test
  @TagLocalERDDAP
  void testSpeed(int firstTest, int lastTest) throws Throwable {
    String2.log(
        "\n*** EDDTableFromNcFiles.testSpeed\n"
            + "THIS REQUIRES THE cwwcNDBCMet DATASET TO BE IN LOCALHOST ERDDAP!!!\n"
            + SgtUtil.isBufferedImageAccelerated()
            + "\n");
    int language = 0;
    // boolean oReallyVerbose = reallyVerbose;
    // reallyVerbose = false;
    String outName;
    // 2017-10-13 I switched from getFile to curl
    // The advantage is: curl will detect if outputstream isn't being closed.
    // 2018-05-17 switched from curl to SSR.downloadFile
    String baseRequest = "http://localhost:8080/cwexperimental/tabledap/cwwcNDBCMet";
    // userDapQuery will make time series graphs
    // not just a 121000 points at the same location on a map
    String userDapQuery =
        "?"
            + SSR.minimalPercentEncode(
                "time,wtmp,station,longitude,latitude,wd,wspd,gst,wvht,dpd,apd,mwd,"
                    + "bar,atmp,dewp,vis,ptdy,tide,wspu,wspv&station=\"41006\""
                    + "&time>0."); // random integer will be appended to avoid cached response
    String baseOut = EDStatic.fullTestCacheDirectory + "EDDTableFromNcFilesTestSpeed";
    ArrayList al;
    int timeOutSeconds = 120;
    String extensions[] =
        new String[] { // .help not available at this level
          ".asc",
          ".csv",
          ".csvp",
          ".csv0",
          ".dataTable",
          ".das",
          ".dds",
          ".dods",
          ".esriCsv",
          ".geoJson",
          ".graph",
          ".html",
          ".htmlTable",
          ".json",
          ".jsonlCSV1",
          ".jsonlCSV",
          ".jsonlKVP",
          ".mat",
          ".nc",
          ".ncHeader",
          ".nccsv",
          ".nccsvMetadata",
          ".ncoJson",
          ".odvTxt",
          ".subset",
          ".tsv",
          ".tsvp",
          ".tsv0",
          ".xhtml", // 26?
          ".kml",
          ".smallPdf",
          ".pdf",
          ".largePdf",
          ".smallPng",
          ".png",
          ".largePng"
        };
    int expectedMs[] =
        new int[] {
          // 2017-10-13 I added 200 ms with change from getFile to curl
          // now Java 1.7 M4700 //was Java 1.6 //was Java 1.5
          // graphics tests changed a little 1.5 -> 1.6, so not perfectly comparable
          // 2018-05-07 I changed (often 200ms faster) with change from curl to
          // SSR.downloadFile
          // 2018-08-08 adjusted (mostly slower) for Lenovo
          // 2020-03-09 times faster after big changes to cwwcNDBCMet, because files
          // smaller with no extra rows on-the-hour with all mv's.
          1287,
          1210,
          1197,
          1196, // 3125, 2625, 2687, ?, //4469, 4125, 4094, ?,
          1503,
          14,
          16,
          3855, // 2014-09 .dods slower 176->508 why? // 16, 31, 687 //16, 32, 1782,
          1371,
          1658,
          48,
          40, // 3531, 5219, 47, 31, //5156, 6922, 125, 100,
          517,
          1226,
          1173,
          1242,
          1639, // 1672, 2719, ., ., //4109, 4921, ., .,
          3849,
          1163,
          578, // 1531, 1922, 1797, //4921, 4921, 4610,
          1268,
          19,
          1631,
          1581,
          21,
          1017,
          1000,
          1049, // 4266, 32, 2562, 2531, ?, //8359, 31, 3969, 3921, ?,
          1362, // but really slow if hard drive is busy! //4266 //6531,
          517,
          706,
          676,
          717, // 2078, 2500, 2063, 2047, //4500, 5800, 5812, 5610,
          964,
          974,
          1022
        }; // 2984, 3125, 3391 //5421, 5204, 5343};
    int bytes[] =
        new int[] { // 2020-03-09 sizes changed after big changes to cwwcNDBCMet, because no extra
          // rows on-the-hour with all mv's.
          14493013,
          10818144,
          10818181,
          10817912,
          43563367,
          15905,
          394,
          9594837,
          12806297,
          45015505,
          162741,
          201524,
          10271462,
          14327112,
          13627044,
          13626879,
          28018527,
          8596992,
          8111472,
          16504,
          13431604,
          14306,
          16022691,
          9568422,
          28826,
          10818144,
          10818181,
          10817912,
          41180319,
          5839,
          72560,
          117505,
          138010,
          10529,
          16301,
          37397
        };

    // warm up
    boolean tryToCompress = true;
    outName = baseOut + "Warmup.pdf.pdf";
    SSR.downloadFile(
        baseRequest + ".pdf" + userDapQuery + Math2.random(10000), outName, tryToCompress);
    // al = SSR.dosShell(baseRequest + ".pdf" + userDapQuery + Math2.random(10000) +
    // " -o " + outName, timeOutSeconds);
    // String2.log(String2.toNewlineString(al.toArray()));

    outName = baseOut + "Warmup.png.png";
    SSR.downloadFile(
        baseRequest + ".png" + userDapQuery + Math2.random(10000), outName, tryToCompress);
    // al = SSR.dosShell(baseRequest + ".png" + userDapQuery + Math2.random(10000) +
    // " -o " + outName, timeOutSeconds);

    lastTest = Math.min(lastTest, extensions.length - 1);
    for (int ext = firstTest; ext <= lastTest; ext++) {
      Math2.sleep(2000); // try not to let computer get bogged down (anti virus checking)
      // String2.pressEnterToContinue("");
      String dotExt = extensions[ext];
      try {
        String2.log("\n*** EDDTableFromNcFiles.testSpeed test#" + ext + ": " + dotExt + " speed\n");
        long time = 0, cLength = 0;
        for (int chance = 0; chance < 3; chance++) {
          Math2.gcAndWait("EDDGridFromNcFiles (between tests)"); // in a test
          time = System.currentTimeMillis();
          outName = baseOut + chance + dotExt;
          SSR.downloadFile(
              baseRequest + dotExt + userDapQuery + Math2.random(10000), outName, tryToCompress);
          // al = SSR.dosShell(baseRequest + dotExt + userDapQuery +
          // Math2.random(10000) +
          // " -o " + outName, timeOutSeconds);

          time = System.currentTimeMillis() - time;
          cLength = File2.length(outName);
          String2.log(
              "\n*** EDDTableFromNcFiles.testSpeed test#"
                  + ext
                  + " chance#"
                  + chance
                  + ": "
                  + dotExt
                  + " done.\n  "
                  + cLength
                  + " bytes (expected="
                  + bytes[ext]
                  + ").  time="
                  + time
                  + "ms (expected="
                  + expectedMs[ext]
                  + ")\n");
          Math2.sleep(3000);

          // if not too slow or too fast, break
          if (time > 1.5 * Math.max(100, expectedMs[ext])
              || time < (expectedMs[ext] <= 50 ? 0.1 : 0.5) * expectedMs[ext]) {
            // give it another chance
          } else {
            break;
          }
        }

        // display?
        if (false) { // String2.indexOf(EDDTable.imageFileTypeNames, dotExt) >= 0
          // Test.displayInBrowser("file://" + outName);
          Math2.gc("EDDTableFromNcFiles (between tests)", 5000); // in a test, pause for
          // image display
        }

        // size test
        Test.ensureTrue(
            cLength > 0.9 * bytes[ext],
            "File shorter than expected.  observed="
                + cLength
                + " expected=~"
                + bytes[ext]
                + "\n"
                + outName);
        Test.ensureTrue(
            cLength < 1.1 * bytes[ext],
            "File longer than expected.  observed="
                + cLength
                + " expected=~"
                + bytes[ext]
                + "\n"
                + outName);

        // time test
        if (time > 1.5 * Math.max(100, expectedMs[ext]))
          throw new SimpleException(
              "Slower than expected. observed=" + time + " expected=~" + expectedMs[ext] + " ms.");
        if (expectedMs[ext] >= 50 && time < 0.5 * expectedMs[ext])
          throw new SimpleException(
              "Faster than expected! observed=" + time + " expected=~" + expectedMs[ext] + " ms.");

        // display last image
        if (ext == extensions.length - 1) {
          File2.rename(outName, outName + ".png");
          // Test.displayInBrowser( outName + ".png");
        }

        // data test for .nc (especially string column)
        // This is important test of EDDTable.saveAsFlatNc for nRows >
        // partialRequestMaxCells
        // (especially since changes on 2010-09-07).
        if (dotExt.equals(".nc")) {
          Table table = new Table();
          table.readFlatNc(outName, null, 1); // standardizeWhat=1
          int nRows = table.nRows();
          String2.log(".nc fileName=" + outName + "\n" + "nRows=" + nRows);
          String results = table.dataToString(2);
          String expected =
              "time,wtmp,station,longitude,latitude,wd,wspd,gst,wvht,dpd,apd,mwd,bar,atmp,dewp,vis,ptdy,tide,wspu,wspv\n"
                  + "3.912804E8,24.8,41006,-77.4,29.3,297,4.1,5.3,1.0,8.3,4.8,,1014.7,22.0,,,,,3.7,-1.9\n"
                  + "3.91284E8,24.7,41006,-77.4,29.3,,,,1.1,9.1,4.5,,1014.6,22.2,,,,,,\n"
                  + "...\n";
          String2.log("results=\n" + results);
          Test.ensureEqual(results, expected, "");
          for (int row = 0; row < nRows; row++) {
            Test.ensureEqual(table.getStringData(2, row), "41006", "");
            Test.ensureEqual(table.getFloatData(3, row), -77.4f, "");
            Test.ensureEqual(table.getFloatData(4, row), 29.3f, "");
          }
        }
        // String2.pressEnterToContinue("Okay.");
      } catch (Exception e) {
        throw new Exception(
            MustBe.throwableToString(e) + "Unexpected error for Test#" + ext + ": " + dotExt + ".");
      }
    }
    // reallyVerbose = oReallyVerbose;
  }

  /**
   * This a graph with many years.
   *
   * @param whichTest -1 for all, or 0..
   */
  @org.junit.jupiter.api.Test
  @TagImageComparison
  void testManyYears() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testManyYears\n");

    int language = 0;
    EDDTable eddTable = (EDDTable) EDDTestDataset.geterdCAMarCatSY();
    String dir = Image2Tests.urlToAbsolutePath(Image2Tests.OBS_DIR);
    String dapQuery =
        "time,landings&port=%22Santa%20Barbara%22&fish=%22Abalone%22&.draw=lines&.color=0x000000";
    String baseName = eddTable.className() + "_manyYears";
    String tName =
        eddTable.makeNewFileForDapQuery(language, null, null, dapQuery, dir, baseName, ".png");
    // Test.displayInBrowser("file://" + dir + tName);
    Image2Tests.testImagesIdentical(tName, baseName + ".png", baseName + "_diff.png");
  }

  /**
   * Tests the data created by getCAMarCatShort() and getCAMarCatLong() and served by erdCAMarCatSM,
   * SY, LM, LY.
   */
  @org.junit.jupiter.api.Test
  @TagSlowTests
  void testCAMarCat() throws Throwable {

    int language = 0;
    EDDTable eddTable;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String tName, results, expected;

    // ***test short name list
    // http://las.pfeg.noaa.gov:8082/thredds/dodsC/CA_market_catch/ca_fish_grouped_short.nc.ascii
    // ?landings[12:23][1=Los Angeles][1=Barracuda, California]
    /*
     * landings.landings[12][1][1]
     * [0][0], 15356
     * [1][0], 93891
     * [2][0], 178492
     * [3][0], 367186
     * [4][0], 918303
     * [5][0], 454981
     * [6][0], 342464
     * [7][0], 261587
     * [8][0], 175979
     * [9][0], 113828
     * [10][0], 46916
     * [11][0], 73743
     *
     * landings.time_series[12]
     * 254568.0, 255312.0, 255984.0, 256728.0, 257448.0, 258192.0, 258912.0,
     * 259656.0, 260400.0, 261120.0, 261864.0, 262584.0
     *
     * 254568 hours since 1900-01-01 = 1929-01-16T00:00:00Z
     * 262584 hours since 1900-01-01 = 1929-12-16T00:00:00Z
     */

    for (int i = 0; i < 2; i++) {
      char SL = i == 0 ? 'S' : 'L';

      // *** monthly
      String2.log("\n*** test erdCAMarCat" + SL + "M");
      eddTable =
          (EDDTable)
              (i == 0 ? EDDTestDataset.geterdCAMarCatSM() : EDDTestDataset.geterdCAMarCatLM());
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "&port=\"Los Angeles\"&fish=\"Barracuda, California\"&year=1929",
              dir,
              eddTable.className() + "_" + SL + "M",
              ".csv");
      results = File2.directReadFrom88591File(dir + tName);
      expected =
          "time,year,fish,port,landings\n"
              + "UTC,,,,pounds\n"
              + "1929-01-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,15356\n"
              + "1929-02-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,93891\n"
              + "1929-03-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,178492\n"
              + "1929-04-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,367186\n"
              + "1929-05-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,918303\n"
              + "1929-06-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,454981\n"
              + "1929-07-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,342464\n"
              + "1929-08-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,261587\n"
              + "1929-09-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,175979\n"
              + "1929-10-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,113828\n"
              + "1929-11-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,46916\n"
              + "1929-12-16T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,73743\n";
      Test.ensureEqual(results, expected, "erdCAMarCat" + SL + "M results=\n" + results);

      // salmon became separable in 1972. Separation appears in Long list of names,
      // not Short.
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "&port=\"All\"&fish=\"Salmon\"&year>=1976&year<=1977",
              dir,
              eddTable.className() + "_" + SL + "M",
              ".csv");
      results = File2.directReadFrom88591File(dir + tName);
      expected =
          SL == 'S'
              ? "time,year,fish,port,landings\n"
                  + "UTC,,,,pounds\n"
                  + "1976-01-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1976-02-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1976-03-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1976-04-16T00:00:00Z,1976,Salmon,All,465896\n"
                  + "1976-05-16T00:00:00Z,1976,Salmon,All,1932912\n"
                  + "1976-06-16T00:00:00Z,1976,Salmon,All,2770715\n"
                  + "1976-07-16T00:00:00Z,1976,Salmon,All,1780115\n"
                  + "1976-08-16T00:00:00Z,1976,Salmon,All,581702\n"
                  + "1976-09-16T00:00:00Z,1976,Salmon,All,244695\n"
                  + "1976-10-16T00:00:00Z,1976,Salmon,All,485\n"
                  + "1976-11-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1976-12-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1977-01-16T00:00:00Z,1977,Salmon,All,0\n"
                  + "1977-02-16T00:00:00Z,1977,Salmon,All,43\n"
                  + "1977-03-16T00:00:00Z,1977,Salmon,All,0\n"
                  + "1977-04-16T00:00:00Z,1977,Salmon,All,680999\n"
                  + "1977-05-16T00:00:00Z,1977,Salmon,All,1490628\n"
                  + "1977-06-16T00:00:00Z,1977,Salmon,All,980842\n"
                  + "1977-07-16T00:00:00Z,1977,Salmon,All,1533176\n"
                  + "1977-08-16T00:00:00Z,1977,Salmon,All,928234\n"
                  + "1977-09-16T00:00:00Z,1977,Salmon,All,314464\n"
                  + "1977-10-16T00:00:00Z,1977,Salmon,All,247\n"
                  + "1977-11-16T00:00:00Z,1977,Salmon,All,0\n"
                  + "1977-12-16T00:00:00Z,1977,Salmon,All,0\n"
              : "time,year,fish,port,landings\n"
                  + "UTC,,,,pounds\n"
                  + "1976-01-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1976-02-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1976-03-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1976-04-16T00:00:00Z,1976,Salmon,All,465896\n"
                  + "1976-05-16T00:00:00Z,1976,Salmon,All,1932912\n"
                  + "1976-06-16T00:00:00Z,1976,Salmon,All,2770715\n"
                  + "1976-07-16T00:00:00Z,1976,Salmon,All,1780115\n"
                  + "1976-08-16T00:00:00Z,1976,Salmon,All,581702\n"
                  + "1976-09-16T00:00:00Z,1976,Salmon,All,244695\n"
                  + "1976-10-16T00:00:00Z,1976,Salmon,All,485\n"
                  + "1976-11-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1976-12-16T00:00:00Z,1976,Salmon,All,0\n"
                  + "1977-01-16T00:00:00Z,1977,Salmon,All,0\n"
                  + "1977-02-16T00:00:00Z,1977,Salmon,All,0\n"
                  + "1977-03-16T00:00:00Z,1977,Salmon,All,0\n"
                  + "1977-04-16T00:00:00Z,1977,Salmon,All,1223\n"
                  + "1977-05-16T00:00:00Z,1977,Salmon,All,1673\n"
                  + "1977-06-16T00:00:00Z,1977,Salmon,All,2333\n"
                  + "1977-07-16T00:00:00Z,1977,Salmon,All,1813\n"
                  + "1977-08-16T00:00:00Z,1977,Salmon,All,1300\n"
                  + "1977-09-16T00:00:00Z,1977,Salmon,All,924\n"
                  + "1977-10-16T00:00:00Z,1977,Salmon,All,0\n"
                  + "1977-11-16T00:00:00Z,1977,Salmon,All,0\n"
                  + "1977-12-16T00:00:00Z,1977,Salmon,All,0\n";
      Test.ensureEqual(results, expected, "erdCAMarCat" + SL + "M results=\n" + results);

      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "&port=\"All\"&fish=\"Salmon\"&time>=1976-01-01&time<=1977-12-31",
              dir,
              eddTable.className() + "_" + SL + "M",
              ".csv");
      results = File2.directReadFrom88591File(dir + tName);
      Test.ensureEqual(results, expected, "erdCAMarCat" + SL + "M results=\n" + results);

      // *** yearly
      String2.log("\n**** test erdCAMarCat" + SL + "Y");
      eddTable =
          (EDDTable)
              (i == 0 ? EDDTestDataset.geterdCAMarCatSY() : EDDTestDataset.geterdCAMarCatLY());
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "&port=\"Los Angeles\"&fish=\"Barracuda, California\"&year=1929",
              dir,
              eddTable.className() + "_" + SL + "Y",
              ".csv");
      results = File2.directReadFrom88591File(dir + tName);
      expected =
          "time,year,fish,port,landings\n"
              + "UTC,,,,pounds\n"
              + "1929-07-01T00:00:00Z,1929,\"Barracuda, California\",Los Angeles,3042726\n";
      Test.ensureEqual(results, expected, "erdCAMarCat" + SL + "Y results=\n" + results);

      // salmon became separable in 1972. Separation appears in Long list of names,
      // not Short.
      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "&port=\"All\"&fish=\"Salmon\"&year>=1971&year<=1980",
              dir,
              eddTable.className() + "_" + SL + "M",
              ".csv");
      results = File2.directReadFrom88591File(dir + tName);
      expected =
          SL == 'S'
              ? "time,year,fish,port,landings\n"
                  + "UTC,,,,pounds\n"
                  + "1971-07-01T00:00:00Z,1971,Salmon,All,8115432\n"
                  + "1972-07-01T00:00:00Z,1972,Salmon,All,6422171\n"
                  + "1973-07-01T00:00:00Z,1973,Salmon,All,9668966\n"
                  + "1974-07-01T00:00:00Z,1974,Salmon,All,8749013\n"
                  + "1975-07-01T00:00:00Z,1975,Salmon,All,6925082\n"
                  + "1976-07-01T00:00:00Z,1976,Salmon,All,7776520\n"
                  + "1977-07-01T00:00:00Z,1977,Salmon,All,5928633\n"
                  + "1978-07-01T00:00:00Z,1978,Salmon,All,6810880\n"
                  + "1979-07-01T00:00:00Z,1979,Salmon,All,8747677\n"
                  + "1980-07-01T00:00:00Z,1980,Salmon,All,6021953\n"
              : "time,year,fish,port,landings\n"
                  + "UTC,,,,pounds\n"
                  + "1971-07-01T00:00:00Z,1971,Salmon,All,8115432\n"
                  + "1972-07-01T00:00:00Z,1972,Salmon,All,6422171\n"
                  + "1973-07-01T00:00:00Z,1973,Salmon,All,9668966\n"
                  + "1974-07-01T00:00:00Z,1974,Salmon,All,8749013\n"
                  + "1975-07-01T00:00:00Z,1975,Salmon,All,6925082\n"
                  + "1976-07-01T00:00:00Z,1976,Salmon,All,7776520\n"
                  + "1977-07-01T00:00:00Z,1977,Salmon,All,9266\n"
                  + "1978-07-01T00:00:00Z,1978,Salmon,All,21571\n"
                  + "1979-07-01T00:00:00Z,1979,Salmon,All,30020\n"
                  + "1980-07-01T00:00:00Z,1980,Salmon,All,40653\n";
      Test.ensureEqual(results, expected, "erdCAMarCat" + SL + "M results=\n" + results);

      tName =
          eddTable.makeNewFileForDapQuery(
              language,
              null,
              null,
              "&port=\"All\"&fish=\"Salmon\"&time>=1971-01-01&time<=1980-12-31",
              dir,
              eddTable.className() + "_" + SL + "M",
              ".csv");
      results = File2.directReadFrom88591File(dir + tName);
      Test.ensureEqual(results, expected, "erdCAMarCat" + SL + "M results=\n" + results);
    }
    String2.log("\n**** test EDDTableFromNcFiles.testErdCAMarCat finished successfully");
  }

  /** Tests the data created by getCAMarCatLong() and served by erdCAMarCatLM and erdCAMarCatLY. */
  @org.junit.jupiter.api.Test
  void testCAMarCatL() throws Throwable {
    int language = 0;
    EDDTable eddTable;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String tName, results, expected;

    // *** test long name list
    // http://las.pfeg.noaa.gov:8082/thredds/dodsC/CA_market_catch/ca_fish_grouped.nc.ascii
    // ?landings[12:23][1=Los Angeles][2=Barracuda, California]
    /*
     * landings.landings[12][1][1]
     * [0][0], 15356
     * [1][0], 93891
     * [2][0], 178492
     * [3][0], 367186
     * [4][0], 918303
     * [5][0], 454981
     * [6][0], 342464
     * [7][0], 261587
     * [8][0], 175979
     * [9][0], 113828
     * [10][0], 46916
     * [11][0], 73743
     */

  }

  /**
   * Tests Kerfoot bug fix "problem with time units" bug related to updateEveryNMinutes with numeric
   * time data and units other than "seconds since 1970-01-01T00:00:00Z"
   */
  @org.junit.jupiter.api.Test
  @TagLocalERDDAP
  void testTimeSince19000101() throws Throwable {
    String2.log("\n*** EDDTableFromNcFiles.testTimeSince19000101");
    int language = 0;

    EDDTable eddTable;
    String tName, results;
    String query =
        "http://localhost:8080/cwexperimental/tabledap/allDatasets.csv?"
            + "datasetID,minTime,maxTime&datasetID=%22testTimeSince19000101%22";
    String expected =
        "datasetID,minTime,maxTime\n"
            + ",UTC,UTC\n"
            + "testTimeSince19000101,2016-05-06T22:42:59Z,2016-05-29T23:49:32Z\n";
    // before fix, this showed 2086-05-06 after dataset's update.

    // ensure the dataset is loaded in local ERDDAP
    // and initial time range is correct
    results = SSR.getUrlResponseStringUnchanged(query);
    Test.ensureEqual(results, expected, "results=\n" + results);

    // "touch" the file back
    File2.touch("[putDirHere]/time/since19000101.nc"); // one time

    // wait a second (so update isn't skipped because time elapsed is too small)
    Math2.sleep(1000);

    // look at allDatasets time range
    results = SSR.getUrlResponseStringUnchanged(query);
    Test.ensureEqual(results, expected, "results=\n" + results);
  }

  /** Test making an .ncCF Point file. */
  @org.junit.jupiter.api.Test
  @TagMissingDataset
  void testNcCFPoint() throws Throwable {

    try {

      String2.log("\n*** EDDTableFromNcFiles.testNcCFPoint");
      int language = 0;
      // this dataset is not fromNcFiles, but test here with other testNcCF tests
      EDDTable tedd = (EDDTable) EDDTestDataset.getnwioosCoral();
      String tName, error, results, expected;
      String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
      int po;
      String today =
          Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to
      // check hour.
      // Hard to check
      // min:sec.
      String2.log("\nafter constructor, combinedGlobal=\n" + tedd.combinedGlobalAttributes());

      // lon lat time range
      tName =
          tedd.makeNewFileForDapQuery(
              language,
              null,
              null,
              "longitude,latitude,depth,time,taxa_scientific,institution,species_code"
                  + "&taxa_scientific=\"Alyconaria unident.\"",
              dir,
              "ncCF",
              ".ncCF");
      results = NcHelper.ncdump(dir + tName, "");
      // String2.log(results);
      expected =
          "netcdf ncCF.nc {\n"
              + "  dimensions:\n"
              + "    row = 4;\n"
              + "    taxa_scientific_strlen = 19;\n"
              + "    institution_strlen = 4;\n"
              + "  variables:\n"
              + "    double longitude(row=4);\n"
              + "      :_CoordinateAxisType = \"Lon\";\n"
              + "      :actual_range = -125.00184631347656, -121.3140640258789; // double\n"
              + "      :axis = \"X\";\n"
              + "      :ioos_category = \"Location\";\n"
              + "      :long_name = \"Longitude\";\n"
              + "      :standard_name = \"longitude\";\n"
              + "      :units = \"degrees_east\";\n"
              + "\n"
              + "    double latitude(row=4);\n"
              + "      :_CoordinateAxisType = \"Lat\";\n"
              + "      :actual_range = 34.911373138427734, 47.237003326416016; // double\n"
              + "      :axis = \"Y\";\n"
              + "      :ioos_category = \"Location\";\n"
              + "      :long_name = \"Latitude\";\n"
              + "      :standard_name = \"latitude\";\n"
              + "      :units = \"degrees_north\";\n"
              + "\n"
              + "    double depth(row=4);\n"
              + "      :_CoordinateAxisType = \"Height\";\n"
              + "      :_CoordinateZisPositive = \"down\";\n"
              + "      :actual_range = 77.0, 474.0; // double\n"
              + // note that this is for a
              // subset of the dataset
              "      :axis = \"Z\";\n"
              + "      :colorBarMaximum = 1500.0; // double\n"
              + "      :colorBarMinimum = 0.0; // double\n"
              + "      :ioos_category = \"Location\";\n"
              + "      :long_name = \"Depth\";\n"
              + "      :positive = \"down\";\n"
              + "      :standard_name = \"depth\";\n"
              + "      :units = \"m\";\n"
              + "\n"
              + "    double time(row=4);\n"
              + "      :_CoordinateAxisType = \"Time\";\n"
              + "      :actual_range = 8.836128E8, 9.783072E8; // double\n"
              + "      :axis = \"T\";\n"
              + "      :Description = \"Year of Survey.\";\n"
              + "      :ioos_category = \"Time\";\n"
              + "      :long_name = \"Time (Beginning of Survey Year)\";\n"
              + "      :standard_name = \"time\";\n"
              + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
              + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
              + "\n"
              + "    char taxa_scientific(row=4, taxa_scientific_strlen=19);\n"
              + "      :_Encoding = \"ISO-8859-1\";\n"
              + "      :coordinates = \"time latitude longitude depth\";\n"
              + "      :Description = \"Scientific name of taxa\";\n"
              + "      :ioos_category = \"Taxonomy\";\n"
              + "      :long_name = \"Taxa Scientific\";\n"
              + "\n"
              + "    char institution(row=4, institution_strlen=4);\n"
              + "      :_Encoding = \"ISO-8859-1\";\n"
              + "      :coordinates = \"time latitude longitude depth\";\n"
              + "      :Description = \"Institution is either: Northwest Fisheries Science Center (FRAM Division) or Alaska Fisheries Science Center (RACE Division)\";\n"
              + "      :ioos_category = \"Identifier\";\n"
              + "      :long_name = \"Institution\";\n"
              + "\n"
              + "    double species_code(row=4);\n"
              + "      :actual_range = 41101.0, 41101.0; // double\n"
              + "      :coordinates = \"time latitude longitude depth\";\n"
              + "      :Description = \"Unique identifier for species.\";\n"
              + "      :ioos_category = \"Taxonomy\";\n"
              + "      :long_name = \"Species Code\";\n"
              + "\n"
              + "  // global attributes:\n"
              + "  :cdm_data_type = \"Point\";\n"
              + "  :Conventions = \"COARDS, CF-1.6, ACDD-1.3\";\n"
              + "  :Easternmost_Easting = -121.3140640258789; // double\n"
              + "  :featureType = \"Point\";\n"
              + "  :geospatial_lat_max = 47.237003326416016; // double\n"
              + "  :geospatial_lat_min = 34.911373138427734; // double\n"
              + "  :geospatial_lat_units = \"degrees_north\";\n"
              + "  :geospatial_lon_max = -121.3140640258789; // double\n"
              + "  :geospatial_lon_min = -125.00184631347656; // double\n"
              + "  :geospatial_lon_units = \"degrees_east\";\n"
              + "  :geospatial_vertical_max = 474.0; // double\n"
              + "  :geospatial_vertical_min = 77.0; // double\n"
              + "  :geospatial_vertical_positive = \"down\";\n"
              + "  :geospatial_vertical_units = \"m\";\n"
              + "  :history = \""
              + today;
      String tResults = results.substring(0, Math.min(results.length(), expected.length()));
      Test.ensureEqual(tResults, expected, "\nresults=\n" + results);

      // + " http://nwioos.coas.oregonstate.edu:8080/dods/drds/Coral%201980-2005\n" +
      // today +

      expected =
          "http://localhost:8080/erddap/tabledap/nwioosCoral.ncCF?longitude,latitude,depth,time,taxa_scientific,institution,species_code&taxa_scientific=\"Alyconaria unident.\"\";\n"
              + "  :id = \"nwioosCoral\";\n"
              + "  :infoUrl = \"http://nwioos.coas.oregonstate.edu:8080/dods/drds/Coral%201980-2005.info\";\n"
              + "  :institution = \"NOAA NWFSC\";\n"
              + "  :keywords = \"1980-2005, abbreviation, atmosphere, beginning, coast, code, collected, coral, data, depth, Earth Science > Biological Classification > Animals/Invertebrates > Cnidarians > Anthozoans/Hexacorals > Hard Or Stony Corals, Earth Science > Biosphere > Aquatic Ecosystems > Coastal Habitat, Earth Science > Biosphere > Aquatic Ecosystems > Marine Habitat, family, genus, height, identifier, institution, noaa, nwfsc, off, order, scientific, species, station, survey, taxa, taxonomic, taxonomy, time, west, west coast, year\";\n"
              + "  :keywords_vocabulary = \"GCMD Science Keywords\";\n"
              + "  :license = \"The data may be used and redistributed for free but is not intended\n"
              + "for legal use, since it may contain inaccuracies. Neither the data\n"
              + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
              + "of their employees or contractors, makes any warranty, express or\n"
              + "implied, including warranties of merchantability and fitness for a\n"
              + "particular purpose, or assumes any legal liability for the accuracy,\n"
              + "completeness, or usefulness, of this information.\";\n"
              + "  :Northernmost_Northing = 47.237003326416016; // double\n"
              + "  :sourceUrl = \"http://nwioos.coas.oregonstate.edu:8080/dods/drds/Coral%201980-2005\";\n"
              + "  :Southernmost_Northing = 34.911373138427734; // double\n"
              + "  :standard_name_vocabulary = \"CF Standard Name Table v55\";\n"
              + "  :subsetVariables = \"longitude, latitude, depth, time, institution, institution_id, species_code, taxa_scientific, taxonomic_order, order_abbreviation, taxonomic_family, family_abbreviation, taxonomic_genus\";\n"
              + "  :summary = \"This data contains the locations of some observations of\n"
              + "cold-water/deep-sea corals off the west coast of the United States.\n"
              + "Records of coral catch originate from bottom trawl surveys conducted\n"
              + "from 1980 to 2001 by the Alaska Fisheries Science Center (AFSC) and\n"
              + "2001 to 2005 by the Northwest Fisheries Science Center (NWFSC).\n"
              + "Locational information represent the vessel mid positions (for AFSC\n"
              + "survey trawls) or \"best position\" (i.e., priority order: 1) gear\n"
              + "midpoint 2) vessel midpoint, 3) vessel start point, 4) vessel end\n"
              + "point, 5) station coordinates for NWFSC survey trawls) conducted as\n"
              + "part of regular surveys of groundfish off the coasts of Washington,\n"
              + "Oregon and California by NOAA Fisheries. Only records where corals\n"
              + "were identified in the total catch are included. Each catch sample\n"
              + "of coral was identified down to the most specific taxonomic level\n"
              + "possible by the biologists onboard, therefore identification was\n"
              + "dependent on their expertise. When positive identification was not\n"
              + "possible, samples were sometimes archived for future identification\n"
              + "by systematist experts. Data were compiled by the NWFSC, Fishery\n"
              + "Resource Analysis & Monitoring Division\n"
              + "\n"
              + "Purpose - Examination of the spatial and temporal distributions of\n"
              + "observations of cold-water/deep-sea corals off the west coast of the\n"
              + "United States, including waters off the states of Washington, Oregon,\n"
              + "and California. It is important to note that these records represent\n"
              + "only presence of corals in the area swept by the trawl gear. Since\n"
              + "bottom trawls used during these surveys are not designed to sample\n"
              + "epibenthic invertebrates, absence of corals in the catch does not\n"
              + "necessary mean they do not occupy the area swept by the trawl gear.\n"
              + "\n"
              + "Data Credits - NOAA Fisheries, Alaska Fisheries Science Center,\n"
              + "Resource Assessment & Conservation Engineering Division (RACE) NOAA\n"
              + "Fisheries, Northwest Fisheries Science Center, Fishery Resource\n"
              + "Analysis & Monitoring Division (FRAM)\n"
              + "\n"
              + "Contact: Curt Whitmire, NOAA NWFSC, Curt.Whitmire@noaa.gov\";\n"
              + "  :time_coverage_end = \"2001-01-01T00:00:00Z\";\n"
              + "  :time_coverage_start = \"1998-01-01T00:00:00Z\";\n"
              + "  :title = \"NWFSC Coral Data Collected off West Coast of US (1980-2005)\";\n"
              + "  :Westernmost_Easting = -125.00184631347656; // double\n"
              + " data:\n"
              + "longitude =\n"
              + "  {-125.00184631347656, -124.56075286865234, -121.42329406738281, -121.3140640258789}\n"
              + "latitude =\n"
              + "  {47.237003326416016, 47.082645416259766, 34.911720275878906, 34.911373138427734}\n"
              + "depth =\n"
              + "  {450.0, 77.0, 462.0, 474.0}\n"
              + "time =\n"
              + "  {9.783072E8, 9.783072E8, 8.836128E8, 8.836128E8}\n"
              + "taxa_scientific =\"Alyconaria unident.\", \"Alyconaria unident.\", \"Alyconaria unident.\", \"Alyconaria unident.\"\n"
              + "institution =\"RACE\", \"RACE\", \"RACE\", \"RACE\"\n"
              + "species_code =\n"
              + "  {41101.0, 41101.0, 41101.0, 41101.0}\n"
              + "}\n";
      int tPo = results.indexOf(expected.substring(0, 17));
      Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
      Test.ensureEqual(
          results.substring(tPo, Math.min(results.length(), tPo + expected.length())),
          expected,
          "results=\n" + results);

      String2.log("\n*** EDDTableFromNcFiles.testNcCFPoint finished.");

    } catch (Throwable t) {
      Test.knownProblem("nwioos source currently isn't working.", "", t);
    }
  }

  /** Test making an .ncCF TimeSeries file. */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testNcCF1a() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNcCF1a");

    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.getcwwcNDBCMet(); // should work
    String tName, error, results, expected;
    int po;
    String query =
        "longitude,latitude,station,time,atmp,wtmp"
            + "&longitude>-123&longitude<-122&latitude>37&latitude<38"
            + "&time>=2005-05-01T00:00:00&time<=2005-05-01T02:00:00";
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // lon lat time range
    tName = tedd.makeNewFileForDapQuery(language, null, null, query, dir, "ncCF1a", ".ncCF");
    results = NcHelper.ncdump(dir + tName, "");
    results = results.replaceAll("\\d{4}-\\d{2}-\\d{2}", "9999-99-99");
    results = results.replaceAll("\\d{2}:\\d{2}:\\d{2}", "99:99:99");

    // String2.log(results);
    expected =
        "netcdf ncCF1a.nc {\n"
            + "  dimensions:\n"
            + "    timeseries = 7;\n"
            + "    obs = 62;\n"
            + "    station_strlen = 5;\n"
            + "  variables:\n"
            + "    float longitude(timeseries=7);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :actual_range = -122.975f, -122.21f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :colorBarMaximum = 180.0; // double\n"
            + "      :colorBarMinimum = -180.0; // double\n"
            + "      :comment = \"The longitude of the station.\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "    float latitude(timeseries=7);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :actual_range = 37.363f, 37.997f; // float\n"
            + "      :axis = \"Y\";\n"
            + "      :colorBarMaximum = 90.0; // double\n"
            + "      :colorBarMinimum = -90.0; // double\n"
            + "      :comment = \"The latitude of the station.\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "\n"
            + "    char station(timeseries=7, station_strlen=5);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"timeseries_id\";\n"
            + "      :comment = \"The station identifier.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station Identifier\";\n"
            + "\n"
            + "    int rowSize(timeseries=7);\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Number of Observations for this TimeSeries\";\n"
            + "      :sample_dimension = \"obs\";\n"
            + "\n"
            + "    double time(obs=62);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.1149056E9, 1.1149128E9; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 99:99:99\";\n"
            + "      :units = \"seconds since 9999-99-99T99:99:99Z\";\n"
            + "\n"
            + "    float atmp(obs=62);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 13.3f, 15.2f; // float\n"
            + "      :colorBarMaximum = 40.0; // double\n"
            + "      :colorBarMinimum = -10.0; // double\n"
            + "      :comment = \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\";\n"
            + "      :coordinates = \"time latitude longitude\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Air Temperature\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"air_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    float wtmp(obs=62);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 9.3f, 17.0f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\";\n"
            + "      :coordinates = \"time latitude longitude\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"SST\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"sea_surface_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"TimeSeries\";\n"
            + "  :cdm_timeseries_variables = \"station, longitude, latitude\";\n"
            + "  :contributor_name = \"NOAA NDBC\";\n"
            + "  :contributor_role = \"Source of data.\";\n"
            + "  :Conventions = \"COARDS, CF-1.10, ACDD-1.3\";\n"
            + "  :creator_email = \"erd.data@noaa.gov\";\n"
            + "  :creator_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :creator_type = \"institution\";\n"
            + "  :creator_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :date_created = \"9999-99-99\";\n"
            + "  :date_issued = \"9999-99-99\";\n"
            + "  :Easternmost_Easting = -122.21f; // float\n"
            + "  :featureType = \"TimeSeries\";\n"
            + "  :geospatial_lat_max = 37.997f; // float\n"
            + "  :geospatial_lat_min = 37.363f; // float\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = -122.21f; // float\n"
            + "  :geospatial_lon_min = -122.975f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_positive = \"down\";\n"
            + "  :geospatial_vertical_units = \"m\";\n"
            + "  :history = \"Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\n"
            + "Every 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.\n"
            + "9999-99-99T99:99:99Z https://www.ndbc.noaa.gov/\n"
            + "9999-99-99T99:99:99Z http://localhost:8080/erddap/tabledap/cwwcNDBCMet.ncCF?longitude,latitude,station,time,atmp,wtmp&longitude>-123&longitude<-122&latitude>37&latitude<38&time>=9999-99-99T99:99:99&time<=9999-99-99T99:99:99\";\n"
            + "  :id = \"cwwcNDBCMet\";\n"
            + "  :infoUrl = \"https://www.ndbc.noaa.gov/\";\n"
            + "  :institution = \"NOAA NDBC, NOAA NMFS SWFSC ERD\";\n"
            + "  :keywords = \"air, air_pressure_at_sea_level, air_temperature, atmosphere, atmospheric, average, boundary, buoy, coastwatch, data, dew point, dew_point_temperature, direction, dominant, Earth Science > Atmosphere > Air Quality > Visibility, Earth Science > Atmosphere > Altitude > Planetary Boundary Layer Height, Earth Science > Atmosphere > Atmospheric Pressure > Atmospheric Pressure Measurements, Earth Science > Atmosphere > Atmospheric Pressure > Pressure Tendency, Earth Science > Atmosphere > Atmospheric Pressure > Sea Level Pressure, Earth Science > Atmosphere > Atmospheric Pressure > Static Pressure, Earth Science > Atmosphere > Atmospheric Temperature > Air Temperature, Earth Science > Atmosphere > Atmospheric Temperature > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Water Vapor > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Winds > Surface Winds, Earth Science > Oceans > Ocean Temperature > Sea Surface Temperature, Earth Science > Oceans > Ocean Waves > Significant Wave Height, Earth Science > Oceans > Ocean Waves > Swells, Earth Science > Oceans > Ocean Waves > Wave Period, eastward, eastward_wind, from, gust, height, identifier, layer, level, measurements, meridional, meteorological, meteorology, name, ndbc, noaa, northward, northward_wind, ocean, oceans, period, planetary, pressure, quality, sea, sea level, sea_surface_swell_wave_period, sea_surface_swell_wave_significant_height, sea_surface_swell_wave_to_direction, sea_surface_temperature, seawater, significant, speed, sst, standard, static, station, surface, surface waves, surface_altitude, swell, swells, temperature, tendency, tendency_of_air_pressure, time, vapor, visibility, visibility_in_air, water, wave, waves, wcn, wind, wind_from_direction, wind_speed, wind_speed_of_gust, winds, zonal\";\n"
            + "  :keywords_vocabulary = \"GCMD Science Keywords\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "  :naming_authority = \"gov.noaa.pfeg.coastwatch\";\n"
            + "  :Northernmost_Northing = 37.997f; // float\n"
            + "  :project = \"NOAA NDBC and NOAA NMFS SWFSC ERD\";\n"
            + "  :publisher_email = \"erd.data@noaa.gov\";\n"
            + "  :publisher_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :publisher_type = \"institution\";\n"
            + "  :publisher_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :quality = \"Automated QC checks with periodic manual QC\";\n"
            + "  :source = \"station observation\";\n"
            + "  :sourceUrl = \"https://www.ndbc.noaa.gov/\";\n"
            + "  :Southernmost_Northing = 37.363f; // float\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :subsetVariables = \"station, longitude, latitude\";\n"
            + "  :summary = \"The National Data Buoy Center (NDBC) distributes meteorological data from\n"
            + "moored buoys maintained by NDBC and others. Moored buoys are the weather\n"
            + "sentinels of the sea. They are deployed in the coastal and offshore waters\n"
            + "from the western Atlantic to the Pacific Ocean around Hawaii, and from the\n"
            + "Bering Sea to the South Pacific. NDBC's moored buoys measure and transmit\n"
            + "barometric pressure; wind direction, speed, and gust; air and sea\n"
            + "temperature; and wave energy spectra from which significant wave height,\n"
            + "dominant wave period, and average wave period are derived. Even the\n"
            + "direction of wave propagation is measured on many moored buoys. See\n"
            + "https://www.ndbc.noaa.gov/measdes.shtml for a description of the measurements.\n"
            + "\n"
            + "The source data from NOAA NDBC has different column names, different units,\n"
            + "and different missing values in different files, and other problems\n"
            + "(notably, lots of rows with duplicate or different values for the same time\n"
            + "point). This dataset is a standardized, reformatted, and lightly edited\n"
            + "version of that source data, created by NOAA NMFS SWFSC ERD (email:\n"
            + "erd.data at noaa.gov). Before 9999-99-99, this dataset only had the data\n"
            + "that was closest to a given hour, rounded to the nearest hour. Now, this\n"
            + "dataset has all of the data available from NDBC with the original time\n"
            + "values. If there are multiple source rows for a given buoy for a given\n"
            + "time, only the row with the most non-NaN data values is kept. If there is\n"
            + "a gap in the data, a row of missing values is inserted (which causes a nice\n"
            + "gap when the data is graphed). Also, some impossible data values are\n"
            + "removed, but this data is not perfectly clean. This dataset is now updated\n"
            + "every 5 minutes.\n"
            + "\n"
            + "This dataset has both historical data (quality controlled, before\n"
            + "9999-99-99T99:99:99Z) and near real time data (less quality controlled,\n"
            + "which may change at any time, from 9999-99-99T99:99:99Z on).\";\n"
            + "  :testOutOfDate = \"now-25minutes\";\n"
            + "  :time_coverage_end = \"9999-99-99T99:99:99Z\";\n"
            + "  :time_coverage_start = \"9999-99-99T99:99:99Z\";\n"
            + "  :title = \"NDBC Standard Meteorological Buoy Data, 1970-present\";\n"
            + "  :Westernmost_Easting = -122.975f; // float\n";

    String expected2 =
        "\n"
            + "  data:\n"
            + "    longitude = \n"
            + "      {-122.881, -122.833, -122.298, -122.465, -122.975, -122.4, -122.21}\n"
            + "    latitude = \n"
            + "      {37.363, 37.759, 37.772, 37.807, 37.997, 37.928, 37.507}\n"
            + "    station =   \"46012\",   \"46026\",   \"AAMC1\",   \"FTPC1\",   \"PRYC1\",   \"RCMC1\",   \"RTYC1\"\n"
            + "    rowSize = \n"
            + "      {3, 3, 13, 13, 3, 13, 14}\n"
            + "    time = \n"
            + "      {1.1149056E9, 1.1149092E9, 1.1149128E9, 1.1149056E9, 1.1149092E9, 1.1149128E9, 1.1149056E9, 1.11490668E9, 1.1149074E9, 1.11490776E9, 1.11490848E9, 1.11490884E9, 1.1149092E9, 1.11490956E9, 1.11491028E9, 1.114911E9, 1.11491136E9, 1.11491208E9, 1.1149128E9, 1.1149056E9, 1.11490668E9, 1.1149074E9, 1.11490776E9, 1.11490848E9, 1.11490884E9, 1.1149092E9, 1.11490956E9, 1.11491028E9, 1.114911E9, 1.11491136E9, 1.11491208E9, 1.1149128E9, 1.1149056E9, 1.1149092E9, 1.1149128E9, 1.1149056E9, 1.11490668E9, 1.1149074E9, 1.11490776E9, 1.11490848E9, 1.11490884E9, 1.1149092E9, 1.11490956E9, 1.11491028E9, 1.114911E9, 1.11491136E9, 1.11491208E9, 1.1149128E9, 1.1149056E9, 1.11490596E9, 1.11490668E9, 1.1149074E9, 1.11490776E9, 1.11490848E9, 1.11490884E9, 1.1149092E9, 1.11490956E9, 1.11491028E9, 1.114911E9, 1.11491136E9, 1.11491208E9, 1.1149128E9}\n"
            + "    atmp = \n"
            + "      {13.3, 13.3, 13.3, -9999999.0, 13.3, 13.3, 14.6, 15.0, 14.5, 14.6, 14.7, 14.6, 14.6, 14.6, 14.6, 14.7, 14.7, 14.7, 14.9, 13.4, 13.4, 13.9, 13.8, 13.7, 13.7, 13.7, 13.6, 13.5, 13.6, 13.6, 13.5, 13.5, -9999999.0, -9999999.0, -9999999.0, 14.8, 15.0, 15.1, 15.0, 15.2, 15.0, 14.8, 15.0, 14.4, 14.5, 14.5, 14.1, 13.7, 14.8, 14.6, 14.7, 14.7, 14.9, 14.9, 14.8, 14.9, 14.9, 15.0, 15.0, 15.1, 15.0, 15.2}\n"
            + "    wtmp = \n"
            + "      {13.3, 13.3, 13.4, -9999999.0, 13.4, 13.3, 17.0, 16.9, 16.6, 16.6, 16.1, 16.0, 15.8, 15.8, 15.7, 15.6, 15.4, 15.3, 15.3, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, 9.5, 9.3, -9999999.0, 14.8, 14.7, 14.7, 14.7, 14.7, 14.6, 14.5, 14.5, 14.5, 14.5, 14.6, 14.5, 14.5, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.5, 16.5, 16.6, 16.6, 16.5, 16.5, 16.5}\n"
            + "}\n";
    Test.ensureEqual(results, expected + expected2, "results=\n" + results);

    // .ncCFHeader
    tName = tedd.makeNewFileForDapQuery(language, null, null, query, dir, "ncCF1a", ".ncCFHeader");
    results = File2.readFromFile88591(dir + tName)[1];
    results += "}\n";
    results = results.replaceAll("\\d{4}-\\d{2}-\\d{2}", "9999-99-99");
    results = results.replaceAll("\\d{2}:\\d{2}:\\d{2}", "99:99:99");

    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // String2.log("\n*** EDDTableFromNcFiles.testNcCF1a finished.");

  }

  /** Test making an .ncCFMA TimeSeries file. */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testNcCFMA1a() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNcCFMA1a");

    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.getcwwcNDBCMet(); // should work
    String tName, error, results, expected;
    int po;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.

    // lon lat time range
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "longitude,latitude,station,time,atmp,wtmp"
                + "&longitude>-123&longitude<-122&latitude>37&latitude<38"
                + "&time>=2005-05-01T00:00:00&time<=2005-05-01T02:00:00",
            dir,
            "ncCFMA1a",
            ".ncCFMA");
    results = NcHelper.ncdump(dir + tName, "");
    results = results.replaceAll("\\d{4}-\\d{2}-\\d{2}", "9999-99-99");
    results = results.replaceAll("\\d{2}:\\d{2}:\\d{2}", "99:99:99");

    // String2.log(results);
    expected =
        "netcdf ncCFMA1a.nc {\n"
            + "  dimensions:\n"
            + "    timeseries = 7;\n"
            + "    obs = 14;\n"
            + "    station_strlen = 5;\n"
            + "  variables:\n"
            + "    float longitude(timeseries=7);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :actual_range = -122.975f, -122.21f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :colorBarMaximum = 180.0; // double\n"
            + "      :colorBarMinimum = -180.0; // double\n"
            + "      :comment = \"The longitude of the station.\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "    float latitude(timeseries=7);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :actual_range = 37.363f, 37.997f; // float\n"
            + "      :axis = \"Y\";\n"
            + "      :colorBarMaximum = 90.0; // double\n"
            + "      :colorBarMinimum = -90.0; // double\n"
            + "      :comment = \"The latitude of the station.\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "\n"
            + "    char station(timeseries=7, station_strlen=5);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"timeseries_id\";\n"
            + "      :comment = \"The station identifier.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station Identifier\";\n"
            + "\n"
            + "    double time(timeseries=7, obs=14);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :_FillValue = NaN; // double\n"
            + "      :actual_range = 1.1149056E9, 1.1149128E9; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 99:99:99\";\n"
            + "      :units = \"seconds since 9999-99-99T99:99:99Z\";\n"
            + "\n"
            + "    float atmp(timeseries=7, obs=14);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 13.3f, 15.2f; // float\n"
            + "      :colorBarMaximum = 40.0; // double\n"
            + "      :colorBarMinimum = -10.0; // double\n"
            + "      :comment = \"Air temperature (Celsius). For sensor heights on buoys, see Hull Descriptions. For sensor heights at C-MAN stations, see C-MAN Sensor Locations.\";\n"
            + "      :coordinates = \"time latitude longitude\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Air Temperature\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"air_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    float wtmp(timeseries=7, obs=14);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 9.3f, 17.0f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :comment = \"Sea surface temperature (Celsius). For sensor depth, see Hull Description.\";\n"
            + "      :coordinates = \"time latitude longitude\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"SST\";\n"
            + "      :missing_value = -9999999.0f; // float\n"
            + "      :standard_name = \"sea_surface_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"TimeSeries\";\n"
            + "  :cdm_timeseries_variables = \"station, longitude, latitude\";\n"
            + "  :contributor_name = \"NOAA NDBC\";\n"
            + "  :contributor_role = \"Source of data.\";\n"
            + "  :Conventions = \"COARDS, CF-1.10, ACDD-1.3\";\n"
            + "  :creator_email = \"erd.data@noaa.gov\";\n"
            + "  :creator_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :creator_type = \"institution\";\n"
            + "  :creator_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :date_created = \"9999-99-99\";\n"
            + "  :date_issued = \"9999-99-99\";\n"
            + "  :Easternmost_Easting = -122.21f; // float\n"
            + "  :featureType = \"TimeSeries\";\n"
            + "  :geospatial_lat_max = 37.997f; // float\n"
            + "  :geospatial_lat_min = 37.363f; // float\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = -122.21f; // float\n"
            + "  :geospatial_lon_min = -122.975f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_positive = \"down\";\n"
            + "  :geospatial_vertical_units = \"m\";\n"
            + "  :history = \"Around the 25th of each month, erd.data@noaa.gov downloads the latest yearly and monthly historical .txt.gz files from https://www.ndbc.noaa.gov/data/historical/stdmet/ and generates one historical .nc file for each station. erd.data@noaa.gov also downloads all of the 45day near real time .txt files from https://www.ndbc.noaa.gov/data/realtime2/ and generates one near real time .nc file for each station.\n"
            + "Every 5 minutes, erd.data@noaa.gov downloads the list of latest data from all stations for the last 2 hours from https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt and updates the near real time .nc files.\n"
            + "9999-99-99T99:99:99Z https://www.ndbc.noaa.gov/\n"
            + "9999-99-99T99:99:99Z http://localhost:8080/erddap/tabledap/cwwcNDBCMet.ncCFMA?longitude,latitude,station,time,atmp,wtmp&longitude>-123&longitude<-122&latitude>37&latitude<38&time>=9999-99-99T99:99:99&time<=9999-99-99T99:99:99\";\n"
            + "  :id = \"cwwcNDBCMet\";\n"
            + "  :infoUrl = \"https://www.ndbc.noaa.gov/\";\n"
            + "  :institution = \"NOAA NDBC, NOAA NMFS SWFSC ERD\";\n"
            + "  :keywords = \"air, air_pressure_at_sea_level, air_temperature, atmosphere, atmospheric, average, boundary, buoy, coastwatch, data, dew point, dew_point_temperature, direction, dominant, Earth Science > Atmosphere > Air Quality > Visibility, Earth Science > Atmosphere > Altitude > Planetary Boundary Layer Height, Earth Science > Atmosphere > Atmospheric Pressure > Atmospheric Pressure Measurements, Earth Science > Atmosphere > Atmospheric Pressure > Pressure Tendency, Earth Science > Atmosphere > Atmospheric Pressure > Sea Level Pressure, Earth Science > Atmosphere > Atmospheric Pressure > Static Pressure, Earth Science > Atmosphere > Atmospheric Temperature > Air Temperature, Earth Science > Atmosphere > Atmospheric Temperature > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Water Vapor > Dew Point Temperature, Earth Science > Atmosphere > Atmospheric Winds > Surface Winds, Earth Science > Oceans > Ocean Temperature > Sea Surface Temperature, Earth Science > Oceans > Ocean Waves > Significant Wave Height, Earth Science > Oceans > Ocean Waves > Swells, Earth Science > Oceans > Ocean Waves > Wave Period, eastward, eastward_wind, from, gust, height, identifier, layer, level, measurements, meridional, meteorological, meteorology, name, ndbc, noaa, northward, northward_wind, ocean, oceans, period, planetary, pressure, quality, sea, sea level, sea_surface_swell_wave_period, sea_surface_swell_wave_significant_height, sea_surface_swell_wave_to_direction, sea_surface_temperature, seawater, significant, speed, sst, standard, static, station, surface, surface waves, surface_altitude, swell, swells, temperature, tendency, tendency_of_air_pressure, time, vapor, visibility, visibility_in_air, water, wave, waves, wcn, wind, wind_from_direction, wind_speed, wind_speed_of_gust, winds, zonal\";\n"
            + "  :keywords_vocabulary = \"GCMD Science Keywords\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "  :naming_authority = \"gov.noaa.pfeg.coastwatch\";\n"
            + "  :Northernmost_Northing = 37.997f; // float\n"
            + "  :project = \"NOAA NDBC and NOAA NMFS SWFSC ERD\";\n"
            + "  :publisher_email = \"erd.data@noaa.gov\";\n"
            + "  :publisher_name = \"NOAA NMFS SWFSC ERD\";\n"
            + "  :publisher_type = \"institution\";\n"
            + "  :publisher_url = \"https://www.pfeg.noaa.gov\";\n"
            + "  :quality = \"Automated QC checks with periodic manual QC\";\n"
            + "  :source = \"station observation\";\n"
            + "  :sourceUrl = \"https://www.ndbc.noaa.gov/\";\n"
            + "  :Southernmost_Northing = 37.363f; // float\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :subsetVariables = \"station, longitude, latitude\";\n"
            + "  :summary = \"The National Data Buoy Center (NDBC) distributes meteorological data from\n"
            + "moored buoys maintained by NDBC and others. Moored buoys are the weather\n"
            + "sentinels of the sea. They are deployed in the coastal and offshore waters\n"
            + "from the western Atlantic to the Pacific Ocean around Hawaii, and from the\n"
            + "Bering Sea to the South Pacific. NDBC's moored buoys measure and transmit\n"
            + "barometric pressure; wind direction, speed, and gust; air and sea\n"
            + "temperature; and wave energy spectra from which significant wave height,\n"
            + "dominant wave period, and average wave period are derived. Even the\n"
            + "direction of wave propagation is measured on many moored buoys. See\n"
            + "https://www.ndbc.noaa.gov/measdes.shtml for a description of the measurements.\n"
            + "\n"
            + "The source data from NOAA NDBC has different column names, different units,\n"
            + "and different missing values in different files, and other problems\n"
            + "(notably, lots of rows with duplicate or different values for the same time\n"
            + "point). This dataset is a standardized, reformatted, and lightly edited\n"
            + "version of that source data, created by NOAA NMFS SWFSC ERD (email:\n"
            + "erd.data at noaa.gov). Before 9999-99-99, this dataset only had the data\n"
            + "that was closest to a given hour, rounded to the nearest hour. Now, this\n"
            + "dataset has all of the data available from NDBC with the original time\n"
            + "values. If there are multiple source rows for a given buoy for a given\n"
            + "time, only the row with the most non-NaN data values is kept. If there is\n"
            + "a gap in the data, a row of missing values is inserted (which causes a nice\n"
            + "gap when the data is graphed). Also, some impossible data values are\n"
            + "removed, but this data is not perfectly clean. This dataset is now updated\n"
            + "every 5 minutes.\n"
            + "\n"
            + "This dataset has both historical data (quality controlled, before\n"
            + "9999-99-99T99:99:99Z) and near real time data (less quality controlled,\n"
            + "which may change at any time, from 9999-99-99T99:99:99Z on).\";\n"
            + "  :testOutOfDate = \"now-25minutes\";\n"
            + "  :time_coverage_end = \"9999-99-99T99:99:99Z\";\n"
            + "  :time_coverage_start = \"9999-99-99T99:99:99Z\";\n"
            + "  :title = \"NDBC Standard Meteorological Buoy Data, 1970-present\";\n"
            + "  :Westernmost_Easting = -122.975f; // float\n"
            + "\n"
            + "  data:\n"
            + "    longitude = \n"
            + "      {-122.881, -122.833, -122.298, -122.465, -122.975, -122.4, -122.21}\n"
            + "    latitude = \n"
            + "      {37.363, 37.759, 37.772, 37.807, 37.997, 37.928, 37.507}\n"
            + "    station =   \"46012\",   \"46026\",   \"AAMC1\",   \"FTPC1\",   \"PRYC1\",   \"RCMC1\",   \"RTYC1\"\n"
            + "    time = \n"
            + "      {\n"
            + "        {1.1149056E9, 1.1149092E9, 1.1149128E9, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN},\n"
            + "        {1.1149056E9, 1.1149092E9, 1.1149128E9, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN},\n"
            + "        {1.1149056E9, 1.11490668E9, 1.1149074E9, 1.11490776E9, 1.11490848E9, 1.11490884E9, 1.1149092E9, 1.11490956E9, 1.11491028E9, 1.114911E9, 1.11491136E9, 1.11491208E9, 1.1149128E9, NaN},\n"
            + "        {1.1149056E9, 1.11490668E9, 1.1149074E9, 1.11490776E9, 1.11490848E9, 1.11490884E9, 1.1149092E9, 1.11490956E9, 1.11491028E9, 1.114911E9, 1.11491136E9, 1.11491208E9, 1.1149128E9, NaN},\n"
            + "        {1.1149056E9, 1.1149092E9, 1.1149128E9, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN},\n"
            + "        {1.1149056E9, 1.11490668E9, 1.1149074E9, 1.11490776E9, 1.11490848E9, 1.11490884E9, 1.1149092E9, 1.11490956E9, 1.11491028E9, 1.114911E9, 1.11491136E9, 1.11491208E9, 1.1149128E9, NaN},\n"
            + "        {1.1149056E9, 1.11490596E9, 1.11490668E9, 1.1149074E9, 1.11490776E9, 1.11490848E9, 1.11490884E9, 1.1149092E9, 1.11490956E9, 1.11491028E9, 1.114911E9, 1.11491136E9, 1.11491208E9, 1.1149128E9}\n"
            + "      }\n"
            + "    atmp = \n"
            + "      {\n"
            + "        {13.3, 13.3, 13.3, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0},\n"
            + "        {-9999999.0, 13.3, 13.3, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0},\n"
            + "        {14.6, 15.0, 14.5, 14.6, 14.7, 14.6, 14.6, 14.6, 14.6, 14.7, 14.7, 14.7, 14.9, -9999999.0},\n"
            + "        {13.4, 13.4, 13.9, 13.8, 13.7, 13.7, 13.7, 13.6, 13.5, 13.6, 13.6, 13.5, 13.5, -9999999.0},\n"
            + "        {-9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0},\n"
            + "        {14.8, 15.0, 15.1, 15.0, 15.2, 15.0, 14.8, 15.0, 14.4, 14.5, 14.5, 14.1, 13.7, -9999999.0},\n"
            + "        {14.8, 14.6, 14.7, 14.7, 14.9, 14.9, 14.8, 14.9, 14.9, 15.0, 15.0, 15.1, 15.0, 15.2}\n"
            + "      }\n"
            + "    wtmp = \n"
            + "      {\n"
            + "        {13.3, 13.3, 13.4, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0},\n"
            + "        {-9999999.0, 13.4, 13.3, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0},\n"
            + "        {17.0, 16.9, 16.6, 16.6, 16.1, 16.0, 15.8, 15.8, 15.7, 15.6, 15.4, 15.3, 15.3, -9999999.0},\n"
            + "        {-9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0},\n"
            + "        {9.5, 9.3, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0, -9999999.0},\n"
            + "        {14.8, 14.7, 14.7, 14.7, 14.7, 14.6, 14.5, 14.5, 14.5, 14.5, 14.6, 14.5, 14.5, -9999999.0},\n"
            + "        {16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.6, 16.5, 16.5, 16.6, 16.6, 16.5, 16.5, 16.5}\n"
            + "      }\n"
            + "}\n";
    Test.ensureEqual(results, expected, "results=\n" + results);

    String2.log("\n*** EDDTableFromNcFiles.testNcCFMA1a finished.");
  }

  /** Test making an .ncCF TimeSeries file (notably, different number obs per feature). */
  @org.junit.jupiter.api.Test
  void testNcCF1b() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNcCF1b");

    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.geterdFedRockfishStation();
    String tName, error, results, expected;
    int po;
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // lon lat time range
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "cruise,time,longitude,latitude,bucket_temperature&cruise=~%22(0002|0103)%22",
            dir,
            "ncCF1b",
            ".ncCF");
    results = NcHelper.ncdump(dir + tName, "");
    results = results.replaceAll("\\d{4}-\\d{2}-\\d{2}", "9999-99-99");
    results = results.replaceAll("\\d{2}:\\d{2}:\\d{2}", "99:99:99");

    // String2.log(results);
    expected =
        "netcdf ncCF1b.nc {\n"
            + "  dimensions:\n"
            + "    trajectory = 2;\n"
            + "    obs = 523;\n"
            + "    cruise_strlen = 4;\n"
            + "  variables:\n"
            + "    char cruise(trajectory=2, cruise_strlen=4);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"trajectory_id\";\n"
            + "      :comment = \"The first two digits are the last two digits of the year and the last two are the consecutive cruise number for that particular vessel (01, 02, 03, ...).\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Cruise\";\n"
            + "\n"
            + "    int rowSize(trajectory=2);\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Number of Observations for this Trajectory\";\n"
            + "      :sample_dimension = \"obs\";\n"
            + "\n"
            + "    double time(obs=523);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 9.5810382E8, 9.9199518E8; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 99:99:99\";\n"
            + "      :units = \"seconds since 9999-99-99T99:99:99Z\";\n"
            + "\n"
            + "    float longitude(obs=523);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :actual_range = -124.6335f, -121.854f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "    float latitude(obs=523);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :actual_range = 36.5567f, 38.8782f; // float\n"
            + "      :axis = \"Y\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "\n"
            + "    float bucket_temperature(obs=523);\n"
            + "      :actual_range = 9.1f, 15.5f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :coordinates = \"time latitude longitude\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Bucket Temperature\";\n"
            + "      :standard_name = \"sea_water_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"Trajectory\";\n"
            + "  :cdm_trajectory_variables = \"cruise\";\n"
            + "  :Conventions = \"COARDS, CF-1.10, ACDD-1.3\";\n"
            + "  :creator_email = \"Keith.Sakuma@noaa.gov\";\n"
            + "  :creator_name = \"Keith Sakuma\";\n"
            + "  :creator_type = \"person\";\n"
            + "  :Easternmost_Easting = -121.854f; // float\n"
            + "  :featureType = \"Trajectory\";\n"
            + "  :geospatial_lat_max = 38.8782f; // float\n"
            + "  :geospatial_lat_min = 36.5567f; // float\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = -121.854f; // float\n"
            + "  :geospatial_lon_min = -124.6335f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :history = \"9999-99-99 source files from Keith Sakuma (FED) to Lynn Dewitt (ERD) to Bob Simons (ERD)\n"
            + "9999-99-99 Bob Simons (erd.data@noaa.gov) converted data files for 1987-2011 from .csv to .nc with Projects.convertRockfish().\n"
            + "9999-99-99 Bob Simons (erd.data@noaa.gov) converted data files for 2012-2015 from xlsx to .nc with Projects.convertRockfish().\n"
            + "9999-99-99T99:99:99Z (local files; contact erd.data@noaa.gov)\n"
            + "9999-99-99T99:99:99Z http://localhost:8080/erddap/tabledap/erdFedRockfishStation.ncCF?cruise,time,longitude,latitude,bucket_temperature&cruise=~%22(0002|0103)%22\";\n"
            + "  :id = \"erdFedRockfishStation\";\n"
            + "  :infoUrl = \"https://www.fisheries.noaa.gov/west-coast/science-data/molecular-ecology-and-genetic-analysis-california-salmon-and-groundfish\";\n"
            + "  :institution = \"NOAA SWFSC FED\";\n"
            + "  :keywords = \"bottom, bucket, California, coast, cruise, ctd, data, depth, FED, fisheries, fixed, fluorometer, header, hydrographic, index, juvenile, latitude, longitude, midwater, NMFS, NOAA, pacific, rockfish, salinity, species, station, survey, SWFSC, temperature, thermosalinometer, time, transimissometer, trawl\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "  :naming_authority = \"gov.noaa.pfeg.coastwatch\";\n"
            + "  :Northernmost_Northing = 38.8782f; // float\n"
            + "  :sourceUrl = \"(local files; contact erd.data@noaa.gov)\";\n"
            + "  :Southernmost_Northing = 36.5567f; // float\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :subsetVariables = \"cruise,ctd_index,ctd_no,station,time,longitude,latitude\";\n"
            + "  :summary = \"SWFSC FED Mid Water Trawl Juvenile Rockfish Survey: Station Information and Surface Data.\n"
            + "Surveys have been conducted along the central California coast in May/June \n"
            + "every year since 1983. In 2004 the survey area was expanded to cover the \n"
            + "entire coast from San Diego to Cape Mendocino.  The survey samples a series \n"
            + "of fixed trawl stations using a midwater trawl. The midwater trawl survey \n"
            + "gear captures significant numbers of approximately 10 rockfish species during\n"
            + "their pelagic juvenile stage (i.e., 50-150 days old), by which time annual\n"
            + "reproductive success has been established. Catch-per-unit-effort data from\n"
            + "the survey are analyzed and serve as the basis for predicting future \n"
            + "recruitment to rockfish fisheries. Results for several species (e.g., \n"
            + "bocaccio, chilipepper [S. goodei], and widow rockfish [S. entomelas]) have\n"
            + "shown that the survey data can be useful in predicting year-class strength\n"
            + "in age-based stock assessments.\n"
            + "\n"
            + "The survey's data on YOY Pacific whiting has also been used in the stock\n"
            + "assessment process. To assist in obtaining additional northward spatial\n"
            + "coverage of YOY Pacific whiting off Oregon and Washington, in 2001 the\n"
            + "Pacific Whiting Conservation Cooperative in cooperation with the NOAA NMFS\n"
            + "Northwest Fisheries Science Center began a midwater trawl survey patterned\n"
            + "after the NOAA NMFS SWFSC Fisheries Ecology Division's (FED) existing survey. \n"
            + "Both surveys work cooperatively together each year in order to resolve \n"
            + "interannual abundance patterns of YOY rockfish and Pacific whiting on a \n"
            + "coastwide basis, which provides expedient, critical information that can be \n"
            + "used in the fisheries management process.\n"
            + "\n"
            + "The large quantity of physical data collected during the surveys (e.g., CTD\n"
            + "with attached transimissometer and fluorometer, thermosalinometer, and ADCP)\n"
            + "have provided a better understanding of the hydrographic conditions off the\n"
            + "California coast and analysis of these data have been distributed through the\n"
            + "publication of NOAA NMFS Technical Memoranda.\n"
            + "\n"
            + "For more information, see \n"
            + "https://www.fisheries.noaa.gov/west-coast/science-data/molecular-ecology-and-genetic-analysis-california-salmon-and-groundfish \n"
            + "and http://www.sanctuarysimon.org/projects/project_info.php?projectID=100118\";\n"
            + "  :time_coverage_end = \"9999-99-99T99:99:99Z\";\n"
            + "  :time_coverage_start = \"9999-99-99T99:99:99Z\";\n"
            + "  :title = \"SWFSC FED Mid Water Trawl Juvenile Rockfish Survey, Surface Data, 1987-2015\";\n"
            + "  :Westernmost_Easting = -124.6335f; // float\n"
            + "\n"
            + "  data:\n"
            + "    cruise =   \"0002\",   \"0103\"\n"
            + "    rowSize = \n"
            + "      {250, 273}\n"
            + "    time = \n"
            + "      {9.5810382E8, 9.5810652E8, 9.5811444E8, 9.581178E8, 9.5812548E8, 9.58128E8, 9.581349E8, 9.5814078E8, 9.5814624E8, 9.5815128E8, 9.5815656E8, 9.5816232E8, 9.5816772E8, 9.5817312E8, 9.581784E8, 9.5818404E8, 9.581892E8, 9.581928E8, 9.5820828E8, 9.5821176E8, 9.5822364E8, 9.582279E8, 9.5823264E8, 9.5823852E8, 9.582444E8, 9.5825022E8, 9.5825532E8, 9.5826018E8, 9.582657E8, 9.5827068E8, 9.5827944E8, 9.5828862E8, 9.582906E8, 9.583074E8, 9.5831346E8, 9.5831862E8, 9.583233E8, 9.583293E8, 9.5833446E8, 9.583392E8, 9.5834442E8, 9.5834928E8, 9.583536E8, 9.5836542E8, 9.5837448E8, 9.583788E8, 9.583932E8, 9.5840292E8, 9.584082E8, 9.5841432E8, 9.5842032E8, 9.5842524E8, 9.5842986E8, 9.5843568E8, 9.5844126E8, 9.584517E8, 9.584604E8, 9.5846454E8, 9.5847534E8, 9.584814E8, 9.5848698E8, 9.584919E8, 9.5849766E8, 9.5850462E8, 9.5851146E8, 9.5851752E8, 9.5852418E8, 9.585291E8, 9.5853804E8, 9.5855208E8, 9.5855478E8, 9.5856072E8, 9.585741E8, 9.5857968E8, 9.5862468E8, 9.5863734E8, 9.5871054E8, 9.5872044E8, 9.5872296E8, 9.5872968E8, 9.5873136E8, 9.587391E8, 9.587436E8, 9.5874924E8, 9.5875512E8, 9.5876082E8, 9.5876586E8, 9.587718E8, 9.5877876E8, 9.5878512E8, 9.5879142E8, 9.5879706E8, 9.5880948E8, 9.588123E8, 9.58821E8, 9.5882808E8, 9.588336E8, 9.588387E8, 9.5884476E8, 9.5885076E8, 9.588567E8, 9.588621E8, 9.5886696E8, 9.5887254E8, 9.5887698E8, 9.5888226E8, 9.5889264E8, 9.5889516E8, 9.5890968E8, 9.5891736E8, 9.5892216E8, 9.589269E8, 9.5893272E8, 9.5893758E8, 9.5894208E8, 9.5894772E8, 9.5895198E8, 9.5895768E8, 9.5896992E8, 9.5897928E8, 9.5898348E8, 9.589983E8, 9.59007E8, 9.5901216E8, 9.5901888E8, 9.5902548E8, 9.5903496E8, 9.5904306E8, 9.59049E8, 9.5905548E8, 9.5906838E8, 9.5907216E8, 9.5908914E8, 9.5910342E8, 9.5914278E8, 9.591747E8, 9.5921568E8, 9.5925504E8, 9.593121E8, 9.593166E8, 9.5932494E8, 9.5932806E8, 9.5933724E8, 9.593403E8, 9.5934798E8, 9.595827E8, 9.5958966E8, 9.59592E8, 9.5965548E8, 9.5966238E8, 9.5974764E8, 9.5975562E8, 9.5975856E8, 9.5976948E8, 9.5977182E8, 9.5977812E8, 9.597828E8, 9.5978844E8, 9.597936E8, 9.597996E8, 9.5980722E8, 9.598143E8, 9.5981922E8, 9.5982486E8, 9.5983104E8, 9.5983542E8, 9.598518E8, 9.598662E8, 9.598701E8, 9.5987502E8, 9.5988144E8, 9.5988756E8, 9.5989326E8, 9.598986E8, 9.59904E8, 9.599097E8, 9.5991444E8, 9.59922E8, 9.5992944E8, 9.5993118E8, 9.5995062E8, 9.5995758E8, 9.5996232E8, 9.5996736E8, 9.5997324E8, 9.5997786E8, 9.5998278E8, 9.5998842E8, 9.599934E8, 9.600069E8, 9.600183E8, 9.6002196E8, 9.600372E8, 9.6004446E8, 9.600495E8, 9.600555E8, 9.600612E8, 9.6006618E8, 9.6007122E8, 9.6007668E8, 9.6008232E8, 9.600936E8, 9.6010272E8, 9.6010728E8, 9.601158E8, 9.601221E8, 9.601278E8, 9.6013218E8, 9.6013758E8, 9.6014442E8, 9.6015084E8, 9.6015612E8, 9.601614E8, 9.601662E8, 9.6018E8, 9.601947E8, 9.601974E8, 9.6020892E8, 9.6021384E8, 9.6027684E8, 9.6028956E8, 9.6031308E8, 9.6032172E8, 9.603291E8, 9.603642E8, 9.6039156E8, 9.604035E8, 9.6042414E8, 9.6043758E8, 9.6044334E8, 9.6045168E8, 9.604587E8, 9.6046824E8, 9.604749E8, 9.6048732E8, 9.60498E8, 9.605127E8, 9.6052104E8, 9.6052794E8, 9.6053244E8, 9.6055512E8, 9.605712E8, 9.6057462E8, 9.6057876E8, 9.6058284E8, 9.6058722E8, 9.6059022E8, 9.6059232E8, 9.6059418E8, 9.6059664E8, 9.896394E8, 9.896415E8, 9.896562E8, 9.8965908E8, 9.896676E8, 9.8967702E8, 9.8968158E8, 9.8968626E8, 9.896913E8, 9.8969604E8, 9.897015E8, 9.8970702E8, 9.8971176E8, 9.89715E8, 9.897168E8, 9.8972808E8, 9.8974602E8, 9.897489E8, 9.8976126E8, 9.897657E8, 9.8977026E8, 9.8977572E8, 9.89781E8, 9.8978628E8, 9.8979138E8, 9.8979624E8, 9.8980176E8, 9.8980632E8, 9.898137E8, 9.898227E8, 9.898251E8, 9.898353E8, 9.898392E8, 9.8984694E8, 9.898569E8, 9.898614E8, 9.898659E8, 9.8987136E8, 9.8987616E8, 9.8987964E8, 9.8988132E8, 9.8989134E8, 9.898956E8, 9.898992E8, 9.899088E8, 9.899127E8, 9.899211E8, 9.899244E8, 9.8993388E8, 9.8993856E8, 9.8994366E8, 9.899493E8, 9.89955E8, 9.8995968E8, 9.8996424E8, 9.899703E8, 9.8997588E8, 9.899862E8, 9.899964E8, 9.900009E8, 9.900117E8, 9.900159E8, 9.9002424E8, 9.900291E8, 9.9003456E8, 9.9004146E8, 9.9004854E8, 9.9005436E8, 9.9006E8, 9.9006486E8, 9.90072E8, 9.900837E8, 9.900867E8, 9.9009528E8, 9.901023E8, 9.9010824E8, 9.901593E8, 9.901698E8, 9.901794E8, 9.902469E8, 9.902562E8, 9.902589E8, 9.902661E8, 9.902682E8, 9.902772E8, 9.9028962E8, 9.9029466E8, 9.9029988E8, 9.9030474E8, 9.9030996E8, 9.9031596E8, 9.9032082E8, 9.9032634E8, 9.9033342E8, 9.9034974E8, 9.9035304E8, 9.9036408E8, 9.903678E8, 9.9037236E8, 9.9037818E8, 9.9038376E8, 9.903897E8, 9.9039486E8, 9.903996E8, 9.9040524E8, 9.9041022E8, 9.9041964E8, 9.9043026E8, 9.9043212E8, 9.9044046E8, 9.9044514E8, 9.9045594E8, 9.9046056E8, 9.9046506E8, 9.9047154E8, 9.904758E8, 9.9048042E8, 9.90486E8, 9.904905E8, 9.904947E8, 9.9050604E8, 9.9051576E8, 9.9051936E8, 9.9052824E8, 9.9053124E8, 9.9053838E8, 9.9054204E8, 9.9054684E8, 9.9055344E8, 9.9055884E8, 9.9056352E8, 9.905679E8, 9.905739E8, 9.9057954E8, 9.905925E8, 9.9060282E8, 9.906069E8, 9.9061734E8, 9.906234E8, 9.9062808E8, 9.9063336E8, 9.906387E8, 9.9064518E8, 9.906516E8, 9.9065694E8, 9.9066288E8, 9.9066804E8, 9.906792E8, 9.906948E8, 9.9069762E8, 9.9070482E8, 9.9070998E8, 9.9071406E8, 9.9071928E8, 9.9076548E8, 9.9077514E8, 9.9077898E8, 9.9079908E8, 9.9080478E8, 9.908112E8, 9.9081738E8, 9.9082386E8, 9.9083046E8, 9.908361E8, 9.908418E8, 9.9084768E8, 9.9085314E8, 9.9086388E8, 9.9086958E8, 9.908814E8, 9.9088746E8, 9.9089442E8, 9.909003E8, 9.9090642E8, 9.9091164E8, 9.9091686E8, 9.909222E8, 9.9092838E8, 9.9093456E8, 9.9094992E8, 9.9095598E8, 9.90966E8, 9.9097104E8, 9.9097692E8, 9.9098262E8, 9.909912E8, 9.9099738E8, 9.9127836E8, 9.912849E8, 9.9129342E8, 9.9129642E8, 9.9130326E8, 9.9130554E8, 9.9131472E8, 9.913197E8, 9.9132486E8, 9.913296E8, 9.9133512E8, 9.9133998E8, 9.9134454E8, 9.913494E8, 9.9135702E8, 9.913623E8, 9.913677E8, 9.91371E8, 9.913857E8, 9.9138978E8, 9.9140214E8, 9.914061E8, 9.9141084E8, 9.9141624E8, 9.9142146E8, 9.9142722E8, 9.9143238E8, 9.914373E8, 9.914433E8, 9.914481E8, 9.91458E8, 9.914655E8, 9.914685E8, 9.9147786E8, 9.914862E8, 9.9149634E8, 9.9150156E8, 9.9150732E8, 9.9151452E8, 9.9152418E8, 9.9153606E8, 9.9154488E8, 9.915525E8, 9.915564E8, 9.916725E8, 9.916776E8, 9.916827E8, 9.9168786E8, 9.9169596E8, 9.91701E8, 9.91707E8, 9.917127E8, 9.9171726E8, 9.9172824E8, 9.917337E8, 9.917448E8, 9.9175254E8, 9.9175794E8, 9.91764E8, 9.9176946E8, 9.9177426E8, 9.9177924E8, 9.917847E8, 9.9179016E8, 9.9180414E8, 9.918135E8, 9.9181848E8, 9.918342E8, 9.9183978E8, 9.9184446E8, 9.9189126E8, 9.9190008E8, 9.9190422E8, 9.9191406E8, 9.9191994E8, 9.919251E8, 9.919302E8, 9.9193548E8, 9.9194106E8, 9.9194808E8, 9.9195492E8, 9.9196068E8, 9.919665E8, 9.9198552E8, 9.9199188E8, 9.9199518E8}\n"
            + "    longitude = \n"
            + "      {-121.9383, -121.983, -121.8678, -121.978, -121.8947, -121.8622, -121.9445, -122.165, -122.2658, -122.372, -122.4718, -122.5868, -122.6765, -122.7827, -122.6795, -122.4735, -122.2703, -122.1743, -122.0333, -122.0493, -122.1712, -122.1672, -122.3698, -122.576, -122.7827, -122.9822, -122.8845, -122.7843, -122.5792, -122.3702, -122.2922, -122.4007, -122.4288, -122.602, -122.4748, -122.6752, -122.887, -123.0893, -123.19, -123.0853, -122.8807, -122.6773, -122.4762, -122.5677, -122.6557, -122.8165, -122.9778, -122.988, -123.1957, -123.4012, -123.589, -123.6052, -123.6057, -123.4007, -123.1935, -123.0453, -123.1905, -123.14, -123.3443, -123.4868, -123.5028, -123.7077, -123.9117, -124.1147, -123.914, -123.7028, -123.503, -123.2983, -123.3922, -123.2657, -123.1785, -123.0832, -123.294, -123.0938, -122.87, -122.8973, -121.9863, -121.8953, -121.9795, -121.8875, -121.861, -121.9867, -122.1645, -122.2668, -122.3707, -122.4753, -122.5802, -122.6745, -122.6843, -122.4757, -122.2707, -122.1758, -122.0458, -122.05, -122.1108, -122.1307, -122.1677, -122.3698, -122.5767, -122.7825, -122.99, -122.8838, -122.7855, -122.5772, -122.3728, -122.2993, -122.3583, -122.4263, -122.5778, -122.4738, -122.6782, -122.8847, -123.0892, -123.1888, -123.0898, -122.8842, -122.7025, -122.4732, -122.5672, -122.6413, -122.8162, -122.9707, -122.9878, -123.1925, -123.3987, -123.6032, -123.605, -123.4057, -123.1952, -123.0448, -123.217, -123.151, -123.478, -123.9125, -122.5752, -123.0175, -123.5002, -122.8497, -123.0917, -123.0008, -123.0675, -123.1683, -123.2533, -123.3672, -123.5777, -122.865, -122.8885, -122.8492, -121.9338, -121.9888, -121.9952, -121.8622, -121.978, -121.8885, -121.8595, -121.9693, -122.1527, -122.2703, -122.3707, -122.4725, -122.574, -122.7818, -122.6802, -122.4757, -122.2742, -122.1773, -122.0398, -122.1692, -122.1678, -122.3703, -122.5735, -122.7852, -122.9817, -122.8832, -122.7847, -122.5795, -122.3728, -122.2923, -122.3835, -122.4223, -122.5922, -122.4752, -122.6767, -122.8852, -123.0895, -123.1907, -123.0882, -122.8853, -122.6787, -122.5675, -122.6608, -122.8157, -122.9975, -122.9915, -123.1962, -123.4022, -123.6065, -123.6048, -123.6067, -123.4015, -123.1925, -123.039, -123.2132, -123.1407, -123.3305, -123.486, -123.5062, -123.7095, -123.9142, -124.1162, -123.9128, -123.7062, -123.504, -123.2943, -123.373, -123.2622, -123.167, -123.3012, -123.0875, -122.8728, -122.8223, -122.9352, -123.0797, -123.1307, -123.5353, -123.555, -123.5022, -123.0465, -123.5415, -123.5448, -123.4182, -123.5035, -123.407, -123.2483, -123.0523, -123.2832, -123.5358, -123.4152, -123.5, -123.4767, -123.278, -123.9938, -123.9098, -123.821, -123.7398, -123.6592, -123.6073, -123.5595, -123.515, -123.4487, -121.935, -121.9837, -121.8783, -121.9773, -121.9295, -121.9675, -122.1682, -122.2683, -122.3718, -122.4732, -122.5798, -122.7845, -122.681, -122.274, -122.4772, -122.1835, -122.0435, -122.0428, -122.1655, -122.1667, -122.3745, -122.5795, -122.785, -122.9898, -122.89, -122.7855, -122.5797, -122.2278, -122.294, -122.3792, -122.4268, -122.6173, -122.7585, -122.7515, -122.472, -122.6803, -122.8853, -123.1043, -123.1953, -122.8838, -123.0907, -122.6807, -122.48, -122.567, -122.6508, -122.815, -123.0032, -123.0265, -122.884, -122.9882, -123.195, -123.4022, -123.6077, -123.6063, -123.606, -123.3978, -123.1942, -123.0408, -123.2157, -123.1318, -123.3233, -123.5045, -123.5042, -123.7242, -123.9135, -124.118, -123.9128, -123.7062, -123.5037, -123.2938, -123.2952, -123.1697, -123.1165, -123.0172, -123.0933, -123.2963, -122.895, -122.9217, -122.8875, -121.9975, -121.8617, -121.9662, -121.9013, -121.939, -121.854, -122.172, -122.2683, -122.3733, -122.4725, -122.5828, -122.7793, -122.6798, -122.4717, -122.1695, -122.025, -122.0505, -122.162, -122.1665, -122.3692, -122.5718, -122.78, -122.9942, -122.8835, -122.7828, -122.5775, -122.3755, -122.2805, -122.3933, -122.4087, -122.6017, -122.7418, -122.4722, -122.6818, -122.8838, -123.0885, -123.1875, -123.0882, -122.8838, -122.6778, -122.4737, -122.575, -122.6643, -122.8052, -123.0057, -123.0277, -123.028, -122.9965, -123.1975, -123.4015, -123.6075, -123.6053, -123.604, -123.4007, -123.1945, -123.0337, -123.2143, -123.1398, -123.3497, -123.5195, -123.504, -123.7067, -123.9122, -124.1182, -123.9112, -123.7072, -123.5017, -123.2992, -123.3752, -123.2623, -123.1822, -123.0678, -123.006, -123.091, -123.2953, -122.846, -122.9152, -122.879, -123.4812, -123.579, -123.6772, -123.7663, -123.8853, -123.9257, -123.988, -124.0528, -124.1277, -124.2243, -124.2975, -124.3948, -124.2242, -124.0617, -123.8733, -123.7113, -123.5368, -123.356, -123.5675, -123.7787, -123.9937, -124.2048, -124.4, -124.6335, -124.427, -124.2418, -124.0467, -123.8775, -123.6748, -123.4848, -122.9317, -121.9948, -121.8585, -121.9563, -121.8952, -121.878, -121.9432, -122.1668, -122.2668, -122.3738, -122.4737, -122.5777, -122.6775, -122.7813, -122.6748, -122.4732, -122.272, -122.1878, -122.0237, -122.038, -122.1575, -122.1555, -122.3737, -122.5758, -122.7843, -122.9858, -122.8855, -122.7838, -122.5775, -122.3718, -122.3078, -122.372, -122.433, -122.5848, -122.7522, -122.4738, -122.6763, -122.8827, -123.087, -123.0877, -122.8822, -122.6765, -122.4728, -122.5847, -122.4728, -122.6772, -122.8783, -123.0867, -123.194, -123.09, -122.8865, -122.6798, -122.6605, -122.808, -122.9938, -123.0082, -122.9867, -123.1928, -123.4003, -123.6047, -123.6043, -123.605, -123.4015, -123.1943, -123.06, -123.1995, -123.1495, -123.3497, -123.2977, -123.0918, -123.02, -123.0633, -123.175, -123.2713, -123.352, -123.2973, -123.5008, -123.7057, -123.9122, -124.1138, -123.9128, -123.709, -123.5042, -122.8775, -122.9085, -122.843}\n"
            + "    latitude = \n"
            + "      {36.8817, 36.8435, 36.7667, 36.7393, 36.7065, 36.644, 36.6793, 36.668, 36.7722, 36.6667, 36.7713, 36.6627, 36.772, 36.669, 36.5625, 36.5625, 36.563, 36.584, 36.5778, 36.6458, 36.7925, 36.8727, 36.8805, 36.8783, 36.8783, 36.8748, 36.9762, 37.0815, 37.082, 37.0797, 36.9813, 36.9822, 36.9827, 37.014, 37.1702, 37.1777, 37.1735, 37.1807, 37.2717, 37.3698, 37.3707, 37.3713, 37.3717, 37.2727, 37.2963, 37.2712, 37.291, 37.5142, 37.513, 37.513, 37.5133, 37.6382, 37.7675, 37.7682, 37.7693, 37.6605, 37.671, 37.7405, 37.873, 37.8625, 38.0275, 38.0293, 38.0282, 38.1673, 38.3095, 38.3077, 38.3085, 38.3082, 38.1842, 38.1542, 38.1793, 38.1622, 38.026, 38.0265, 37.7957, 37.6812, 36.845, 36.7605, 36.7428, 36.685, 36.6423, 36.654, 36.6698, 36.7718, 36.6678, 36.7723, 36.6675, 36.7705, 36.5618, 36.5635, 36.5592, 36.5845, 36.5932, 36.6468, 36.6918, 36.7428, 36.8765, 36.8772, 36.877, 36.8773, 36.8778, 36.9835, 37.0838, 37.0845, 37.0835, 36.9902, 36.9677, 36.9862, 36.9652, 37.1795, 37.1793, 37.1793, 37.1785, 37.2765, 37.372, 37.3727, 37.369, 37.3717, 37.2748, 37.2532, 37.2778, 37.2448, 37.5135, 37.512, 37.5105, 37.5118, 37.6397, 37.7702, 37.768, 37.6587, 37.6768, 37.7363, 37.8702, 38.0265, 37.2858, 37.2407, 38.3072, 37.7687, 38.0268, 38.166, 38.1422, 38.1685, 38.146, 38.1675, 38.166, 37.7893, 37.6617, 37.6132, 36.8827, 36.8553, 36.8523, 36.7605, 36.7432, 36.699, 36.6422, 36.671, 36.6672, 36.7747, 36.6662, 36.7725, 36.6663, 36.67, 36.5642, 36.5567, 36.5605, 36.5828, 36.5728, 36.781, 36.8768, 36.8785, 36.8768, 36.877, 36.876, 36.9863, 37.0832, 37.0778, 37.0835, 36.9845, 36.9863, 36.983, 36.9812, 37.1793, 37.1807, 37.179, 37.1807, 37.2772, 37.3725, 37.359, 37.3725, 37.2762, 37.2865, 37.2782, 37.2897, 37.5112, 37.5145, 37.5128, 37.5147, 37.6398, 37.7695, 37.7717, 37.771, 37.6555, 37.6612, 37.7475, 37.886, 37.8637, 38.0247, 38.0273, 38.0293, 38.1695, 38.312, 38.311, 38.3108, 38.3077, 38.1657, 38.1712, 38.1682, 38.0267, 38.0282, 37.7862, 37.5865, 37.499, 37.6465, 37.7122, 38.0843, 38.0692, 37.9557, 37.985, 38.2377, 38.2072, 38.09, 38.0832, 37.9738, 37.9252, 38.1003, 38.17, 38.2578, 38.1047, 38.0927, 38.0208, 38.1807, 38.2947, 38.3463, 38.3983, 38.4457, 38.4998, 38.543, 38.576, 38.6038, 38.6472, 36.8833, 36.8455, 36.7733, 36.7415, 36.7025, 36.6543, 36.6658, 36.7705, 36.6667, 36.7703, 36.6658, 36.668, 36.5632, 36.5622, 36.5602, 36.5782, 36.5978, 36.6432, 36.7628, 36.8748, 36.8775, 36.8785, 36.8767, 36.876, 36.9833, 37.0825, 37.0838, 36.9957, 36.9817, 36.983, 36.9843, 37.0058, 36.986, 36.8898, 37.1792, 37.1808, 37.1787, 37.1797, 37.2737, 37.3707, 37.37, 37.3722, 37.3717, 37.2748, 37.2625, 37.265, 37.2867, 37.3452, 37.4033, 37.5152, 37.5127, 37.5143, 37.5127, 37.6407, 37.7693, 37.7677, 37.7693, 37.6572, 37.656, 37.7328, 37.8805, 37.8885, 38.0233, 38.0258, 38.027, 38.1678, 38.308, 38.3105, 38.3058, 38.31, 38.1683, 38.1663, 38.1862, 38.171, 38.0267, 38.0253, 37.805, 37.7008, 37.9318, 36.8495, 36.7617, 36.7387, 36.7135, 36.6593, 36.6427, 36.6693, 36.7695, 36.6702, 36.8053, 36.6667, 36.6653, 36.5648, 36.5617, 36.5815, 36.59, 36.6458, 36.7795, 36.8777, 36.878, 36.8738, 36.8737, 36.8782, 36.9822, 37.0807, 37.0828, 37.0833, 36.9792, 36.994, 36.9765, 36.9773, 36.9822, 37.1772, 37.1777, 37.1778, 37.1785, 37.2757, 37.3703, 37.3715, 37.3722, 37.3708, 37.2833, 37.2833, 37.2678, 37.2902, 37.3468, 37.4335, 37.5132, 37.517, 37.5162, 37.5128, 37.6413, 37.769, 37.7712, 37.7698, 37.655, 37.6743, 37.7422, 37.8772, 37.8957, 38.0255, 38.0305, 38.0292, 38.168, 38.3112, 38.3097, 38.3072, 38.3078, 38.176, 38.1612, 38.1783, 38.1502, 38.1668, 38.0237, 38.0262, 37.6073, 37.6992, 37.8022, 38.1178, 38.2673, 38.418, 38.57, 38.7202, 38.8782, 38.716, 38.5608, 38.4067, 38.2563, 38.0858, 37.9538, 38.0365, 38.1548, 38.2703, 38.3548, 38.4442, 38.5348, 38.5365, 38.5382, 38.538, 38.5352, 38.5328, 38.5408, 38.459, 38.409, 38.3392, 38.4155, 38.194, 38.1185, 36.8823, 36.8472, 36.766, 36.7403, 36.705, 36.6472, 36.6602, 36.6675, 36.7712, 36.6658, 36.7718, 36.6688, 36.7712, 36.6678, 36.5613, 36.5625, 36.5622, 36.5862, 36.5687, 36.6405, 36.7865, 36.874, 36.8773, 36.877, 36.8775, 36.8765, 36.9822, 37.0822, 37.083, 37.0828, 36.9958, 36.9708, 36.9935, 36.968, 36.9753, 37.1785, 37.177, 37.1798, 37.1787, 37.3697, 37.3712, 37.3712, 37.3703, 37.2902, 37.3727, 37.3722, 37.3722, 37.3707, 37.2755, 37.1757, 37.1783, 37.1775, 37.2835, 37.2637, 37.2825, 37.3348, 37.5122, 37.5138, 37.5125, 37.5135, 37.6375, 37.7692, 37.7695, 37.7698, 37.671, 37.6438, 37.7538, 37.8475, 38.0265, 38.0268, 38.18, 38.145, 38.1737, 38.1498, 38.1502, 38.3067, 38.3068, 38.3058, 38.3068, 38.1687, 38.0272, 38.025, 38.0267, 37.8, 37.6967, 37.6037}\n"
            + "    bucket_temperature = \n"
            + "      {12.0, 11.3, 12.0, 11.7, 11.0, 12.6, 11.1, 12.4, 12.8, 13.7, 13.5, 13.5, 12.7, 13.5, 14.2, 14.0, 13.5, 13.2, 11.2, 11.7, 10.8, 10.8, 11.3, 11.9, 14.0, 12.7, 13.8, 14.1, 13.2, 12.5, 11.6, 12.4, 12.3, 11.7, 10.8, 12.5, 12.6, 13.3, 13.3, 13.4, 13.2, 11.6, 12.0, 12.5, 12.2, 13.3, 13.5, 12.2, 13.5, 13.5, 13.5, 13.8, 13.8, 13.5, 13.3, 11.3, 12.5, 12.8, 13.5, 12.8, 13.3, 12.8, 13.8, 14.0, 13.7, 13.7, 13.5, 13.0, 13.5, 12.8, 11.7, 10.5, 12.4, 10.6, 11.6, 11.5, 12.9, 12.5, 12.5, 13.0, 13.9, 12.2, 12.2, 11.9, 13.4, 12.9, 14.4, 14.3, 14.8, 14.9, 14.1, 13.1, 12.3, 12.0, 11.9, 11.8, 12.8, 11.6, 12.2, 13.2, 13.9, 13.2, 12.7, 12.2, 11.2, 10.6, 10.8, 11.5, 11.7, 11.5, 12.0, 12.6, 11.9, 12.5, 12.2, 12.4, 14.2, 13.5, 12.9, 13.2, 11.8, 11.9, 11.4, 11.5, 10.7, 13.3, 13.2, 10.8, 11.8, 11.5, 11.5, 11.3, 10.1, 13.2, 12.4, 12.2, 10.1, 10.9, 10.2, 10.3, 10.0, 9.5, 9.3, 9.5, 10.1, 10.2, 10.2, 10.2, 13.5, 11.9, 10.8, 11.7, 11.2, 12.2, 13.5, 10.7, 10.2, 11.0, 12.2, 11.5, 12.4, 12.9, 12.9, 12.2, 11.5, 10.9, 10.8, 10.8, 10.8, 11.0, 11.5, 12.2, 13.6, 12.5, 12.6, 11.8, 10.5, 10.2, 11.2, 11.1, 11.8, 10.2, 11.2, 11.5, 13.2, 12.3, 12.5, 12.2, 12.5, 12.1, 11.5, 11.0, 12.0, 10.5, 10.4, 11.2, 13.4, 11.8, 11.8, 11.8, 10.3, 11.0, 11.6, 10.5, 10.1, 10.4, 9.9, 13.2, 13.7, 12.9, 14.2, 14.9, 12.2, 11.3, 11.0, 10.1, 10.8, NaN, 11.8, 13.0, 12.8, 11.8, 12.2, 11.3, 11.7, 11.2, 12.5, 10.3, 13.0, 12.3, 11.0, 11.2, 10.5, 11.2, 11.9, 10.3, 11.5, 10.7, 11.2, 10.6, 10.8, 12.7, 13.3, 13.7, 13.6, 12.2, 12.8, 11.8, 12.1, 10.6, 13.8, 13.1, 11.6, 12.0, 12.2, 11.2, 13.2, 12.5, 12.3, 12.8, 13.4, 13.6, 13.9, 12.8, 13.7, 13.7, 11.2, 11.5, 13.4, 12.2, 12.3, 13.2, 12.5, 13.5, 12.1, 12.2, 12.2, 13.2, 12.8, 11.9, 12.4, 12.7, 12.3, 12.4, 11.9, 12.0, 12.7, 13.0, 12.2, 13.4, 12.9, 12.4, 13.3, 13.0, 12.7, 11.8, 12.0, 12.3, 12.1, 11.6, 13.1, 13.5, 13.7, 13.8, 13.6, 13.8, 12.8, 13.2, 13.3, 12.5, 12.9, 13.4, 13.0, 13.0, 11.4, 11.7, 12.5, 11.3, 11.1, 10.6, 10.5, 10.5, 10.4, 10.6, 10.6, 10.0, 11.7, 11.3, 10.2, 12.3, 12.6, 11.4, 11.9, 11.6, 13.2, 12.7, 12.9, 12.6, 13.1, 13.6, 14.4, 14.8, 13.7, 13.0, 12.3, 12.9, 13.1, 12.9, 13.0, 13.4, 13.6, 13.8, 13.2, 13.3, 12.0, 13.0, 12.3, 12.7, 12.7, 13.3, 12.5, 11.4, 12.4, 12.5, 12.3, 12.7, 13.0, 13.2, 12.7, 12.4, 12.9, 12.5, 12.6, 12.7, 12.6, 12.9, 13.1, 13.4, 13.1, 14.2, 14.5, 14.4, 13.2, 13.3, 13.3, 13.5, 13.0, 11.7, 12.3, 10.9, 13.0, 13.7, 13.5, 13.2, 12.2, 11.2, 11.4, 10.4, 11.0, 11.4, 11.8, 11.9, 11.8, 11.1, 11.8, 11.9, 11.5, 10.2, 10.1, 10.5, 10.4, 10.8, 11.2, 10.8, 12.9, 12.9, 12.4, 12.7, 12.8, 13.2, 13.1, 11.0, 10.7, 10.6, 10.5, 10.6, 10.6, 11.5, 12.5, 12.7, 12.3, 12.4, 12.5, 12.5, 10.7, 12.5, 11.0, 14.0, 13.1, 13.3, 12.5, 13.4, 14.1, 14.1, 13.4, 13.3, 15.1, 13.8, 14.8, 14.0, 15.1, 15.3, 14.6, 15.5, 15.5, 14.4, 14.5, 14.2, 13.4, 13.3, 13.7, 14.0, 14.7, 13.5, 13.5, 13.1, 12.7, 11.7, 12.0, 12.0, 12.4, 12.2, 11.8, 12.9, 12.6, 12.5, 12.5, 11.6, 13.0, 12.3, 12.5, 11.5, 11.9, 11.7, 11.3, 12.3, 12.0, 12.2, 12.1, 12.3, 11.9, 12.1, 12.1, 10.5, 10.6, 11.7, 12.2, 12.5, 12.6, 12.9, 10.7, 10.7, 10.6, 10.4, 12.3, 9.7, 9.7, 11.2, 10.0, 9.6, 9.4, 9.6, 9.1, 9.6, 9.8, 10.5, 11.6, 11.3, 12.5, 10.8, 10.8, 10.7, 11.0}\n"
            + "}\n";
    Test.ensureEqual(results, expected, "results=\n" + results);

    // String2.log("\n*** EDDTableFromNcFiles.testNcCF1b finished.");

  }

  /** Test making an .ncCFMA TimeSeries file (notably, different number obs per feature). */
  @org.junit.jupiter.api.Test
  void testNcCFMA1b() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNcCFMA1b");

    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.geterdFedRockfishStation(); // should work
    String tName, error, results, expected;
    int po;
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // lon lat time range
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "cruise,time,longitude,latitude,bucket_temperature&cruise=~%22(0002|0103)%22",
            dir,
            "ncCFMA1b",
            ".ncCFMA");
    results = NcHelper.ncdump(dir + tName, "");
    // String2.log(results);
    expected =
        "netcdf ncCFMA1b.nc {\n"
            + "  dimensions:\n"
            + "    trajectory = 2;\n"
            + "    obs = 273;\n"
            + "    cruise_strlen = 4;\n"
            + "  variables:\n"
            + "    char cruise(trajectory=2, cruise_strlen=4);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"trajectory_id\";\n"
            + "      :comment = \"The first two digits are the last two digits of the year and the last two are the consecutive cruise number for that particular vessel (01, 02, 03, ...).\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Cruise\";\n"
            + "\n"
            + "    double time(trajectory=2, obs=273);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :_FillValue = NaN; // double\n"
            + "      :actual_range = 9.5810382E8, 9.9199518E8; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    float longitude(trajectory=2, obs=273);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = -124.6335f, -121.854f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "    float latitude(trajectory=2, obs=273);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = 36.5567f, 38.8782f; // float\n"
            + "      :axis = \"Y\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "\n"
            + "    float bucket_temperature(trajectory=2, obs=273);\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = 9.1f, 15.5f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :coordinates = \"time latitude longitude\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Bucket Temperature\";\n"
            + "      :standard_name = \"sea_water_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :cdm_data_type = \"Trajectory\";\n"
            + "  :cdm_trajectory_variables = \"cruise\";\n"
            + "  :Conventions = \"COARDS, CF-1.10, ACDD-1.3\";\n"
            + "  :creator_email = \"Keith.Sakuma@noaa.gov\";\n"
            + "  :creator_name = \"Keith Sakuma\";\n"
            + "  :creator_type = \"person\";\n"
            + "  :Easternmost_Easting = -121.854f; // float\n"
            + "  :featureType = \"Trajectory\";\n"
            + "  :geospatial_lat_max = 38.8782f; // float\n"
            + "  :geospatial_lat_min = 36.5567f; // float\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = -121.854f; // float\n"
            + "  :geospatial_lon_min = -124.6335f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :history = \"2013-04-08 source files from Keith Sakuma (FED) to Lynn Dewitt (ERD) to Bob Simons (ERD)\n"
            + "2013-04-09 Bob Simons (erd.data@noaa.gov) converted data files for 1987-2011 from .csv to .nc with Projects.convertRockfish().\n"
            + "2017-02-03 Bob Simons (erd.data@noaa.gov) converted data files for 2012-2015 from xlsx to .nc with Projects.convertRockfish().\n"
            + today;
    String tResults = results.substring(0, Math.min(results.length(), expected.length()));
    Test.ensureEqual(tResults, expected, "\nresults=\n" + results);

    // + " (local files)\n" +
    // today + " http://127.0.0.1:8080/cwexperimental/
    expected =
        "  :id = \"erdFedRockfishStation\";\n"
            + "  :infoUrl = \"https://www.fisheries.noaa.gov/west-coast/science-data/molecular-ecology-and-genetic-analysis-california-salmon-and-groundfish\";\n"
            + "  :institution = \"NOAA SWFSC FED\";\n"
            + "  :keywords = \"bottom, bucket, California, coast, cruise, ctd, data, depth, FED, fisheries, fixed, fluorometer, header, hydrographic, index, juvenile, latitude, longitude, midwater, NMFS, NOAA, pacific, rockfish, salinity, species, station, survey, SWFSC, temperature, thermosalinometer, time, transimissometer, trawl\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "  :naming_authority = \"gov.noaa.pfeg.coastwatch\";\n"
            + "  :Northernmost_Northing = 38.8782f; // float\n"
            + "  :sourceUrl = \"(local files; contact erd.data@noaa.gov)\";\n"
            + "  :Southernmost_Northing = 36.5567f; // float\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :subsetVariables = \"cruise,ctd_index,ctd_no,station,time,longitude,latitude\";\n"
            + "  :summary = \"SWFSC FED Mid Water Trawl Juvenile Rockfish Survey: Station Information and Surface Data.\n"
            + "Surveys have been conducted along the central California coast in May/June \n"
            + "every year since 1983. In 2004 the survey area was expanded to cover the \n"
            + "entire coast from San Diego to Cape Mendocino.  The survey samples a series \n"
            + "of fixed trawl stations using a midwater trawl. The midwater trawl survey \n"
            + "gear captures significant numbers of approximately 10 rockfish species during\n"
            + "their pelagic juvenile stage (i.e., 50-150 days old), by which time annual\n"
            + "reproductive success has been established. Catch-per-unit-effort data from\n"
            + "the survey are analyzed and serve as the basis for predicting future \n"
            + "recruitment to rockfish fisheries. Results for several species (e.g., \n"
            + "bocaccio, chilipepper [S. goodei], and widow rockfish [S. entomelas]) have\n"
            + "shown that the survey data can be useful in predicting year-class strength\n"
            + "in age-based stock assessments.\n"
            + "\n"
            + "The survey's data on YOY Pacific whiting has also been used in the stock\n"
            + "assessment process. To assist in obtaining additional northward spatial\n"
            + "coverage of YOY Pacific whiting off Oregon and Washington, in 2001 the\n"
            + "Pacific Whiting Conservation Cooperative in cooperation with the NOAA NMFS\n"
            + "Northwest Fisheries Science Center began a midwater trawl survey patterned\n"
            + "after the NOAA NMFS SWFSC Fisheries Ecology Division's (FED) existing survey. \n"
            + "Both surveys work cooperatively together each year in order to resolve \n"
            + "interannual abundance patterns of YOY rockfish and Pacific whiting on a \n"
            + "coastwide basis, which provides expedient, critical information that can be \n"
            + "used in the fisheries management process.\n"
            + "\n"
            + "The large quantity of physical data collected during the surveys (e.g., CTD\n"
            + "with attached transimissometer and fluorometer, thermosalinometer, and ADCP)\n"
            + "have provided a better understanding of the hydrographic conditions off the\n"
            + "California coast and analysis of these data have been distributed through the\n"
            + "publication of NOAA NMFS Technical Memoranda.\n"
            + "\n"
            + "For more information, see \n"
            + "https://www.fisheries.noaa.gov/west-coast/science-data/molecular-ecology-and-genetic-analysis-california-salmon-and-groundfish \n"
            + "and http://www.sanctuarysimon.org/projects/project_info.php?projectID=100118\";\n"
            + "  :time_coverage_end = \"2001-06-08T10:13:00Z\";\n"
            + "  :time_coverage_start = \"2000-05-12T03:57:00Z\";\n"
            + "  :title = \"SWFSC FED Mid Water Trawl Juvenile Rockfish Survey, Surface Data, 1987-2015\";\n"
            + "  :Westernmost_Easting = -124.6335f; // float\n"
            + "\n"
            + "  data:\n"
            + "    cruise =   \"0002\",   \"0103\"\n"
            + "    time = \n"
            + "      {\n"
            + "        {9.5810382E8, 9.5810652E8, 9.5811444E8, 9.581178E8, 9.5812548E8, 9.58128E8, 9.581349E8, 9.5814078E8, 9.5814"
            + "624E8, 9.5815128E8, 9.5815656E8, 9.5816232E8, 9.5816772E8, 9.5817312E8, 9.581784E8, 9.5818404E8, 9.581892E8, 9."
            + "581928E8, 9.5820828E8, 9.5821176E8, 9.5822364E8, 9.582279E8, 9.5823264E8, 9.5823852E8, 9.582444E8, 9.5825022E8,"
            + " 9.5825532E8, 9.5826018E8, 9.582657E8, 9.5827068E8, 9.5827944E8, 9.5828862E8, 9.582906E8, 9.583074E8, 9.5831346"
            + "E8, 9.5831862E8, 9.583233E8, 9.583293E8, 9.5833446E8, 9.583392E8, 9.5834442E8, 9.5834928E8, 9.583536E8, 9.58365"
            + "42E8, 9.5837448E8, 9.583788E8, 9.583932E8, 9.5840292E8, 9.584082E8, 9.5841432E8, 9.5842032E8, 9.5842524E8, 9.58"
            + "42986E8, 9.5843568E8, 9.5844126E8, 9.584517E8, 9.584604E8, 9.5846454E8, 9.5847534E8, 9.584814E8, 9.5848698E8, 9"
            + ".584919E8, 9.5849766E8, 9.5850462E8, 9.5851146E8, 9.5851752E8, 9.5852418E8, 9.585291E8, 9.5853804E8, 9.5855208E"
            + "8, 9.5855478E8, 9.5856072E8, 9.585741E8, 9.5857968E8, 9.5862468E8, 9.5863734E8, 9.5871054E8, 9.5872044E8, 9.587"
            + "2296E8, 9.5872968E8, 9.5873136E8, 9.587391E8, 9.587436E8, 9.5874924E8, 9.5875512E8, 9.5876082E8, 9.5876586E8, 9"
            + ".587718E8, 9.5877876E8, 9.5878512E8, 9.5879142E8, 9.5879706E8, 9.5880948E8, 9.588123E8, 9.58821E8, 9.5882808E8,"
            + " 9.588336E8, 9.588387E8, 9.5884476E8, 9.5885076E8, 9.588567E8, 9.588621E8, 9.5886696E8, 9.5887254E8, 9.5887698E"
            + "8, 9.5888226E8, 9.5889264E8, 9.5889516E8, 9.5890968E8, 9.5891736E8, 9.5892216E8, 9.589269E8, 9.5893272E8, 9.589"
            + "3758E8, 9.5894208E8, 9.5894772E8, 9.5895198E8, 9.5895768E8, 9.5896992E8, 9.5897928E8, 9.5898348E8, 9.589983E8, "
            + "9.59007E8, 9.5901216E8, 9.5901888E8, 9.5902548E8, 9.5903496E8, 9.5904306E8, 9.59049E8, 9.5905548E8, 9.5906838E8"
            + ", 9.5907216E8, 9.5908914E8, 9.5910342E8, 9.5914278E8, 9.591747E8, 9.5921568E8, 9.5925504E8, 9.593121E8, 9.59316"
            + "6E8, 9.5932494E8, 9.5932806E8, 9.5933724E8, 9.593403E8, 9.5934798E8, 9.595827E8, 9.5958966E8, 9.59592E8, 9.5965"
            + "548E8, 9.5966238E8, 9.5974764E8, 9.5975562E8, 9.5975856E8, 9.5976948E8, 9.5977182E8, 9.5977812E8, 9.597828E8, 9"
            + ".5978844E8, 9.597936E8, 9.597996E8, 9.5980722E8, 9.598143E8, 9.5981922E8, 9.5982486E8, 9.5983104E8, 9.5983542E8"
            + ", 9.598518E8, 9.598662E8, 9.598701E8, 9.5987502E8, 9.5988144E8, 9.5988756E8, 9.5989326E8, 9.598986E8, 9.59904E8"
            + ", 9.599097E8, 9.5991444E8, 9.59922E8, 9.5992944E8, 9.5993118E8, 9.5995062E8, 9.5995758E8, 9.5996232E8, 9.599673"
            + "6E8, 9.5997324E8, 9.5997786E8, 9.5998278E8, 9.5998842E8, 9.599934E8, 9.600069E8, 9.600183E8, 9.6002196E8, 9.600"
            + "372E8, 9.6004446E8, 9.600495E8, 9.600555E8, 9.600612E8, 9.6006618E8, 9.6007122E8, 9.6007668E8, 9.6008232E8, 9.6"
            + "00936E8, 9.6010272E8, 9.6010728E8, 9.601158E8, 9.601221E8, 9.601278E8, 9.6013218E8, 9.6013758E8, 9.6014442E8, 9"
            + ".6015084E8, 9.6015612E8, 9.601614E8, 9.601662E8, 9.6018E8, 9.601947E8, 9.601974E8, 9.6020892E8, 9.6021384E8, 9."
            + "6027684E8, 9.6028956E8, 9.6031308E8, 9.6032172E8, 9.603291E8, 9.603642E8, 9.6039156E8, 9.604035E8, 9.6042414E8,"
            + " 9.6043758E8, 9.6044334E8, 9.6045168E8, 9.604587E8, 9.6046824E8, 9.604749E8, 9.6048732E8, 9.60498E8, 9.605127E8"
            + ", 9.6052104E8, 9.6052794E8, 9.6053244E8, 9.6055512E8, 9.605712E8, 9.6057462E8, 9.6057876E8, 9.6058284E8, 9.6058"
            + "722E8, 9.6059022E8, 9.6059232E8, 9.6059418E8, 9.6059664E8, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN},\n"
            + "        {9.896394E8, 9.896415E8, 9.896562E8, 9.8965908E8, 9.896676E8, 9.8967702E8, 9.8968158E8, 9.8968626E8, 9.8969"
            + "13E8, 9.8969604E8, 9.897015E8, 9.8970702E8, 9.8971176E8, 9.89715E8, 9.897168E8, 9.8972808E8, 9.8974602E8, 9.897"
            + "489E8, 9.8976126E8, 9.897657E8, 9.8977026E8, 9.8977572E8, 9.89781E8, 9.8978628E8, 9.8979138E8, 9.8979624E8, 9.8"
            + "980176E8, 9.8980632E8, 9.898137E8, 9.898227E8, 9.898251E8, 9.898353E8, 9.898392E8, 9.8984694E8, 9.898569E8, 9.8"
            + "98614E8, 9.898659E8, 9.8987136E8, 9.8987616E8, 9.8987964E8, 9.8988132E8, 9.8989134E8, 9.898956E8, 9.898992E8, 9"
            + ".899088E8, 9.899127E8, 9.899211E8, 9.899244E8, 9.8993388E8, 9.8993856E8, 9.8994366E8, 9.899493E8, 9.89955E8, 9."
            + "8995968E8, 9.8996424E8, 9.899703E8, 9.8997588E8, 9.899862E8, 9.899964E8, 9.900009E8, 9.900117E8, 9.900159E8, 9."
            + "9002424E8, 9.900291E8, 9.9003456E8, 9.9004146E8, 9.9004854E8, 9.9005436E8, 9.9006E8, 9.9006486E8, 9.90072E8, 9."
            + "900837E8, 9.900867E8, 9.9009528E8, 9.901023E8, 9.9010824E8, 9.901593E8, 9.901698E8, 9.901794E8, 9.902469E8, 9.9"
            + "02562E8, 9.902589E8, 9.902661E8, 9.902682E8, 9.902772E8, 9.9028962E8, 9.9029466E8, 9.9029988E8, 9.9030474E8, 9."
            + "9030996E8, 9.9031596E8, 9.9032082E8, 9.9032634E8, 9.9033342E8, 9.9034974E8, 9.9035304E8, 9.9036408E8, 9.903678E"
            + "8, 9.9037236E8, 9.9037818E8, 9.9038376E8, 9.903897E8, 9.9039486E8, 9.903996E8, 9.9040524E8, 9.9041022E8, 9.9041"
            + "964E8, 9.9043026E8, 9.9043212E8, 9.9044046E8, 9.9044514E8, 9.9045594E8, 9.9046056E8, 9.9046506E8, 9.9047154E8, "
            + "9.904758E8, 9.9048042E8, 9.90486E8, 9.904905E8, 9.904947E8, 9.9050604E8, 9.9051576E8, 9.9051936E8, 9.9052824E8,"
            + " 9.9053124E8, 9.9053838E8, 9.9054204E8, 9.9054684E8, 9.9055344E8, 9.9055884E8, 9.9056352E8, 9.905679E8, 9.90573"
            + "9E8, 9.9057954E8, 9.905925E8, 9.9060282E8, 9.906069E8, 9.9061734E8, 9.906234E8, 9.9062808E8, 9.9063336E8, 9.906"
            + "387E8, 9.9064518E8, 9.906516E8, 9.9065694E8, 9.9066288E8, 9.9066804E8, 9.906792E8, 9.906948E8, 9.9069762E8, 9.9"
            + "070482E8, 9.9070998E8, 9.9071406E8, 9.9071928E8, 9.9076548E8, 9.9077514E8, 9.9077898E8, 9.9079908E8, 9.9080478E"
            + "8, 9.908112E8, 9.9081738E8, 9.9082386E8, 9.9083046E8, 9.908361E8, 9.908418E8, 9.9084768E8, 9.9085314E8, 9.90863"
            + "88E8, 9.9086958E8, 9.908814E8, 9.9088746E8, 9.9089442E8, 9.909003E8, 9.9090642E8, 9.9091164E8, 9.9091686E8, 9.9"
            + "09222E8, 9.9092838E8, 9.9093456E8, 9.9094992E8, 9.9095598E8, 9.90966E8, 9.9097104E8, 9.9097692E8, 9.9098262E8, "
            + "9.909912E8, 9.9099738E8, 9.9127836E8, 9.912849E8, 9.9129342E8, 9.9129642E8, 9.9130326E8, 9.9130554E8, 9.9131472"
            + "E8, 9.913197E8, 9.9132486E8, 9.913296E8, 9.9133512E8, 9.9133998E8, 9.9134454E8, 9.913494E8, 9.9135702E8, 9.9136"
            + "23E8, 9.913677E8, 9.91371E8, 9.913857E8, 9.9138978E8, 9.9140214E8, 9.914061E8, 9.9141084E8, 9.9141624E8, 9.9142"
            + "146E8, 9.9142722E8, 9.9143238E8, 9.914373E8, 9.914433E8, 9.914481E8, 9.91458E8, 9.914655E8, 9.914685E8, 9.91477"
            + "86E8, 9.914862E8, 9.9149634E8, 9.9150156E8, 9.9150732E8, 9.9151452E8, 9.9152418E8, 9.9153606E8, 9.9154488E8, 9."
            + "915525E8, 9.915564E8, 9.916725E8, 9.916776E8, 9.916827E8, 9.9168786E8, 9.9169596E8, 9.91701E8, 9.91707E8, 9.917"
            + "127E8, 9.9171726E8, 9.9172824E8, 9.917337E8, 9.917448E8, 9.9175254E8, 9.9175794E8, 9.91764E8, 9.9176946E8, 9.91"
            + "77426E8, 9.9177924E8, 9.917847E8, 9.9179016E8, 9.9180414E8, 9.918135E8, 9.9181848E8, 9.918342E8, 9.9183978E8, 9"
            + ".9184446E8, 9.9189126E8, 9.9190008E8, 9.9190422E8, 9.9191406E8, 9.9191994E8, 9.919251E8, 9.919302E8, 9.9193548E"
            + "8, 9.9194106E8, 9.9194808E8, 9.9195492E8, 9.9196068E8, 9.919665E8, 9.9198552E8, 9.9199188E8, 9.9199518E8}\n"
            + "      }\n"
            + "    longitude = \n"
            + "      {\n"
            + "        {-121.9383, -121.983, -121.8678, -121.978, -121.8947, -121.8622, -121.9445, -122.165, -122.2658, -122.372, "
            + "-122.4718, -122.5868, -122.6765, -122.7827, -122.6795, -122.4735, -122.2703, -122.1743, -122.0333, -122.0493, -"
            + "122.1712, -122.1672, -122.3698, -122.576, -122.7827, -122.9822, -122.8845, -122.7843, -122.5792, -122.3702, -12"
            + "2.2922, -122.4007, -122.4288, -122.602, -122.4748, -122.6752, -122.887, -123.0893, -123.19, -123.0853, -122.880"
            + "7, -122.6773, -122.4762, -122.5677, -122.6557, -122.8165, -122.9778, -122.988, -123.1957, -123.4012, -123.589, "
            + "-123.6052, -123.6057, -123.4007, -123.1935, -123.0453, -123.1905, -123.14, -123.3443, -123.4868, -123.5028, -12"
            + "3.7077, -123.9117, -124.1147, -123.914, -123.7028, -123.503, -123.2983, -123.3922, -123.2657, -123.1785, -123.0"
            + "832, -123.294, -123.0938, -122.87, -122.8973, -121.9863, -121.8953, -121.9795, -121.8875, -121.861, -121.9867, "
            + "-122.1645, -122.2668, -122.3707, -122.4753, -122.5802, -122.6745, -122.6843, -122.4757, -122.2707, -122.1758, -"
            + "122.0458, -122.05, -122.1108, -122.1307, -122.1677, -122.3698, -122.5767, -122.7825, -122.99, -122.8838, -122.7"
            + "855, -122.5772, -122.3728, -122.2993, -122.3583, -122.4263, -122.5778, -122.4738, -122.6782, -122.8847, -123.08"
            + "92, -123.1888, -123.0898, -122.8842, -122.7025, -122.4732, -122.5672, -122.6413, -122.8162, -122.9707, -122.987"
            + "8, -123.1925, -123.3987, -123.6032, -123.605, -123.4057, -123.1952, -123.0448, -123.217, -123.151, -123.478, -1"
            + "23.9125, -122.5752, -123.0175, -123.5002, -122.8497, -123.0917, -123.0008, -123.0675, -123.1683, -123.2533, -12"
            + "3.3672, -123.5777, -122.865, -122.8885, -122.8492, -121.9338, -121.9888, -121.9952, -121.8622, -121.978, -121.8"
            + "885, -121.8595, -121.9693, -122.1527, -122.2703, -122.3707, -122.4725, -122.574, -122.7818, -122.6802, -122.475"
            + "7, -122.2742, -122.1773, -122.0398, -122.1692, -122.1678, -122.3703, -122.5735, -122.7852, -122.9817, -122.8832"
            + ", -122.7847, -122.5795, -122.3728, -122.2923, -122.3835, -122.4223, -122.5922, -122.4752, -122.6767, -122.8852,"
            + " -123.0895, -123.1907, -123.0882, -122.8853, -122.6787, -122.5675, -122.6608, -122.8157, -122.9975, -122.9915, "
            + "-123.1962, -123.4022, -123.6065, -123.6048, -123.6067, -123.4015, -123.1925, -123.039, -123.2132, -123.1407, -1"
            + "23.3305, -123.486, -123.5062, -123.7095, -123.9142, -124.1162, -123.9128, -123.7062, -123.504, -123.2943, -123."
            + "373, -123.2622, -123.167, -123.3012, -123.0875, -122.8728, -122.8223, -122.9352, -123.0797, -123.1307, -123.535"
            + "3, -123.555, -123.5022, -123.0465, -123.5415, -123.5448, -123.4182, -123.5035, -123.407, -123.2483, -123.0523, "
            + "-123.2832, -123.5358, -123.4152, -123.5, -123.4767, -123.278, -123.9938, -123.9098, -123.821, -123.7398, -123.6"
            + "592, -123.6073, -123.5595, -123.515, -123.4487, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN},\n"
            + "        {-121.935, -121.9837, -121.8783, -121.9773, -121.9295, -121.9675, -122.1682, -122.2683, -122.3718, -122.473"
            + "2, -122.5798, -122.7845, -122.681, -122.274, -122.4772, -122.1835, -122.0435, -122.0428, -122.1655, -122.1667, "
            + "-122.3745, -122.5795, -122.785, -122.9898, -122.89, -122.7855, -122.5797, -122.2278, -122.294, -122.3792, -122."
            + "4268, -122.6173, -122.7585, -122.7515, -122.472, -122.6803, -122.8853, -123.1043, -123.1953, -122.8838, -123.09"
            + "07, -122.6807, -122.48, -122.567, -122.6508, -122.815, -123.0032, -123.0265, -122.884, -122.9882, -123.195, -12"
            + "3.4022, -123.6077, -123.6063, -123.606, -123.3978, -123.1942, -123.0408, -123.2157, -123.1318, -123.3233, -123."
            + "5045, -123.5042, -123.7242, -123.9135, -124.118, -123.9128, -123.7062, -123.5037, -123.2938, -123.2952, -123.16"
            + "97, -123.1165, -123.0172, -123.0933, -123.2963, -122.895, -122.9217, -122.8875, -121.9975, -121.8617, -121.9662"
            + ", -121.9013, -121.939, -121.854, -122.172, -122.2683, -122.3733, -122.4725, -122.5828, -122.7793, -122.6798, -1"
            + "22.4717, -122.1695, -122.025, -122.0505, -122.162, -122.1665, -122.3692, -122.5718, -122.78, -122.9942, -122.88"
            + "35, -122.7828, -122.5775, -122.3755, -122.2805, -122.3933, -122.4087, -122.6017, -122.7418, -122.4722, -122.681"
            + "8, -122.8838, -123.0885, -123.1875, -123.0882, -122.8838, -122.6778, -122.4737, -122.575, -122.6643, -122.8052,"
            + " -123.0057, -123.0277, -123.028, -122.9965, -123.1975, -123.4015, -123.6075, -123.6053, -123.604, -123.4007, -1"
            + "23.1945, -123.0337, -123.2143, -123.1398, -123.3497, -123.5195, -123.504, -123.7067, -123.9122, -124.1182, -123"
            + ".9112, -123.7072, -123.5017, -123.2992, -123.3752, -123.2623, -123.1822, -123.0678, -123.006, -123.091, -123.29"
            + "53, -122.846, -122.9152, -122.879, -123.4812, -123.579, -123.6772, -123.7663, -123.8853, -123.9257, -123.988, -"
            + "124.0528, -124.1277, -124.2243, -124.2975, -124.3948, -124.2242, -124.0617, -123.8733, -123.7113, -123.5368, -1"
            + "23.356, -123.5675, -123.7787, -123.9937, -124.2048, -124.4, -124.6335, -124.427, -124.2418, -124.0467, -123.877"
            + "5, -123.6748, -123.4848, -122.9317, -121.9948, -121.8585, -121.9563, -121.8952, -121.878, -121.9432, -122.1668,"
            + " -122.2668, -122.3738, -122.4737, -122.5777, -122.6775, -122.7813, -122.6748, -122.4732, -122.272, -122.1878, -"
            + "122.0237, -122.038, -122.1575, -122.1555, -122.3737, -122.5758, -122.7843, -122.9858, -122.8855, -122.7838, -12"
            + "2.5775, -122.3718, -122.3078, -122.372, -122.433, -122.5848, -122.7522, -122.4738, -122.6763, -122.8827, -123.0"
            + "87, -123.0877, -122.8822, -122.6765, -122.4728, -122.5847, -122.4728, -122.6772, -122.8783, -123.0867, -123.194"
            + ", -123.09, -122.8865, -122.6798, -122.6605, -122.808, -122.9938, -123.0082, -122.9867, -123.1928, -123.4003, -1"
            + "23.6047, -123.6043, -123.605, -123.4015, -123.1943, -123.06, -123.1995, -123.1495, -123.3497, -123.2977, -123.0"
            + "918, -123.02, -123.0633, -123.175, -123.2713, -123.352, -123.2973, -123.5008, -123.7057, -123.9122, -124.1138, "
            + "-123.9128, -123.709, -123.5042, -122.8775, -122.9085, -122.843}\n"
            + "      }\n"
            + "    latitude = \n"
            + "      {\n"
            + "        {36.8817, 36.8435, 36.7667, 36.7393, 36.7065, 36.644, 36.6793, 36.668, 36.7722, 36.6667, 36.7713, 36.6627, "
            + "36.772, 36.669, 36.5625, 36.5625, 36.563, 36.584, 36.5778, 36.6458, 36.7925, 36.8727, 36.8805, 36.8783, 36.8783"
            + ", 36.8748, 36.9762, 37.0815, 37.082, 37.0797, 36.9813, 36.9822, 36.9827, 37.014, 37.1702, 37.1777, 37.1735, 37."
            + "1807, 37.2717, 37.3698, 37.3707, 37.3713, 37.3717, 37.2727, 37.2963, 37.2712, 37.291, 37.5142, 37.513, 37.513, "
            + "37.5133, 37.6382, 37.7675, 37.7682, 37.7693, 37.6605, 37.671, 37.7405, 37.873, 37.8625, 38.0275, 38.0293, 38.02"
            + "82, 38.1673, 38.3095, 38.3077, 38.3085, 38.3082, 38.1842, 38.1542, 38.1793, 38.1622, 38.026, 38.0265, 37.7957, "
            + "37.6812, 36.845, 36.7605, 36.7428, 36.685, 36.6423, 36.654, 36.6698, 36.7718, 36.6678, 36.7723, 36.6675, 36.770"
            + "5, 36.5618, 36.5635, 36.5592, 36.5845, 36.5932, 36.6468, 36.6918, 36.7428, 36.8765, 36.8772, 36.877, 36.8773, 3"
            + "6.8778, 36.9835, 37.0838, 37.0845, 37.0835, 36.9902, 36.9677, 36.9862, 36.9652, 37.1795, 37.1793, 37.1793, 37.1"
            + "785, 37.2765, 37.372, 37.3727, 37.369, 37.3717, 37.2748, 37.2532, 37.2778, 37.2448, 37.5135, 37.512, 37.5105, 3"
            + "7.5118, 37.6397, 37.7702, 37.768, 37.6587, 37.6768, 37.7363, 37.8702, 38.0265, 37.2858, 37.2407, 38.3072, 37.76"
            + "87, 38.0268, 38.166, 38.1422, 38.1685, 38.146, 38.1675, 38.166, 37.7893, 37.6617, 37.6132, 36.8827, 36.8553, 36"
            + ".8523, 36.7605, 36.7432, 36.699, 36.6422, 36.671, 36.6672, 36.7747, 36.6662, 36.7725, 36.6663, 36.67, 36.5642, "
            + "36.5567, 36.5605, 36.5828, 36.5728, 36.781, 36.8768, 36.8785, 36.8768, 36.877, 36.876, 36.9863, 37.0832, 37.077"
            + "8, 37.0835, 36.9845, 36.9863, 36.983, 36.9812, 37.1793, 37.1807, 37.179, 37.1807, 37.2772, 37.3725, 37.359, 37."
            + "3725, 37.2762, 37.2865, 37.2782, 37.2897, 37.5112, 37.5145, 37.5128, 37.5147, 37.6398, 37.7695, 37.7717, 37.771"
            + ", 37.6555, 37.6612, 37.7475, 37.886, 37.8637, 38.0247, 38.0273, 38.0293, 38.1695, 38.312, 38.311, 38.3108, 38.3"
            + "077, 38.1657, 38.1712, 38.1682, 38.0267, 38.0282, 37.7862, 37.5865, 37.499, 37.6465, 37.7122, 38.0843, 38.0692,"
            + " 37.9557, 37.985, 38.2377, 38.2072, 38.09, 38.0832, 37.9738, 37.9252, 38.1003, 38.17, 38.2578, 38.1047, 38.0927"
            + ", 38.0208, 38.1807, 38.2947, 38.3463, 38.3983, 38.4457, 38.4998, 38.543, 38.576, 38.6038, 38.6472, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN},\n"
            + "        {36.8833, 36.8455, 36.7733, 36.7415, 36.7025, 36.6543, 36.6658, 36.7705, 36.6667, 36.7703, 36.6658, 36.668,"
            + " 36.5632, 36.5622, 36.5602, 36.5782, 36.5978, 36.6432, 36.7628, 36.8748, 36.8775, 36.8785, 36.8767, 36.876, 36."
            + "9833, 37.0825, 37.0838, 36.9957, 36.9817, 36.983, 36.9843, 37.0058, 36.986, 36.8898, 37.1792, 37.1808, 37.1787,"
            + " 37.1797, 37.2737, 37.3707, 37.37, 37.3722, 37.3717, 37.2748, 37.2625, 37.265, 37.2867, 37.3452, 37.4033, 37.51"
            + "52, 37.5127, 37.5143, 37.5127, 37.6407, 37.7693, 37.7677, 37.7693, 37.6572, 37.656, 37.7328, 37.8805, 37.8885, "
            + "38.0233, 38.0258, 38.027, 38.1678, 38.308, 38.3105, 38.3058, 38.31, 38.1683, 38.1663, 38.1862, 38.171, 38.0267,"
            + " 38.0253, 37.805, 37.7008, 37.9318, 36.8495, 36.7617, 36.7387, 36.7135, 36.6593, 36.6427, 36.6693, 36.7695, 36."
            + "6702, 36.8053, 36.6667, 36.6653, 36.5648, 36.5617, 36.5815, 36.59, 36.6458, 36.7795, 36.8777, 36.878, 36.8738, "
            + "36.8737, 36.8782, 36.9822, 37.0807, 37.0828, 37.0833, 36.9792, 36.994, 36.9765, 36.9773, 36.9822, 37.1772, 37.1"
            + "777, 37.1778, 37.1785, 37.2757, 37.3703, 37.3715, 37.3722, 37.3708, 37.2833, 37.2833, 37.2678, 37.2902, 37.3468"
            + ", 37.4335, 37.5132, 37.517, 37.5162, 37.5128, 37.6413, 37.769, 37.7712, 37.7698, 37.655, 37.6743, 37.7422, 37.8"
            + "772, 37.8957, 38.0255, 38.0305, 38.0292, 38.168, 38.3112, 38.3097, 38.3072, 38.3078, 38.176, 38.1612, 38.1783, "
            + "38.1502, 38.1668, 38.0237, 38.0262, 37.6073, 37.6992, 37.8022, 38.1178, 38.2673, 38.418, 38.57, 38.7202, 38.878"
            + "2, 38.716, 38.5608, 38.4067, 38.2563, 38.0858, 37.9538, 38.0365, 38.1548, 38.2703, 38.3548, 38.4442, 38.5348, 3"
            + "8.5365, 38.5382, 38.538, 38.5352, 38.5328, 38.5408, 38.459, 38.409, 38.3392, 38.4155, 38.194, 38.1185, 36.8823,"
            + " 36.8472, 36.766, 36.7403, 36.705, 36.6472, 36.6602, 36.6675, 36.7712, 36.6658, 36.7718, 36.6688, 36.7712, 36.6"
            + "678, 36.5613, 36.5625, 36.5622, 36.5862, 36.5687, 36.6405, 36.7865, 36.874, 36.8773, 36.877, 36.8775, 36.8765, "
            + "36.9822, 37.0822, 37.083, 37.0828, 36.9958, 36.9708, 36.9935, 36.968, 36.9753, 37.1785, 37.177, 37.1798, 37.178"
            + "7, 37.3697, 37.3712, 37.3712, 37.3703, 37.2902, 37.3727, 37.3722, 37.3722, 37.3707, 37.2755, 37.1757, 37.1783, "
            + "37.1775, 37.2835, 37.2637, 37.2825, 37.3348, 37.5122, 37.5138, 37.5125, 37.5135, 37.6375, 37.7692, 37.7695, 37."
            + "7698, 37.671, 37.6438, 37.7538, 37.8475, 38.0265, 38.0268, 38.18, 38.145, 38.1737, 38.1498, 38.1502, 38.3067, 3"
            + "8.3068, 38.3058, 38.3068, 38.1687, 38.0272, 38.025, 38.0267, 37.8, 37.6967, 37.6037}\n"
            + "      }\n"
            + "    bucket_temperature = \n"
            + "      {\n"
            + "        {12.0, 11.3, 12.0, 11.7, 11.0, 12.6, 11.1, 12.4, 12.8, 13.7, 13.5, 13.5, 12.7, 13.5, 14.2, 14.0, 13.5, 13.2"
            + ", 11.2, 11.7, 10.8, 10.8, 11.3, 11.9, 14.0, 12.7, 13.8, 14.1, 13.2, 12.5, 11.6, 12.4, 12.3, 11.7, 10.8, 12.5, 1"
            + "2.6, 13.3, 13.3, 13.4, 13.2, 11.6, 12.0, 12.5, 12.2, 13.3, 13.5, 12.2, 13.5, 13.5, 13.5, 13.8, 13.8, 13.5, 13.3"
            + ", 11.3, 12.5, 12.8, 13.5, 12.8, 13.3, 12.8, 13.8, 14.0, 13.7, 13.7, 13.5, 13.0, 13.5, 12.8, 11.7, 10.5, 12.4, 1"
            + "0.6, 11.6, 11.5, 12.9, 12.5, 12.5, 13.0, 13.9, 12.2, 12.2, 11.9, 13.4, 12.9, 14.4, 14.3, 14.8, 14.9, 14.1, 13.1"
            + ", 12.3, 12.0, 11.9, 11.8, 12.8, 11.6, 12.2, 13.2, 13.9, 13.2, 12.7, 12.2, 11.2, 10.6, 10.8, 11.5, 11.7, 11.5, 1"
            + "2.0, 12.6, 11.9, 12.5, 12.2, 12.4, 14.2, 13.5, 12.9, 13.2, 11.8, 11.9, 11.4, 11.5, 10.7, 13.3, 13.2, 10.8, 11.8"
            + ", 11.5, 11.5, 11.3, 10.1, 13.2, 12.4, 12.2, 10.1, 10.9, 10.2, 10.3, 10.0, 9.5, 9.3, 9.5, 10.1, 10.2, 10.2, 10.2"
            + ", 13.5, 11.9, 10.8, 11.7, 11.2, 12.2, 13.5, 10.7, 10.2, 11.0, 12.2, 11.5, 12.4, 12.9, 12.9, 12.2, 11.5, 10.9, 1"
            + "0.8, 10.8, 10.8, 11.0, 11.5, 12.2, 13.6, 12.5, 12.6, 11.8, 10.5, 10.2, 11.2, 11.1, 11.8, 10.2, 11.2, 11.5, 13.2"
            + ", 12.3, 12.5, 12.2, 12.5, 12.1, 11.5, 11.0, 12.0, 10.5, 10.4, 11.2, 13.4, 11.8, 11.8, 11.8, 10.3, 11.0, 11.6, 1"
            + "0.5, 10.1, 10.4, 9.9, 13.2, 13.7, 12.9, 14.2, 14.9, 12.2, 11.3, 11.0, 10.1, 10.8, NaN, 11.8, 13.0, 12.8, 11.8, "
            + "12.2, 11.3, 11.7, 11.2, 12.5, 10.3, 13.0, 12.3, 11.0, 11.2, 10.5, 11.2, 11.9, 10.3, 11.5, 10.7, 11.2, 10.6, 10."
            + "8, 12.7, 13.3, 13.7, 13.6, 12.2, 12.8, 11.8, 12.1, 10.6, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN},\n"
            + "        {13.8, 13.1, 11.6, 12.0, 12.2, 11.2, 13.2, 12.5, 12.3, 12.8, 13.4, 13.6, 13.9, 12.8, 13.7, 13.7, 11.2, 11.5"
            + ", 13.4, 12.2, 12.3, 13.2, 12.5, 13.5, 12.1, 12.2, 12.2, 13.2, 12.8, 11.9, 12.4, 12.7, 12.3, 12.4, 11.9, 12.0, 1"
            + "2.7, 13.0, 12.2, 13.4, 12.9, 12.4, 13.3, 13.0, 12.7, 11.8, 12.0, 12.3, 12.1, 11.6, 13.1, 13.5, 13.7, 13.8, 13.6"
            + ", 13.8, 12.8, 13.2, 13.3, 12.5, 12.9, 13.4, 13.0, 13.0, 11.4, 11.7, 12.5, 11.3, 11.1, 10.6, 10.5, 10.5, 10.4, 1"
            + "0.6, 10.6, 10.0, 11.7, 11.3, 10.2, 12.3, 12.6, 11.4, 11.9, 11.6, 13.2, 12.7, 12.9, 12.6, 13.1, 13.6, 14.4, 14.8"
            + ", 13.7, 13.0, 12.3, 12.9, 13.1, 12.9, 13.0, 13.4, 13.6, 13.8, 13.2, 13.3, 12.0, 13.0, 12.3, 12.7, 12.7, 13.3, 1"
            + "2.5, 11.4, 12.4, 12.5, 12.3, 12.7, 13.0, 13.2, 12.7, 12.4, 12.9, 12.5, 12.6, 12.7, 12.6, 12.9, 13.1, 13.4, 13.1"
            + ", 14.2, 14.5, 14.4, 13.2, 13.3, 13.3, 13.5, 13.0, 11.7, 12.3, 10.9, 13.0, 13.7, 13.5, 13.2, 12.2, 11.2, 11.4, 1"
            + "0.4, 11.0, 11.4, 11.8, 11.9, 11.8, 11.1, 11.8, 11.9, 11.5, 10.2, 10.1, 10.5, 10.4, 10.8, 11.2, 10.8, 12.9, 12.9"
            + ", 12.4, 12.7, 12.8, 13.2, 13.1, 11.0, 10.7, 10.6, 10.5, 10.6, 10.6, 11.5, 12.5, 12.7, 12.3, 12.4, 12.5, 12.5, 1"
            + "0.7, 12.5, 11.0, 14.0, 13.1, 13.3, 12.5, 13.4, 14.1, 14.1, 13.4, 13.3, 15.1, 13.8, 14.8, 14.0, 15.1, 15.3, 14.6"
            + ", 15.5, 15.5, 14.4, 14.5, 14.2, 13.4, 13.3, 13.7, 14.0, 14.7, 13.5, 13.5, 13.1, 12.7, 11.7, 12.0, 12.0, 12.4, 1"
            + "2.2, 11.8, 12.9, 12.6, 12.5, 12.5, 11.6, 13.0, 12.3, 12.5, 11.5, 11.9, 11.7, 11.3, 12.3, 12.0, 12.2, 12.1, 12.3"
            + ", 11.9, 12.1, 12.1, 10.5, 10.6, 11.7, 12.2, 12.5, 12.6, 12.9, 10.7, 10.7, 10.6, 10.4, 12.3, 9.7, 9.7, 11.2, 10."
            + "0, 9.6, 9.4, 9.6, 9.1, 9.6, 9.8, 10.5, 11.6, 11.3, 12.5, 10.8, 10.8, 10.7, 11.0}\n"
            + "      }\n"
            + "}\n";
    int tPo = results.indexOf(expected.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(
        results.substring(tPo, Math.min(results.length(), tPo + expected.length())),
        expected,
        "results=\n" + results);

    // String2.log("\n*** EDDTableFromNcFiles.testNcCFMA1b finished.");

  }

  /** Test making an .ncCF TrajectoryProfile file. */
  @org.junit.jupiter.api.Test
  void testNcCF2a() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNcCF2a");

    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.gettestGlobecBottle(); // should work
    String tName, error, results, expected;
    int po;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.

    // lon lat time range
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            // for nwioosAdcp1995
            // "yearday,longitude,latitude,altitude,eastv,northv" +
            // "&yearday>=241.995&yearday<=242",
            // for erdGlobecBottle
            "cruise_id,ship,cast,longitude,latitude,time,bottle_posn,temperature0"
                + "&time>=2002-08-19T08:00:00Z&time<=2002-08-19T12:00:00Z",
            dir,
            "ncCF2a",
            ".ncCF");
    results = NcHelper.ncdump(dir + tName, "");
    // String2.log(results);
    expected =
        "netcdf ncCF2a.nc {\n"
            + "  dimensions:\n"
            + "    trajectory = 1;\n"
            + "    profile = 2;\n"
            + "    obs = 13;\n"
            + "    cruise_id_strlen = 6;\n"
            + "    ship_strlen = 11;\n"
            + "  variables:\n"
            + "    char cruise_id(trajectory=1, cruise_id_strlen=6);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"trajectory_id\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Cruise ID\";\n"
            + "\n"
            + "    char ship(trajectory=1, ship_strlen=11);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Ship\";\n"
            + "\n"
            + "    short cast(profile=2);\n"
            + "      :_FillValue = 32767S; // short\n"
            + "      :actual_range = 127S, 127S; // short\n"
            + "      :colorBarMaximum = 140.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Cast Number\";\n"
            + "      :missing_value = 32767S; // short\n"
            + "\n"
            + "    float longitude(profile=2);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :_FillValue = 327.67f; // float\n"
            + "      :actual_range = -124.3f, -124.18f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :missing_value = 327.67f; // float\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "    float latitude(profile=2);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :_FillValue = 327.67f; // float\n"
            + "      :actual_range = 44.65f, 44.65f; // float\n"
            + "      :axis = \"Y\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :missing_value = 327.67f; // float\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "\n"
            + "    double time(profile=2);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.02974748E9, 1.02975156E9; // double\n"
            + "      :axis = \"T\";\n"
            + "      :cf_role = \"profile_id\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    int trajectoryIndex(profile=2);\n"
            + "      :instance_dimension = \"trajectory\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"The trajectory to which this profile is associated.\";\n"
            + "\n"
            + "    int rowSize(profile=2);\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Number of Observations for this Profile\";\n"
            + "      :sample_dimension = \"obs\";\n"
            + "\n"
            + "    int altitude(obs=13);\n"
            + "      :_CoordinateAxisType = \"Height\";\n"
            + "      :_CoordinateZisPositive = \"up\";\n"
            + "      :actual_range = 0, 0; // int\n"
            + "      :axis = \"Z\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Altitude\";\n"
            + "      :positive = \"up\";\n"
            + "      :standard_name = \"altitude\";\n"
            + "      :units = \"m\";\n"
            + "\n"
            + "    byte bottle_posn(obs=13);\n"
            +
            // " :_CoordinateAxisType = \"Height\";\n" +
            "      :_FillValue = 127B; // byte\n"
            + "      :actual_range = 1B, 7B; // byte\n"
            +
            // " :axis = \"Z\";\n" +
            "      :colorBarMaximum = 12.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :coordinates = \"time latitude longitude altitude\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Bottle Number\";\n"
            + "      :missing_value = -128B; // byte\n"
            + "\n"
            + "    float temperature0(obs=13);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 7.223f, 9.62f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :coordinates = \"time latitude longitude altitude\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Sea Water Temperature from T0 Sensor\";\n"
            + "      :missing_value = -9999.0f; // float\n"
            + "      :standard_name = \"sea_water_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "  // global attributes:\n"
            +
            // " :cdm_altitude_proxy = \"bottle_posn\";\n" +
            "  :cdm_data_type = \"TrajectoryProfile\";\n"
            + "  :cdm_profile_variables = \"cast, longitude, latitude, time\";\n"
            + "  :cdm_trajectory_variables = \"cruise_id, ship\";\n"
            + "  :Conventions = \"COARDS, CF-1.10, ACDD-1.3\";\n"
            + "  :Easternmost_Easting = -124.18f; // float\n"
            + "  :featureType = \"TrajectoryProfile\";\n"
            + "  :geospatial_lat_max = 44.65f; // float\n"
            + "  :geospatial_lat_min = 44.65f; // float\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = -124.18f; // float\n"
            + "  :geospatial_lon_min = -124.3f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_max = 0; // int\n"
            + //
            "  :geospatial_vertical_min = 0; // int\n"
            + //
            "  :geospatial_vertical_positive = \"up\";\n"
            + //
            "  :geospatial_vertical_units = \"m\";\n"
            + "  :history = \""
            + today;
    String tResults = results.substring(0, Math.min(results.length(), expected.length()));
    Test.ensureEqual(tResults, expected, "\nresults=\n" + results);

    // + " https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_bottle\n" +
    // today + " http://127.0.0.1:8080/cwexperimental/
    expected =
        "tabledap/testGlobecBottle.ncCF?altitude,cruise_id,ship,cast,longitude,latitude,time,bottle_posn,temperature0&time>=2002-08-19T08:00:00Z&time<=2002-08-19T12:00:00Z\";\n"
            + "  :id = \"Globec_bottle_data_2002\";\n"
            + "  :infoUrl = \"https://en.wikipedia.org/wiki/Global_Ocean_Ecosystem_Dynamics\";\n"
            + "  :institution = \"GLOBEC\";\n"
            + "  :keywords = \"10um, active, after, ammonia, ammonium, attenuation, biosphere, bottle, cast, chemistry, chlorophyll, chlorophyll-a, color, concentration, concentration_of_chlorophyll_in_sea_water, cruise, data, density, dissolved, dissolved nutrients, dissolved o2, Earth Science > Biosphere > Vegetation > Photosynthetically Active Radiation, Earth Science > Oceans > Ocean Chemistry > Ammonia, Earth Science > Oceans > Ocean Chemistry > Chlorophyll, Earth Science > Oceans > Ocean Chemistry > Nitrate, Earth Science > Oceans > Ocean Chemistry > Nitrite, Earth Science > Oceans > Ocean Chemistry > Nitrogen, Earth Science > Oceans > Ocean Chemistry > Oxygen, Earth Science > Oceans > Ocean Chemistry > Phosphate, Earth Science > Oceans > Ocean Chemistry > Pigments, Earth Science > Oceans > Ocean Chemistry > Silicate, Earth Science > Oceans > Ocean Optics > Attenuation/Transmission, Earth Science > Oceans > Ocean Temperature > Water Temperature, Earth Science > Oceans > Salinity/Density > Salinity, fluorescence, fraction, from, globec, identifier, mass, mole, mole_concentration_of_ammonium_in_sea_water, mole_concentration_of_nitrate_in_sea_water, mole_concentration_of_nitrite_in_sea_water, mole_concentration_of_phosphate_in_sea_water, mole_concentration_of_silicate_in_sea_water, moles, moles_of_nitrate_and_nitrite_per_unit_mass_in_sea_water, n02, nep, nh4, nitrate, nitrite, nitrogen, no3, number, nutrients, o2, ocean, ocean color, oceans, optical, optical properties, optics, oxygen, passing, per, phaeopigments, phosphate, photosynthetically, pigments, plus, po4, properties, radiation, rosette, salinity, screen, sea, sea_water_practical_salinity, sea_water_temperature, seawater, sensor, sensors, ship, silicate, temperature, time, total, transmission, transmissivity, unit, vegetation, voltage, volume, volume_fraction_of_oxygen_in_sea_water, water\";\n"
            + "  :keywords_vocabulary = \"GCMD Science Keywords\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            +
            // " :naming_authority = \"gov.noaa.pfeg.coastwatch\";\n" +
            "  :Northernmost_Northing = 44.65f; // float\n"
            + "  :sourceUrl = \"(local files; contact erd.data@noaa.gov)\";\n"
            + "  :Southernmost_Northing = 44.65f; // float\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :subsetVariables = \"cruise_id, ship, cast, longitude, latitude, time\";\n"
            + "  :summary = \"GLOBEC (GLOBal Ocean ECosystems Dynamics) NEP (Northeast Pacific)\n"
            + "Rosette Bottle Data from New Horizon Cruise (NH0207: 1-19 August 2002).\n"
            + "Notes:\n"
            + "Physical data processed by Jane Fleischbein (OSU).\n"
            + "Chlorophyll readings done by Leah Feinberg (OSU).\n"
            + "Nutrient analysis done by Burke Hales (OSU).\n"
            + "Sal00 - salinity calculated from primary sensors (C0,T0).\n"
            + "Sal11 - salinity calculated from secondary sensors (C1,T1).\n"
            + "secondary sensor pair was used in final processing of CTD data for\n"
            + "most stations because the primary had more noise and spikes. The\n"
            + "primary pair were used for cast #9, 24, 48, 111 and 150 due to\n"
            + "multiple spikes or offsets in the secondary pair.\n"
            + "Nutrient samples were collected from most bottles; all nutrient data\n"
            + "developed from samples frozen during the cruise and analyzed ashore;\n"
            + "data developed by Burke Hales (OSU).\n"
            + "Operation Detection Limits for Nutrient Concentrations\n"
            + "Nutrient  Range         Mean    Variable         Units\n"
            + "PO4       0.003-0.004   0.004   Phosphate        micromoles per liter\n"
            + "N+N       0.04-0.08     0.06    Nitrate+Nitrite  micromoles per liter\n"
            + "Si        0.13-0.24     0.16    Silicate         micromoles per liter\n"
            + "NO2       0.003-0.004   0.003   Nitrite          micromoles per liter\n"
            + "Dates and Times are UTC.\n"
            + "\n"
            + "For more information, see https://www.bco-dmo.org/dataset/2452\n"
            + "\n"
            + "Inquiries about how to access this data should be directed to\n"
            + "Dr. Hal Batchelder (hbatchelder@coas.oregonstate.edu).\";\n"
            + "  :time_coverage_end = \"2002-08-19T10:06:00Z\";\n"
            + "  :time_coverage_start = \"2002-08-19T08:58:00Z\";\n"
            + "  :title = \"GLOBEC NEP Rosette Bottle Data (2002)\";\n"
            + "  :Westernmost_Easting = -124.3f; // float\n"
            + "\n"
            + "  data:\n"
            + "    cruise_id =   \"nh0207\"\n"
            + "    ship =   \"New_Horizon\"\n"
            + "    cast = \n"
            + "      {127, 127}\n"
            + "    longitude = \n"
            + "      {-124.3, -124.18}\n"
            + "    latitude = \n"
            + "      {44.65, 44.65}\n"
            + "    time = \n"
            + "      {1.02974748E9, 1.02975156E9}\n"
            + "    trajectoryIndex = \n"
            + "      {0, 0}\n"
            + "    rowSize = \n"
            + "      {7, 6}\n"
            + "    altitude = \n"
            + "      {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n"
            + "    bottle_posn = \n"
            + "      {1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6}\n"
            + "    temperature0 = \n"
            + "      {7.314, 7.47, 7.223, 7.962, 9.515, 9.576, 9.62, 7.378, 7.897, 7.335, 8.591, 8.693, 8.708}\n"
            + "}\n";
    int tPo = results.indexOf(expected.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(
        results.substring(tPo, Math.min(results.length(), tPo + expected.length())),
        expected,
        "results=\n" + results);

    // String2.log("\n*** EDDTableFromNcFiles.testNcCF2a finished.");

  }

  /** Test making an .ncCFMA TrajectoryProfile file. */
  @org.junit.jupiter.api.Test
  void testNcCFMA2a() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNcCFMA2a");

    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.gettestGlobecBottle(); // should work
    String tName, error, results, expected;
    int po;
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // lon lat time range
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            // for nwioosAdcp1995
            // "yearday,longitude,latitude,altitude,eastv,northv" +
            // "&yearday>=241.995&yearday<=242",
            // for erdGlobecBottle
            "cruise_id,ship,cast,longitude,latitude,time,bottle_posn,temperature0"
                + "&time>=2002-08-19T08:00:00Z&time<=2002-08-19T12:00:00Z",
            dir,
            "ncCFMA2a",
            ".ncCFMA");
    results = NcHelper.ncdump(dir + tName, "");
    // String2.log(results);
    expected =
        "netcdf ncCFMA2a.nc {\n"
            + "  dimensions:\n"
            + "    trajectory = 1;\n"
            + "    profile = 2;\n"
            + "    obs = 7;\n"
            + "    cruise_id_strlen = 6;\n"
            + "    ship_strlen = 11;\n"
            + "  variables:\n"
            + "    char cruise_id(trajectory=1, cruise_id_strlen=6);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"trajectory_id\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Cruise ID\";\n"
            + "\n"
            + "    char ship(trajectory=1, ship_strlen=11);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Ship\";\n"
            + "\n"
            + "    short cast(trajectory=1, profile=2);\n"
            + "      :_FillValue = 32767S; // short\n"
            + "      :actual_range = 127S, 127S; // short\n"
            + "      :colorBarMaximum = 140.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Cast Number\";\n"
            + "      :missing_value = 32767S; // short\n"
            + "\n"
            + "    float longitude(trajectory=1, profile=2);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :_FillValue = 327.67f; // float\n"
            + "      :actual_range = -124.3f, -124.18f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :missing_value = 327.67f; // float\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "\n"
            + "    float latitude(trajectory=1, profile=2);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :_FillValue = 327.67f; // float\n"
            + "      :actual_range = 44.65f, 44.65f; // float\n"
            + "      :axis = \"Y\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :missing_value = 327.67f; // float\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "\n"
            + "    double time(trajectory=1, profile=2);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.02974748E9, 1.02975156E9; // double\n"
            + "      :axis = \"T\";\n"
            + "      :cf_role = \"profile_id\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    int altitude(trajectory=1, profile=2, obs=7);\n"
            + "      :_CoordinateAxisType = \"Height\";\n"
            + "      :_CoordinateZisPositive = \"up\";\n"
            + "      :_FillValue = 2147483647; // int\n"
            + "      :actual_range = 0, 0; // int\n"
            + "      :axis = \"Z\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Altitude\";\n"
            + "      :positive = \"up\";\n"
            + "      :standard_name = \"altitude\";\n"
            + "      :units = \"m\";\n"
            + "\n"
            + "    byte bottle_posn(trajectory=1, profile=2, obs=7);\n"
            +
            // " :_CoordinateAxisType = \"Height\";\n" +
            "      :_FillValue = 127B; // byte\n"
            + "      :actual_range = 1B, 7B; // byte\n"
            +
            // " :axis = \"Z\";\n" +
            "      :colorBarMaximum = 12.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :coordinates = \"time latitude longitude altitude\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Bottle Number\";\n"
            + "      :missing_value = -128B; // byte\n"
            + "\n"
            + "    float temperature0(trajectory=1, profile=2, obs=7);\n"
            + "      :_FillValue = -9999999.0f; // float\n"
            + "      :actual_range = 7.223f, 9.62f; // float\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :coordinates = \"time latitude longitude altitude\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Sea Water Temperature from T0 Sensor\";\n"
            + "      :missing_value = -9999.0f; // float\n"
            + "      :standard_name = \"sea_water_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "  // global attributes:\n"
            +
            // " :cdm_altitude_proxy = \"bottle_posn\";\n" +
            "  :cdm_data_type = \"TrajectoryProfile\";\n"
            + "  :cdm_profile_variables = \"cast, longitude, latitude, time\";\n"
            + "  :cdm_trajectory_variables = \"cruise_id, ship\";\n"
            + "  :Conventions = \"COARDS, CF-1.10, ACDD-1.3\";\n"
            + "  :Easternmost_Easting = -124.18f; // float\n"
            + "  :featureType = \"TrajectoryProfile\";\n"
            + "  :geospatial_lat_max = 44.65f; // float\n"
            + "  :geospatial_lat_min = 44.65f; // float\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = -124.18f; // float\n"
            + "  :geospatial_lon_min = -124.3f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_max = 0; // int\n"
            + //
            "  :geospatial_vertical_min = 0; // int\n"
            + //
            "  :geospatial_vertical_positive = \"up\";\n"
            + //
            "  :geospatial_vertical_units = \"m\";\n"
            + "  :history = \""
            + today;
    String tResults = results.substring(0, Math.min(results.length(), expected.length()));
    Test.ensureEqual(tResults, expected, "\nresults=\n" + results);

    // + " https://oceanwatch.pfeg.noaa.gov/opendap/GLOBEC/GLOBEC_bottle\n" +
    // today + " http://127.0.0.1:8080/cwexperimental/
    expected =
        "tabledap/testGlobecBottle.ncCFMA?altitude,cruise_id,ship,cast,longitude,latitude,time,bottle_posn,temperature0&time>=2002-08-19T08:00:00Z&time<=2002-08-19T12:00:00Z\";\n"
            + "  :id = \"Globec_bottle_data_2002\";\n"
            + "  :infoUrl = \"https://en.wikipedia.org/wiki/Global_Ocean_Ecosystem_Dynamics\";\n"
            + "  :institution = \"GLOBEC\";\n"
            + "  :keywords = \"10um, active, after, ammonia, ammonium, attenuation, biosphere, bottle, cast, chemistry, chlorophyll, chlorophyll-a, color, concentration, concentration_of_chlorophyll_in_sea_water, cruise, data, density, dissolved, dissolved nutrients, dissolved o2, Earth Science > Biosphere > Vegetation > Photosynthetically Active Radiation, Earth Science > Oceans > Ocean Chemistry > Ammonia, Earth Science > Oceans > Ocean Chemistry > Chlorophyll, Earth Science > Oceans > Ocean Chemistry > Nitrate, Earth Science > Oceans > Ocean Chemistry > Nitrite, Earth Science > Oceans > Ocean Chemistry > Nitrogen, Earth Science > Oceans > Ocean Chemistry > Oxygen, Earth Science > Oceans > Ocean Chemistry > Phosphate, Earth Science > Oceans > Ocean Chemistry > Pigments, Earth Science > Oceans > Ocean Chemistry > Silicate, Earth Science > Oceans > Ocean Optics > Attenuation/Transmission, Earth Science > Oceans > Ocean Temperature > Water Temperature, Earth Science > Oceans > Salinity/Density > Salinity, fluorescence, fraction, from, globec, identifier, mass, mole, mole_concentration_of_ammonium_in_sea_water, mole_concentration_of_nitrate_in_sea_water, mole_concentration_of_nitrite_in_sea_water, mole_concentration_of_phosphate_in_sea_water, mole_concentration_of_silicate_in_sea_water, moles, moles_of_nitrate_and_nitrite_per_unit_mass_in_sea_water, n02, nep, nh4, nitrate, nitrite, nitrogen, no3, number, nutrients, o2, ocean, ocean color, oceans, optical, optical properties, optics, oxygen, passing, per, phaeopigments, phosphate, photosynthetically, pigments, plus, po4, properties, radiation, rosette, salinity, screen, sea, sea_water_practical_salinity, sea_water_temperature, seawater, sensor, sensors, ship, silicate, temperature, time, total, transmission, transmissivity, unit, vegetation, voltage, volume, volume_fraction_of_oxygen_in_sea_water, water\";\n"
            + "  :keywords_vocabulary = \"GCMD Science Keywords\";\n"
            + "  :license = \"The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            +
            // " :naming_authority = \"gov.noaa.pfeg.coastwatch\";\n" +
            "  :Northernmost_Northing = 44.65f; // float\n"
            + "  :sourceUrl = \"(local files; contact erd.data@noaa.gov)\";\n"
            + "  :Southernmost_Northing = 44.65f; // float\n"
            + "  :standard_name_vocabulary = \"CF Standard Name Table v70\";\n"
            + "  :subsetVariables = \"cruise_id, ship, cast, longitude, latitude, time\";\n"
            + "  :summary = \"GLOBEC (GLOBal Ocean ECosystems Dynamics) NEP (Northeast Pacific)\n"
            + "Rosette Bottle Data from New Horizon Cruise (NH0207: 1-19 August 2002).\n"
            + "Notes:\n"
            + "Physical data processed by Jane Fleischbein (OSU).\n"
            + "Chlorophyll readings done by Leah Feinberg (OSU).\n"
            + "Nutrient analysis done by Burke Hales (OSU).\n"
            + "Sal00 - salinity calculated from primary sensors (C0,T0).\n"
            + "Sal11 - salinity calculated from secondary sensors (C1,T1).\n"
            + "secondary sensor pair was used in final processing of CTD data for\n"
            + "most stations because the primary had more noise and spikes. The\n"
            + "primary pair were used for cast #9, 24, 48, 111 and 150 due to\n"
            + "multiple spikes or offsets in the secondary pair.\n"
            + "Nutrient samples were collected from most bottles; all nutrient data\n"
            + "developed from samples frozen during the cruise and analyzed ashore;\n"
            + "data developed by Burke Hales (OSU).\n"
            + "Operation Detection Limits for Nutrient Concentrations\n"
            + "Nutrient  Range         Mean    Variable         Units\n"
            + "PO4       0.003-0.004   0.004   Phosphate        micromoles per liter\n"
            + "N+N       0.04-0.08     0.06    Nitrate+Nitrite  micromoles per liter\n"
            + "Si        0.13-0.24     0.16    Silicate         micromoles per liter\n"
            + "NO2       0.003-0.004   0.003   Nitrite          micromoles per liter\n"
            + "Dates and Times are UTC.\n"
            + "\n"
            + "For more information, see https://www.bco-dmo.org/dataset/2452\n"
            + "\n"
            + "Inquiries about how to access this data should be directed to\n"
            + "Dr. Hal Batchelder (hbatchelder@coas.oregonstate.edu).\";\n"
            + "  :time_coverage_end = \"2002-08-19T10:06:00Z\";\n"
            + "  :time_coverage_start = \"2002-08-19T08:58:00Z\";\n"
            + "  :title = \"GLOBEC NEP Rosette Bottle Data (2002)\";\n"
            + //
            "  :Westernmost_Easting = -124.3f; // float\n"
            + //
            "\n"
            + //
            "  data:\n"
            + //
            "    cruise_id =   \"nh0207\"\n"
            + //
            "    ship =   \"New_Horizon\"\n"
            + //
            "    cast = \n"
            + //
            "      {\n"
            + //
            "        {127, 127}\n"
            + //
            "      }\n"
            + //
            "    longitude = \n"
            + //
            "      {\n"
            + //
            "        {-124.3, -124.18}\n"
            + //
            "      }\n"
            + //
            "    latitude = \n"
            + //
            "      {\n"
            + //
            "        {44.65, 44.65}\n"
            + //
            "      }\n"
            + //
            "    time = \n"
            + //
            "      {\n"
            + //
            "        {1.02974748E9, 1.02975156E9}\n"
            + //
            "      }\n"
            + //
            "    altitude = \n"
            + //
            "      {\n"
            + //
            "        {\n"
            + //
            "          {0, 0, 0, 0, 0, 0, 0},\n"
            + //
            "          {0, 0, 0, 0, 0, 0, 2147483647}\n"
            + //
            "        }\n"
            + //
            "      }\n"
            + //
            "    bottle_posn = \n"
            + //
            "      {\n"
            + //
            "        {\n"
            + //
            "          {1, 2, 3, 4, 5, 6, 7},\n"
            + //
            "          {1, 2, 3, 4, 5, 6, 127}\n"
            + //
            "        }\n"
            + //
            "      }\n"
            + //
            "    temperature0 = \n"
            + //
            "      {\n"
            + //
            "        {\n"
            + //
            "          {7.314, 7.47, 7.223, 7.962, 9.515, 9.576, 9.62},\n"
            + //
            "          {7.378, 7.897, 7.335, 8.591, 8.693, 8.708, -9999999.0}\n"
            + //
            "        }\n"
            + //
            "      }\n"
            + //
            "}\n";

    int tPo = results.indexOf(expected.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureEqual(
        results.substring(tPo, Math.min(results.length(), tPo + expected.length())),
        expected,
        "results=\n" + results);

    // String2.log("\n*** EDDTableFromNcFiles.testNcCFMA2a finished.");
  }

  /**
   * Test making an .ncCF TrajectoryProfile file (notably with different numbers of profiles and
   * obs).
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testNcCF2b() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNcCF2b");

    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.geterdGtsppBest(); // should work
    String tName, error, results, expected;
    int po;
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // lon lat time range
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "platform,cruise,org,type,station_id,longitude,latitude,time,depth,"
                + "temperature,salinity&cruise=~%22%28VKLD%2012|Q990046312%29%22"
                + "&longitude%3E=170&time%3E=2012-04-23T00:00:00Z&time%3C=2012-04-24T00:00:00Z",
            dir,
            "ncCF2b",
            ".ncCF");
    results = NcHelper.ncdump(dir + tName, "");
    // String2.log(results);
    expected =
        "netcdf ncCF2b.nc \\{\n"
            + "  dimensions:\n"
            + "    trajectory = 2;\n"
            + "    profile = 3;\n"
            + "    obs = 560;\n"
            + "    trajectory_strlen = 21;\n"
            + "    platform_strlen = 4;\n"
            + "    cruise_strlen = 10;\n"
            + "    org_strlen = 2;\n"
            + "    type_strlen = 2;\n"
            + "  variables:\n"
            + "    char trajectory\\(trajectory=2, trajectory_strlen=21\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"trajectory_id\";\n"
            + "      :comment = \"Constructed from org_type_platform_cruise\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Trajectory ID\";\n"
            + "\n"
            + "    char platform\\(trajectory=2, platform_strlen=4\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :comment = \"See the list of platform codes \\(sorted in various ways\\) at https://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"GTSPP Platform Code\";\n"
            + "      :references = \"https://www.nodc.noaa.gov/gtspp/document/codetbls/callist.html\";\n"
            + "\n"
            + "    char cruise\\(trajectory=2, cruise_strlen=10\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :comment = \"Radio callsign \\+ year for real time data, or NODC reference number for delayed mode data.  See\n"
            + "https://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html .\n"
            + "'X' indicates a missing value.\n"
            + "Two or more adjacent spaces in the original cruise names have been compacted to 1 space.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Cruise_ID\";\n"
            + "\n"
            + "    char org\\(trajectory=2, org_strlen=2\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :comment = \"From the first 2 characters of stream_ident:\n"
            + "Code  Meaning\n"
            + "AD  Australian Oceanographic Data Centre\n"
            + "AF  Argentina Fisheries \\(Fisheries Research and Development National Institute \\(INIDEP\\), Mar del Plata, Argentina\n"
            + "AO  Atlantic Oceanographic and Meteorological Lab\n"
            + "AP  Asia-Pacific \\(International Pacific Research Center/ Asia-Pacific Data-Research Center\\)\n"
            + "BI  BIO Bedford institute of Oceanography\n"
            + "CF  Canadian Navy\n"
            + "CS  CSIRO in Australia\n"
            + "DA  Dalhousie University\n"
            + "FN  FNOC in Monterey, California\n"
            + "FR  Orstom, Brest\n"
            + "FW  Fresh Water Institute \\(Winnipeg\\)\n"
            + "GE  BSH, Germany\n"
            + "IC  ICES\n"
            + "II  IIP\n"
            + "IK  Institut fur Meereskunde, Kiel\n"
            + "IM  IML\n"
            + "IO  IOS in Pat Bay, BC\n"
            + "JA  Japanese Meteorologocal Agency\n"
            + "JF  Japan Fisheries Agency\n"
            + "ME  EDS\n"
            + "MO  Moncton\n"
            + "MU  Memorial University\n"
            + "NA  NAFC\n"
            + "NO  NODC \\(Washington\\)\n"
            + "NW  US National Weather Service\n"
            + "OD  Old Dominion Univ, USA\n"
            + "RU  Russian Federation\n"
            + "SA  St Andrews\n"
            + "SI  Scripps Institute of Oceanography\n"
            + "SO  Southampton Oceanographic Centre, UK\n"
            + "TC  TOGA Subsurface Data Centre \\(France\\)\n"
            + "TI  Tiberon lab US\n"
            + "UB  University of BC\n"
            + "UQ  University of Quebec at Rimouski\n"
            + "VL  Far Eastern Regional Hydromet. Res. Inst. of V\n"
            + "WH  Woods Hole\n"
            + "\n"
            + "from https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref006\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Organization\";\n"
            + "\n"
            + "    char type\\(trajectory=2, type_strlen=2\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :comment = \"From the 3rd and 4th characters of stream_ident:\n"
            + "Code  Meaning\n"
            + "AR  Animal mounted recorder\n"
            + "BA  BATHY message\n"
            + "BF  Undulating Oceanographic Recorder \\(e.g. Batfish CTD\\)\n"
            + "BO  Bottle\n"
            + "BT  general BT data\n"
            + "CD  CTD down trace\n"
            + "CT  CTD data, up or down\n"
            + "CU  CTD up trace\n"
            + "DB  Drifting buoy\n"
            + "DD  Delayed mode drifting buoy data\n"
            + "DM  Delayed mode version from originator\n"
            + "DT  Digital BT\n"
            + "IC  Ice core\n"
            + "ID  Interpolated drifting buoy data\n"
            + "IN  Ship intake samples\n"
            + "MB  MBT\n"
            + "MC  CTD and bottle data are mixed for the station\n"
            + "MI  Data from a mixed set of instruments\n"
            + "ML  Minilog\n"
            + "OF  Real-time oxygen and fluorescence\n"
            + "PF  Profiling float\n"
            + "RM  Radio message\n"
            + "RQ  Radio message with scientific QC\n"
            + "SC  Sediment core\n"
            + "SG  Thermosalinograph data\n"
            + "ST  STD data\n"
            + "SV  Sound velocity probe\n"
            + "TE  TESAC message\n"
            + "TG  Thermograph data\n"
            + "TK  TRACKOB message\n"
            + "TO  Towed CTD\n"
            + "TR  Thermistor chain\n"
            + "XB  XBT\n"
            + "XC  Expendable CTD\n"
            + "\n"
            + "from https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref082\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Data Type\";\n"
            + "\n"
            + "    int station_id\\(profile=3\\);\n"
            + "      :_FillValue = 2147483647; // int\n"
            + "      :actual_range = 13968849, 27478599; // int\n"
            + "      :cf_role = \"profile_id\";\n"
            + "      :comment = \"Identification number of the station \\(profile\\) in the GTSPP Continuously Managed Database\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station ID Number\";\n"
            + "      :missing_value = 2147483647; // int\n"
            + "\n"
            + "    float longitude\\(profile=3\\);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = 173.5403f, 176.64f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :C_format = \"%9.4f\";\n"
            + "      :colorBarMaximum = 180.0; // double\n"
            + "      :colorBarMinimum = -180.0; // double\n"
            + "      :epic_code = 502; // int\n"
            + "      :FORTRAN_format = \"F9.4\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "      :valid_max = 180.0f; // float\n"
            + "      :valid_min = -180.0f; // float\n"
            + "\n"
            + "    float latitude\\(profile=3\\);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = -75.45f, -34.5796f; // float\n"
            + "      :axis = \"Y\";\n"
            + "      :C_format = \"%8.4f\";\n"
            + "      :colorBarMaximum = 90.0; // double\n"
            + "      :colorBarMinimum = -90.0; // double\n"
            + "      :epic_code = 500; // int\n"
            + "      :FORTRAN_format = \"F8.4\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "      :valid_max = 90.0f; // float\n"
            + "      :valid_min = -90.0f; // float\n"
            + "\n"
            + "    double time\\(profile=3\\);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.33514142E9, 1.335216E9; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    int trajectoryIndex\\(profile=3\\);\n"
            + "      :instance_dimension = \"trajectory\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"The trajectory to which this profile is associated.\";\n"
            + "\n"
            + "    int rowSize\\(profile=3\\);\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Number of Observations for this Profile\";\n"
            + "      :sample_dimension = \"obs\";\n"
            + "\n"
            + "    float depth\\(obs=560\\);\n"
            + "      :_CoordinateAxisType = \"Height\";\n"
            + "      :_CoordinateZisPositive = \"down\";\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = 4.0f, 368.0f; // float\n"
            + "      :axis = \"Z\";\n"
            + "      :C_format = \"%6.2f\";\n"
            + "      :colorBarMaximum = 5000.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :epic_code = 3; // int\n"
            + "      :FORTRAN_format = \"F6.2\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Depth of the Observations\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :positive = \"down\";\n"
            + "      :standard_name = \"depth\";\n"
            + "      :units = \"m\";\n"
            + "\n"
            + "    float temperature\\(obs=560\\);\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = -1.84f, 19.984f; // float\n"
            + "      :C_format = \"%9.4f\";\n"
            + "      :cell_methods = \"time: point longitude: point latitude: point depth: point\";\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :coordinates = \"time latitude longitude depth\";\n"
            + "      :epic_code = 28; // int\n"
            + "      :FORTRAN_format = \"F9.4\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Sea Water Temperature\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :standard_name = \"sea_water_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    float salinity\\(obs=560\\);\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = 35.5f, 36.0f; // float\n"
            + "      :C_format = \"%9.4f\";\n"
            + "      :cell_methods = \"time: point longitude: point latitude: point depth: point\";\n"
            + "      :colorBarMaximum = 37.0; // double\n"
            + "      :colorBarMinimum = 32.0; // double\n"
            + "      :coordinates = \"time latitude longitude depth\";\n"
            + "      :epic_code = 41; // int\n"
            + "      :FORTRAN_format = \"F9.4\";\n"
            + "      :ioos_category = \"Salinity\";\n"
            + "      :long_name = \"Practical Salinity\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :salinity_scale = \"PSU\";\n"
            + "      :standard_name = \"sea_water_practical_salinity\";\n"
            + "      :units = \"PSU\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :acknowledgment = \"These data were acquired from the US NOAA National Oceanographic Data Center \\(NODC\\) on 20.{8} from https://www.nodc.noaa.gov/GTSPP/.\";\n"
            + // \\( because in regex
            "  :cdm_altitude_proxy = \"depth\";\n"
            + "  :cdm_data_type = \"TrajectoryProfile\";\n"
            + "  :cdm_profile_variables = \"station_id, longitude, latitude, time\";\n"
            + "  :cdm_trajectory_variables = \"trajectory, org, type, platform, cruise\";\n"
            + "  :Conventions = \"COARDS, WOCE, GTSPP, CF-1.10, ACDD-1.3\";\n"
            + "  :creator_email = \"nodc.gtspp@noaa.gov\";\n"
            + "  :creator_name = \"NOAA NESDIS NODC \\(IN295\\)\";\n"
            + "  :creator_url = \"https://www.nodc.noaa.gov/GTSPP/\";\n"
            + "  :crs = \"EPSG:4326\";\n"
            + "  :defaultGraphQuery = \"longitude,latitude,station_id&time%3E=max\\(time\\)-7days&time%3C=max\\(time\\)&.draw=markers&.marker=10\\|5\";\n"
            + // \\( and \\| because in regex
            "  :Easternmost_Easting = 176.64f; // float\n"
            + "  :featureType = \"TrajectoryProfile\";\n"
            + "  :file_source = \"The GTSPP Continuously Managed Data Base\";\n"
            + "  :geospatial_lat_max = -34.5796f; // float\n"
            + "  :geospatial_lat_min = -75.45f; // float\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = 176.64f; // float\n"
            + "  :geospatial_lon_min = 173.5403f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_max = 368.0f; // float\n"
            + "  :geospatial_vertical_min = 4.0f; // float\n"
            + "  :geospatial_vertical_positive = \"down\";\n"
            + "  :geospatial_vertical_units = \"m\";\n"
            + "  :gtspp_ConventionVersion = \"GTSPP4.0\";\n"
            + "  :gtspp_handbook_version = \"GTSPP Data User's Manual 1.0\";\n"
            + "  :gtspp_program = \"writeGTSPPnc40.f90\";\n"
            + "  :gtspp_programVersion = \"1.8\";\n"
            + "  :history = \"20.{8} csun writeGTSPPnc40.f90 Version 1.8\n"
            + ".tgz files from ftp.nodc.noaa.gov /pub/data.nodc/gtspp/bestcopy/netcdf \\(https://www.nodc.noaa.gov/GTSPP/\\)\n"
            + "20.{8} Most recent ingest, clean, and reformat at ERD \\(erd.data at noaa.gov\\).";

    int tPo = results.indexOf("(erd.data at noaa.gov).");
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureLinesMatch(results.substring(0, tPo + 23), expected, "\nresults=\n" + results);

    // summary was to hard to work with don't test it
    expected =
        "  :time_coverage_end = \"2012-04-23T21:20:00Z\";\n"
            + "  :time_coverage_start = \"2012-04-23T00:37:00Z\";\n"
            + "  :title = \"Global Temperature and Salinity Profile Programme \\(GTSPP\\) Data, 1985-present\";\n"
            + "  :Westernmost_Easting = 173.5403f; // float\n"
            + "\n"
            + "  data:\n"
            + "    trajectory =   \"AD_XB_09WR_VKLD 12\",   \"ME_TE_33P2_Q990046312\"\n"
            + "    platform =   \"09WR\",   \"33P2\"\n"
            + "    cruise =   \"VKLD 12\",   \"Q990046312\"\n"
            + "    org =   \"AD\",   \"ME\"\n"
            + "    type =   \"XB\",   \"TE\"\n"
            + "    station_id = \n"
            + "      \\{27478599, 13968849, 13968850\\}\n"
            + "    longitude = \n"
            + "      \\{173.5403, 176.64, 176.64\\}\n"
            + "    latitude = \n"
            + "      \\{-34.5796, -75.45, -75.43\\}\n"
            + "    time = \n"
            + "      \\{1.33514142E9, 1.3351446E9, 1.335216E9\\}\n"
            + "    trajectoryIndex = \n"
            + "      \\{0, 1, 1\\}\n"
            + "    rowSize = \n"
            + "      \\{528, 16, 16\\}\n"
            + "    depth = \n"
            + "      \\{4.01, 4.68, 5.35, 6.02, 6.69, 7.36, 8.03, 8.69, 9.36, 10.03, 10.7, 11.37, 12.04, 12.7, 13.37, 14.04, 14.71, "
            + "15.38, 16.05, 16.71, 17.38, 18.05, 18.72, 19.38, 20.05, 20.72, 21.39, 22.06, 22.72, 23.39, 24.06, 24.73, 25.39,"
            + " 26.06, 26.73, 27.4, 28.06, 28.73, 29.4, 30.06, 30.73, 31.4, 32.06, 32.73, 33.4, 34.07, 34.73, 35.4, 36.07, 36."
            + "73, 37.4, 38.07, 38.73, 39.4, 40.06, 40.73, 41.4, 42.06, 42.73, 43.4, 44.06, 44.73, 45.39, 46.06, 46.73, 47.39,"
            + " 48.06, 48.72, 49.39, 50.06, 50.72, 51.39, 52.05, 52.72, 53.38, 54.05, 54.71, 55.38, 56.05, 56.71, 57.38, 58.04"
            + ", 58.71, 59.37, 60.04, 60.7, 61.37, 62.03, 62.7, 63.36, 64.03, 64.69, 65.36, 66.02, 66.68, 67.35, 68.01, 68.68,"
            + " 69.34, 70.01, 70.67, 71.34, 72.0, 72.66, 73.33, 73.99, 74.66, 75.32, 75.98, 76.65, 77.31, 77.98, 78.64, 79.3, "
            + "79.97, 80.63, 81.3, 81.96, 82.62, 83.29, 83.95, 84.61, 85.28, 85.94, 86.6, 87.27, 87.93, 88.59, 89.26, 89.92, 9"
            + "0.58, 91.24, 91.91, 92.57, 93.23, 93.9, 94.56, 95.22, 95.88, 96.55, 97.21, 97.87, 98.53, 99.2, 99.86, 100.52, 1"
            + "01.18, 101.85, 102.51, 103.17, 103.83, 104.49, 105.16, 105.82, 106.48, 107.14, 107.8, 108.47, 109.13, 109.79, 1"
            + "10.45, 111.11, 111.77, 112.44, 113.1, 113.76, 114.42, 115.08, 115.74, 116.4, 117.06, 117.73, 118.39, 119.05, 11"
            + "9.71, 120.37, 121.03, 121.69, 122.35, 123.01, 123.67, 124.33, 125.0, 125.66, 126.32, 126.98, 127.64, 128.3, 128"
            + ".96, 129.62, 130.28, 130.94, 131.6, 132.26, 132.92, 133.58, 134.24, 134.9, 135.56, 136.22, 136.88, 137.54, 138."
            + "2, 138.86, 139.52, 140.18, 140.84, 141.5, 142.16, 142.82, 143.48, 144.14, 144.79, 145.45, 146.11, 146.77, 147.4"
            + "3, 148.09, 148.75, 149.41, 150.07, 150.73, 151.39, 152.04, 152.7, 153.36, 154.02, 154.68, 155.34, 156.0, 156.65"
            + ", 157.31, 157.97, 158.63, 159.29, 159.95, 160.6, 161.26, 161.92, 162.58, 163.24, 163.89, 164.55, 165.21, 165.87"
            + ", 166.53, 167.18, 167.84, 168.5, 169.16, 169.82, 170.47, 171.13, 171.79, 172.44, 173.1, 173.76, 174.42, 175.07,"
            + " 175.73, 176.39, 177.05, 177.7, 178.36, 179.02, 179.67, 180.33, 180.99, 181.64, 182.3, 182.96, 183.61, 184.27, "
            + "184.93, 185.58, 186.24, 186.9, 187.55, 188.21, 188.87, 189.52, 190.18, 190.83, 191.49, 192.15, 192.8, 193.46, 1"
            + "94.11, 194.77, 195.43, 196.08, 196.74, 197.39, 198.05, 198.7, 199.36, 200.02, 200.67, 201.33, 201.98, 202.64, 2"
            + "03.29, 203.95, 204.6, 205.26, 205.91, 206.57, 207.22, 207.88, 208.53, 209.19, 209.84, 210.5, 211.15, 211.81, 21"
            + "2.46, 213.12, 213.77, 214.43, 215.08, 215.74, 216.39, 217.04, 217.7, 218.35, 219.01, 219.66, 220.32, 220.97, 22"
            + "1.62, 222.28, 222.93, 223.59, 224.24, 224.89, 225.55, 226.2, 226.85, 227.51, 228.16, 228.81, 229.47, 230.12, 23"
            + "0.78, 231.43, 232.08, 232.74, 233.39, 234.04, 234.69, 235.35, 236.0, 236.65, 237.31, 237.96, 238.61, 239.27, 23"
            + "9.92, 240.57, 241.22, 241.88, 242.53, 243.18, 243.83, 244.49, 245.14, 245.79, 246.44, 247.1, 247.75, 248.4, 249"
            + ".05, 249.7, 250.36, 251.01, 251.66, 252.31, 252.96, 253.62, 254.27, 254.92, 255.57, 256.22, 256.88, 257.53, 258"
            + ".18, 258.83, 259.48, 260.13, 260.78, 261.44, 262.09, 262.74, 263.39, 264.04, 264.69, 265.34, 265.99, 266.64, 26"
            + "7.29, 267.95, 268.6, 269.25, 269.9, 270.55, 271.2, 271.85, 272.5, 273.15, 273.8, 274.45, 275.1, 275.75, 276.4, "
            + "277.05, 277.7, 278.35, 279.0, 279.65, 280.3, 280.95, 281.6, 282.25, 282.9, 283.55, 284.2, 284.85, 285.5, 286.15"
            + ", 286.8, 287.45, 288.1, 288.75, 289.4, 290.05, 290.7, 291.35, 292.0, 292.64, 293.29, 293.94, 294.59, 295.24, 29"
            + "5.89, 296.54, 297.19, 297.84, 298.49, 299.13, 299.78, 300.43, 301.08, 301.73, 302.38, 303.02, 303.67, 304.32, 3"
            + "04.97, 305.62, 306.27, 306.91, 307.56, 308.21, 308.86, 309.51, 310.15, 310.8, 311.45, 312.1, 312.75, 313.39, 31"
            + "4.04, 314.69, 315.34, 315.98, 316.63, 317.28, 317.93, 318.57, 319.22, 319.87, 320.52, 321.16, 321.81, 322.46, 3"
            + "23.1, 323.75, 324.4, 325.04, 325.69, 326.34, 326.98, 327.63, 328.28, 328.92, 329.57, 330.22, 330.86, 331.51, 33"
            + "2.16, 332.8, 333.45, 334.1, 334.74, 335.39, 336.03, 336.68, 337.33, 337.97, 338.62, 339.26, 339.91, 340.56, 341"
            + ".2, 341.85, 342.49, 343.14, 343.78, 344.43, 345.08, 345.72, 346.37, 347.01, 347.66, 348.3, 348.95, 349.59, 350."
            + "24, 4.0, 10.0, 20.0, 30.0, 49.0, 99.0, 138.0, 142.0, 146.0, 148.0, 170.0, 198.0, 247.0, 297.0, 356.0, 366.0, 4."
            + "0, 10.0, 20.0, 30.0, 49.0, 99.0, 142.0, 144.0, 148.0, 154.0, 198.0, 208.0, 235.0, 297.0, 328.0, 368.0\\}\n"
            + "    temperature = \n"
            + "      \\{19.984, 19.976, 19.973, 19.974, 19.975, 19.976, 19.981, 19.981, 19.98, 19.979, 19.981, 19.975, 19.974, 19.97"
            + "3, 19.976, 19.975, 19.976, 19.973, 19.973, 19.974, 19.975, 19.973, 19.971, 19.966, 19.965, 19.962, 19.962, 19.9"
            + "59, 19.958, 19.956, 19.948, 19.945, 19.945, 19.942, 19.942, 19.94, 19.94, 19.938, 19.936, 19.939, 19.933, 19.93"
            + "8, 19.933, 19.932, 19.931, 19.931, 19.932, 19.93, 19.93, 19.928, 19.928, 19.925, 19.919, 19.919, 19.917, 19.917"
            + ", 19.916, 19.915, 19.91, 19.905, 19.89, 19.877, 19.87, 19.861, 19.864, 19.86, 19.858, 19.857, 19.857, 19.853, 1"
            + "9.852, 19.825, 19.799, 19.778, 19.702, 19.604, 19.454, 19.334, 19.279, 19.23, 19.204, 19.151, 19.048, 18.947, 1"
            + "8.867, 18.797, 18.749, 18.685, 18.629, 18.553, 18.489, 18.392, 18.303, 18.195, 18.055, 17.962, 17.909, 17.878, "
            + "17.869, 17.855, 17.834, 17.82, 17.807, 17.787, 17.773, 17.766, 17.764, 17.756, 17.747, 17.746, 17.727, 17.703, "
            + "17.691, 17.66, 17.629, 17.602, 17.578, 17.558, 17.533, 17.502, 17.475, 17.458, 17.454, 17.448, 17.432, 17.418, "
            + "17.403, 17.397, 17.376, 17.343, 17.305, 17.275, 17.255, 17.248, 17.229, 17.208, 17.196, 17.159, 17.143, 17.134,"
            + " 17.092, 17.034, 16.99, 16.952, 16.919, 16.887, 16.875, 16.872, 16.867, 16.837, 16.813, 16.801, 16.787, 16.776,"
            + " 16.762, 16.756, 16.752, 16.742, 16.733, 16.732, 16.723, 16.72, 16.716, 16.71, 16.714, 16.702, 16.682, 16.669, "
            + "16.663, 16.66, 16.656, 16.648, 16.635, 16.624, 16.611, 16.596, 16.59, 16.578, 16.575, 16.569, 16.556, 16.552, 1"
            + "6.547, 16.535, 16.511, 16.491, 16.473, 16.462, 16.457, 16.457, 16.452, 16.45, 16.45, 16.442, 16.434, 16.426, 16"
            + ".417, 16.403, 16.384, 16.356, 16.336, 16.31, 16.293, 16.211, 16.144, 16.047, 15.915, 15.835, 15.798, 15.756, 15"
            + ".735, 15.716, 15.712, 15.71, 15.712, 15.712, 15.71, 15.683, 15.661, 15.656, 15.653, 15.647, 15.644, 15.637, 15."
            + "628, 15.628, 15.619, 15.589, 15.572, 15.562, 15.558, 15.55, 15.543, 15.535, 15.52, 15.492, 15.397, 15.302, 15.2"
            + "17, 15.174, 15.147, 15.121, 15.08, 15.054, 15.023, 15.011, 15.003, 14.985, 14.935, 14.914, 14.89, 14.848, 14.81"
            + "2, 14.778, 14.747, 14.715, 14.698, 14.703, 14.71, 14.721, 14.722, 14.71, 14.69, 14.673, 14.654, 14.661, 14.654,"
            + " 14.658, 14.659, 14.665, 14.665, 14.659, 14.653, 14.655, 14.658, 14.657, 14.651, 14.647, 14.646, 14.645, 14.646"
            + ", 14.646, 14.643, 14.637, 14.64, 14.64, 14.603, 14.588, 14.578, 14.57, 14.568, 14.563, 14.562, 14.556, 14.555, "
            + "14.534, 14.524, 14.525, 14.52, 14.419, 14.303, 14.25, 14.235, 14.22, 14.212, 14.199, 14.154, 14.127, 14.09, 14."
            + "055, 14.031, 14.019, 14.005, 14.002, 14.001, 14.0, 13.995, 13.996, 13.998, 13.995, 13.992, 13.983, 13.968, 13.9"
            + "39, 13.897, 13.872, 13.847, 13.832, 13.807, 13.751, 13.7, 13.687, 13.669, 13.637, 13.602, 13.564, 13.53, 13.508"
            + ", 13.498, 13.493, 13.482, 13.466, 13.462, 13.461, 13.459, 13.454, 13.454, 13.451, 13.448, 13.446, 13.443, 13.43"
            + "7, 13.432, 13.429, 13.431, 13.426, 13.403, 13.329, 13.282, 13.257, 13.233, 13.208, 13.191, 13.162, 13.138, 13.1"
            + "26, 13.122, 13.118, 13.106, 13.1, 13.093, 13.062, 13.045, 13.031, 13.019, 13.012, 13.008, 12.998, 12.985, 12.96"
            + "7, 12.934, 12.898, 12.885, 12.854, 12.835, 12.811, 12.792, 12.778, 12.752, 12.74, 12.73, 12.726, 12.715, 12.703"
            + ", 12.689, 12.669, 12.661, 12.655, 12.652, 12.649, 12.636, 12.604, 12.575, 12.552, 12.538, 12.533, 12.524, 12.49"
            + "8, 12.461, 12.443, 12.424, 12.41, 12.414, 12.41, 12.403, 12.4, 12.402, 12.394, 12.383, 12.382, 12.379, 12.375, "
            + "12.374, 12.368, 12.361, 12.36, 12.353, 12.341, 12.332, 12.326, 12.321, 12.314, 12.293, 12.282, 12.264, 12.245, "
            + "12.232, 12.223, 12.215, 12.212, 12.206, 12.2, 12.202, 12.198, 12.192, 12.182, 12.177, 12.176, 12.173, 12.168, 1"
            + "2.167, 12.162, 12.158, 12.155, 12.145, 12.133, 12.128, 12.127, 12.125, 12.125, 12.123, 12.121, 12.12, 12.119, 1"
            + "2.117, 12.116, 12.117, 12.113, 12.109, 12.091, 12.063, 12.039, 12.021, 12.013, 12.008, 11.981, 11.953, 11.933, "
            + "11.928, 11.926, 11.923, 11.926, 11.926, 11.918, 11.909, 11.9, 11.892, 11.876, 11.871, 11.844, 11.815, 11.796, 1"
            + "1.781, 11.764, 11.737, 11.724, 11.718, 11.711, 11.691, 11.673, 11.667, 11.657, 11.649, 11.646, 11.643, 11.639, "
            + "11.639, 11.632, 11.621, 11.607, 11.59, 11.581, 11.58, 11.581, 11.582, 11.583, 11.575, 11.576, 11.574, 11.576, 1"
            + "1.569, 11.569, 11.569, 11.572, 11.572, 11.573, 11.574, 11.575, -1.84, -1.84, -1.83, -1.83, -1.83, -1.82, -1.78,"
            + " -1.6, -1.18, -1.1, -1.25, -1.29, -1.13, -1.25, -1.76, -1.8, -1.84, -1.84, -1.84, -1.83, -1.83, -1.82, -1.77, -"
            + "1.74, -1.36, -1.12, -1.23, -1.07, -1.04, -1.32, -1.65, -1.74\\}\n"
            + "    salinity = \n"
            + "      \\{NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 35.64, 35.64, 35.64, "
            + "35.64, 35.64, 35.63, 35.59, 35.52, 35.56, 35.77, 35.81, 35.82, 35.88, 35.94, 35.99, 36.0, 35.64, 35.64, 35.64, "
            + "35.64, 35.63, 35.63, 35.61, 35.58, 35.5, 35.77, 35.81, 35.86, 35.9, 35.93, 35.96, 35.98\\}\n"
            + "\\}\n";
    tPo = results.indexOf(expected.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureLinesMatch(results.substring(tPo), expected, "results=\n" + results);

    // String2.log("\n*** EDDTableFromNcFiles.testNcCF2b finished.");
  }

  /**
   * Test making an .ncCFMA TrajectoryProfile file (notably with different numbers of profiles and
   * obs).
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testNcCFMA2b() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testNcCFMA2b");

    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.geterdGtsppBest(); // should work
    String tName, error, results, expected;
    int po;
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String query =
        "platform,cruise,org,type,station_id,longitude,latitude,time,depth,"
            + "temperature,salinity&cruise=~%22%28VKLD%2012|Q990046312%29%22"
            + "&longitude%3E=170&time%3E=2012-04-23T00:00:00Z&time%3C=2012-04-24T00:00:00Z";

    // lon lat time range
    tName = tedd.makeNewFileForDapQuery(language, null, null, query, dir, "ncCFMA2b", ".ncCFMA");
    results = NcHelper.ncdump(dir + tName, "");
    // String2.log(results);
    expected =
        "netcdf ncCFMA2b.nc \\{\n"
            + "  dimensions:\n"
            + "    trajectory = 2;\n"
            + "    profile = 2;\n"
            + "    obs = 528;\n"
            + "    trajectory_strlen = 21;\n"
            + "    platform_strlen = 4;\n"
            + "    cruise_strlen = 10;\n"
            + "    org_strlen = 2;\n"
            + "    type_strlen = 2;\n"
            + "  variables:\n"
            + "    char trajectory\\(trajectory=2, trajectory_strlen=21\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :cf_role = \"trajectory_id\";\n"
            + "      :comment = \"Constructed from org_type_platform_cruise\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Trajectory ID\";\n"
            + "\n"
            + "    char platform\\(trajectory=2, platform_strlen=4\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :comment = \"See the list of platform codes \\(sorted in various ways\\) at https://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"GTSPP Platform Code\";\n"
            + "      :references = \"https://www.nodc.noaa.gov/gtspp/document/codetbls/callist.html\";\n"
            + "\n"
            + "    char cruise\\(trajectory=2, cruise_strlen=10\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :comment = \"Radio callsign \\+ year for real time data, or NODC reference number for delayed mode data.  See\n"
            + "https://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html .\n"
            + "'X' indicates a missing value.\n"
            + "Two or more adjacent spaces in the original cruise names have been compacted to 1 space.\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Cruise_ID\";\n"
            + "\n"
            + "    char org\\(trajectory=2, org_strlen=2\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :comment = \"From the first 2 characters of stream_ident:\n"
            + "Code  Meaning\n"
            + "AD  Australian Oceanographic Data Centre\n"
            + "AF  Argentina Fisheries \\(Fisheries Research and Development National Institute \\(INIDEP\\), Mar del Plata, Argentina\n"
            + "AO  Atlantic Oceanographic and Meteorological Lab\n"
            + "AP  Asia-Pacific \\(International Pacific Research Center/ Asia-Pacific Data-Research Center\\)\n"
            + "BI  BIO Bedford institute of Oceanography\n"
            + "CF  Canadian Navy\n"
            + "CS  CSIRO in Australia\n"
            + "DA  Dalhousie University\n"
            + "FN  FNOC in Monterey, California\n"
            + "FR  Orstom, Brest\n"
            + "FW  Fresh Water Institute \\(Winnipeg\\)\n"
            + "GE  BSH, Germany\n"
            + "IC  ICES\n"
            + "II  IIP\n"
            + "IK  Institut fur Meereskunde, Kiel\n"
            + "IM  IML\n"
            + "IO  IOS in Pat Bay, BC\n"
            + "JA  Japanese Meteorologocal Agency\n"
            + "JF  Japan Fisheries Agency\n"
            + "ME  EDS\n"
            + "MO  Moncton\n"
            + "MU  Memorial University\n"
            + "NA  NAFC\n"
            + "NO  NODC \\(Washington\\)\n"
            + "NW  US National Weather Service\n"
            + "OD  Old Dominion Univ, USA\n"
            + "RU  Russian Federation\n"
            + "SA  St Andrews\n"
            + "SI  Scripps Institute of Oceanography\n"
            + "SO  Southampton Oceanographic Centre, UK\n"
            + "TC  TOGA Subsurface Data Centre \\(France\\)\n"
            + "TI  Tiberon lab US\n"
            + "UB  University of BC\n"
            + "UQ  University of Quebec at Rimouski\n"
            + "VL  Far Eastern Regional Hydromet. Res. Inst. of V\n"
            + "WH  Woods Hole\n"
            + "\n"
            + "from https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref006\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Organization\";\n"
            + "\n"
            + "    char type\\(trajectory=2, type_strlen=2\\);\n"
            + "      :_Encoding = \"ISO-8859-1\";\n"
            + "      :comment = \"From the 3rd and 4th characters of stream_ident:\n"
            + "Code  Meaning\n"
            + "AR  Animal mounted recorder\n"
            + "BA  BATHY message\n"
            + "BF  Undulating Oceanographic Recorder \\(e.g. Batfish CTD\\)\n"
            + "BO  Bottle\n"
            + "BT  general BT data\n"
            + "CD  CTD down trace\n"
            + "CT  CTD data, up or down\n"
            + "CU  CTD up trace\n"
            + "DB  Drifting buoy\n"
            + "DD  Delayed mode drifting buoy data\n"
            + "DM  Delayed mode version from originator\n"
            + "DT  Digital BT\n"
            + "IC  Ice core\n"
            + "ID  Interpolated drifting buoy data\n"
            + "IN  Ship intake samples\n"
            + "MB  MBT\n"
            + "MC  CTD and bottle data are mixed for the station\n"
            + "MI  Data from a mixed set of instruments\n"
            + "ML  Minilog\n"
            + "OF  Real-time oxygen and fluorescence\n"
            + "PF  Profiling float\n"
            + "RM  Radio message\n"
            + "RQ  Radio message with scientific QC\n"
            + "SC  Sediment core\n"
            + "SG  Thermosalinograph data\n"
            + "ST  STD data\n"
            + "SV  Sound velocity probe\n"
            + "TE  TESAC message\n"
            + "TG  Thermograph data\n"
            + "TK  TRACKOB message\n"
            + "TO  Towed CTD\n"
            + "TR  Thermistor chain\n"
            + "XB  XBT\n"
            + "XC  Expendable CTD\n"
            + "\n"
            + "from https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref082\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Data Type\";\n"
            + "\n"
            + "    int station_id\\(trajectory=2, profile=2\\);\n"
            + "      :_FillValue = 2147483647; // int\n"
            + "      :actual_range = 13968849, 27478599; // int\n"
            + "      :cf_role = \"profile_id\";\n"
            + "      :comment = \"Identification number of the station \\(profile\\) in the GTSPP Continuously Managed Database\";\n"
            + "      :ioos_category = \"Identifier\";\n"
            + "      :long_name = \"Station ID Number\";\n"
            + "      :missing_value = 2147483647; // int\n"
            + "\n"
            + "    float longitude\\(trajectory=2, profile=2\\);\n"
            + "      :_CoordinateAxisType = \"Lon\";\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = 173.5403f, 176.64f; // float\n"
            + "      :axis = \"X\";\n"
            + "      :C_format = \"%9.4f\";\n"
            + "      :colorBarMaximum = 180.0; // double\n"
            + "      :colorBarMinimum = -180.0; // double\n"
            + "      :epic_code = 502; // int\n"
            + "      :FORTRAN_format = \"F9.4\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Longitude\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :standard_name = \"longitude\";\n"
            + "      :units = \"degrees_east\";\n"
            + "      :valid_max = 180.0f; // float\n"
            + "      :valid_min = -180.0f; // float\n"
            + "\n"
            + "    float latitude\\(trajectory=2, profile=2\\);\n"
            + "      :_CoordinateAxisType = \"Lat\";\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = -75.45f, -34.5796f; // float\n"
            + "      :axis = \"Y\";\n"
            + "      :C_format = \"%8.4f\";\n"
            + "      :colorBarMaximum = 90.0; // double\n"
            + "      :colorBarMinimum = -90.0; // double\n"
            + "      :epic_code = 500; // int\n"
            + "      :FORTRAN_format = \"F8.4\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Latitude\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :standard_name = \"latitude\";\n"
            + "      :units = \"degrees_north\";\n"
            + "      :valid_max = 90.0f; // float\n"
            + "      :valid_min = -90.0f; // float\n"
            + "\n"
            + "    double time\\(trajectory=2, profile=2\\);\n"
            + "      :_CoordinateAxisType = \"Time\";\n"
            + "      :actual_range = 1.33514142E9, 1.335216E9; // double\n"
            + "      :axis = \"T\";\n"
            + "      :ioos_category = \"Time\";\n"
            + "      :long_name = \"Time\";\n"
            + "      :standard_name = \"time\";\n"
            + "      :time_origin = \"01-JAN-1970 00:00:00\";\n"
            + "      :units = \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "\n"
            + "    float depth\\(trajectory=2, profile=2, obs=528\\);\n"
            + "      :_CoordinateAxisType = \"Height\";\n"
            + "      :_CoordinateZisPositive = \"down\";\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = 4.0f, 368.0f; // float\n"
            + "      :axis = \"Z\";\n"
            + "      :C_format = \"%6.2f\";\n"
            + "      :colorBarMaximum = 5000.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :epic_code = 3; // int\n"
            + "      :FORTRAN_format = \"F6.2\";\n"
            + "      :ioos_category = \"Location\";\n"
            + "      :long_name = \"Depth of the Observations\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :positive = \"down\";\n"
            + "      :standard_name = \"depth\";\n"
            + "      :units = \"m\";\n"
            + "\n"
            + "    float temperature\\(trajectory=2, profile=2, obs=528\\);\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = -1.84f, 19.984f; // float\n"
            + "      :C_format = \"%9.4f\";\n"
            + "      :cell_methods = \"time: point longitude: point latitude: point depth: point\";\n"
            + "      :colorBarMaximum = 32.0; // double\n"
            + "      :colorBarMinimum = 0.0; // double\n"
            + "      :coordinates = \"time latitude longitude depth\";\n"
            + "      :epic_code = 28; // int\n"
            + "      :FORTRAN_format = \"F9.4\";\n"
            + "      :ioos_category = \"Temperature\";\n"
            + "      :long_name = \"Sea Water Temperature\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :standard_name = \"sea_water_temperature\";\n"
            + "      :units = \"degree_C\";\n"
            + "\n"
            + "    float salinity\\(trajectory=2, profile=2, obs=528\\);\n"
            + "      :_FillValue = NaNf; // float\n"
            + "      :actual_range = 35.5f, 36.0f; // float\n"
            + "      :C_format = \"%9.4f\";\n"
            + "      :cell_methods = \"time: point longitude: point latitude: point depth: point\";\n"
            + "      :colorBarMaximum = 37.0; // double\n"
            + "      :colorBarMinimum = 32.0; // double\n"
            + "      :coordinates = \"time latitude longitude depth\";\n"
            + "      :epic_code = 41; // int\n"
            + "      :FORTRAN_format = \"F9.4\";\n"
            + "      :ioos_category = \"Salinity\";\n"
            + "      :long_name = \"Practical Salinity\";\n"
            + "      :missing_value = NaNf; // float\n"
            + "      :salinity_scale = \"PSU\";\n"
            + "      :standard_name = \"sea_water_practical_salinity\";\n"
            + "      :units = \"PSU\";\n"
            + "\n"
            + "  // global attributes:\n"
            + "  :acknowledgment = \"These data were acquired from the US NOAA National Oceanographic Data Center \\(NODC\\) on 20.{8} from https://www.nodc.noaa.gov/GTSPP/.\";\n"
            + // \\( because in regex
            "  :cdm_altitude_proxy = \"depth\";\n"
            + "  :cdm_data_type = \"TrajectoryProfile\";\n"
            + "  :cdm_profile_variables = \"station_id, longitude, latitude, time\";\n"
            + "  :cdm_trajectory_variables = \"trajectory, org, type, platform, cruise\";\n"
            + "  :Conventions = \"COARDS, WOCE, GTSPP, CF-1.10, ACDD-1.3\";\n"
            + "  :creator_email = \"nodc.gtspp@noaa.gov\";\n"
            + "  :creator_name = \"NOAA NESDIS NODC \\(IN295\\)\";\n"
            + "  :creator_url = \"https://www.nodc.noaa.gov/GTSPP/\";\n"
            + "  :crs = \"EPSG:4326\";\n"
            + "  :defaultGraphQuery = \"longitude,latitude,station_id&time%3E=max\\(time\\)-7days&time%3C=max\\(time\\)&.draw=markers&.marker=10\\|5\";\n"
            + // \\( and \\| because in regex
            "  :Easternmost_Easting = 176.64f; // float\n"
            + "  :featureType = \"TrajectoryProfile\";\n"
            + "  :file_source = \"The GTSPP Continuously Managed Data Base\";\n"
            + "  :geospatial_lat_max = -34.5796f; // float\n"
            + "  :geospatial_lat_min = -75.45f; // float\n"
            + "  :geospatial_lat_units = \"degrees_north\";\n"
            + "  :geospatial_lon_max = 176.64f; // float\n"
            + "  :geospatial_lon_min = 173.5403f; // float\n"
            + "  :geospatial_lon_units = \"degrees_east\";\n"
            + "  :geospatial_vertical_max = 368.0f; // float\n"
            + "  :geospatial_vertical_min = 4.0f; // float\n"
            + "  :geospatial_vertical_positive = \"down\";\n"
            + "  :geospatial_vertical_units = \"m\";\n"
            + "  :gtspp_ConventionVersion = \"GTSPP4.0\";\n"
            + "  :gtspp_handbook_version = \"GTSPP Data User's Manual 1.0\";\n"
            + "  :gtspp_program = \"writeGTSPPnc40.f90\";\n"
            + "  :gtspp_programVersion = \"1.8\";\n"
            + "  :history = \"20.{8} csun writeGTSPPnc40.f90 Version 1.8\n"
            + ".tgz files from ftp.nodc.noaa.gov /pub/data.nodc/gtspp/bestcopy/netcdf \\(https://www.nodc.noaa.gov/GTSPP/\\)\n"
            + "20.{8} Most recent ingest, clean, and reformat at ERD \\(erd.data at noaa.gov\\)."; // date
    // changes
    int tPo = results.indexOf("(erd.data at noaa.gov).");
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureLinesMatch(results.substring(0, tPo + 23), expected, "\nresults=\n" + results);

    // today + " (local files)\n" + //from upwell, so time not to seconds until ver
    // 1.40
    // today + " https://upwell.pfeg.noaa.gov/erddap/tabledap/erdGtsppBest.das\n" +
    // today + " (local files)\n" +
    // today + " http://127.0.0.1:8080/cwexperimental/tabledap/
    /*
     * 2013-10-28 Too hard to get summary converted to regex. So skip testing it.
     * String expected2 =
     * "erdGtsppBest.ncCFMA?platform,cruise,org,type,station_id,longitude,latitude,time,depth,temperature,salinity&cruise=~%22%28SHIP%20%20%20%2012|Q990046312%29%22&longitude%3E=170&time%3E=2012-04-23T00:00:00Z&time%3C=2012-04-24T00:00:00Z\";\n"
     * +
     * "  :id = \"ncCFMA2b\";\n" +
     * "  :infoUrl = \"https://www.nodc.noaa.gov/GTSPP/\";\n" +
     * "  :institution = \"NOAA NODC\";\n" +
     * "  :keywords = \"Oceans > Ocean Temperature > Water Temperature,\n" +
     * "Oceans > Salinity/Density > Salinity,\n" +
     * "cruise, data, density, depth, global, gtspp, identifier, noaa, nodc, observation, ocean, oceans, organization, profile, program, salinity, sea, sea_water_salinity, sea_water_temperature, seawater, station, temperature, temperature-salinity, time, type, water\";\n"
     * +
     * "  :keywords_vocabulary = \"NODC Data Types, CF Standard Names, GCMD Science Keywords\";\n"
     * +
     * "  :LEXICON = \"NODC_GTSPP\";\n" + //date below changes
     * "  :license = \"These data are openly available to the public.  Please acknowledge the use of these data with:\n"
     * +
     * "These data were acquired from the US NOAA National Oceanographic Data Center (NODC) on 2013-06-13 from https://www.nodc.noaa.gov/GTSPP/.\n"
     * +
     * "\n" +
     * "The data may be used and redistributed for free but is not intended\n" +
     * "for legal use, since it may contain inaccuracies. Neither the data\n" +
     * "Contributor, ERD, NOAA, nor the United States Government, nor any\n" +
     * "of their employees or contractors, makes any warranty, express or\n" +
     * "implied, including warranties of merchantability and fitness for a\n" +
     * "particular purpose, or assumes any legal liability for the accuracy,\n" +
     * "completeness, or usefulness, of this information.\";\n" +
     * "  :naming_authority = \"gov.noaa.nodc\";\n" +
     * "  :Northernmost_Northing = -34.58f; // float\n" +
     * "  :project = \"Joint IODE/JCOMM Global Temperature-Salinity Profile Programme\";\n"
     * +
     * "  :references = \"https://www.nodc.noaa.gov/GTSPP/\";\n" +
     * "  :sourceUrl = \"(local files)\";\n" +
     * "  :Southernmost_Northing = -75.45f; // float\n" +
     * "  :standard_name_vocabulary = \"CF Standard Name Table v55\";\n" +
     * "  :subsetVariables = \"platform, cruise, org, type\";\n" +
     * "  :summary = \"The Global Temperature-Salinity Profile Programme (GTSPP) develops and maintains "
     * +
     * "a global ocean temperature and salinity resource with data that are both up-to-date and of "
     * +
     * "the highest quality. It is a joint World Meteorological Organization (WMO) and Intergovernmental "
     * +
     * "Oceanographic Commission (IOC) program.  It includes data from XBTs, CTDs, moored and drifting "
     * +
     * "buoys, and PALACE floats. For information about organizations contributing data to GTSPP, see "
     * +
     * "http://gosic.org/goos/GTSPP-data-flow.htm .  The U.S. National Oceanographic Data Center "
     * +
     * "(NODC) maintains the GTSPP Continuously Managed Data Base and releases new 'best-copy' "
     * +
     * "data once per month.\\\\n\\\\nWARNING: This dataset has a *lot* of data.  To avoid having "
     * +
     * "your request fail because you are requesting too much data at once, you should almost "
     * +
     * "always specify either:\\\\n* a small time bounding box (at most, a few days), and/or"
     * +
     * "\\\\n* a small longitude and latitude bounding box (at most, several degrees square)."
     * +
     * "\\\\nRequesting data for a specific platform, cruise, org, type, and/or station_id may "
     * +
     * "be slow, but it works.\\\\n\\\\n*** This ERDDAP dataset has data for the entire world for "
     * +
     * "all available times (currently, up to and including the May 2013 data) but is a "
     * + //date changes
     * "subset of the original NODC 'best-copy' data.  It only includes data where the quality "
     * +
     * "flags indicate the data is 1=CORRECT, 2=PROBABLY GOOD, or 5=MODIFIED. It does not include "
     * +
     * "some of the metadata, any of the history data, or any of the quality flag data of the "
     * +
     * "original dataset. You can always get the complete, up-to-date dataset (and additional, "
     * +
     * "near-real-time data) from the source: https://www.nodc.noaa.gov/GTSPP/ .  Specific "
     * +
     * "differences are:\\\\n* Profiles with a position_quality_flag or a time_quality_flag other "
     * +
     * "than 1|2|5 were removed.\\\\n* Rows with a depth (z) value less than -0.4 or greater than "
     * +
     * "10000 or a z_variable_quality_flag other than 1|2|5 were removed.\\\\n* Temperature values "
     * +
     * "less than -4 or greater than 40 or with a temperature_quality_flag other than 1|2|5 were "
     * +
     * "set to NaN.\\\\n* Salinity values less than 0 or greater than 41 or with a "
     * +
     * "salinity_quality_flag other than 1|2|5 were set to NaN.\\\\n* Time values were converted from "
     * +
     * "\\\\\\\"days since 1900-01-01 00:00:00\\\\\\\" to \\\\\\\"seconds since 1970-01-01T00:00:00"
     * +
     * "\\\\\\\".\\\\n\\\\nSee the Quality Flag definitions on page 5 and \\\\\\\"Table 2.1: Global "
     * +
     * "Impossible Parameter Values\\\\\\\" on page 61 of" +
     * "\\\\nhttps://www.nodc.noaa.gov/GTSPP/document/qcmans/GTSPP_RT_QC_Manual_20090916.pdf ."
     * +
     * "\\\\nThe Quality Flag definitions are also at" +
     * "\\\\nhttps://www.nodc.noaa.gov/GTSPP/document/qcmans/qcflags.htm .\";\n" +
     */
    String expected2 =
        "  :time_coverage_end = \"2012-04-23T21:20:00Z\";\n"
            + "  :time_coverage_start = \"2012-04-23T00:37:00Z\";\n"
            + "  :title = \"Global Temperature and Salinity Profile Programme \\(GTSPP\\) Data, 1985-present\";\n"
            + "  :Westernmost_Easting = 173.5403f; // float\n";

    String expected3 =
        expected2
            + "\n"
            + "  data:\n"
            + "    trajectory =   \"AD_XB_09WR_VKLD 12\",   \"ME_TE_33P2_Q990046312\"\n"
            + "    platform =   \"09WR\",   \"33P2\"\n"
            + "    cruise =   \"VKLD 12\",   \"Q990046312\"\n"
            + "    org =   \"AD\",   \"ME\"\n"
            + "    type =   \"XB\",   \"TE\"\n"
            + "    station_id = \n"
            + "      \\{\n"
            + "        \\{27478599, 2147483647\\},\n"
            + "        \\{13968849, 13968850\\}\n"
            + "      \\}\n"
            + "    longitude = \n"
            + "      \\{\n"
            + "        \\{173.5403, NaN\\},\n"
            + "        \\{176.64, 176.64\\}\n"
            + "      \\}\n"
            + "    latitude = \n"
            + "      \\{\n"
            + "        \\{-34.5796, NaN\\},\n"
            + "        \\{-75.45, -75.43\\}\n"
            + "      \\}\n"
            + "    time = \n"
            + "      \\{\n"
            + "        \\{1.33514142E9, NaN\\},\n"
            + "        \\{1.3351446E9, 1.335216E9\\}\n"
            + "      \\}\n"
            + "    depth = \n"
            + "      \\{\n"
            + "        \\{\n"
            + "          \\{4.01, 4.68, 5.35, 6.02, 6.69, 7.36, 8.03, 8.69, 9.36, 10.03, 10.7, 11.37, 12.04, 12.7, 13.37, 14.04, 14."
            + "71, 15.38, 16.05, 16.71, 17.38, 18.05, 18.72, 19.38, 20.05, 20.72, 21.39, 22.06, 22.72, 23.39, 24.06, 24.73, 25"
            + ".39, 26.06, 26.73, 27.4, 28.06, 28.73, 29.4, 30.06, 30.73, 31.4, 32.06, 32.73, 33.4, 34.07, 34.73, 35.4, 36.07,"
            + " 36.73, 37.4, 38.07, 38.73, 39.4, 40.06, 40.73, 41.4, 42.06, 42.73, 43.4, 44.06, 44.73, 45.39, 46.06, 46.73, 47"
            + ".39, 48.06, 48.72, 49.39, 50.06, 50.72, 51.39, 52.05, 52.72, 53.38, 54.05, 54.71, 55.38, 56.05, 56.71, 57.38, 5"
            + "8.04, 58.71, 59.37, 60.04, 60.7, 61.37, 62.03, 62.7, 63.36, 64.03, 64.69, 65.36, 66.02, 66.68, 67.35, 68.01, 68"
            + ".68, 69.34, 70.01, 70.67, 71.34, 72.0, 72.66, 73.33, 73.99, 74.66, 75.32, 75.98, 76.65, 77.31, 77.98, 78.64, 79"
            + ".3, 79.97, 80.63, 81.3, 81.96, 82.62, 83.29, 83.95, 84.61, 85.28, 85.94, 86.6, 87.27, 87.93, 88.59, 89.26, 89.9"
            + "2, 90.58, 91.24, 91.91, 92.57, 93.23, 93.9, 94.56, 95.22, 95.88, 96.55, 97.21, 97.87, 98.53, 99.2, 99.86, 100.5"
            + "2, 101.18, 101.85, 102.51, 103.17, 103.83, 104.49, 105.16, 105.82, 106.48, 107.14, 107.8, 108.47, 109.13, 109.7"
            + "9, 110.45, 111.11, 111.77, 112.44, 113.1, 113.76, 114.42, 115.08, 115.74, 116.4, 117.06, 117.73, 118.39, 119.05"
            + ", 119.71, 120.37, 121.03, 121.69, 122.35, 123.01, 123.67, 124.33, 125.0, 125.66, 126.32, 126.98, 127.64, 128.3,"
            + " 128.96, 129.62, 130.28, 130.94, 131.6, 132.26, 132.92, 133.58, 134.24, 134.9, 135.56, 136.22, 136.88, 137.54, "
            + "138.2, 138.86, 139.52, 140.18, 140.84, 141.5, 142.16, 142.82, 143.48, 144.14, 144.79, 145.45, 146.11, 146.77, 1"
            + "47.43, 148.09, 148.75, 149.41, 150.07, 150.73, 151.39, 152.04, 152.7, 153.36, 154.02, 154.68, 155.34, 156.0, 15"
            + "6.65, 157.31, 157.97, 158.63, 159.29, 159.95, 160.6, 161.26, 161.92, 162.58, 163.24, 163.89, 164.55, 165.21, 16"
            + "5.87, 166.53, 167.18, 167.84, 168.5, 169.16, 169.82, 170.47, 171.13, 171.79, 172.44, 173.1, 173.76, 174.42, 175"
            + ".07, 175.73, 176.39, 177.05, 177.7, 178.36, 179.02, 179.67, 180.33, 180.99, 181.64, 182.3, 182.96, 183.61, 184."
            + "27, 184.93, 185.58, 186.24, 186.9, 187.55, 188.21, 188.87, 189.52, 190.18, 190.83, 191.49, 192.15, 192.8, 193.4"
            + "6, 194.11, 194.77, 195.43, 196.08, 196.74, 197.39, 198.05, 198.7, 199.36, 200.02, 200.67, 201.33, 201.98, 202.6"
            + "4, 203.29, 203.95, 204.6, 205.26, 205.91, 206.57, 207.22, 207.88, 208.53, 209.19, 209.84, 210.5, 211.15, 211.81"
            + ", 212.46, 213.12, 213.77, 214.43, 215.08, 215.74, 216.39, 217.04, 217.7, 218.35, 219.01, 219.66, 220.32, 220.97"
            + ", 221.62, 222.28, 222.93, 223.59, 224.24, 224.89, 225.55, 226.2, 226.85, 227.51, 228.16, 228.81, 229.47, 230.12"
            + ", 230.78, 231.43, 232.08, 232.74, 233.39, 234.04, 234.69, 235.35, 236.0, 236.65, 237.31, 237.96, 238.61, 239.27"
            + ", 239.92, 240.57, 241.22, 241.88, 242.53, 243.18, 243.83, 244.49, 245.14, 245.79, 246.44, 247.1, 247.75, 248.4,"
            + " 249.05, 249.7, 250.36, 251.01, 251.66, 252.31, 252.96, 253.62, 254.27, 254.92, 255.57, 256.22, 256.88, 257.53,"
            + " 258.18, 258.83, 259.48, 260.13, 260.78, 261.44, 262.09, 262.74, 263.39, 264.04, 264.69, 265.34, 265.99, 266.64"
            + ", 267.29, 267.95, 268.6, 269.25, 269.9, 270.55, 271.2, 271.85, 272.5, 273.15, 273.8, 274.45, 275.1, 275.75, 276"
            + ".4, 277.05, 277.7, 278.35, 279.0, 279.65, 280.3, 280.95, 281.6, 282.25, 282.9, 283.55, 284.2, 284.85, 285.5, 28"
            + "6.15, 286.8, 287.45, 288.1, 288.75, 289.4, 290.05, 290.7, 291.35, 292.0, 292.64, 293.29, 293.94, 294.59, 295.24"
            + ", 295.89, 296.54, 297.19, 297.84, 298.49, 299.13, 299.78, 300.43, 301.08, 301.73, 302.38, 303.02, 303.67, 304.3"
            + "2, 304.97, 305.62, 306.27, 306.91, 307.56, 308.21, 308.86, 309.51, 310.15, 310.8, 311.45, 312.1, 312.75, 313.39"
            + ", 314.04, 314.69, 315.34, 315.98, 316.63, 317.28, 317.93, 318.57, 319.22, 319.87, 320.52, 321.16, 321.81, 322.4"
            + "6, 323.1, 323.75, 324.4, 325.04, 325.69, 326.34, 326.98, 327.63, 328.28, 328.92, 329.57, 330.22, 330.86, 331.51"
            + ", 332.16, 332.8, 333.45, 334.1, 334.74, 335.39, 336.03, 336.68, 337.33, 337.97, 338.62, 339.26, 339.91, 340.56,"
            + " 341.2, 341.85, 342.49, 343.14, 343.78, 344.43, 345.08, 345.72, 346.37, 347.01, 347.66, 348.3, 348.95, 349.59, "
            + "350.24\\},\n"
            + "          \\{NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN\\}\n"
            + "        \\},\n"
            + "        \\{\n"
            + "          \\{4.0, 10.0, 20.0, 30.0, 49.0, 99.0, 138.0, 142.0, 146.0, 148.0, 170.0, 198.0, 247.0, 297.0, 356.0, 366.0,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN\\},\n"
            + "          \\{4.0, 10.0, 20.0, 30.0, 49.0, 99.0, 142.0, 144.0, 148.0, 154.0, 198.0, 208.0, 235.0, 297.0, 328.0, 368.0,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN\\}\n"
            + "        \\}\n"
            + "      \\}\n"
            + "    temperature = \n"
            + "      \\{\n"
            + "        \\{\n"
            + "          \\{19.984, 19.976, 19.973, 19.974, 19.975, 19.976, 19.981, 19.981, 19.98, 19.979, 19.981, 19.975, 19.974, 1"
            + "9.973, 19.976, 19.975, 19.976, 19.973, 19.973, 19.974, 19.975, 19.973, 19.971, 19.966, 19.965, 19.962, 19.962, "
            + "19.959, 19.958, 19.956, 19.948, 19.945, 19.945, 19.942, 19.942, 19.94, 19.94, 19.938, 19.936, 19.939, 19.933, 1"
            + "9.938, 19.933, 19.932, 19.931, 19.931, 19.932, 19.93, 19.93, 19.928, 19.928, 19.925, 19.919, 19.919, 19.917, 19"
            + ".917, 19.916, 19.915, 19.91, 19.905, 19.89, 19.877, 19.87, 19.861, 19.864, 19.86, 19.858, 19.857, 19.857, 19.85"
            + "3, 19.852, 19.825, 19.799, 19.778, 19.702, 19.604, 19.454, 19.334, 19.279, 19.23, 19.204, 19.151, 19.048, 18.94"
            + "7, 18.867, 18.797, 18.749, 18.685, 18.629, 18.553, 18.489, 18.392, 18.303, 18.195, 18.055, 17.962, 17.909, 17.8"
            + "78, 17.869, 17.855, 17.834, 17.82, 17.807, 17.787, 17.773, 17.766, 17.764, 17.756, 17.747, 17.746, 17.727, 17.7"
            + "03, 17.691, 17.66, 17.629, 17.602, 17.578, 17.558, 17.533, 17.502, 17.475, 17.458, 17.454, 17.448, 17.432, 17.4"
            + "18, 17.403, 17.397, 17.376, 17.343, 17.305, 17.275, 17.255, 17.248, 17.229, 17.208, 17.196, 17.159, 17.143, 17."
            + "134, 17.092, 17.034, 16.99, 16.952, 16.919, 16.887, 16.875, 16.872, 16.867, 16.837, 16.813, 16.801, 16.787, 16."
            + "776, 16.762, 16.756, 16.752, 16.742, 16.733, 16.732, 16.723, 16.72, 16.716, 16.71, 16.714, 16.702, 16.682, 16.6"
            + "69, 16.663, 16.66, 16.656, 16.648, 16.635, 16.624, 16.611, 16.596, 16.59, 16.578, 16.575, 16.569, 16.556, 16.55"
            + "2, 16.547, 16.535, 16.511, 16.491, 16.473, 16.462, 16.457, 16.457, 16.452, 16.45, 16.45, 16.442, 16.434, 16.426"
            + ", 16.417, 16.403, 16.384, 16.356, 16.336, 16.31, 16.293, 16.211, 16.144, 16.047, 15.915, 15.835, 15.798, 15.756"
            + ", 15.735, 15.716, 15.712, 15.71, 15.712, 15.712, 15.71, 15.683, 15.661, 15.656, 15.653, 15.647, 15.644, 15.637,"
            + " 15.628, 15.628, 15.619, 15.589, 15.572, 15.562, 15.558, 15.55, 15.543, 15.535, 15.52, 15.492, 15.397, 15.302, "
            + "15.217, 15.174, 15.147, 15.121, 15.08, 15.054, 15.023, 15.011, 15.003, 14.985, 14.935, 14.914, 14.89, 14.848, 1"
            + "4.812, 14.778, 14.747, 14.715, 14.698, 14.703, 14.71, 14.721, 14.722, 14.71, 14.69, 14.673, 14.654, 14.661, 14."
            + "654, 14.658, 14.659, 14.665, 14.665, 14.659, 14.653, 14.655, 14.658, 14.657, 14.651, 14.647, 14.646, 14.645, 14"
            + ".646, 14.646, 14.643, 14.637, 14.64, 14.64, 14.603, 14.588, 14.578, 14.57, 14.568, 14.563, 14.562, 14.556, 14.5"
            + "55, 14.534, 14.524, 14.525, 14.52, 14.419, 14.303, 14.25, 14.235, 14.22, 14.212, 14.199, 14.154, 14.127, 14.09,"
            + " 14.055, 14.031, 14.019, 14.005, 14.002, 14.001, 14.0, 13.995, 13.996, 13.998, 13.995, 13.992, 13.983, 13.968, "
            + "13.939, 13.897, 13.872, 13.847, 13.832, 13.807, 13.751, 13.7, 13.687, 13.669, 13.637, 13.602, 13.564, 13.53, 13"
            + ".508, 13.498, 13.493, 13.482, 13.466, 13.462, 13.461, 13.459, 13.454, 13.454, 13.451, 13.448, 13.446, 13.443, 1"
            + "3.437, 13.432, 13.429, 13.431, 13.426, 13.403, 13.329, 13.282, 13.257, 13.233, 13.208, 13.191, 13.162, 13.138, "
            + "13.126, 13.122, 13.118, 13.106, 13.1, 13.093, 13.062, 13.045, 13.031, 13.019, 13.012, 13.008, 12.998, 12.985, 1"
            + "2.967, 12.934, 12.898, 12.885, 12.854, 12.835, 12.811, 12.792, 12.778, 12.752, 12.74, 12.73, 12.726, 12.715, 12"
            + ".703, 12.689, 12.669, 12.661, 12.655, 12.652, 12.649, 12.636, 12.604, 12.575, 12.552, 12.538, 12.533, 12.524, 1"
            + "2.498, 12.461, 12.443, 12.424, 12.41, 12.414, 12.41, 12.403, 12.4, 12.402, 12.394, 12.383, 12.382, 12.379, 12.3"
            + "75, 12.374, 12.368, 12.361, 12.36, 12.353, 12.341, 12.332, 12.326, 12.321, 12.314, 12.293, 12.282, 12.264, 12.2"
            + "45, 12.232, 12.223, 12.215, 12.212, 12.206, 12.2, 12.202, 12.198, 12.192, 12.182, 12.177, 12.176, 12.173, 12.16"
            + "8, 12.167, 12.162, 12.158, 12.155, 12.145, 12.133, 12.128, 12.127, 12.125, 12.125, 12.123, 12.121, 12.12, 12.11"
            + "9, 12.117, 12.116, 12.117, 12.113, 12.109, 12.091, 12.063, 12.039, 12.021, 12.013, 12.008, 11.981, 11.953, 11.9"
            + "33, 11.928, 11.926, 11.923, 11.926, 11.926, 11.918, 11.909, 11.9, 11.892, 11.876, 11.871, 11.844, 11.815, 11.79"
            + "6, 11.781, 11.764, 11.737, 11.724, 11.718, 11.711, 11.691, 11.673, 11.667, 11.657, 11.649, 11.646, 11.643, 11.6"
            + "39, 11.639, 11.632, 11.621, 11.607, 11.59, 11.581, 11.58, 11.581, 11.582, 11.583, 11.575, 11.576, 11.574, 11.57"
            + "6, 11.569, 11.569, 11.569, 11.572, 11.572, 11.573, 11.574, 11.575\\},\n"
            + "          \\{NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN\\}\n"
            + "        \\},\n"
            + "        \\{\n"
            + "          \\{-1.84, -1.84, -1.83, -1.83, -1.83, -1.82, -1.78, -1.6, -1.18, -1.1, -1.25, -1.29, -1.13, -1.25, -1.76, -"
            + "1.8, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN\\},\n"
            + "          \\{-1.84, -1.84, -1.84, -1.83, -1.83, -1.82, -1.77, -1.74, -1.36, -1.12, -1.23, -1.07, -1.04, -1.32, -1.65,"
            + " -1.74, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN\\}\n"
            + "        \\}\n"
            + "      \\}\n"
            + "    salinity = \n"
            + "      \\{\n"
            + "        \\{\n"
            + "          \\{NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN\\},\n"
            + "          \\{NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN\\}\n"
            + "        \\},\n"
            + "        \\{\n"
            + "          \\{35.64, 35.64, 35.64, 35.64, 35.64, 35.63, 35.59, 35.52, 35.56, 35.77, 35.81, 35.82, 35.88, 35.94, 35.99,"
            + " 36.0, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN\\},\n"
            + "          \\{35.64, 35.64, 35.64, 35.64, 35.63, 35.63, 35.61, 35.58, 35.5, 35.77, 35.81, 35.86, 35.9, 35.93, 35.96, 3"
            + "5.98, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN"
            + ", NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,"
            + " NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, "
            + "NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N"
            + "aN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, Na"
            + "N, NaN, NaN\\}\n"
            + "        \\}\n"
            + "      \\}\n"
            + "\\}\n";
    tPo = results.indexOf(expected3.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureLinesMatch(results.substring(tPo), expected3, "results=\n" + results);

    // .ncCFMAHeader
    tName =
        tedd.makeNewFileForDapQuery(language, null, null, query, dir, "ncCFMA2b", ".ncCFMAHeader");
    results = File2.readFromFile88591(dir + tName)[1];
    tPo = results.indexOf("(erd.data at noaa.gov).");
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureLinesMatch(results.substring(0, tPo + 23), expected, "\nresults=\n" + results);

    expected3 = expected2 + "}\n";
    tPo = results.indexOf(expected3.substring(0, 17));
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    Test.ensureLinesMatch(results.substring(tPo), expected3, "results=\n" + results);

    String2.log("\n*** EDDTableFromNcFiles.testNcCFMA2b finished.");
  }

  /**
   * Test speed of Data Access Form. Sometimes: use this with profiler:
   * -agentlib:hprof=cpu=samples,depth=20,file=/JavaHeap.txt
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testSpeedDAF() throws Throwable {
    // setup and warmup
    // EDD.testVerbose(false);

    int language = 0;
    EDDTable tableDataset = (EDDTable) EDDTestDataset.getcwwcNDBCMet();
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String fileName = dir + "tableTestSpeedDAF.txt";
    Writer writer = File2.getBufferedFileWriterUtf8(fileName);
    tableDataset.writeDapHtmlForm(language, null, "", writer);

    // time it DAF
    String2.log("start timing");
    long time = System.currentTimeMillis();
    int n = 100; // use 1000 so it dominates program run time if profiling
    for (int i = 0; i < n; i++) tableDataset.writeDapHtmlForm(language, null, "", writer);
    float results = ((System.currentTimeMillis() - time) / (float) n);
    double expected = 12.4;
    String msg =
        "\nEDDTableFromNcFiles.testSpeedDAF time per .html = "
            + results
            + "ms (Java 1.8Lenovo 12.4, 1.7M4700 "
            + expected
            + "ms, 1.6 14.6ms, 1.5 40.8ms)\n"
            + // slow
            // because
            // of info
            // for
            // sliders
            // and
            // subset
            // variables
            "  outputFileName="
            + fileName;
    String2.log(msg);
    Test.ensureTrue(results < expected * 1.5, "Too slow! (common if computer is busy)" + msg);

    // EDD.testVerbose(true);
  }

  /**
   * Test speed of Make A Graph Form. Sometimes: use this with profiler:
   * -agentlib:hprof=cpu=samples,depth=20,file=/JavaHeap.txt
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testSpeedMAG() throws Throwable {
    // setup and warmup
    // EDD.testVerbose(false);

    int language = 0;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    EDDTable tableDataset = (EDDTable) EDDTestDataset.getcwwcNDBCMet();
    String fileName = dir + "tableTestSpeedMAG.txt";
    String2.log("fileName=" + fileName);
    OutputStreamSource oss =
        new OutputStreamSourceSimple(new BufferedOutputStream(new FileOutputStream(fileName)));
    tableDataset.respondToGraphQuery(0, null, null, "", "", "", oss, null, null, null);

    // time it
    String2.log("start timing");
    long time2 = System.currentTimeMillis();
    int n = 2000; // 1000 so it dominates program run time if profiling
    for (int i = 0; i < n; i++)
      tableDataset.respondToGraphQuery(
          0, null, null, "", "", "", oss, dir, "testSpeedMAG.txt", ".graph");
    double observe = (System.currentTimeMillis() - time2) / (float) n;
    double expect =
        11; // but slower in TestAll. java 8 was 8ms, 2014-09 java 1.7 was 4.38ms, java 1.6
    // 10.7ms, java 1.5 55.172ms
    String msg =
        "\nEDDTableFromNcFiles.testSpeedMAG time per .graph = "
            + observe
            + "ms (java 1.7M4700 "
            + expect
            + "ms)\n"
            + // slow because of info for sliders and subset
            // variables
            "  outputFileName="
            + fileName;
    String2.log(msg);
    Test.ensureTrue(observe < 1.7 * expect, "Too slow!" + msg);
    // EDD.testVerbose(true);
  }

  /**
   * Test speed of Subset Form. Sometimes: use this with profiler:
   * -agentlib:hprof=cpu=samples,depth=20,file=/JavaHeap.txt
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testSpeedSubset() throws Throwable {
    // setup and warmup
    // EDD.testVerbose(false);

    int language = 0;
    EDDTable tableDataset = (EDDTable) EDDTestDataset.getcwwcNDBCMet();
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String fileName = dir + "tableTestSpeedSubset.txt";
    String2.log("fileName=" + fileName);
    OutputStreamSource oss =
        new OutputStreamSourceSimple(new BufferedOutputStream(new FileOutputStream(fileName)));
    tableDataset.respondToGraphQuery(
        0, null, null, "", "", "", oss, dir, "testSpeedSubset.txt", ".graph");

    // time it
    String2.log("start timing");
    long time2 = System.currentTimeMillis();
    int n = 100; // if profiling, use 1000 so it dominates program run time
    for (int i = 0; i < n; i++)
      tableDataset.respondToGraphQuery(
          0, null, null, "", "", "", oss, dir, "testSpeedSubset.txt", ".graph");

    double observe = (System.currentTimeMillis() - time2) / (float) n;
    double expect = 12; // ms 2020-11-25 was 4.23ms (no explanation for jump) 2013-10-28 ~10ms
    String msg =
        "\nEDDTableFromNcFiles.testSpeedSubset time per .graph = "
            + observe
            + "ms (java 1.7M4700 "
            + expect
            + "ms, 1.6 17.36ms)\n"
            + "  outputFileName="
            + fileName;
    String2.log(msg);
    Test.ensureTrue(observe < 1.5 * expect, "Too slow! (common if computer is busy)" + msg);
    // EDD.testVerbose(true);
  }

  /** Test requesting float=NaN. */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testEqualsNaN() throws Throwable {
    // String2.log("\n*** EDDTableFromNcFiles.testEqualsNaN");

    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.geterdGtsppBest();
    String tName, error, results, expected;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    // lon lat time range
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&trajectory=%22ME_BA_067F_66021%2014%22&time=2014-01-01T00:00:00Z&salinity=NaN",
            dir,
            "equalsNaN",
            ".csv");
    results = File2.readFromFile88591(dir + tName)[1];
    // String2.log(results);
    expected =
        "trajectory,org,type,platform,cruise,station_id,longitude,latitude,time,depth,temperature,salinity\n"
            + ",,,,,,degrees_east,degrees_north,UTC,m,degree_C,PSU\n"
            + "ME_BA_067F_66021 14,ME,BA,067F,66021 14,18867634,13.92,54.88,2014-01-01T00:00:00Z,2.0,5.2,NaN\n"
            + "ME_BA_067F_66021 14,ME,BA,067F,66021 14,18867634,13.92,54.88,2014-01-01T00:00:00Z,5.0,5.2,NaN\n"
            + "ME_BA_067F_66021 14,ME,BA,067F,66021 14,18867634,13.92,54.88,2014-01-01T00:00:00Z,7.0,5.2,NaN\n"
            + "ME_BA_067F_66021 14,ME,BA,067F,66021 14,18867634,13.92,54.88,2014-01-01T00:00:00Z,25.0,5.1,NaN\n"
            + "ME_BA_067F_66021 14,ME,BA,067F,66021 14,18867634,13.92,54.88,2014-01-01T00:00:00Z,40.0,8.0,NaN\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    String2.log("\n*** EDDTableFromNcFiles.testEqualsNaN finished.");
  }

  /**
   * Test requesting altitude=-2. This tests fix of bug where EDDTable.getSourceQueryFromDapQuery
   * didn't use scale_factor to convert altitude constraints to source units (e.g., /-1)!
   *
   * <p>And this tests altitude&gt;= should become depth&lt;= internally. (and related)
   */
  @org.junit.jupiter.api.Test
  void testAltitude() throws Throwable {

    // String2.log("\n*** EDDTableFromNcFiles.testAltitude");

    int language = 0;

    // tests of REVERSED_OPERATOR
    EDDTable tedd;
    String tName, error, results, expected;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";

    tedd = (EDDTable) EDDTestDataset.geterdCinpKfmT();
    expected =
        "station,longitude,latitude,depth,time,temperature\n"
            + ",degrees_east,degrees_north,m,UTC,degree_C\n"
            + "Santa_Rosa_Johnsons_Lee_North,-120.1,33.883335,11.0,2007-09-26T22:13:00Z,16.38\n"
            + "Santa_Rosa_Johnsons_Lee_North,-120.1,33.883335,11.0,2007-09-26T23:13:00Z,16.7\n";

    // >=
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&depth<=17&time>=2007-09-26T22", // what we want to work
            dir,
            "depth1",
            ".csv");
    results = File2.readFromFile88591(dir + tName)[1];
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // >
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&depth<18&time>=2007-09-26T22", // what we want to work
            dir,
            "depth2",
            ".csv");
    results = File2.readFromFile88591(dir + tName)[1];
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // <=
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&depth<=11&time>=2007-09-26T22", // what we want to work
            dir,
            "depth3",
            ".csv");
    results = File2.readFromFile88591(dir + tName)[1];
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // <
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&depth>10.9&time>=2007-09-26T22", // what we want to work
            dir,
            "depth4",
            ".csv");
    results = File2.readFromFile88591(dir + tName)[1];
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // =
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&depth=11&time>=2007-09-26T22", // what we want to work
            dir,
            "depth5",
            ".csv");
    results = File2.readFromFile88591(dir + tName)[1];
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // !=
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&depth!=10&time>=2007-09-26T22", // what we want to work
            dir,
            "depth6",
            ".csv");
    results = File2.readFromFile88591(dir + tName)[1];
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // =~
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&depth=~\"(1000|11\\.0)\"&time>=2007-09-26T22", // what we want to work
            dir,
            "depth7",
            ".csv");
    results = File2.readFromFile88591(dir + tName)[1];
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    // *** original test
    tedd = (EDDTable) EDDTestDataset.getepaseamapTimeSeriesProfiles();

    // lon lat time range
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&depth=2", // what we want to work
            dir,
            "depth8",
            ".csv");
    results = File2.readFromFile88591(dir + tName)[1];
    // String2.log(results);
    expected =
        "station_name,station,latitude,longitude,time,depth,WaterTemperature,salinity,chlorophyll,Nitrogen,Phosphate,Ammonium\n"
            + ",,degrees_north,degrees_east,UTC,m,Celsius,psu,mg_m-3,percent,percent,percent\n"
            + "ED16,1,29.728,-88.00584,2004-06-08T18:00:00Z,2.0,27.2501,34.843,NaN,NaN,NaN,NaN\n";
    Test.ensureEqual(results.substring(0, expected.length()), expected, "\nresults=\n" + results);

    String2.log("\n*** EDDTableFromNcFiles.testAltitude finished.");
  }

  /** These tests an odd response related to missing values. */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testMV() throws Throwable {
    Test.ensureTrue(
        !PrimitiveArray.testValueOpValue(Double.NaN, "<=", -5), "!(NaN<=-5) should be true.");

    int language = 0;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    String name, tName, results, tResults, expected, dapQuery;
    String error = "";
    try {
      EDDTable eddTable = (EDDTable) EDDTestDataset.getcwwcNDBCMet();
      String baseName = eddTable.className() + "TestMV";
      dapQuery =
          "station,longitude,latitude,time,wtmp&station<=\"41024\"&time>=2012-06-20T00:00:00Z&time<=2012-06-20T02:00:00Z&wtmp<=-5";

      tName =
          eddTable.makeNewFileForDapQuery(language, null, null, dapQuery, dir, baseName, ".csv");
      results = File2.directReadFrom88591File(dir + tName);
      String2.log(results);
      expected = "Shouldn't get here!";
      Test.ensureEqual(results, expected, "results=\n" + results); // should fail

    } catch (Throwable t) {
      String msg = t.toString();
      if (msg.indexOf(MustBe.THERE_IS_NO_DATA) < 0)
        throw new RuntimeException("Unexpected error.  expected=" + MustBe.THERE_IS_NO_DATA, t);
    }
  } // end of testMV

  /**
   * Test erdGtsppBest against source files (.zip to .nc to ncdump).
   *
   * @param datasetID The datasetID to be tested: erdGtsppBestNc or erdGtsppBest (.ncCF)
   */
  @org.junit.jupiter.api.Test
  @TagLargeFiles
  void testErdGtsppBest() throws Throwable {

    String tDatasetID =
        "erdGtsppBest"; // used to test erdGtsppBestNc as well (two calls to the same test),
    // but
    // erdGtsppBestNc depends on large files
    // String2.log("\n*** EDDTableFromNcFiles.testErdGtsppBest test:" + tDatasetID);
    int language = 0;
    EDDTable tedd = (EDDTable) EDDTestDataset.geterdGtsppBest(); // should work
    String tName, error, results = null, expected;
    String dir = TEMP_DIR.toAbsolutePath().toString() + "/";
    int po;
    String today =
        Calendar2.getCurrentISODateTimeStringZulu().substring(0, 14); // 14 is enough to check
    // hour. Hard
    // to check min:sec.

    // *** .das
    tName = tedd.makeNewFileForDapQuery(language, null, null, "", dir, "gtspp", ".das");
    String2.log("results fileName=" + dir + tName);
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "Attributes {\n"
            + " s {\n"
            + "  trajectory {\n"
            + "    String cf_role \"trajectory_id\";\n"
            + "    String comment \"Constructed from org_type_platform_cruise\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Trajectory ID\";\n"
            + "  }\n"
            + "  org {\n"
            + "    String comment \"From the first 2 characters of stream_ident:\n"
            + "Code  Meaning\n"
            + "AD  Australian Oceanographic Data Centre\n"
            + "AF  Argentina Fisheries (Fisheries Research and Development National Institute (INIDEP), Mar del Plata, Argentina\n"
            + "AO  Atlantic Oceanographic and Meteorological Lab\n"
            + "AP  Asia-Pacific (International Pacific Research Center/ Asia-Pacific Data-Research Center)\n"
            + "BI  BIO Bedford institute of Oceanography\n"
            + "CF  Canadian Navy\n"
            + "CS  CSIRO in Australia\n"
            + "DA  Dalhousie University\n"
            + "FN  FNOC in Monterey, California\n"
            + "FR  Orstom, Brest\n"
            + "FW  Fresh Water Institute (Winnipeg)\n"
            + "GE  BSH, Germany\n"
            + "IC  ICES\n"
            + "II  IIP\n"
            + "IK  Institut fur Meereskunde, Kiel\n"
            + "IM  IML\n"
            + "IO  IOS in Pat Bay, BC\n"
            + "JA  Japanese Meteorologocal Agency\n"
            + "JF  Japan Fisheries Agency\n"
            + "ME  EDS\n"
            + "MO  Moncton\n"
            + "MU  Memorial University\n"
            + "NA  NAFC\n"
            + "NO  NODC (Washington)\n"
            + "NW  US National Weather Service\n"
            + "OD  Old Dominion Univ, USA\n"
            + "RU  Russian Federation\n"
            + "SA  St Andrews\n"
            + "SI  Scripps Institute of Oceanography\n"
            + "SO  Southampton Oceanographic Centre, UK\n"
            + "TC  TOGA Subsurface Data Centre (France)\n"
            + "TI  Tiberon lab US\n"
            + "UB  University of BC\n"
            + "UQ  University of Quebec at Rimouski\n"
            + "VL  Far Eastern Regional Hydromet. Res. Inst. of V\n"
            + "WH  Woods Hole\n"
            + "\n"
            + "from https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref006\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Organization\";\n"
            + "  }\n"
            + "  type {\n"
            + "    String comment \"From the 3rd and 4th characters of stream_ident:\n"
            + "Code  Meaning\n"
            + "AR  Animal mounted recorder\n"
            + "BA  BATHY message\n"
            + "BF  Undulating Oceanographic Recorder (e.g. Batfish CTD)\n"
            + "BO  Bottle\n"
            + "BT  general BT data\n"
            + "CD  CTD down trace\n"
            + "CT  CTD data, up or down\n"
            + "CU  CTD up trace\n"
            + "DB  Drifting buoy\n"
            + "DD  Delayed mode drifting buoy data\n"
            + "DM  Delayed mode version from originator\n"
            + "DT  Digital BT\n"
            + "IC  Ice core\n"
            + "ID  Interpolated drifting buoy data\n"
            + "IN  Ship intake samples\n"
            + "MB  MBT\n"
            + "MC  CTD and bottle data are mixed for the station\n"
            + "MI  Data from a mixed set of instruments\n"
            + "ML  Minilog\n"
            + "OF  Real-time oxygen and fluorescence\n"
            + "PF  Profiling float\n"
            + "RM  Radio message\n"
            + "RQ  Radio message with scientific QC\n"
            + "SC  Sediment core\n"
            + "SG  Thermosalinograph data\n"
            + "ST  STD data\n"
            + "SV  Sound velocity probe\n"
            + "TE  TESAC message\n"
            + "TG  Thermograph data\n"
            + "TK  TRACKOB message\n"
            + "TO  Towed CTD\n"
            + "TR  Thermistor chain\n"
            + "XB  XBT\n"
            + "XC  Expendable CTD\n"
            + "\n"
            + "from https://www.nodc.noaa.gov/GTSPP/document/codetbls/gtsppcode.html#ref082\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Data Type\";\n"
            + "  }\n"
            + "  platform {\n"
            + "    String comment \"See the list of platform codes (sorted in various ways) at https://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"GTSPP Platform Code\";\n"
            + "    String references \"https://www.nodc.noaa.gov/gtspp/document/codetbls/callist.html\";\n"
            + "  }\n"
            + "  cruise {\n"
            + "    String comment \"Radio callsign + year for real time data, or NODC reference number for delayed mode data.  See\n"
            + "https://www.nodc.noaa.gov/GTSPP/document/codetbls/calllist.html .\n"
            + "'X' indicates a missing value.\n"
            + "Two or more adjacent spaces in the original cruise names have been compacted to 1 space.\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Cruise_ID\";\n"
            + "  }\n"
            + "  station_id {\n"
            + "    Int32 _FillValue 2147483647;\n"
            + "    Int32 actual_range 1, 45282398;\n"
            + // changes every month //don't regex this.
            // It's important to
            // see the changes.
            "    String cf_role \"profile_id\";\n"
            + "    String comment \"Identification number of the station (profile) in the GTSPP Continuously Managed Database\";\n"
            + "    String ioos_category \"Identifier\";\n"
            + "    String long_name \"Station ID Number\";\n"
            + "    Int32 missing_value 2147483647;\n"
            + "  }\n"
            + "  longitude {\n"
            + "    String _CoordinateAxisType \"Lon\";\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range -180.0, 179.999;\n"
            + "    String axis \"X\";\n"
            + "    String C_format \"%9.4f\";\n"
            + "    Float64 colorBarMaximum 180.0;\n"
            + "    Float64 colorBarMinimum -180.0;\n"
            + "    Int32 epic_code 502;\n"
            + "    String FORTRAN_format \"F9.4\";\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Longitude\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String standard_name \"longitude\";\n"
            + "    String units \"degrees_east\";\n"
            + "    Float32 valid_max 180.0;\n"
            + "    Float32 valid_min -180.0;\n"
            + "  }\n"
            + "  latitude {\n"
            + "    String _CoordinateAxisType \"Lat\";\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range -78.579, 90.0;\n"
            + "    String axis \"Y\";\n"
            + "    String C_format \"%8.4f\";\n"
            + "    Float64 colorBarMaximum 90.0;\n"
            + "    Float64 colorBarMinimum -90.0;\n"
            + "    Int32 epic_code 500;\n"
            + "    String FORTRAN_format \"F8.4\";\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Latitude\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String standard_name \"latitude\";\n"
            + "    String units \"degrees_north\";\n"
            + "    Float32 valid_max 90.0;\n"
            + "    Float32 valid_min -90.0;\n"
            + "  }\n"
            + "  time {\n"
            + "    String _CoordinateAxisType \"Time\";\n"
            + "    Float64 actual_range 4.772736e+8, 1.6433712e+9;\n"
            + // 2nd value changes use +
            // //first value was
            // 4.811229e8 until 2020-07-12
            "    String axis \"T\";\n"
            + "    String ioos_category \"Time\";\n"
            + "    String long_name \"Time\";\n"
            + "    String standard_name \"time\";\n"
            + "    String time_origin \"01-JAN-1970 00:00:00\";\n"
            + "    String units \"seconds since 1970-01-01T00:00:00Z\";\n"
            + "  }\n"
            + "  depth {\n"
            + "    String _CoordinateAxisType \"Height\";\n"
            + "    String _CoordinateZisPositive \"down\";\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range -0.4, 9910.0;\n"
            + "    String axis \"Z\";\n"
            + "    String C_format \"%6.2f\";\n"
            + "    Float64 colorBarMaximum 5000.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    Int32 epic_code 3;\n"
            + "    String FORTRAN_format \"F6.2\";\n"
            + "    String ioos_category \"Location\";\n"
            + "    String long_name \"Depth of the Observations\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String positive \"down\";\n"
            + "    String standard_name \"depth\";\n"
            + "    String units \"m\";\n"
            + "  }\n"
            + "  temperature {\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range -3.91, 40.0;\n"
            + "    String C_format \"%9.4f\";\n"
            + "    String cell_methods \"time: point longitude: point latitude: point depth: point\";\n"
            + "    Float64 colorBarMaximum 32.0;\n"
            + "    Float64 colorBarMinimum 0.0;\n"
            + "    String coordinates \"time latitude longitude depth\";\n"
            + "    Int32 epic_code 28;\n"
            + "    String FORTRAN_format \"F9.4\";\n"
            + "    String ioos_category \"Temperature\";\n"
            + "    String long_name \"Sea Water Temperature\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String standard_name \"sea_water_temperature\";\n"
            + "    String units \"degree_C\";\n"
            + "  }\n"
            + "  salinity {\n"
            + "    Float32 _FillValue NaN;\n"
            + "    Float32 actual_range 0.0, 41.0;\n"
            + "    String C_format \"%9.4f\";\n"
            + "    String cell_methods \"time: point longitude: point latitude: point depth: point\";\n"
            + "    Float64 colorBarMaximum 37.0;\n"
            + "    Float64 colorBarMinimum 32.0;\n"
            + "    String coordinates \"time latitude longitude depth\";\n"
            + "    Int32 epic_code 41;\n"
            + "    String FORTRAN_format \"F9.4\";\n"
            + "    String ioos_category \"Salinity\";\n"
            + "    String long_name \"Practical Salinity\";\n"
            + "    Float32 missing_value NaN;\n"
            + "    String salinity_scale \"PSU\";\n"
            + "    String standard_name \"sea_water_practical_salinity\";\n"
            + "    String units \"PSU\";\n"
            + "  }\n"
            + " }\n"
            + "  NC_GLOBAL {\n"
            + "    String acknowledgment \"These data were acquired from the US NOAA National Oceanographic "
            + "Data Center (NODC) on 2022-02-10 from https://www.nodc.noaa.gov/GTSPP/.\";\n"
            + // changes
            // monthly
            "    String cdm_altitude_proxy \"depth\";\n"
            + "    String cdm_data_type \"TrajectoryProfile\";\n"
            + "    String cdm_profile_variables \"station_id, longitude, latitude, time\";\n"
            + "    String cdm_trajectory_variables \"trajectory, org, type, platform, cruise\";\n"
            + "    String Conventions \"COARDS, WOCE, GTSPP, CF-1.6, ACDD-1.3\";\n"
            + "    String creator_email \"nodc.gtspp@noaa.gov\";\n"
            + "    String creator_name \"NOAA NESDIS NODC (IN295)\";\n"
            + "    String creator_url \"https://www.nodc.noaa.gov/GTSPP/\";\n"
            + "    String crs \"EPSG:4326\";\n"
            + "    String defaultGraphQuery \"longitude,latitude,station_id&time%3E=max(time)-7days&time%3C=max(time)&.draw=markers&.marker=10|5\";\n"
            + "    Float64 Easternmost_Easting 179.999;\n"
            + "    String featureType \"TrajectoryProfile\";\n"
            + "    String file_source \"The GTSPP Continuously Managed Data Base\";\n"
            + "    Float64 geospatial_lat_max 90.0;\n"
            + "    Float64 geospatial_lat_min -78.579;\n"
            + "    String geospatial_lat_units \"degrees_north\";\n"
            + "    Float64 geospatial_lon_max 179.999;\n"
            + "    Float64 geospatial_lon_min -180.0;\n"
            + "    String geospatial_lon_units \"degrees_east\";\n"
            + "    Float64 geospatial_vertical_max 9910.0;\n"
            + "    Float64 geospatial_vertical_min -0.4;\n"
            + "    String geospatial_vertical_positive \"down\";\n"
            + "    String geospatial_vertical_units \"m\";\n"
            + "    String gtspp_ConventionVersion \"GTSPP4.0\";\n"
            + "    String gtspp_handbook_version \"GTSPP Data User's Manual 1.0\";\n"
            + "    String gtspp_program \"writeGTSPPnc40.f90\";\n"
            + "    String gtspp_programVersion \"1.8\";\n"
            + "    String history \"2022-02-01 csun writeGTSPPnc40.f90 Version 1.8\n"
            + // date
            // changes
            ".tgz files from ftp.nodc.noaa.gov /pub/data.nodc/gtspp/bestcopy/netcdf (https://www.nodc.noaa.gov/GTSPP/)\n"
            + "2022-02-10 Most recent ingest, clean, and reformat at ERD (erd.data at noaa.gov).\n"; // date
    // changes

    po = results.indexOf("erd.data at noaa.gov).\n");
    Test.ensureTrue(po > 0, "\nresults=\n" + results);
    String tResults = results.substring(0, po + 23);
    // String2.log("tResults=" + tResults);
    Test.ensureEqual(tResults, expected, "\nresults=\n" + results);

    // + " (local files)\n" +
    // today + " http://localhost:8080/cwexperimental/
    expected =
        "    String id \"erdGtsppBest\";\n"
            + "    String infoUrl \"https://www.nodc.noaa.gov/GTSPP/\";\n"
            + "    String institution \"NOAA NODC\";\n"
            + "    String keywords \"cruise, data, density, depth, Earth Science > Oceans > Ocean Temperature > Water Temperature, Earth Science > Oceans > Salinity/Density > Salinity, global, gtspp, identifier, noaa, nodc, observation, ocean, oceans, organization, profile, program, salinity, sea, sea_water_practical_salinity, sea_water_temperature, seawater, station, temperature, temperature-salinity, time, type, water\";\n"
            + "    String keywords_vocabulary \"NODC Data Types, CF Standard Names, GCMD Science Keywords\";\n"
            + "    String LEXICON \"NODC_GTSPP\";\n"
            + // date below changes
            "    String license \"These data are openly available to the public.  Please acknowledge the use of these data with:\n"
            + "These data were acquired from the US NOAA National Oceanographic Data Center (NODC) on 2022-02-10 from https://www.nodc.noaa.gov/GTSPP/.\n"
            + "\n"
            + "The data may be used and redistributed for free but is not intended\n"
            + "for legal use, since it may contain inaccuracies. Neither the data\n"
            + "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + "of their employees or contractors, makes any warranty, express or\n"
            + "implied, including warranties of merchantability and fitness for a\n"
            + "particular purpose, or assumes any legal liability for the accuracy,\n"
            + "completeness, or usefulness, of this information.\";\n"
            + "    String naming_authority \"gov.noaa.nodc\";\n"
            + "    Float64 Northernmost_Northing 90.0;\n"
            + "    String project \"Joint IODE/JCOMM Global Temperature-Salinity Profile Programme\";\n"
            + "    String references \"https://www.nodc.noaa.gov/GTSPP/\";\n"
            + "    String sourceUrl \"(local files)\";\n"
            + "    Float64 Southernmost_Northing -78.579;\n"
            + "    String standard_name_vocabulary \"CF Standard Name Table v70\";\n"
            + "    String subsetVariables \"trajectory, org, type, platform, cruise\";\n"
            + "    String summary \"The Global Temperature-Salinity Profile Programme (GTSPP) develops and maintains a global ocean temperature and salinity resource with data that are both up-to-date and of the highest quality. It is a joint World Meteorological Organization (WMO) and Intergovernmental Oceanographic Commission (IOC) program.  It includes data from XBTs, CTDs, moored and drifting buoys, and PALACE floats. For information about organizations contributing data to GTSPP, see http://gosic.org/goos/GTSPP-data-flow.htm .  The U.S. National Oceanographic Data Center (NODC) maintains the GTSPP Continuously Managed Data Base and releases new 'best-copy' data once per month.\n"
            + "\n"
            + "WARNING: This dataset has a *lot* of data.  If you request too much data, your request will fail.\n"
            + "* If you don't specify a longitude and latitude bounding box, don't request more than a month's data at a time.\n"
            + "* If you do specify a longitude and latitude bounding box, you can request data for a proportionally longer time period.\n"
            + "Requesting data for a specific station_id may be slow, but it works.\n"
            + "\n"
            + "*** This ERDDAP dataset has data for the entire world for all available times (currently, "
            + "up to and including the January 2022 data) but is a subset of the "
            + // month changes
            "original NODC 'best-copy' data.  It only includes data where the quality flags indicate the data is 1=CORRECT, 2=PROBABLY GOOD, or 5=MODIFIED. It does not include some of the metadata, any of the history data, or any of the quality flag data of the original dataset. You can always get the complete, up-to-date dataset (and additional, near-real-time data) from the source: https://www.nodc.noaa.gov/GTSPP/ .  Specific differences are:\n"
            + "* Profiles with a position_quality_flag or a time_quality_flag other than 1|2|5 were removed.\n"
            + "* Rows with a depth (z) value less than -0.4 or greater than 10000 or a z_variable_quality_flag other than 1|2|5 were removed.\n"
            + "* Temperature values less than -4 or greater than 40 or with a temperature_quality_flag other than 1|2|5 were set to NaN.\n"
            + "* Salinity values less than 0 or greater than 41 or with a salinity_quality_flag other than 1|2|5 were set to NaN.\n"
            + "* Time values were converted from \\\"days since 1900-01-01 00:00:00\\\" to \\\"seconds since 1970-01-01T00:00:00\\\".\n"
            + "\n"
            + "See the Quality Flag definitions on page 5 and \\\"Table 2.1: Global Impossible Parameter Values\\\" on page 61 of\n"
            + "https://www.nodc.noaa.gov/GTSPP/document/qcmans/GTSPP_RT_QC_Manual_20090916.pdf .\n"
            + "The Quality Flag definitions are also at\n"
            + "https://www.nodc.noaa.gov/GTSPP/document/qcmans/qcflags.htm .\";\n"
            + "    String testOutOfDate \"now-45days\";\n"
            + "    String time_coverage_end \"2022-01-28T12:00:00Z\";\n"
            + // changes
            "    String time_coverage_start \"1985-02-15T00:00:00Z\";\n"
            + // was
            // 1985-03-31T13:15:00Z
            // before
            // 2020-07-12 the new
            // time is such a
            // round number!
            "    String title \"Global Temperature and Salinity Profile Programme (GTSPP) Data, 1985-present\";\n"
            + "    Float64 Westernmost_Easting -180.0;\n"
            + "  }\n"
            + "}\n";
    int tPo =
        results.indexOf(
            expected.substring(0, 14)); // not more than 14 because of regex special chars
    Test.ensureTrue(tPo >= 0, "tPo=-1 results=\n" + results);
    tResults = results.substring(tPo);
    Test.ensureEqual(tResults, expected, "\nresults=\n" + results);

    // *** .dds
    tName = tedd.makeNewFileForDapQuery(language, null, null, "", dir, "gtspp", ".dds");
    results = File2.directReadFrom88591File(dir + tName);
    expected =
        "Dataset {\n"
            + "  Sequence {\n"
            + "    String trajectory;\n"
            + "    String org;\n"
            + "    String type;\n"
            + "    String platform;\n"
            + "    String cruise;\n"
            + "    Int32 station_id;\n"
            + "    Float32 longitude;\n"
            + "    Float32 latitude;\n"
            + "    Float64 time;\n"
            + "    Float32 depth;\n"
            + "    Float32 temperature;\n"
            + "    Float32 salinity;\n"
            + "  } s;\n"
            + "} s;\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // station_id (slow for .nc, faster for .ncCF)
    tName =
        tedd.makeNewFileForDapQuery(
            language, null, null, "&station_id=1254666", dir, "gtspp1254666", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "trajectory,org,type,platform,cruise,station_id,longitude,latitude,time,depth,temperature,salinity\n"
            + ",,,,,,degrees_east,degrees_north,UTC,m,degree_C,PSU\n"
            + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,0.0,20.8,NaN\n"
            + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,50.0,20.7,NaN\n"
            + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,100.0,20.7,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // tests that should fail quickly
    String tests[] = {
      "&station_id<1",
      "&station_id=NaN",
      "&longitude<-180",
      "&longitude>180",
      "&longitude=NaN",
      "&latitude<-90",
      "&latitude>90",
      "&latitude=NaN",
      "&depth<-0.4",
      "&depth>10000",
      "&depth=NaN",
      "&time<1985-02-01",
      "&time>" + today,
      "&time=NaN",
      "&temperature<-4",
      "&temperature>40",
      "&salinity<0",
      "&salinity>41",
    };
    for (int test = 0; test < tests.length; test++) {
      try {
        String2.log("\n*** start testing " + tests[test]);
        error = "";
        results = "";
        long eTime = System.currentTimeMillis();
        tName =
            tedd.makeNewFileForDapQuery(
                language, null, null, tests[test], dir, "gtspp" + test, ".csv");
        String2.log(
            "\n*** finished testing "
                + tests[test]
                + " time="
                + (System.currentTimeMillis() - eTime)
                + "ms");
        results = File2.directReadFrom88591File(dir + tName);
      } catch (Throwable t) {
        error = MustBe.throwableToString(t);
      }
      Test.ensureEqual(results, "", "results=\n" + results);
      Test.ensureTrue(error.indexOf(MustBe.THERE_IS_NO_DATA) >= 0, "error=" + error);
    }

    // latitude = -78.579002 the minmin value as of 2014-07-21
    // should succeed quickly (except for println statements here)
    tName =
        tedd.makeNewFileForDapQuery(
            language, null, null, "&latitude=-78.579002", dir, "gtspp77", ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "trajectory,org,type,platform,cruise,station_id,longitude,latitude,time,depth,temperature,salinity\n"
            + ",,,,,,degrees_east,degrees_north,UTC,m,degree_C,PSU\n"
            + "ME_BA_49K6_JNZL 05,ME,BA,49K6,JNZL 05,2509050,-165.432,-78.579,2005-01-31T02:31:00Z,4.0,-0.9,NaN\n"
            + "ME_BA_49K6_JNZL 05,ME,BA,49K6,JNZL 05,2509050,-165.432,-78.579,2005-01-31T02:31:00Z,100.0,-0.9,NaN\n"
            + "ME_BA_49K6_JNZL 05,ME,BA,49K6,JNZL 05,2509050,-165.432,-78.579,2005-01-31T02:31:00Z,200.0,-1.9,NaN\n"
            + "ME_BA_49K6_JNZL 05,ME,BA,49K6,JNZL 05,2509050,-165.432,-78.579,2005-01-31T02:31:00Z,487.0,-1.9,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);

    // time range should succeed quickly (except for println statements here)
    // !!! sort order of nc (by time, station_id ?) vs ncCF (by time, lat, lon ?!)
    // is different
    long eTime = System.currentTimeMillis();
    tName =
        tedd.makeNewFileForDapQuery(
            language,
            null,
            null,
            "&time>2000-01-01T02:59:59Z&time<2000-01-01T03:00:01Z&orderBy(\"station_id,depth\")",
            dir,
            "gtsppLL",
            ".csv");
    results = File2.directReadFrom88591File(dir + tName);
    // String2.log(results);
    expected =
        "trajectory,org,type,platform,cruise,station_id,longitude,latitude,time,depth,temperature,salinity\n"
            + ",,,,,,degrees_east,degrees_north,UTC,m,degree_C,PSU\n"
            + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,0.0,20.8,NaN\n"
            + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,50.0,20.7,NaN\n"
            + "ME_BA_33TT_21004 00,ME,BA,33TT,21004 00,1254666,134.9833,28.9833,2000-01-01T03:00:00Z,100.0,20.7,NaN\n"
            + "ME_BA_33TT_21002 00,ME,BA,33TT,21002 00,1254689,134.5333,37.9,2000-01-01T03:00:00Z,0.0,14.7,NaN\n"
            + "ME_BA_33TT_21002 00,ME,BA,33TT,21002 00,1254689,134.5333,37.9,2000-01-01T03:00:00Z,50.0,14.8,NaN\n"
            + "ME_BA_33TT_21002 00,ME,BA,33TT,21002 00,1254689,134.5333,37.9,2000-01-01T03:00:00Z,100.0,14.7,NaN\n"
            + "ME_BA_33TT_22001 00,ME,BA,33TT,22001 00,1254716,126.3,28.1667,2000-01-01T03:00:00Z,0.0,22.3,NaN\n"
            + "ME_BA_33TT_22001 00,ME,BA,33TT,22001 00,1254716,126.3,28.1667,2000-01-01T03:00:00Z,50.0,21.3,NaN\n"
            + "ME_BA_33TT_22001 00,ME,BA,33TT,22001 00,1254716,126.3,28.1667,2000-01-01T03:00:00Z,100.0,19.8,NaN\n";
    Test.ensureEqual(results, expected, "\nresults=\n" + results);
    String2.log("time. elapsedTime=" + (System.currentTimeMillis() - eTime) + "ms");
    // String2.pressEnterToContinue();
  }

  @org.junit.jupiter.api.Test
  void testZarr() throws Throwable {

    EDD zarr = EDDTestDataset.gettestZarr_testData();
    int language = 0;

    // *** test getting das for entire dataset
    String2.log("\n*** .nc test das dds for entire dataset\n");
    String tName =
        zarr.makeNewFileForDapQuery(
            language,
            null,
            null,
            "",
            EDStatic.fullTestCacheDirectory,
            zarr.className() + "_testData",
            ".das");
    String results = File2.directReadFrom88591File(EDStatic.fullTestCacheDirectory + tName);
    String expected =
        "Attributes {\n"
            + //
            " s {\n"
            + //
            "  dim0 {\n"
            + //
            "    Byte _FillValue 127;\n"
            + //
            "    String _Unsigned \"false\";\n"
            + //
            (results.indexOf("Byte actual_range 0, 19;") != -1
                ? "    Byte actual_range 0, 19;\n"
                : "")
            + "    String ioos_category \"Unknown\";\n"
            + //
            "    String long_name \"Dim0\";\n"
            + //
            "  }\n"
            + //
            "  dim1 {\n"
            + //
            "    Byte _FillValue 127;\n"
            + //
            "    String _Unsigned \"false\";\n"
            + (results.indexOf("Byte actual_range 0, 19;") != -1
                ? "    Byte actual_range 0, 19;\n"
                : "")
            + "    String ioos_category \"Unknown\";\n"
            + //
            "    String long_name \"Dim1\";\n"
            + //
            "  }\n"
            + //
            "  dim2 {\n"
            + //
            "    Byte _FillValue 127;\n"
            + //
            "    String _Unsigned \"false\";\n"
            + (results.indexOf("Byte actual_range 0, 19;") != -1
                ? "    Byte actual_range 0, 19;\n"
                : "")
            + "    String ioos_category \"Unknown\";\n"
            + //
            "    String long_name \"Dim2\";\n"
            + //
            "  }\n"
            + //
            "  dim3 {\n"
            + //
            "    Byte _FillValue 127;\n"
            + //
            "    String _Unsigned \"false\";\n"
            + (results.indexOf("Byte actual_range 0, 19;") != -1
                ? "    Byte actual_range 0, 19;\n"
                : "")
            + "    String ioos_category \"Unknown\";\n"
            + //
            "    String long_name \"Dim3\";\n"
            + //
            "  }\n"
            + //
            "  group_with_dims_var4D {\n"
            + //
            "    Int32 _FillValue 2147483647;\n"
            + (results.indexOf("Int32 actual_range 0, 19;") != -1
                ? "    Int32 actual_range 0, 19;\n"
                : "")
            + "    String ioos_category \"Unknown\";\n"
            + //
            "    String long_name \"Group With Dims/var4 D\";\n"
            + //
            "  }\n"
            + //
            " }\n"
            + //
            "  NC_GLOBAL {\n"
            + //
            "    String cdm_data_type \"Other\";\n"
            + //
            "    String Conventions \"COARDS, CF-1.10, ACDD-1.3\";\n"
            + //
            "    String history \"YYYY-MM-DDThh:mm:ssZ (local files)\n"
            + //
            "YYYY-MM-DDThh:mm:ssZ http://localhost:8080/erddap/tabledap/zarr_testData.das\";\n"
            + //
            "    String infoUrl \"???\";\n"
            + //
            "    String institution \"???\";\n"
            + //
            "    String keywords \"data, dim0, dim1, dim2, dim3, dims, dims/var4, group, group_with_dims_var4D, local, source, var4, with\";\n"
            + //
            "    String license \"The data may be used and redistributed for free but is not intended\n"
            + //
            "for legal use, since it may contain inaccuracies. Neither the data\n"
            + //
            "Contributor, ERD, NOAA, nor the United States Government, nor any\n"
            + //
            "of their employees or contractors, makes any warranty, express or\n"
            + //
            "implied, including warranties of merchantability and fitness for a\n"
            + //
            "particular purpose, or assumes any legal liability for the accuracy,\n"
            + //
            "completeness, or usefulness, of this information.\";\n"
            + //
            "    String sourceUrl \"(local files)\";\n"
            + //
            "    String standard_name_vocabulary \"CF Standard Name Table v70\";\n"
            + //
            "    String summary \"Data from a local source.\";\n"
            + //
            "    String title \"Data from a local source.\";\n"
            + //
            "  }\n"
            + //
            "}\n";
    results = results.replaceAll("....-..-..T..:..:..Z", "YYYY-MM-DDThh:mm:ssZ");
    Test.ensureEqual(results, expected, "results=\n" + results);

    tName =
        zarr.makeNewFileForDapQuery(
            language,
            null,
            null,
            "dim0,dim1,dim2,dim3,group_with_dims_var4D&dim0%3E=0&dim0%3C=0&dim3%3E=4&dim3%3C=6&dim2%3E=9&dim2%3C=10",
            EDStatic.fullTestCacheDirectory,
            zarr.className(),
            ".csv");
    results = File2.directReadFrom88591File(EDStatic.fullTestCacheDirectory + tName);
    expected =
        "dim0,dim1,dim2,dim3,group_with_dims_var4D\n"
            + //
            ",,,,\n"
            + //
            "0,0,9,4,4\n"
            + //
            "0,0,9,5,5\n"
            + //
            "0,0,9,6,6\n"
            + //
            "0,0,10,4,4\n"
            + //
            "0,0,10,5,5\n"
            + //
            "0,0,10,6,6\n"
            + //
            "0,1,9,4,4\n"
            + //
            "0,1,9,5,5\n"
            + //
            "0,1,9,6,6\n"
            + //
            "0,1,10,4,4\n"
            + //
            "0,1,10,5,5\n"
            + //
            "0,1,10,6,6\n"
            + //
            "0,2,9,4,4\n"
            + //
            "0,2,9,5,5\n"
            + //
            "0,2,9,6,6\n"
            + //
            "0,2,10,4,4\n"
            + //
            "0,2,10,5,5\n"
            + //
            "0,2,10,6,6\n"
            + //
            "0,3,9,4,4\n"
            + //
            "0,3,9,5,5\n"
            + //
            "0,3,9,6,6\n"
            + //
            "0,3,10,4,4\n"
            + //
            "0,3,10,5,5\n"
            + //
            "0,3,10,6,6\n"
            + //
            "0,4,9,4,4\n"
            + //
            "0,4,9,5,5\n"
            + //
            "0,4,9,6,6\n"
            + //
            "0,4,10,4,4\n"
            + //
            "0,4,10,5,5\n"
            + //
            "0,4,10,6,6\n"
            + //
            "0,5,9,4,4\n"
            + //
            "0,5,9,5,5\n"
            + //
            "0,5,9,6,6\n"
            + //
            "0,5,10,4,4\n"
            + //
            "0,5,10,5,5\n"
            + //
            "0,5,10,6,6\n"
            + //
            "0,6,9,4,4\n"
            + //
            "0,6,9,5,5\n"
            + //
            "0,6,9,6,6\n"
            + //
            "0,6,10,4,4\n"
            + //
            "0,6,10,5,5\n"
            + //
            "0,6,10,6,6\n"
            + //
            "0,7,9,4,4\n"
            + //
            "0,7,9,5,5\n"
            + //
            "0,7,9,6,6\n"
            + //
            "0,7,10,4,4\n"
            + //
            "0,7,10,5,5\n"
            + //
            "0,7,10,6,6\n"
            + //
            "0,8,9,4,4\n"
            + //
            "0,8,9,5,5\n"
            + //
            "0,8,9,6,6\n"
            + //
            "0,8,10,4,4\n"
            + //
            "0,8,10,5,5\n"
            + //
            "0,8,10,6,6\n"
            + //
            "0,9,9,4,4\n"
            + //
            "0,9,9,5,5\n"
            + //
            "0,9,9,6,6\n"
            + //
            "0,9,10,4,4\n"
            + //
            "0,9,10,5,5\n"
            + //
            "0,9,10,6,6\n"
            + //
            "0,10,9,4,4\n"
            + //
            "0,10,9,5,5\n"
            + //
            "0,10,9,6,6\n"
            + //
            "0,10,10,4,4\n"
            + //
            "0,10,10,5,5\n"
            + //
            "0,10,10,6,6\n"
            + //
            "0,11,9,4,4\n"
            + //
            "0,11,9,5,5\n"
            + //
            "0,11,9,6,6\n"
            + //
            "0,11,10,4,4\n"
            + //
            "0,11,10,5,5\n"
            + //
            "0,11,10,6,6\n"
            + //
            "0,12,9,4,4\n"
            + //
            "0,12,9,5,5\n"
            + //
            "0,12,9,6,6\n"
            + //
            "0,12,10,4,4\n"
            + //
            "0,12,10,5,5\n"
            + //
            "0,12,10,6,6\n"
            + //
            "0,13,9,4,4\n"
            + //
            "0,13,9,5,5\n"
            + //
            "0,13,9,6,6\n"
            + //
            "0,13,10,4,4\n"
            + //
            "0,13,10,5,5\n"
            + //
            "0,13,10,6,6\n"
            + //
            "0,14,9,4,4\n"
            + //
            "0,14,9,5,5\n"
            + //
            "0,14,9,6,6\n"
            + //
            "0,14,10,4,4\n"
            + //
            "0,14,10,5,5\n"
            + //
            "0,14,10,6,6\n"
            + //
            "0,15,9,4,4\n"
            + //
            "0,15,9,5,5\n"
            + //
            "0,15,9,6,6\n"
            + //
            "0,15,10,4,4\n"
            + //
            "0,15,10,5,5\n"
            + //
            "0,15,10,6,6\n"
            + //
            "0,16,9,4,4\n"
            + //
            "0,16,9,5,5\n"
            + //
            "0,16,9,6,6\n"
            + //
            "0,16,10,4,4\n"
            + //
            "0,16,10,5,5\n"
            + //
            "0,16,10,6,6\n"
            + //
            "0,17,9,4,4\n"
            + //
            "0,17,9,5,5\n"
            + //
            "0,17,9,6,6\n"
            + //
            "0,17,10,4,4\n"
            + //
            "0,17,10,5,5\n"
            + //
            "0,17,10,6,6\n"
            + //
            "0,18,9,4,4\n"
            + //
            "0,18,9,5,5\n"
            + //
            "0,18,9,6,6\n"
            + //
            "0,18,10,4,4\n"
            + //
            "0,18,10,5,5\n"
            + //
            "0,18,10,6,6\n"
            + //
            "0,19,9,4,4\n"
            + //
            "0,19,9,5,5\n"
            + //
            "0,19,9,6,6\n"
            + //
            "0,19,10,4,4\n"
            + //
            "0,19,10,5,5\n"
            + //
            "0,19,10,6,6\n";
    Test.ensureEqual(results, expected, "results=\n" + results);
  }

  /**
   * One time: make c:/u00/data/points/nc2d and String2.testU00Dir/u00/data/points/nc3d test files
   * from c:/u00/data/points/ndbcMet nc4d files.
   */
  public static void makeTestFiles() {
    // get list of files
    String fromDir = "c:/u00/data/points/ndbcMet/";
    String dir3 = "c:/u00/data/points/nc3d/";
    String dir2 = "c:/u00/data/points/nc2d/";
    String[] names = RegexFilenameFilter.list(fromDir, "NDBC_(3|4).*nc");

    // for each file
    for (int f = 0; f < names.length; f++) {
      NetcdfFile in = null;
      NetcdfFormatWriter ncWriter2 = null;
      NetcdfFormatWriter ncWriter3 = null;

      try {
        NetcdfFormatWriter.Builder out2 = null;
        NetcdfFormatWriter.Builder out3 = null;

        String2.log("in #" + f + "=" + fromDir + names[f]);
        if (f == 0) String2.log(NcHelper.ncdump(fromDir + names[f], "-h"));

        in = NcHelper.openFile(fromDir + names[f]);
        out2 = NetcdfFormatWriter.createNewNetcdf3(dir2 + names[f]);
        out3 = NetcdfFormatWriter.createNewNetcdf3(dir3 + names[f]);
        boolean nc3Mode = true;
        Group.Builder rootGroup2 = out2.getRootGroup();
        Group.Builder rootGroup3 = out3.getRootGroup();
        out2.setFill(false);
        out3.setFill(false);

        // write the globalAttributes
        Attributes atts = new Attributes();
        NcHelper.getGroupAttributes(in.getRootGroup(), atts);
        NcHelper.setAttributes(nc3Mode, rootGroup2, atts);
        NcHelper.setAttributes(nc3Mode, rootGroup3, atts);

        Variable vars[] = NcHelper.find4DVariables(in, null);
        Variable timeVar = in.findVariable("TIME");
        Variable latVar = in.findVariable("LAT");
        Variable lonVar = in.findVariable("LON");
        Math2.ensureArraySizeOkay(timeVar.getSize(), "EDDTableFromNcFiles.makeTestFiles");
        Dimension tDim2 =
            NcHelper.addDimension(rootGroup2, "TIME", (int) timeVar.getSize()); // safe
        // since
        // checked
        // above
        Dimension tDim3 =
            NcHelper.addDimension(rootGroup3, "TIME", (int) timeVar.getSize()); // safe
        // since
        // checked
        // above
        Dimension yDim2 = NcHelper.addDimension(rootGroup2, "LAT", 1);
        Dimension yDim3 = NcHelper.addDimension(rootGroup3, "LAT", 1);
        Dimension xDim3 = NcHelper.addDimension(rootGroup3, "LON", 1);

        // create axis variables
        Variable.Builder timeVar2 =
            NcHelper.addVariable(rootGroup2, "TIME", timeVar.getDataType(), Arrays.asList(tDim2));
        Variable.Builder latVar2 =
            NcHelper.addVariable(rootGroup2, "LAT", latVar.getDataType(), Arrays.asList(yDim2));

        Variable.Builder timeVar3 =
            NcHelper.addVariable(rootGroup3, "TIME", timeVar.getDataType(), Arrays.asList(tDim3));
        Variable.Builder latVar3 =
            NcHelper.addVariable(rootGroup3, "LAT", latVar.getDataType(), Arrays.asList(yDim3));
        Variable.Builder lonVar3 =
            NcHelper.addVariable(rootGroup3, "LON", lonVar.getDataType(), Arrays.asList(xDim3));

        // write the axis variable attributes
        atts.clear();
        NcHelper.getVariableAttributes(timeVar, atts);
        NcHelper.setAttributes(nc3Mode, timeVar2, atts, NcHelper.isUnsigned(timeVar.getDataType()));
        NcHelper.setAttributes(nc3Mode, timeVar3, atts, NcHelper.isUnsigned(timeVar.getDataType()));

        atts.clear();
        NcHelper.getVariableAttributes(latVar, atts);
        NcHelper.setAttributes(nc3Mode, latVar2, atts, NcHelper.isUnsigned(latVar.getDataType()));
        NcHelper.setAttributes(nc3Mode, latVar3, atts, NcHelper.isUnsigned(latVar.getDataType()));

        atts.clear();
        NcHelper.getVariableAttributes(lonVar, atts);
        NcHelper.setAttributes(nc3Mode, lonVar3, atts, NcHelper.isUnsigned(lonVar.getDataType()));

        // create data variables
        Variable.Builder newVars2[] = new Variable.Builder[vars.length];
        Variable.Builder newVars3[] = new Variable.Builder[vars.length];
        for (int col = 0; col < vars.length; col++) {
          // create the data variables
          Variable var = vars[col];
          String varName = var.getFullName();
          Array ar = var.read();
          DataType dataType = var.getDataType();
          newVars2[col] =
              NcHelper.addVariable(rootGroup2, varName, dataType, Arrays.asList(tDim2, yDim2));
          newVars3[col] =
              NcHelper.addVariable(
                  rootGroup3, varName, dataType, Arrays.asList(tDim3, yDim3, xDim3));

          // write the data variable attributes
          atts.clear();
          NcHelper.getVariableAttributes(var, atts);
          NcHelper.setAttributes(nc3Mode, newVars2[col], atts, NcHelper.isUnsigned(dataType));
          NcHelper.setAttributes(nc3Mode, newVars3[col], atts, NcHelper.isUnsigned(dataType));
        }

        // leave "define" mode
        ncWriter2 = out2.build();
        ncWriter3 = out3.build();

        // write axis data
        Array ar = in.findVariable("TIME").read();
        ncWriter2.write(timeVar2.getFullName(), ar);
        ncWriter3.write(timeVar3.getFullName(), ar);
        ar = in.findVariable("LAT").read();
        ncWriter2.write(latVar2.getFullName(), ar);
        ncWriter3.write(latVar3.getFullName(), ar);
        ar = in.findVariable("LON").read();
        ncWriter3.write(lonVar3.getFullName(), ar);

        for (int col = 0; col < vars.length; col++) {
          // write the data for each var
          Variable var = vars[col];
          String varName = var.getFullName();
          ar = var.read();
          int oldShape[] = ar.getShape();
          int newShape2[] = {oldShape[0], 1};
          int newShape3[] = {oldShape[0], 1, 1};
          ncWriter2.write(newVars2[col].getFullName(), ar.reshape(newShape2));
          ncWriter3.write(newVars3[col].getFullName(), ar.reshape(newShape3));
        }

        in.close();
        ncWriter2.close();
        ncWriter3.close();

        if (f == 0) {
          String2.log("\nout2=" + NcHelper.ncdump(dir2 + names[f], "-h"));
          String2.log("\nout3=" + NcHelper.ncdump(dir3 + names[f], "-h"));
        }

      } catch (Throwable t) {
        String2.log(MustBe.throwableToString(t));
        try {
          if (in != null) in.close();
        } catch (Exception t2) {
        }
        if (ncWriter2 != null) {
          try {
            ncWriter2.abort();
          } catch (Exception t2) {
          }
          File2.delete(dir2 + names[f]);
          ncWriter2 = null;
        }
        if (ncWriter3 != null) {
          try {
            ncWriter3.abort();
          } catch (Exception t2) {
          }
          File2.delete(dir3 + names[f]);
          ncWriter3 = null;
        }
      }
    }
  }

  /** NOT FOR GENERAL USE. Bob used this to generate the GTSPP datasets.xml content. */
  public static void bobGenerateGtsppDatasetsXml() throws Throwable {
    String2.log(
        EDDTableFromNcFiles.generateDatasetsXml(
            "c:/data/gtspp/bestNcConsolidated/",
            ".*\\.nc",
            "c:/data/gtspp/bestNcConsolidated/2010/01/2010-01_0E_-60N.nc.nc",
            "",
            EDDTableFromNcFiles.DEFAULT_RELOAD_EVERY_N_MINUTES,
            "",
            "\\.nc",
            ".*", // tPreExtractRegex, tPostExtractRegex, tExtractRegex
            "station_id",
            "depth", // tColumnNameForExtract, tSortedColumnSourceName
            "time, station_id", // tSortFilesBySourceNames
            "https://www.nodc.noaa.gov/GTSPP/",
            "NOAA NODC", // tInfoUrl, tInstitution
            "put the summary here", // summary
            "Global Temperature-Salinity Profile Program", // tTitle
            -1,
            null, // defaultStandardizeWhat
            new Attributes())); // externalAddGlobalAttributes)
  }

  /**
   * NOT FOR GENERAL USE. Bob uses this to consolidate the individual GTSPP data files into 30 x
   * 30 x 1 month files (tiles). 30 x 30 leads to 12x6=72 files for a given time point, so a
   * request for a short time but entire world opens ~72 files. There are ~240 months worth of data,
   * so a request for a small lon lat range for all time opens ~240 files.
   *
   * <p>Why tile? Because there are ~10^6 profiles/year now, so ~10^7 total. And if 100 bytes of
   * info per file for EDDTableFromFiles fileTable, that's 1 GB!. So there needs to be fewer files.
   * We want to balance number of files for 1 time point (all region tiles), and number of time
   * point files (I'll stick with their use of 1 month). The tiling size selected is ok, but
   * searches for single profile (by name) are slow since a given file may have a wide range of
   * station_ids.
   *
   * <p>Quality flags <br>
   * https://www.nodc.noaa.gov/GTSPP/document/qcmans/GTSPP_RT_QC_Manual_20090916.pdf <br>
   * http://www.ifremer.fr/gosud/formats/gtspp_qcflags.htm <br>
   * CODE SIGNIFICATION <br>
   * 0 NOT CONTROLLED VALUE <br>
   * 1 CORRECT VALUE <br>
   * 2 VALUE INCONSISTENT WITH STATISTICS <br>
   * 3 DOUBTFUL VALUE (spike, ...) <br>
   * 4 FALSE VALUE (out of scale, constant profile, vertical instability, ...) <br>
   * 5 VALUE MODIFIED DURING QC (only for interpolate location or date) <br>
   * 6-8 Not USED <br>
   * 9 NO VALUE <br>
   * <br>
   * I interpret as: okay values are 1, 2, 5
   *
   * @param firstYear e.g., 1990
   * @param firstMonth e.g., 1 (1..)
   * @param lastYear e.g., 2010
   * @param lastMonth e.g., 12 (1..)
   * @param testMode if true, this just processes .nc files already in testTempDir
   *     f:/data/gtspp/testTemp/ and puts results in testDestDir f:/data/gtspp/testDest/. So the
   *     first/last/Year/Month params are ignored.
   */
  public static void bobConsolidateGtsppTgz(
      int firstYear, int firstMonth, int lastYear, int lastMonth, boolean testMode)
      throws Throwable {

    int chunkSize = 45; // lon width, lat height of a tile, in degrees
    int minLat = -90;
    int maxLat = 90;
    int minLon = -180;
    int maxLon = 180;
    String today = Calendar2.getCurrentISODateTimeStringZulu().substring(0, 10); // to nearest day
    String sevenZip = "c:\\progra~1\\7-Zip\\7z";
    String zipDir = "c:\\data\\gtspp\\bestNcZip\\"; // gtspp_at199001.tgz
    String destDir = "c:\\data\\gtspp\\bestNcConsolidated\\";
    String hardTempDir = "c:\\data\\gtspp\\temp\\"; // on hard drive
    String tempDir = "R:\\Temp\\"; // 100MB ram disk: to control it, run: c:/Program
    // Files/ImDisk/RamdiskUI.exe
    String testTempDir = "c:\\data\\gtspp\\testTemp\\"; // tempDir if testMode=true
    String testDestDir = "c:\\data\\gtspp\\testDest\\"; // destDir if testMode=true
    String logFile = "c:\\data\\gtspp\\log" + String2.replaceAll(today, "-", "") + ".txt";
    File2.deleteAllFiles(hardTempDir);
    File2.deleteAllFiles(tempDir);
    File2.makeDirectory(hardTempDir);
    File2.makeDirectory(tempDir);
    // https://www.nodc.noaa.gov/GTSPP/document/qcmans/qcflags.htm
    // 1=correct, 2=probably correct, 5=modified (so now correct)
    // pre 2012-04-15 was {1,2,5}
    // pre 2012-05-25 was {1,2}
    int okQF[] = {1, 2, 5};
    String okQFCsv = String2.toCSSVString(okQF);
    float depthMV = 99999; // was -99;
    float depthFV = 99999; // was -99;
    float temperatureMV = 99999; // was -99;
    float temperatureFV = 99999; // was -99;
    float salinityMV = 99999; // was -99;
    float salinityFV = 99999; // was -99;
    int qMV = 9;
    String timeUnits = "days since 1900-01-01 00:00:00"; // causes roundoff error(!)
    double timeBaseAndFactor[] = Calendar2.getTimeBaseAndFactor(timeUnits);
    // impossible values:
    float minDepth = -0.4f, maxDepth = 10000; // -0.4 allows for imprecise values
    float minTemperature = -4, maxTemperature = 40;
    float minSalinity = 0, maxSalinity = 41;

    if (testMode) {
      firstYear = 1990;
      firstMonth = 1;
      lastYear = 1990;
      lastMonth = 1;
    }

    SSR.verbose = false;

    String2.setupLog(true, false, logFile, false, 1000000000);
    String2.log(
        "*** starting bobConsolidateGtsppTgz "
            + Calendar2.getCurrentISODateTimeStringLocalTZ()
            + "\n"
            + "logFile="
            + String2.logFileName()
            + "\n"
            + String2.standardHelpAboutMessage());
    long elapsedTime = System.currentTimeMillis();
    // q_pos (position quality flag), q_date_time (time quality flag)
    int stationCol = -1,
        organizationCol = -1,
        dataTypeCol = -1,
        platformCol = -1,
        cruiseCol = -1,
        longitudeCol = -1,
        latitudeCol = -1,
        timeCol = -1,
        depthCol = -1,
        temperatureCol = -1,
        salinityCol = -1;
    int totalNGoodStation = 0,
        totalNGoodPos = 0,
        totalNGoodTime = 0,
        totalNGoodDepth = 0,
        totalNGoodTemperature = 0,
        totalNGoodSalinity = 0;
    int totalNBadStation = 0,
        totalNBadPos = 0,
        totalNBadTime = 0,
        totalNBadDepth = 0,
        totalNBadTemperature = 0,
        totalNBadSalinity = 0,
        totalNWarnings = 0,
        totalNExceptions = 0;
    long totalNGoodRows = 0, totalNBadRows = 0;
    StringArray impossibleNanLat = new StringArray();
    StringArray impossibleMinLat = new StringArray();
    StringArray impossibleMaxLat = new StringArray();
    StringArray impossibleNanLon = new StringArray();
    StringArray impossibleMinLon = new StringArray();
    StringArray impossibleMaxLon = new StringArray();
    // StringArray impossibleNaNDepth = new StringArray();
    StringArray impossibleMinDepth = new StringArray();
    StringArray impossibleMaxDepth = new StringArray();
    // StringArray impossibleNanTemperature = new StringArray();
    StringArray impossibleMinTemperature = new StringArray();
    StringArray impossibleMaxTemperature = new StringArray();
    // StringArray impossibleNanSalinity = new StringArray();
    StringArray impossibleMinSalinity = new StringArray();
    StringArray impossibleMaxSalinity = new StringArray();
    int nLons = 0, nLats = 0, nFiles = 0;
    int lonSum = 0, latSum = 0;
    long profilesSum = 0;
    long rowsSum = 0;

    // *** process a month's data
    int year = firstYear;
    int month = firstMonth;
    long chunkTime = System.currentTimeMillis();
    StringBuilder errors = new StringBuilder();
    while (year <= lastYear) {
      String2.log(
          "\n*** "
              + Calendar2.getCurrentISODateTimeStringLocalTZ()
              + " start processing year="
              + year
              + " month="
              + month);

      String zMonth = String2.zeroPad("" + month, 2);
      String zMonth1 = String2.zeroPad("" + (month + 1), 2);
      double minEpochSeconds = Calendar2.isoStringToEpochSeconds(year + "-" + zMonth + "-01");
      double maxEpochSeconds = Calendar2.isoStringToEpochSeconds(year + "-" + zMonth1 + "-01");

      // destination directory
      String tDestDir = testMode ? testDestDir : destDir + year + "\\" + zMonth + "\\";
      File2.makeDirectory(tDestDir);
      HashMap tableHashMap = new HashMap();
      // make sure all files are deleted
      int waitSeconds = 2;
      int nAttempts = 10;
      long cmdTime = System.currentTimeMillis();
      String cmd = "del/q " + tDestDir + "*.*";
      for (int attempt = 0; attempt < nAttempts; attempt++) {
        if (attempt % 8 == 0) {
          String2.log(cmd);
          SSR.dosShell(cmd, 30 * 60); // 10 minutes*60 seconds
          // File2.deleteAllFiles(tempDir); //previous method
        }
        Math2.gc("bobConsolidateGtsppTgz (between attempts)", waitSeconds * 1000); // gtspp:
        // give OS
        // time to
        // settle
        File destDirFile = new File(tDestDir);
        File files[] = destDirFile.listFiles();
        String2.log("  nRemainingFiles=" + files.length);
        if (files.length == 0) break;
        waitSeconds = 2 * nAttempts;
      }
      String2.log(
          "  cmd total time=" + Calendar2.elapsedTimeString(System.currentTimeMillis() - cmdTime));

      // unzip all atlantic, indian, and pacific .zip files for that month
      String region2[] = {"at", "in", "pa"};
      int nRegions = testMode ? 1 : 3;
      for (int region = 0; region < nRegions; region++) {

        String sourceBaseName = "gtspp4_" + region2[region] + year + zMonth;
        String sourceTgzJustFileName = sourceBaseName + ".tgz";
        String sourceTgzName = zipDir + sourceTgzJustFileName;
        String sourceTarName = hardTempDir + sourceBaseName + ".tar";

        try {

          // un-gz file into hardTempDir
          cmd = sevenZip + " -y e " + sourceTgzName + " -o" + hardTempDir + " -r";
          cmdTime = System.currentTimeMillis();
          String2.log("\n*** " + cmd);
          if (!File2.isFile(sourceTgzName)) {
            String msg = String2.ERROR + " no sourceTgzName=" + sourceTgzName + "\n";
            String2.log(msg);
            errors.append(msg);
            continue;

            /*
             * no source data for lots of early months + regions:
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198603.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198603.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198603.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198604.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198604.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198604.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198605.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198605.tgz
             * data!
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198606.tgz
             * data!
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198607.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198607.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198608.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198608.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198609.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198609.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198610.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198610.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198610.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198611.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198611.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198611.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198612.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198612.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198612.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198701.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198701.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198702.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198702.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198702.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198703.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198704.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198704.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198704.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198705.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198705.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198705.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198706.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198706.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198706.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198707.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198707.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198707.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198708.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198708.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198708.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198709.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198709.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198710.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198710.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198710.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198711.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198712.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198712.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198712.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198801.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198801.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198801.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198802.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198802.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198802.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198803.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198803.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198803.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198804.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198804.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198804.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198805.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198805.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198805.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198806.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198806.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198806.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198807.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198807.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198807.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198808.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198808.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198808.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198809.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198809.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198809.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198810.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198810.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198810.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198811.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198811.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198811.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198812.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198812.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198812.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198901.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198901.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198901.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198902.tgz
             * data!
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198903.tgz
             * data!
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198904.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198904.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198904.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198905.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198905.tgz
             * data!
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198906.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198906.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198906.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198907.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198907.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198907.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198908.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198908.tgz
             * data!
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198909.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198909.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198910.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198910.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198910.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198911.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198911.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198911.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_at198912.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_in198912.tgz
             * ERROR no sourceTgzName=c:\data\gtspp\bestNcZip\gtspp4_pa198912.tgz
             */
          }

          SSR.dosShell(cmd, 30 * 60); // 10 minutes*60 seconds
          String2.log(
              "  cmd time=" + Calendar2.elapsedTimeString(System.currentTimeMillis() - cmdTime));

          // previous method
          // SSR.unzip(sourceTgzName,
          // tempDir, true, 100 * 60, null); //ignoreZipDirectories, timeOutSeconds 100
          // minutes

          // read each file from .tar to tempDir and put data in proper table
          String tTempDir = testMode ? testTempDir : tempDir;
          int nSourceFileNames = 0;
          int nGoodStation = 0,
              nGoodPos = 0,
              nGoodTime = 0,
              nGoodDepth = 0,
              nGoodTemperature = 0,
              nGoodSalinity = 0,
              nGoodRows = 0;
          int nBadStation = 0,
              nBadPos = 0,
              nBadTime = 0,
              nBadDepth = 0,
              nBadTemperature = 0,
              nBadSalinity = 0,
              nBadRows = 0,
              nWarnings = 0,
              nExceptions = 0;
          long fileReadTime = System.currentTimeMillis();
          profilesSum += nSourceFileNames;

          // delete all tTempDir files
          File2.deleteAllFiles(tTempDir);

          // open tar
          TarArchiveInputStream tarIS =
              new TarArchiveInputStream(File2.getBufferedInputStream(sourceTarName)); // not
          // File2.getDecompressedBufferedInputStream().
          // Read file as
          // is.
          TarArchiveEntry entry = null;
          try {
            while ((entry = tarIS.getNextTarEntry()) != null) {
              if (entry.isDirectory()) {
                String2.log("  skipping dir=" + entry.getName());
                continue;
              }

              // save file to r:
              nSourceFileNames++;
              String sourceFileName = File2.getNameAndExtension(entry.getName());
              // String2.log(nSourceFileNames + " creating " + tTempDir +
              // sourceFileName);
              BufferedOutputStream bos =
                  new BufferedOutputStream(new FileOutputStream(tTempDir + sourceFileName));
              try {
                if (!File2.copy(tarIS, bos)) {
                  String2.log("  ERROR: failed to create " + tTempDir + sourceFileName);
                  continue;
                }
                bos.close();
                bos = null;
              } catch (Exception e) {
                try {
                  bos.close();
                } catch (Exception e2) {
                }
                File2.delete(tTempDir + sourceFileName);
              }
              // String2.pressEnterToContinue("created " + tTempDir +
              // sourceFileName);

              if (nSourceFileNames % 10000 == 0) {
                // if (sfi > 0) //2012-12-13 commented out. Let Java
                // handle it.
                // Math2.gc(3 * 1000); //gtspp: give OS time to settle
                // high water mark is ~160 MB, so memory not a problem
                String2.log("file #" + nSourceFileNames + " " + Math2.memoryString());
              }

              if (!sourceFileName.endsWith(".nc")) {
                String2.log("ERROR: not a .nc file: " + sourceFileName);
                continue;
              }

              NetcdfFile ncFile = null;

              try {
                // get the station name
                // gtspp_13635162_te_111.nc gtspp_10313692_cu_111.nc
                if (!sourceFileName.matches("gtspp_[0-9]+_.*\\.nc")) { // was
                  // "\\d+"))
                  // {//all
                  // digits
                  nBadStation++;
                  throw new SimpleException("Invalid sourceFileName=" + sourceFileName);
                }
                int po = sourceFileName.indexOf('_', 6);
                if (po < 0) {
                  nBadStation++;
                  throw new SimpleException("Invalid sourceFileName=" + sourceFileName);
                }
                int station = String2.parseInt(sourceFileName.substring(6, po));
                nGoodStation++;
                String key = sourceTgzJustFileName + " " + sourceFileName;

                // open the file
                ncFile = NcHelper.openFile(tTempDir + sourceFileName);
                Variable var;
                Attributes tVarAtts = new Attributes();
                String tUnits;

                // get all of the data

                // stream_ident
                var = ncFile.findVariable("stream_ident");
                String organization = "";
                String dataType = "";
                if (var == null) {
                  nWarnings++;
                  String2.log("WARNING: No stream_ident in " + sourceFileName);
                } else {
                  PrimitiveArray streamPA = NcHelper.getPrimitiveArray(var);
                  if (streamPA instanceof StringArray && streamPA.size() > 0) {
                    String stream = streamPA.getString(0);
                    if (stream.length() >= 4) {
                      organization = stream.substring(0, 2).trim();
                      dataType = stream.substring(2, 4).trim();
                    } else {
                      String2.log("WARNING: stream_ident isn't a 4 char string: " + stream);
                    }
                  } else {
                    String2.log(
                        "WARNING: stream_ident isn't a StringArray: " + streamPA.toString());
                  }
                }

                // platform_code
                var = ncFile.findVariable("gtspp_platform_code");
                String platform = "";
                if (var == null) {
                  // a small percentage have this problem
                  // nWarnings++;
                  // String2.log("WARNING: No gtspp_platform_code
                  // in " + sourceFileName);
                } else {
                  PrimitiveArray pa = NcHelper.getPrimitiveArray(var);
                  if (pa instanceof StringArray && pa.size() > 0) {
                    platform = pa.getString(0).trim();
                    // String2.log("platform_code=" +
                    // platform_code);
                  } else {
                    String2.log(
                        "WARNING: gtspp_platform_code isn't a StringArray: " + pa.toString());
                  }
                }

                // cruise
                var = ncFile.findVariable("cruise_id");
                String cruise = "";
                if (var == null) {
                  nWarnings++;
                  String2.log("WARNING: No cruise_id in " + sourceFileName);
                } else {
                  PrimitiveArray cruisePA = NcHelper.getPrimitiveArray(var);
                  if (cruisePA instanceof StringArray && cruisePA.size() > 0) {
                    cruise = cruisePA.getString(0).trim();
                  } else {
                    String2.log("WARNING: cruise_id isn't a StringArray: " + cruisePA.toString());
                  }
                }

                // prof_type is TEMP or PSAL so don't save it.
                /*
                 * var = ncFile.findVariable("prof_type");
                 * String prof_type = "";
                 * if (var == null) {
                 * nWarnings++;
                 * String2.log("WARNING: No prof_type in " +
                 * sourceFileName);
                 * } else {
                 * PrimitiveArray pa = NcHelper.getPrimitiveArray(var);
                 * if (pa instanceof StringArray && pa.size() > 0) {
                 * prof_type = pa.getString(0).trim();
                 * String2.log("prof_type=" + prof_type);
                 * } else {
                 * String2.
                 * log("WARNING: prof_type isn't a StringArray: " +
                 * pa.toString());
                 * }
                 * }
                 */

                // position quality flag
                var = ncFile.findVariable("position_quality_flag"); // was
                // "q_pos");
                if (var == null) {
                  nWarnings++;
                  String2.log("WARNING: No position_quality_flag in " + sourceFileName);
                } else {
                  PrimitiveArray q_pos = NcHelper.getPrimitiveArray(var);
                  if (!(q_pos instanceof IntArray) || q_pos.size() != 1)
                    throw new SimpleException("Invalid position_quality_flag=" + q_pos);
                  int ti = q_pos.getInt(0);
                  if (String2.indexOf(okQF, ti) < 0) {
                    nBadPos++;
                    continue;
                  }
                  // nGoodPos++; is below
                }

                // time quality flag
                var = ncFile.findVariable("time_quality_flag"); // q_date_time");
                if (var == null) {
                  nWarnings++;
                  String2.log("WARNING: No time_quality_flag in " + sourceFileName);
                } else {
                  PrimitiveArray q_date_time = NcHelper.getPrimitiveArray(var);
                  if (!(q_date_time instanceof IntArray) || q_date_time.size() != 1)
                    throw new SimpleException("Invalid time_quality_flag=" + q_date_time);
                  int ti = q_date_time.getInt(0);
                  if (String2.indexOf(okQF, ti) < 0) {
                    nBadTime++;
                    continue;
                  }
                  // nGoodTime is below
                }

                // time
                var = ncFile.findVariable("time");
                if (var == null) throw new SimpleException("No time!");
                tVarAtts.clear();
                NcHelper.getVariableAttributes(var, tVarAtts);
                tUnits = tVarAtts.getString("units");
                if (!timeUnits.equals(tUnits))
                  throw new SimpleException("Invalid time units=" + tUnits);
                PrimitiveArray time = NcHelper.getPrimitiveArray(var);
                if (!(time instanceof DoubleArray) || time.size() != 1)
                  throw new SimpleException("Invalid time=" + time);
                double tTime =
                    Calendar2.unitsSinceToEpochSeconds(
                        timeBaseAndFactor[0], timeBaseAndFactor[1], time.getDouble(0));
                if (tTime < minEpochSeconds || tTime > maxEpochSeconds)
                  throw new SimpleException(
                      "Invalid tTime=" + Calendar2.safeEpochSecondsToIsoStringTZ(tTime, ""));
                // original times (that I looked at) are to nearest
                // second
                // so round to nearest second (fix .99999 problems)
                tTime = Math.rint(tTime);
                nGoodTime++;

                // longitude (position qFlag is good)
                var = ncFile.findVariable("longitude");
                if (var == null) {
                  impossibleNanLon.add(key + " lon=null");
                  continue;
                }
                PrimitiveArray longitude = NcHelper.getPrimitiveArray(var);
                if (!(longitude instanceof FloatArray) || longitude.size() != 1) {
                  impossibleNanLon.add(key + " lon=wrongTypeOrSize");
                  continue;
                }
                float lon = longitude.getFloat(0);
                if (Float.isNaN(lon)) {
                  impossibleNanLon.add(key + " lon=NaN");
                  continue;
                } else if (lon < minLon) {
                  impossibleMinLon.add(key + " lon=" + lon);
                  // fall through
                } else if (lon > maxLon) {
                  impossibleMaxLon.add(key + " lon=" + lon);
                  // fall through
                }
                lon = (float) Math2.anglePM180(lon);

                // latitude (position qFlag is good)
                var = ncFile.findVariable("latitude");
                if (var == null) {
                  impossibleNanLat.add(key + " lat=null");
                  continue;
                }
                PrimitiveArray latitude = NcHelper.getPrimitiveArray(var);
                if (!(latitude instanceof FloatArray) || latitude.size() != 1) {
                  impossibleNanLat.add(key + " lat=wrongTypeOrSize");
                  continue;
                }
                float lat = latitude.getFloat(0);
                if (Float.isNaN(lat)) {
                  impossibleNanLat.add(key + " lat=NaN");
                  continue;
                } else if (lat < minLat) {
                  impossibleMinLat.add(key + " lat=" + lat);
                  continue;
                } else if (lat > maxLat) {
                  impossibleMaxLat.add(key + " lat=" + lat);
                  continue;
                }
                nGoodPos++;

                // depth
                var = ncFile.findVariable("z");
                if (var == null) throw new SimpleException("No z!");
                PrimitiveArray depth = NcHelper.getPrimitiveArray(var);
                if (!(depth instanceof FloatArray) || depth.size() == 0)
                  throw new SimpleException("Invalid z=" + depth);
                int nDepth = depth.size();
                tVarAtts.clear();
                NcHelper.getVariableAttributes(var, tVarAtts);
                depthFV = tVarAtts.getFloat("_FillValue");
                if (Float.isNaN(depthFV)) depthFV = depthMV;

                // DEPH_qparm
                var = ncFile.findVariable("z_variable_quality_flag"); // DEPH_qparm");
                if (var == null) throw new SimpleException("No z_variable_quality_flag!");
                PrimitiveArray DEPH_qparm = NcHelper.getPrimitiveArray(var);
                if (!(DEPH_qparm instanceof IntArray) || DEPH_qparm.size() != nDepth)
                  throw new SimpleException("Invalid z_variable_quality_flag=" + DEPH_qparm);
                // nGoodDepth is below

                // temperature
                var = ncFile.findVariable("temperature");
                PrimitiveArray temperature;
                PrimitiveArray TEMP_qparm;
                if (var == null) {
                  // nWarnings++;
                  // String2.log("WARNING: No temperature in " +
                  // sourceFileName); reasonably
                  // common
                  temperature = PrimitiveArray.factory(PAType.FLOAT, nDepth, "" + temperatureMV);
                  TEMP_qparm = PrimitiveArray.factory(PAType.INT, nDepth, "" + qMV);
                } else {
                  temperature = NcHelper.getPrimitiveArray(var);
                  if (!(temperature instanceof FloatArray) || temperature.size() != nDepth)
                    throw new SimpleException("Invalid temperature=" + temperature);

                  tVarAtts.clear();
                  NcHelper.getVariableAttributes(var, tVarAtts);
                  temperatureFV = tVarAtts.getFloat("_FillValue");
                  if (Float.isNaN(temperatureFV)) temperatureFV = temperatureMV;

                  // TEMP_qparm
                  var = ncFile.findVariable("temperature_quality_flag"); // TEMP_qparm");
                  if (var == null) {
                    nWarnings++;
                    String2.log("WARNING: No temperature_quality_flag in " + sourceFileName);
                    TEMP_qparm = PrimitiveArray.factory(PAType.INT, nDepth, "" + qMV);
                  } else {
                    TEMP_qparm = NcHelper.getPrimitiveArray(var);
                    if (!(TEMP_qparm instanceof IntArray) || TEMP_qparm.size() != nDepth)
                      throw new SimpleException("Invalid temperature_quality_flag=" + TEMP_qparm);
                  }
                }

                // salinity
                var = ncFile.findVariable("salinity");
                PrimitiveArray salinity;
                PrimitiveArray PSAL_qparm;
                if (var == null) {
                  // String2.log("WARNING: No salinity in " +
                  // sourceFileName); //very common
                  salinity = PrimitiveArray.factory(PAType.FLOAT, nDepth, "" + salinityMV);
                  PSAL_qparm = PrimitiveArray.factory(PAType.INT, nDepth, "" + qMV);
                } else {
                  salinity = NcHelper.getPrimitiveArray(var);
                  if (!(salinity instanceof FloatArray) || salinity.size() != nDepth)
                    throw new SimpleException("Invalid salinity=" + salinity);

                  tVarAtts.clear();
                  NcHelper.getVariableAttributes(var, tVarAtts);
                  salinityFV = tVarAtts.getFloat("_FillValue");
                  if (Float.isNaN(salinityFV)) salinityFV = salinityMV;

                  // PSAL_qparm
                  var = ncFile.findVariable("salinity_quality_flag"); // PSAL_qparm");
                  if (var == null) {
                    nWarnings++;
                    String2.log("WARNING: No salinity_quality_flag in " + sourceFileName);
                    PSAL_qparm = PrimitiveArray.factory(PAType.INT, nDepth, "" + qMV);
                  } else {
                    PSAL_qparm = NcHelper.getPrimitiveArray(var);
                    if (!(PSAL_qparm instanceof IntArray) || PSAL_qparm.size() != nDepth)
                      throw new SimpleException("Invalid salinity_quality_flag=" + PSAL_qparm);
                  }
                }

                // clean the data
                // (good to do it here so memory usage is low -- table
                // remains as small as
                // possible)
                // Change "impossible" data to NaN
                // (from
                // https://www.nodc.noaa.gov/GTSPP/document/qcmans/GTSPP_RT_QC_Manual_20090916.pdf
                // pg 61 has Table 2.1: Global Impossible Parameter
                // Values).
                BitSet keep = new BitSet();
                keep.set(0, nDepth); // all true

                // find worst impossible depth/temperature/salinity for
                // this station
                // boolean tImpossibleNanDepth = false;
                // boolean tImpossibleNanTemperature = false;
                // boolean tImpossibleNanSalinity = false;
                float tImpossibleMinDepth = minDepth;
                float tImpossibleMaxDepth = maxDepth;
                float tImpossibleMinTemperature = minTemperature;
                float tImpossibleMaxTemperature = maxTemperature;
                float tImpossibleMinSalinity = minSalinity;
                float tImpossibleMaxSalinity = maxSalinity;

                for (int row = 0; row < nDepth; row++) {

                  // DEPH_qparm
                  int qs = DEPH_qparm.getInt(row);
                  float f = depth.getFloat(row);
                  if (String2.indexOf(okQF, qs) < 0) {
                    nBadDepth++;
                    keep.clear(row);
                    continue;
                  } else if (Float.isNaN(f) || f == depthMV || f == depthFV) { // "impossible"
                    // depth
                    // tImpossibleNanDepth = true;
                    nBadDepth++;
                    keep.clear(row);
                    continue;
                  } else if (f < minDepth) {
                    tImpossibleMinDepth = Math.min(tImpossibleMinDepth, f);
                    nBadDepth++;
                    keep.clear(row);
                    continue;
                  } else if (f > maxDepth) {
                    tImpossibleMaxDepth = Math.max(tImpossibleMaxDepth, f);
                    nBadDepth++;
                    keep.clear(row);
                    continue;
                  }
                  nGoodDepth++;

                  boolean hasData = false;

                  // temperature
                  qs = TEMP_qparm.getInt(row);
                  f = temperature.getFloat(row);
                  if (String2.indexOf(okQF, qs) < 0) {
                    temperature.setString(row, ""); // so
                    // bad
                    // value
                    // is
                    // now
                    // NaN
                    nBadTemperature++;
                  } else if (Float.isNaN(f) || f == temperatureMV || f == temperatureFV) {
                    temperature.setString(row, ""); // so
                    // missing
                    // value
                    // is
                    // now
                    // NaN
                    nBadTemperature++;
                  } else if (f < minTemperature) { // "impossible"
                    // water
                    // temperature
                    tImpossibleMinTemperature = Math.min(tImpossibleMinTemperature, f);
                    temperature.setString(row, ""); // so
                    // impossible
                    // value
                    // is
                    // now
                    // NaN
                    nBadTemperature++;
                  } else if (f > maxTemperature) { // "impossible"
                    // water
                    // temperature
                    tImpossibleMaxTemperature = Math.max(tImpossibleMaxTemperature, f);
                    temperature.setString(row, ""); // so
                    // impossible
                    // value
                    // is
                    // now
                    // NaN
                    nBadTemperature++;
                  } else {
                    nGoodTemperature++;
                    hasData = true;
                  }

                  // salinity
                  qs = PSAL_qparm.getInt(row);
                  f = salinity.getFloat(row);
                  if (String2.indexOf(okQF, qs) < 0) {
                    salinity.setString(row, ""); // so bad
                    // value is
                    // now NaN
                    nBadSalinity++;
                  } else if (Float.isNaN(f) || f == salinityMV || f == salinityFV) {
                    salinity.setString(row, ""); // so
                    // missing
                    // value is
                    // now NaN
                    nBadSalinity++;
                  } else if (f < minSalinity) { // "impossible"
                    // salinity
                    tImpossibleMinSalinity = Math.min(tImpossibleMinSalinity, f);
                    salinity.setString(row, ""); // so
                    // impossible
                    // value is
                    // now NaN
                    nBadSalinity++;
                  } else if (f > maxSalinity) { // "impossible"
                    // salinity
                    tImpossibleMaxSalinity = Math.max(tImpossibleMaxSalinity, f);
                    salinity.setString(row, ""); // so
                    // impossible
                    // value is
                    // now NaN
                    nBadSalinity++;
                  } else {
                    nGoodSalinity++;
                    hasData = true;
                  }

                  // no valid temperature or salinity data?
                  if (!hasData) {
                    keep.clear(row);
                  }
                }

                // ensure sizes still correct
                Test.ensureEqual(depth.size(), nDepth, "depth.size changed!");
                Test.ensureEqual(temperature.size(), nDepth, "temperature.size changed!");
                Test.ensureEqual(salinity.size(), nDepth, "salinity.size changed!");

                // actually remove the bad rows
                int tnGood = keep.cardinality();
                if (testMode && EDDTableFromNcFiles.verbose)
                  String2.log(
                      sourceFileName + ": nGoodRows=" + tnGood + " nBadRows=" + (nDepth - tnGood));
                nGoodRows += tnGood;
                nBadRows += nDepth - tnGood;
                depth.justKeep(keep);
                temperature.justKeep(keep);
                salinity.justKeep(keep);
                nDepth = depth.size();

                // impossible
                // if (tImpossibleNanDepth)
                // impossibleNanDepth.add(key + " hasNaN=true");
                // if (tImpossibleNanTemperature)
                // impossibleNanTemperature.add(key + " hasNaN=true");
                // if (tImpossibleNanSalinity)
                // impossibleNanSalinity.add(key + " hasNaN=true");

                if (tImpossibleMinDepth < minDepth)
                  impossibleMinDepth.add(key + " worst = " + tImpossibleMinDepth);
                if (tImpossibleMaxDepth > maxDepth)
                  impossibleMaxDepth.add(key + " worst = " + tImpossibleMaxDepth);
                if (tImpossibleMinTemperature < minTemperature)
                  impossibleMinTemperature.add(key + " worst = " + tImpossibleMinTemperature);
                if (tImpossibleMaxTemperature > maxTemperature)
                  impossibleMaxTemperature.add(key + " worst = " + tImpossibleMaxTemperature);
                if (tImpossibleMinSalinity < minSalinity)
                  impossibleMinSalinity.add(key + " worst = " + tImpossibleMinSalinity);
                if (tImpossibleMaxSalinity > maxSalinity)
                  impossibleMaxSalinity.add(key + " worst = " + tImpossibleMaxSalinity);

                // which table
                if (tnGood == 0) continue;
                int loni =
                    Math2.roundToInt(
                        Math.floor((Math.min(lon, maxLon - 0.1f) - minLon) / chunkSize));
                int lati =
                    Math2.roundToInt(
                        Math.floor((Math.min(lat, maxLat - 0.1f) - minLat) / chunkSize));
                String outTableName =
                    (minLon + loni * chunkSize) + "E_" + (minLat + lati * chunkSize) + "N";
                // String2.replaceAll(cruise + "_" + organization +
                // dataType, ' ', '_'); //too
                // many: 3000+/month in 2011
                Table tTable = (Table) tableHashMap.get(outTableName);

                if (tTable == null) {

                  Attributes ncGlobalAtts = new Attributes();
                  NcHelper.getGroupAttributes(ncFile.getRootGroup(), ncGlobalAtts);
                  String tHistory = ncGlobalAtts.getString("history");
                  tHistory = tHistory != null && tHistory.length() > 0 ? tHistory + "\n" : "";

                  // make a table for this platform
                  tTable = new Table();
                  Attributes ga = tTable.globalAttributes();
                  String ack =
                      "These data were acquired from the US NOAA National Oceanographic Data Center (NODC) on "
                          + today
                          + " from https://www.nodc.noaa.gov/GTSPP/.";
                  ga.add("acknowledgment", ack);
                  ga.add(
                      "license",
                      "These data are openly available to the public.  "
                          + "Please acknowledge the use of these data with:\n"
                          + ack
                          + "\n\n"
                          + "[standard]");
                  ga.add(
                      "history",
                      tHistory
                          + ".tgz files from ftp.nodc.noaa.gov /pub/gtspp/best_nc/ (https://www.nodc.noaa.gov/GTSPP/)\n"
                          + today
                          + " Most recent ingest, clean, and reformat at ERD (erd.data at noaa.gov).");
                  ga.add("infoUrl", "https://www.nodc.noaa.gov/GTSPP/");
                  ga.add("institution", "NOAA NODC");
                  ga.add("title", "Global Temperature and Salinity Profile Programme (GTSPP) Data");

                  String attName = "gtspp_ConventionVersion";
                  String attValue = ncGlobalAtts.getString(attName);
                  if (attValue != null && attValue.length() > 0) ga.add(attName, attValue);

                  attName = "gtspp_program";
                  attValue = ncGlobalAtts.getString(attName);
                  if (attValue != null && attValue.length() > 0) ga.add(attName, attValue);

                  attName = "gtspp_programVersion";
                  attValue = ncGlobalAtts.getString(attName);
                  if (attValue != null && attValue.length() > 0) ga.add(attName, attValue);

                  attName = "gtspp_handbook_version";
                  attValue = ncGlobalAtts.getString(attName);
                  if (attValue != null && attValue.length() > 0) ga.add(attName, attValue);

                  organizationCol =
                      tTable.addColumn(
                          tTable.nColumns(), "org", new StringArray(), new Attributes());
                  platformCol =
                      tTable.addColumn(
                          tTable.nColumns(), "platform", new StringArray(), new Attributes());
                  dataTypeCol =
                      tTable.addColumn(
                          tTable.nColumns(), "type", new StringArray(), new Attributes());
                  cruiseCol =
                      tTable.addColumn(
                          tTable.nColumns(), "cruise", new StringArray(), new Attributes());
                  stationCol =
                      tTable.addColumn(
                          tTable.nColumns(), "station_id", new IntArray(), new Attributes());
                  longitudeCol =
                      tTable.addColumn(
                          tTable.nColumns(),
                          "longitude",
                          new FloatArray(),
                          new Attributes().add("units", EDV.LON_UNITS));
                  latitudeCol =
                      tTable.addColumn(
                          tTable.nColumns(),
                          "latitude",
                          new FloatArray(),
                          new Attributes().add("units", EDV.LAT_UNITS));
                  timeCol =
                      tTable.addColumn(
                          tTable.nColumns(),
                          "time",
                          new DoubleArray(),
                          new Attributes().add("units", EDV.TIME_UNITS));
                  depthCol =
                      tTable.addColumn(
                          tTable.nColumns(),
                          "depth",
                          new FloatArray(),
                          new Attributes().add("units", "m"));
                  temperatureCol =
                      tTable.addColumn(
                          tTable.nColumns(),
                          "temperature",
                          new FloatArray(),
                          new Attributes().add("units", "degree_C"));
                  salinityCol =
                      tTable.addColumn(
                          tTable.nColumns(),
                          "salinity",
                          new FloatArray(),
                          new Attributes().add("units", "1e-3")); // PSU
                  // changed
                  // to
                  // 1e-3
                  // with
                  // CF
                  // std
                  // names
                  // 25

                  tableHashMap.put(outTableName, tTable);
                }

                // put data in tTable
                int oNRows = tTable.nRows();
                ((StringArray) tTable.getColumn(organizationCol)).addN(nDepth, organization);
                ((StringArray) tTable.getColumn(platformCol)).addN(nDepth, platform);
                ((StringArray) tTable.getColumn(dataTypeCol)).addN(nDepth, dataType);
                ((StringArray) tTable.getColumn(cruiseCol)).addN(nDepth, cruise);
                ((IntArray) tTable.getColumn(stationCol)).addN(nDepth, station);
                ((FloatArray) tTable.getColumn(longitudeCol)).addN(nDepth, lon);
                ((FloatArray) tTable.getColumn(latitudeCol)).addN(nDepth, lat);
                ((DoubleArray) tTable.getColumn(timeCol)).addN(nDepth, tTime);
                ((FloatArray) tTable.getColumn(depthCol)).append(depth);
                ((FloatArray) tTable.getColumn(temperatureCol)).append(temperature);
                ((FloatArray) tTable.getColumn(salinityCol)).append(salinity);

                // ensure the table is valid (same size for each column)
                tTable.ensureValid();

              } catch (Throwable t) {
                nExceptions++;
                String2.log(
                    "ERROR while processing "
                        + sourceFileName
                        + "\n  "
                        + MustBe.throwableToString(t));
              } finally {
                // always close the ncFile
                if (ncFile != null) {
                  try {
                    ncFile.close();
                  } catch (Throwable t) {
                    String2.log(
                        "ERROR: unable to close "
                            + sourceFileName
                            + "\n"
                            + MustBe.getShortErrorMessage(t));
                  }
                  ncFile = null;
                }

                // always delete the ncFile
                File2.delete(tTempDir + sourceFileName);
              }
            }
          } catch (Throwable t8) {
            String msg = MustBe.throwableToString(t8);
            String2.log(msg);
            errors.append(msg);
          } finally {
            // close and delete the .tar
            tarIS.close();
            File2.delete(sourceTarName);
          }

          String2.log(
              "\n  time to read all "
                  + nSourceFileNames
                  + " files = "
                  + Calendar2.elapsedTimeString(System.currentTimeMillis() - fileReadTime));

          // end of region loop
          String2.log(
              "\nIn tgz="
                  + sourceTgzName
                  + "\n nExceptions=    "
                  + nExceptions
                  + "        nWarnings="
                  + nWarnings
                  + "\n nBadStation=    "
                  + nBadStation
                  + "        nGoodStation="
                  + nGoodStation
                  + "\n nBadPos=        "
                  + nBadPos
                  + "        nGoodPos="
                  + nGoodPos
                  + "\n nBadTime=       "
                  + nBadTime
                  + "        nGoodTime="
                  + nGoodTime
                  + "\n nBadDepth=      "
                  + nBadDepth
                  + "        nGoodDepth="
                  + nGoodDepth
                  + "\n nBadTemperature="
                  + nBadTemperature
                  + "        nGoodTemperature="
                  + nGoodTemperature
                  + "\n nBadSalinity=   "
                  + nBadSalinity
                  + "        nGoodSalinity="
                  + nGoodSalinity);
          totalNGoodStation += nGoodStation;
          totalNGoodPos += nGoodPos;
          totalNGoodTime += nGoodTime;
          totalNGoodDepth += nGoodDepth;
          totalNGoodTemperature += nGoodTemperature;
          totalNGoodSalinity += nGoodSalinity;
          totalNGoodRows += nGoodRows;
          totalNBadPos += nBadPos;
          totalNBadTime += nBadTime;
          totalNBadDepth += nBadDepth;
          totalNBadTemperature += nBadTemperature;
          totalNBadSalinity += nBadSalinity;
          totalNBadRows += nBadRows;
          totalNWarnings += nWarnings;
          totalNExceptions += nExceptions;
        } catch (Throwable t9) {
          String msg = MustBe.throwableToString(t9);
          String2.log(msg);
          errors.append(msg);
        }
      } // end of region loop

      // save by outTableName
      boolean filePrinted = false;
      Object keys[] = tableHashMap.keySet().toArray();
      int nKeys = keys.length;
      String2.log("\n*** saving nFiles=" + nKeys);
      for (int keyi = 0; keyi < nKeys; keyi++) {
        String key = keys[keyi].toString();
        Table tTable = (Table) tableHashMap.remove(key);
        if (tTable == null || tTable.nRows() == 0) {
          String2.log("Unexpected: no table for key=" + key);
          continue;
        }

        // sort by time, station, depth
        // depth matches the source files: from surface to deepest
        tTable.sort(new int[] {timeCol, stationCol, depthCol}, new boolean[] {true, true, true});

        // is this saving a small lat lon range?
        double stationStats[] = tTable.getColumn(stationCol).calculateStats();
        // double lonStats[] = tTable.getColumn(longitudeCol).calculateStats();
        // double latStats[] = tTable.getColumn(latitudeCol).calculateStats();
        // nLats++;
        // double latRange = latStats[PrimitiveArray.STATS_MAX] -
        // latStats[PrimitiveArray.STATS_MIN];
        // latSum += latRange;
        rowsSum += tTable.nRows();
        String2.log(
            "    stationRange="
                + Math2.roundToInt(
                    stationStats[PrimitiveArray.STATS_MAX] - stationStats[PrimitiveArray.STATS_MIN])
                +
                // " lonRange=" + Math2.roundToInt(lonStats[
                // PrimitiveArray.STATS_MAX] -
                // lonStats[ PrimitiveArray.STATS_MIN]) +
                // " latRange=" + Math2.roundToInt(latRange) +
                "  nRows="
                + tTable.nRows());

        // save it
        String tName = tDestDir + String2.encodeFileNameSafe(key);
        /*
         * if (lonStats[PrimitiveArray.STATS_MAX] > 45 &&
         * lonStats[PrimitiveArray.STATS_MIN] < -45) {
         *
         * //NO MORE: This happened with 1 file/cruise,
         * // but won't happen now with lon/lat tiles.
         * //crosses dateline (or widely across lon=0)? split into 2 files
         * Table ttTable = (Table)tTable.clone();
         * ttTable.oneStepApplyConstraint(0, "longitude", "<", "0");
         * ttTable.saveAsFlatNc(tName + "_W.nc", "row", false);
         * double lonStatsW[] = ttTable.getColumn(longitudeCol).calculateStats();
         * nLons++;
         * double lonRangeW = lonStatsW[PrimitiveArray.STATS_MAX] -
         * lonStatsW[PrimitiveArray.STATS_MIN];
         * lonSum += lonRangeW;
         *
         * ttTable = (Table)tTable.clone();
         * ttTable.oneStepApplyConstraint(0, "longitude", ">=", "0");
         * ttTable.saveAsFlatNc(tName + "_E.nc", "row", false);
         * double lonStatsE[] = ttTable.getColumn(longitudeCol).calculateStats();
         * nLons++;
         * double lonRangeE = lonStatsE[PrimitiveArray.STATS_MAX] -
         * lonStatsE[PrimitiveArray.STATS_MIN];
         * lonSum += lonRangeE;
         * String2.log("  westLonRange=" + Math2.roundToInt(lonRangeW) +
         * "  eastLonRange=" + Math2.roundToInt(lonRangeE));
         * } else
         */
        {
          // nLons++;
          nFiles++;

          // create trajectory variable: platform + cruise
          StringArray pl = (StringArray) tTable.getColumn("platform");
          StringArray cr = (StringArray) tTable.getColumn("cruise");
          StringArray or = (StringArray) tTable.getColumn("org");
          StringArray ty = (StringArray) tTable.getColumn("type");
          StringArray tr = new StringArray();
          int n = pl.size();
          for (int i = 0; i < n; i++) {
            pl.set(i, String2.whitespacesToSpace(pl.get(i)));
            cr.set(i, String2.whitespacesToSpace(cr.get(i)));
            or.set(i, String2.whitespacesToSpace(or.get(i)));
            ty.set(i, String2.whitespacesToSpace(ty.get(i)));
            tr.add(
                or.getString(i)
                    + "_"
                    + ty.getString(i)
                    + "_"
                    + pl.getString(i)
                    + "_"
                    + cr.getString(i));
          }
          tTable.addColumn(0, "trajectory", tr, new Attributes());

          tTable.saveAsFlatNc(
              tName + ".nc", "row", false); // convertToFakeMissingValues (keep mv's as NaNs)
        }

        // print a file
        if (testMode && !filePrinted) {
          filePrinted = true;
          String2.log(NcHelper.ncdump(tName, ""));
        }
      }
      String2.log(
          "\ncumulative nProfiles="
              + profilesSum
              + " nRows="
              + rowsSum
              + " mean nRows/file="
              + (rowsSum / Math.max(1, nFiles)));
      // if (nLats > 0)
      // String2.log( "cumulative nLats=" + nLats + " meanLatRange=" + (float)(latSum
      // / nLats));
      // if (nLons > 0) {
      // String2.log( "cumulative nLons=" + nLons + " meanLonRange=" + (float)(lonSum
      // / nLons));
      // String2.log("mean nRows per saved file = " + (rowsSum / nLons));
      // }

      // print list of impossible at end of year or end of run
      if (month == 12 || (year == lastYear && month == lastMonth)) {

        String2.log(
            "\n*** "
                + Calendar2.getCurrentISODateTimeStringLocalTZ()
                + " bobConsolidateGtsppTgz finished the chunk ending "
                + year
                + "-"
                + month
                + "\n"
                + "chunkTime="
                + Calendar2.elapsedTimeString(System.currentTimeMillis() - chunkTime));
        chunkTime = System.currentTimeMillis();

        // print impossible statistics
        String2.log(
            "\nCumulative number of stations with:\n"
                + "impossibleNanLon         = "
                + impossibleNanLon.size()
                + "\n"
                + "impossibleMinLon         = "
                + impossibleMinLon.size()
                + "\n"
                + "impossibleMaxLon         = "
                + impossibleMaxLon.size()
                + "\n"
                + "impossibleNanLat         = "
                + impossibleNanLat.size()
                + "\n"
                + "impossibleMinLat         = "
                + impossibleMinLat.size()
                + "\n"
                + "impossibleMaxLat         = "
                + impossibleMaxLat.size()
                + "\n"
                + "impossibleMinDepth       = "
                + impossibleMinDepth.size()
                + "\n"
                + "impossibleMaxDepth       = "
                + impossibleMaxDepth.size()
                + "\n"
                +
                // "impossibleLatLon = " + impossibleLatLon.size() + "\n" +
                "impossibleMinTemperature = "
                + impossibleMinTemperature.size()
                + "\n"
                + "impossibleMaxTemperature = "
                + impossibleMaxTemperature.size()
                + "\n"
                + "impossibleMinSalinity    = "
                + impossibleMinSalinity.size()
                + "\n"
                + "impossibleMaxSalinity    = "
                + impossibleMaxSalinity.size()
                + "\n");

        // lon
        String2.log(
            "\n*** "
                + impossibleNanLon.size()
                + " stations had invalid lon"
                + " and good pos quality flags ("
                + okQFCsv
                + ").");
        impossibleNanLon.sortIgnoreCase();
        String2.log(impossibleNanLon.toNewlineString());

        String2.log(
            "\n*** "
                + impossibleMinLon.size()
                + " stations had lon<"
                + minLon
                + " and good pos quality flags ("
                + okQFCsv
                + ").");
        impossibleMinLon.sortIgnoreCase();
        String2.log(impossibleMinLon.toNewlineString());

        String2.log(
            "\n*** "
                + impossibleMaxLon.size()
                + " stations had lon>"
                + maxLon
                + " and good pos quality flags ("
                + okQFCsv
                + ").");
        impossibleMaxLon.sortIgnoreCase();
        String2.log(impossibleMaxLon.toNewlineString());

        // lat
        String2.log(
            "\n*** "
                + impossibleNanLat.size()
                + " stations had invalid lat"
                + " and good pos quality flags ("
                + okQFCsv
                + ").");
        impossibleNanLat.sortIgnoreCase();
        String2.log(impossibleNanLat.toNewlineString());

        String2.log(
            "\n*** "
                + impossibleMinLat.size()
                + " stations had lat<"
                + minLat
                + " and good pos quality flags ("
                + okQFCsv
                + ").");
        impossibleMinLat.sortIgnoreCase();
        String2.log(impossibleMinLat.toNewlineString());

        String2.log(
            "\n*** "
                + impossibleMaxLat.size()
                + " stations had lat>"
                + maxLat
                + " and good pos quality flags ("
                + okQFCsv
                + ").");
        impossibleMaxLat.sortIgnoreCase();
        String2.log(impossibleMaxLat.toNewlineString());

        // depth
        String2.log(
            "\n*** "
                + impossibleMinDepth.size()
                + " stations had depth<"
                + minDepth
                + " and good depth quality flags ("
                + okQFCsv
                + ").");
        impossibleMinDepth.sortIgnoreCase();
        String2.log(impossibleMinDepth.toNewlineString());

        String2.log(
            "\n*** "
                + impossibleMaxDepth.size()
                + " stations had depth>"
                + maxDepth
                + " and good depth quality flags ("
                + okQFCsv
                + ").");
        impossibleMaxDepth.sortIgnoreCase();
        String2.log(impossibleMaxDepth.toNewlineString());

        // sa = impossibleLatLon.toArray();
        // Arrays.sort(sa);
        // String2.log("\n*** " + sa.length + " stations had impossible latitude or
        // longitude values" +
        // " and good q_pos quality flags.");
        // String2.log(String2.toNewlineString(sa));

        String2.log(
            "\n*** "
                + impossibleMinTemperature.size()
                + " stations had temperature<"
                + minTemperature
                + " and good temperature quality flags ("
                + okQFCsv
                + ").");
        impossibleMinTemperature.sortIgnoreCase();
        String2.log(impossibleMinTemperature.toNewlineString());

        String2.log(
            "\n*** "
                + impossibleMaxTemperature.size()
                + " stations had temperature>"
                + maxTemperature
                + " and good temperature quality flags ("
                + okQFCsv
                + ").");
        impossibleMaxTemperature.sortIgnoreCase();
        String2.log(impossibleMaxTemperature.toNewlineString());

        String2.log(
            "\n*** "
                + impossibleMinSalinity.size()
                + " stations had salinity<"
                + minSalinity
                + " and good salinity quality flags ("
                + okQFCsv
                + ").");
        impossibleMinSalinity.sortIgnoreCase();
        String2.log(impossibleMinSalinity.toNewlineString());

        String2.log(
            "\n*** "
                + impossibleMaxSalinity.size()
                + " stations had salinity>"
                + maxSalinity
                + " and good salinity quality flags ("
                + okQFCsv
                + ").");
        impossibleMaxSalinity.sortIgnoreCase();
        String2.log(impossibleMaxSalinity.toNewlineString());
      }

      // are we done?
      if (year == lastYear && month == lastMonth) break;

      // increment the month
      month++;
      if (month == 13) {
        year++;
        month = 1;
      }
    } // end of month/year loop

    String2.log(
        "\n*** bobConsolidateGtspp completely finished "
            + firstYear
            + "-"
            + firstMonth
            + " through "
            + lastYear
            + "-"
            + lastMonth);

    String2.log(
        "\n***"
            + "\ntotalNExceptions=    "
            + totalNExceptions
            + "        totalNWarnings=       "
            + totalNWarnings
            + "\ntotalNBadStation=    "
            + totalNBadStation
            + "        totalNGoodStation=    "
            + totalNGoodStation
            + "\ntotalNBadPos=        "
            + totalNBadPos
            + "        totalNGoodPos=        "
            + totalNGoodPos
            + "\ntotalNBadTime=       "
            + totalNBadTime
            + "        totalNGoodTime=       "
            + totalNGoodTime
            + "\ntotalNBadDepth=      "
            + totalNBadDepth
            + "        totalNGoodDepth=      "
            + totalNGoodDepth
            + "\ntotalNBadTemperature="
            + totalNBadTemperature
            + "        totalNGoodTemperature="
            + totalNGoodTemperature
            + "\ntotalNBadSalinity=   "
            + totalNBadSalinity
            + "        totalNGoodSalinity=   "
            + totalNGoodSalinity
            + "\ntotalNBadRows=       "
            + totalNBadRows
            + "        totalNGoodRows=       "
            + totalNGoodRows
            + "\nlogFile=F:/data/gtspp/log.txt"
            + "\n\n*** all finished time="
            + Calendar2.elapsedTimeString(System.currentTimeMillis() - elapsedTime));
    String2.log("\nERRORS=\n" + errors.toString());
    String2.returnLoggingToSystemOut();
  }

  /** Really one time: resort the gtspp files. */
  public static void resortGtspp() throws Throwable {

    String sourceDir = "c:/data/gtspp/bestNcConsolidated/";

    // get the names of all of the .nc files
    String names[] = RegexFilenameFilter.recursiveFullNameList(sourceDir, ".*.nc", false);
    int n = 1; // names.length;
    for (int i = 0; i < n; i++) {
      if (i % 100 == 0) String2.log("#" + i + " " + names[i]);

      // read
      Table table = new Table();
      table.readFlatNc(names[i], null, 0); // standardizeWhat=0

      // table.globalAttributes().set("history",
      // "(From .zip files from https://www.nodc.noaa.gov/GTSPP/)\n" +
      // "2010-06-16 Incremental ingest, clean, and reformat at ERD (erd.data at
      // noaa.gov).");

      // resort
      table.sort(
          new int[] {
            table.findColumnNumber("time"),
            table.findColumnNumber("station_id"),
            table.findColumnNumber("depth")
          },
          new boolean[] {true, true, true});

      // write
      String tName = String2.replaceAll(names[i], "bestNcConsolidated/", "bestNcConsolidated2/");
      File2.makeDirectory(File2.getDirectory(tName));
      table.saveAsFlatNc(tName, "row", false);

      // compare
      if (i == 0) {
        String ncdump1 = NcHelper.ncdump(names[i], "-h");
        String ncdump2 = NcHelper.ncdump(tName, "-h");
        Test.ensureEqual(ncdump1, ncdump2, "");

        String2.log("\n*** Old:\n" + NcHelper.ncdump(names[i], ""));
        String2.log("\n*** New:\n" + NcHelper.ncdump(tName, ""));
      }
    }
  }

  /**
   * This creates the /u00/data/points/gtspp/*.ncCF GTSPP files from the
   * /data/gtspp/bestNcConsolidated/... .nc GTSPP files by making calls to the testGtsppBest
   * dataset. This doesn't need/use localhost ERDDAP.
   *
   * @param firstYear e.g., 1990
   * @param firstMonth e.g., 1=January
   * @param lastYear e.g., 2014
   * @param lastMonth e.g., 1=January
   */
  public static void bobCreateGtsppNcCFFiles(
      int firstYear, int firstMonth, int lastYear, int lastMonth) throws Throwable {

    String2.log("*** bobCreateGtsppNcCFFiles");
    int language = 0;
    long time = System.currentTimeMillis();
    EDDTable eddTable = (EDDTable) EDDTableFromNcFiles.oneFromDatasetsXml(null, "erdGtsppBestNc");
    StringBuilder errors = new StringBuilder();
    for (int year = firstYear; year <= lastYear; year++) {
      int tFirstMonth = year == firstYear ? firstMonth : 1;
      int tLastMonth = year == lastYear ? lastMonth : 12;
      for (int month = tFirstMonth; month <= tLastMonth; month++) {
        try {
          String2.log("\n*** year=" + year + " month=" + month);
          String ym = year + String2.zeroPad("" + month, 2);
          String ydm = year + "-" + String2.zeroPad("" + month, 2);
          String zp1 = ydm + "-01";
          String zp16 = ydm + "-16";
          String zpNext = year + "-" + String2.zeroPad("" + (month + 1), 2) + "-01";
          // ? orderBy not very relevant, because .ncCF forces a storage order?
          String qa =
              "&time>=" + zp1 + "&time<" + zp16 + "&orderBy(\"trajectory,station_id,time,depth\")";
          String qb =
              "&time>="
                  + zp16
                  + "&time<"
                  + zpNext
                  + "&orderBy(\"trajectory,station_id,time,depth\")";
          String2.log(qa + "\n" + qb);
          try {
            eddTable.makeNewFileForDapQuery(
                language, null, null, qa, "/u00/data/points/gtsppNcCF/", ym + "a", ".ncCF");
          } catch (Exception e1) {
            String msg = "ERROR while creating " + ym + "a.ncCF :\n" + MustBe.throwableToString(e1);
            String2.log(msg);
            errors.append(msg);
          }
          try {
            eddTable.makeNewFileForDapQuery(
                language, null, null, qb, "/u00/data/points/gtsppNcCF/", ym + "b", ".ncCF");
          } catch (Exception e2) {
            String msg = "ERROR while creating " + ym + "b.ncCF :\n" + MustBe.throwableToString(e2);
            String2.log(msg);
            errors.append(msg);
          }
        } catch (Exception e) {
          String2.log(MustBe.throwableToString(e));
        }
      }
    }
    if (errors.length() > 0) String2.log("errors:\n" + errors);
    String2.log(
        "bobCreateGtsppNcCFFiles finished successfully in "
            + Calendar2.elapsedTimeString(System.currentTimeMillis() - time));
  }

  /** one time(?) test for Bob */
  public static void bobFindGtsppDuplicateCruises() throws Throwable {
    int language = 0;
    EDDTable eddTable = (EDDTable) EDDTableFromNcFiles.oneFromDatasetsXml(null, "testErdGtsppBest");
    eddTable.makeNewFileForDapQuery(
        language,
        null,
        null,
        "cruise,type,org,platform&orderBy(\"cruise,type,org,platform\")&distinct()",
        "/temp/",
        "gtsppDuplicates",
        ".nc");
    Table table = new Table();
    table.readFlatNc("/temp/gtsppDuplicates.nc", null, 0); // standardizeWhat=0
    int n = table.nRows();
    BitSet keep = new BitSet(n); // all false
    PrimitiveArray cr = table.getColumn(0);
    PrimitiveArray ty = table.getColumn(1);
    PrimitiveArray or = table.getColumn(2);
    String2.log("nRows=" + n);
    for (int row = 1; row < n; row++) { // look back
      if (cr.getString(row - 1).equals(cr.getString(row))
          && ty.getString(row - 1).equals(ty.getString(row))
          && or.getString(row - 1).equals(or.getString(row))) {
        keep.set(row - 1);
        keep.set(row);
      }
    }
    table.justKeep(keep);
    String2.log("nRows=" + table.nRows());
    String2.log(table.toString());
  }
}
